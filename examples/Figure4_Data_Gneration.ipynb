{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from LDGD.model import ARDRBFKernel, LDGD\n",
    "from LDGD.model.experimental.GP_scratch import bGPLVM\n",
    "from LDGD.visualization import plot_box_plots\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.io import savemat, loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import winsound\n",
    "\n",
    "from LDGD.visualization.vizualize_utils import plot_heatmap, plot_2d_scatter, plot_ARD_gplvm\n",
    "from LDGD.visualization.vizualize_utils import plot_loss_gplvm, plot_scatter_gplvm, plot_box_plots\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T19:50:41.483707300Z",
     "start_time": "2024-02-27T19:50:40.571935Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T19:50:41.606222500Z",
     "start_time": "2024-02-27T19:50:41.481712100Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "def train_model(data_cont, data_cat, settings, filename):\n",
    "    num_points, data_dim = data_cont.shape\n",
    "    batch_shape = torch.Size([data_dim])\n",
    "    settings['use_gpytorch'] = True\n",
    "    if settings['use_gpytorch'] is False:\n",
    "        kernel_cls = ARDRBFKernel(input_dim=settings['latent_dim'])\n",
    "        kernel_reg = ARDRBFKernel(input_dim=settings['latent_dim'])\n",
    "    else:\n",
    "        kernel_reg = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=settings['latent_dim']))\n",
    "        kernel_cls = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=settings['latent_dim']))\n",
    "\n",
    "    likelihood_reg = GaussianLikelihood(batch_shape=batch_shape)\n",
    "    likelihood_cls = BernoulliLikelihood()\n",
    "\n",
    "\n",
    "    if settings['load_model'] is True:\n",
    "        with open(f'./saved_models/fig3_ldgd_{filename}_settings.json', 'r') as file:\n",
    "            settings = json.load(file)\n",
    "        model = LDGD(data_cont,\n",
    "                kernel_reg=kernel_reg,\n",
    "                kernel_cls=kernel_cls,\n",
    "                num_classes=data_cat.shape[-1],\n",
    "                num_inducing_points_cls=settings['num_inducing_points_cls'],\n",
    "                num_inducing_points_reg=settings['num_inducing_points_reg'],\n",
    "                latent_dim=settings['latent_dim'],\n",
    "                likelihood_reg=likelihood_reg,\n",
    "                likelihood_cls=likelihood_cls,\n",
    "                use_gpytorch=settings['use_gpytorch'],\n",
    "                shared_inducing_points=settings['shared_inducing_points'],\n",
    "                x_init=settings['x_init'])\n",
    "        model.load_weights(path_save='./saved_models/', file_name=f\"fig3_ldgd_{filename}.pth\")\n",
    "        history_train = model.history_train\n",
    "        losses = model.history_train['elbo_loss']\n",
    "    else:\n",
    "        model = LDGD(data_cont,\n",
    "                kernel_reg=kernel_reg,\n",
    "                kernel_cls=kernel_cls,\n",
    "                num_classes=data_cat.shape[-1],\n",
    "                num_inducing_points_cls=settings['num_inducing_points_cls'],\n",
    "                num_inducing_points_reg=settings['num_inducing_points_reg'],\n",
    "                latent_dim=settings['latent_dim'],\n",
    "                likelihood_reg=likelihood_reg,\n",
    "                likelihood_cls=likelihood_cls,\n",
    "                use_gpytorch=settings['use_gpytorch'],\n",
    "                shared_inducing_points=settings['shared_inducing_points'],\n",
    "                x_init=settings['x_init'])\n",
    "\n",
    "        losses, history_train = model.train_model(yn=data_cont,\n",
    "                                                  ys=data_cat,\n",
    "                                                  epochs=settings['num_epochs_train'],\n",
    "                                                  batch_size=settings['batch_size'])\n",
    "\n",
    "        if settings['save_model'] is True:\n",
    "            model.save_wights(path_save='./saved_models/', file_name=f\"fig3_ldgd_{filename}\")\n",
    "        with open(f'./saved_models/fig3_ldgd_{filename}_settings.json', 'w') as f:\n",
    "            json.dump(settings, f)\n",
    "    return model, losses, history_train, model_settings\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T19:50:41.733741700Z",
     "start_time": "2024-02-27T19:50:41.613708300Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load MNIST dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def create_dataset(random_state, test_size, dataset='mnist', **kwargs):\n",
    "    if dataset == 'mnist':\n",
    "        mnist_train = MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "        mnist_test = MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "        # Flatten the images and convert labels\n",
    "        x_train = mnist_train.data.view(mnist_train.data.size(0), -1).numpy()\n",
    "        x_train = x_train/x_train.max()\n",
    "        y_train = mnist_train.targets.numpy()\n",
    "\n",
    "        # Concatenate train and test sets to split them later\n",
    "        x_test = mnist_test.data.view(mnist_test.data.size(0), -1).numpy()\n",
    "        x_test = x_test/x_test.max()\n",
    "        y_test = mnist_test.targets.numpy()\n",
    "\n",
    "        # One-hot encode the labels\n",
    "        y_one_hot_train = np.zeros((y_train.shape[0], len(np.unique(y_train))))\n",
    "        y_one_hot_train[np.arange(y_train.shape[0]), y_train] = 1\n",
    "\n",
    "        y_one_hot_test = np.zeros((y_test.shape[0], len(np.unique(y_test))))\n",
    "        y_one_hot_test[np.arange(y_test.shape[0]), y_test] = 1\n",
    "\n",
    "        orig_data = None  # No original data in the case of MNIST\n",
    "\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_one_hot_train, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_one_hot_test, dtype=torch.float32)\n",
    "    y_train_labels_tensor = torch.tensor(y_train)\n",
    "    y_test_labels_tensor = torch.tensor(y_test)\n",
    "\n",
    "    return X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, y_train_labels_tensor, y_test_labels_tensor, orig_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T19:55:11.936202700Z",
     "start_time": "2024-02-27T19:55:11.824196100Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Oil dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_data_oil = np.load('../data/train_data.npy', allow_pickle=True)\n",
    "test_data_oil = np.load('../data/test_data.npy', allow_pickle=True)\n",
    "\n",
    "yn_train_oil, ys_train_oil, labels_train_oil = train_data_oil.take(0)['yn_train'], train_data_oil.take(0)['ys_train'], train_data_oil.take(0)['labels_train']\n",
    "yn_test_oil, ys_test_oil, labels_test_oil = test_data_oil.take(0)['yn_test'], test_data_oil.take(0)['ys_test'], test_data_oil.take(0)['labels_test']\n",
    "\n",
    "yn_train_oil, ys_train_oil, labels_train_oil = torch.Tensor(yn_train_oil), torch.Tensor(ys_train_oil), torch.Tensor(labels_train_oil)\n",
    "yn_test_oil, ys_test_oil, labels_test_oil = torch.Tensor(yn_test_oil), torch.Tensor(ys_test_oil), torch.Tensor(labels_test_oil)\n",
    "\n",
    "print(f\"Train size : {yn_train_oil.shape[0]} Test size : {yn_test_oil.shape[0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:06:55.338595700Z",
     "start_time": "2024-02-27T02:06:55.197977400Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load IRIS dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_data_iris = np.load('../data/train_data_iris.npy', allow_pickle=True)\n",
    "test_data_iris = np.load('../data/test_data_iris.npy', allow_pickle=True)\n",
    "\n",
    "yn_train_iris, ys_train_iris, labels_train_iris = train_data_iris.take(0)['yn_train'], train_data_iris.take(0)['ys_train'], train_data_iris.take(0)['labels_train']\n",
    "yn_test_iris, ys_test_iris, labels_test_iris = test_data_iris.take(0)['yn_test'], test_data_iris.take(0)['ys_test'], test_data_iris.take(0)['labels_test']\n",
    "\n",
    "yn_train_iris, ys_train_iris, labels_train_iris = torch.Tensor(yn_train_iris), torch.Tensor(ys_train_iris), torch.Tensor(labels_train_iris)\n",
    "yn_test_iris, ys_test_iris, labels_test_iris = torch.Tensor(yn_test_iris), torch.Tensor(ys_test_iris), torch.Tensor(labels_test_iris)\n",
    "\n",
    "print(f\"Train size : {yn_train_iris.shape[0]} Test size : {yn_test_iris.shape[0]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:06:55.479672400Z",
     "start_time": "2024-02-27T02:06:55.338595700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 4: Reconstruction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "model_settings = {\n",
    "    'latent_dim': 2,\n",
    "    'num_inducing_points_reg': 30,\n",
    "    'num_inducing_points_cls': 30,\n",
    "    'num_epochs_train': 5000,\n",
    "    'num_epochs_test': 5000,\n",
    "    'batch_size': 100,\n",
    "    'load_trained_model': False,\n",
    "    'load_tested_model': False,\n",
    "    'use_gpytorch': True,\n",
    "    'n_features': 10,\n",
    "    'save_model': True,\n",
    "    'load_model':True,\n",
    "    'x_init': 'pca',\n",
    "    'shared_inducing_points': False\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:53:16.314571800Z",
     "start_time": "2024-02-27T02:53:16.153837Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model_oil, losses_oil, history_train_oil, model_settings = train_model(data_cont = yn_train_oil,\n",
    "                                                                       data_cat = ys_train_oil,\n",
    "                                                                       settings = model_settings,\n",
    "                                                                       filename = 'oil_2d')\n",
    "winsound.Beep(freq, duration*3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:53:20.141256800Z",
     "start_time": "2024-02-27T02:53:16.973925300Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "predictions_oil, metrics_oil, history_test = model_oil.evaluate(yn_test=yn_test_oil, ys_test=labels_test_oil, epochs=5000)\n",
    "\n",
    "alpha_reg_oil = 1 / model_oil.kernel_reg.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "alpha_cls_oil = 1 / model_oil.kernel_cls.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "\n",
    "x_oil = model_oil.x.q_mu.cpu().detach().numpy()\n",
    "std_oil = torch.nn.functional.softplus(model_oil.x.q_log_sigma).cpu().detach().numpy()\n",
    "\n",
    "x_test_oil = model_oil.x_test.q_mu.cpu().detach().numpy()\n",
    "std_test_oil = torch.nn.functional.softplus(model_oil.x_test.q_log_sigma).cpu().detach().numpy()\n",
    "winsound.Beep(freq, duration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:54:57.316120500Z",
     "start_time": "2024-02-27T02:53:21.166413700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "latent_dim = x_oil.shape[-1]\n",
    "values, indices = torch.topk(torch.tensor(alpha_cls_oil), k=2, largest=True)\n",
    "l1 = indices.numpy().flatten()[0]\n",
    "l2 = indices.numpy().flatten()[1]\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(32, 8))\n",
    "\n",
    "\n",
    "plot_loss_gplvm(losses_oil, ax=axs[0])\n",
    "plot_ARD_gplvm(latent_dim, alpha_cls_oil, ax=axs[2])\n",
    "plot_ARD_gplvm(latent_dim, alpha_reg_oil, ax=axs[1])\n",
    "plot_scatter_gplvm(x_oil, labels_train_oil, l1=l1, l2=l2, ax=axs[3], colors=['r', 'b', 'g'], show_errorbars=True, std=std_oil)\n",
    "plot_scatter_gplvm(x_test_oil, labels_test_oil, l1=l1, l2=l2, ax=axs[4], colors=['r', 'b', 'g'], show_errorbars=True, std=std_test_oil)\n",
    "plt.tight_layout()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:54:58.174326300Z",
     "start_time": "2024-02-27T02:54:57.316120500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "test_point = torch.tensor([[3,3], [0, 0], [-2,-2]])\n",
    "\n",
    "test_point_reconstructed, predictions_std = model_oil.regress_x(test_point)\n",
    "plot_scatter_gplvm(x_oil, labels_train_oil, l1=l1, l2=l2, ax=ax, colors=['r', 'b', 'g'], show_errorbars=True, std=std_oil)\n",
    "ax.scatter(test_point[0,0], test_point[0,1], marker='X', color='green', s=400, alpha=1, edgecolor='black', linewidth=2)\n",
    "ax.scatter(test_point[1,0], test_point[1,1], marker='X', color='red', s=400, alpha=1, edgecolor='black', linewidth=2)\n",
    "ax.scatter(test_point[2,0], test_point[2,1], marker='X', color='blue', s=400, alpha=1, edgecolor='black', linewidth=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./saved_results/figure4_oil_latent_scatter_with_test_point.png\", bbox_inches='tight')\n",
    "plt.savefig(\"./saved_results/figure4_oil_latent_scatter_with_test_point.svg\", bbox_inches='tight')\n",
    "\n",
    "plot_box_plots(data=yn_train_oil, labels=labels_train_oil, save_path='saved_results/',\n",
    "               file_name='box_plot_oil_with_point', new_point_values=test_point_reconstructed.cpu().detach(),\n",
    "               new_point_label=[2, 0, 1], marker='X')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./saved_results/figure4_oil_barplot_with_test_point.png\")\n",
    "plt.savefig(\"./saved_results/figure4_oil_barplot_with_test_point.svg\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T05:54:27.303503300Z",
     "start_time": "2024-02-27T05:54:21.530739700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "model_iris, losses_iris, history_train_iris, model_settings = train_model(data_cont = yn_train_iris,\n",
    "                                                                       data_cat = ys_train_iris,\n",
    "                                                                       settings = model_settings,\n",
    "                                                                       filename = 'iris_2d')\n",
    "winsound.Beep(freq, duration*3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:55:05.628796700Z",
     "start_time": "2024-02-27T02:55:02.472795800Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "predictions_iris, metrics_iris, history_test = model_iris.evaluate(yn_test=yn_test_iris, ys_test=labels_test_iris, epochs=2000)\n",
    "\n",
    "alpha_reg_iris = 1 / model_iris.kernel_reg.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "alpha_cls_iris = 1 / model_iris.kernel_cls.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "\n",
    "x_iris = model_iris.x.q_mu.cpu().detach().numpy()\n",
    "std_iris = torch.nn.functional.softplus(model_iris.x.q_log_sigma).cpu().detach().numpy()\n",
    "\n",
    "x_test_iris = model_iris.x_test.q_mu.cpu().detach().numpy()\n",
    "std_test_iris = torch.nn.functional.softplus(model_iris.x_test.q_log_sigma).cpu().detach().numpy()\n",
    "winsound.Beep(freq, duration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:55:47.248075600Z",
     "start_time": "2024-02-27T02:55:05.628796700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "latent_dim = x_iris.shape[-1]\n",
    "values, indices = torch.topk(torch.tensor(alpha_cls_iris), k=2, largest=True)\n",
    "l1 = indices.numpy().flatten()[0]\n",
    "l2 = indices.numpy().flatten()[1]\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(32, 8))\n",
    "\n",
    "\n",
    "plot_loss_gplvm(losses_iris, ax=axs[0])\n",
    "plot_ARD_gplvm(latent_dim, alpha_cls_iris, ax=axs[2])\n",
    "plot_ARD_gplvm(latent_dim, alpha_reg_iris, ax=axs[1])\n",
    "plot_scatter_gplvm(x_iris, labels_train_iris, l1=l1, l2=l2, ax=axs[3], colors=['r', 'b', 'g'], show_errorbars=True, std=std_iris)\n",
    "plot_scatter_gplvm(x_test_iris, labels_test_iris, l1=l1, l2=l2, ax=axs[4], colors=['r', 'b', 'g'], show_errorbars=True, std=std_test_iris)\n",
    "plt.tight_layout()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:55:48.047730100Z",
     "start_time": "2024-02-27T02:55:47.248075600Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "test_point = torch.tensor([[1,1.7], [-2, 0], [0,-1]])\n",
    "\n",
    "test_point_reconstructed, predictions_std = model_iris.regress_x(test_point)\n",
    "plot_scatter_gplvm(x_iris, labels_train_iris, l1=l1, l2=l2, ax=ax, colors=['r', 'b', 'g'], show_errorbars=True, std=std_iris)\n",
    "ax.scatter(test_point[0,0], test_point[0,1], marker='X', color='green', s=400, alpha=1, edgecolor='black', linewidth=2)\n",
    "ax.scatter(test_point[1,0], test_point[1,1], marker='X', color='red', s=400, alpha=1, edgecolor='black', linewidth=2)\n",
    "ax.scatter(test_point[2,0], test_point[2,1], marker='X', color='blue', s=400, alpha=1, edgecolor='black', linewidth=2)\n",
    "plt.grid('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./saved_results/fig4_iris_latent_scatter_with_test_point.png\", bbox_inches='tight')\n",
    "plt.savefig(\"./saved_results/fig4_iris_latent_scatter_with_test_point.svg\", bbox_inches='tight')\n",
    "\n",
    "plot_box_plots(data=yn_train_iris, labels=labels_train_iris, save_path='saved_results/', file_name='box_plot_iris_with_point', new_point_values=test_point_reconstructed.cpu().detach(), new_point_label=[2, 0, 1], marker='X')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./saved_results/fig4_iris_barplot_with_test_point.png\")\n",
    "plt.savefig(\"./saved_results/fig4_iris_barplot_with_test_point.svg\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T05:41:33.632254300Z",
     "start_time": "2024-02-27T05:41:31.631608700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "model_settings = {\n",
    "    'latent_dim': 10,\n",
    "    'num_inducing_points_reg': 150,\n",
    "    'num_inducing_points_cls': 150,\n",
    "    'num_epochs_train': 20000,\n",
    "    'num_epochs_test': 20000,\n",
    "    'batch_size': 700,\n",
    "    'load_trained_model': False,\n",
    "    'load_tested_model': False,\n",
    "    'shared_inducing_points': False,\n",
    "    'use_gpytorch': True,\n",
    "    'random_state': 65,\n",
    "    'test_size': 0.2,\n",
    "    'cls_weight': 1.0,\n",
    "    'reg_weight': 1.0,\n",
    "    'num_samples': 500,\n",
    "\n",
    "}\n",
    "np.random.seed(model_settings['random_state'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T19:52:03.473992200Z",
     "start_time": "2024-02-27T19:52:03.359832300Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# load raw data\n",
    "yn_train, yn_test, ys_train, ys_test, labels_train, labels_test, _ = create_dataset(random_state=model_settings['random_state'], test_size=0.2, dataset='mnist')\n",
    "yn_train = yn_train/yn_train.max()\n",
    "yn_test = yn_test/yn_test.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T19:55:17.363093Z",
     "start_time": "2024-02-27T19:55:16.892014700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "load_saved_result = True\n",
    "batch_shape = torch.Size([yn_train.shape[-1]])\n",
    "metric_fastldgd_list = []\n",
    "model_mnist, losses_mnist, history_train_mnist, model_settings = train_model(data_cont = yn_train_iris,\n",
    "                                                                           data_cat = ys_train_iris,\n",
    "                                                                           settings = model_settings,\n",
    "                                                                           filename = 'mnist')\n",
    "winsound.Beep(freq, duration*3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T19:56:47.037536Z",
     "start_time": "2024-02-27T19:56:46.905841400Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions, metrics, history_test = model.evaluate(yn_test=yn_test, ys_test=labels_test,\n",
    "                                                    epochs=model_settings['num_epochs_test'])\n",
    "winsound.Beep(freq, duration*3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
