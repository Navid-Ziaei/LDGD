{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import torch\n",
    "import winsound\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from LDGD.model import LDGD, FastLDGD, VAE\n",
    "from LDGD.visualization.vizualize_utils import plot_heatmap, plot_2d_scatter, plot_ARD_gplvm\n",
    "from LDGD.visualization.vizualize_utils import plot_loss_gplvm, plot_scatter_gplvm, plot_box_plots\n",
    "from LDGD.data.data_loader import generate_data\n",
    "\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "\n",
    "from LDGD.utils import dicts_to_dict_of_lists\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T02:07:23.667745800Z",
     "start_time": "2024-04-26T02:07:17.645526500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compare_decoding_on_dataset.ipynb# Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1- Create Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def create_dataset(num_dimension, random_state, test_size, **kwargs):\n",
    "    # Extract parameters for synthetic data generation\n",
    "    pattern = kwargs.get('pattern', 'moon')  # default pattern\n",
    "    n_samples = kwargs.get('n_samples', 1500)\n",
    "    noise = kwargs.get('noise', 0.1)\n",
    "    increase_method = kwargs.get('increase_method', 'linear')\n",
    "\n",
    "    X, y, orig_data = generate_data(pattern, n_samples, noise, num_dimension, increase_method, random_state=random_state)\n",
    "    # One-hot encode the labels\n",
    "    y_one_hot = np.zeros((y.shape[0], len(np.unique(y))))\n",
    "    y_one_hot[np.arange(y.shape[0]), np.uint(y)] = 1\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test, y_train_labels, y_test_labels = train_test_split(X, y_one_hot, y,\n",
    "                                                                                       test_size=test_size,\n",
    "                                                                                       random_state=random_state)\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "    y_train_labels_tensor = torch.tensor(y_train_labels)\n",
    "    y_test_labels_tensor = torch.tensor(y_test_labels)\n",
    "\n",
    "    return X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, y_train_labels_tensor, y_test_labels_tensor, orig_data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T02:07:23.820913500Z",
     "start_time": "2024-04-26T02:07:23.667745800Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 - Create Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def create_LDGD_model(data_cont, data_cat, ldgd_settings, batch_shape, x_init='pca'):\n",
    "    kernel_reg = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=ldgd_settings['latent_dim']))\n",
    "    kernel_cls = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=ldgd_settings['latent_dim']))\n",
    "\n",
    "    likelihood_reg = GaussianLikelihood(batch_shape=batch_shape)\n",
    "    likelihood_cls = BernoulliLikelihood()\n",
    "    model = LDGD(data_cont,\n",
    "                 kernel_reg=kernel_reg,\n",
    "                 kernel_cls=kernel_cls,\n",
    "                 num_classes=data_cat.shape[-1],\n",
    "                 latent_dim=ldgd_settings['latent_dim'],\n",
    "                 num_inducing_points_cls=ldgd_settings['num_inducing_points_cls'],\n",
    "                 num_inducing_points_reg=ldgd_settings['num_inducing_points_reg'],\n",
    "                 likelihood_reg=likelihood_reg,\n",
    "                 likelihood_cls=likelihood_cls,\n",
    "                 use_gpytorch=ldgd_settings['use_gpytorch'],\n",
    "                 shared_inducing_points=ldgd_settings['shared_inducing_points'],\n",
    "                 use_shared_kernel=False,\n",
    "                 x_init=x_init,\n",
    "                 device=device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_FastLDGD_model(data_cont, data_cat, ldgd_settings, batch_shape):\n",
    "    kernel_reg = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=ldgd_settings['latent_dim']))\n",
    "    kernel_cls = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=ldgd_settings['latent_dim']))\n",
    "\n",
    "    likelihood_reg = GaussianLikelihood(batch_shape=batch_shape)\n",
    "    likelihood_cls = BernoulliLikelihood()\n",
    "    model = FastLDGD(data_cont,\n",
    "             kernel_reg=kernel_reg,\n",
    "             kernel_cls=kernel_cls,\n",
    "             num_classes=data_cat.shape[-1],\n",
    "             latent_dim=ldgd_settings['latent_dim'],\n",
    "             num_inducing_points_cls= ldgd_settings['num_inducing_points_cls'],\n",
    "             num_inducing_points_reg= ldgd_settings['num_inducing_points_reg'],\n",
    "             likelihood_reg=likelihood_reg,\n",
    "             likelihood_cls=likelihood_cls,\n",
    "             use_gpytorch=ldgd_settings['use_gpytorch'],\n",
    "             shared_inducing_points=ldgd_settings['shared_inducing_points'],\n",
    "             use_shared_kernel=False,\n",
    "             device=device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T02:07:23.992936900Z",
     "start_time": "2024-04-26T02:07:23.820913500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "# Assuming X, y are numpy arrays\n",
    "def cross_validate_model(n_dim, settings, n_splits=5, load_saved_result=False, save_model=True, **kwargs):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=model_settings['random_state'])\n",
    "\n",
    "    performances = []\n",
    "\n",
    "    for n_dim in n_dim:\n",
    "        # Code to generate data for different dimensional synthetic datasets\n",
    "        pattern = kwargs.get('pattern', 'moon')  # default pattern\n",
    "        n_samples = kwargs.get('n_samples', 1500)\n",
    "        noise = kwargs.get('noise', 0.1)\n",
    "        increase_method = kwargs.get('increase_method', 'linear')\n",
    "\n",
    "        X, y, orig_data = generate_data(pattern, n_samples, noise, n_dim, increase_method,\n",
    "                                        random_state=model_settings['random_state'])\n",
    "        # One-hot encode the labels\n",
    "        y_one_hot = np.zeros((y.shape[0], len(np.unique(y))))\n",
    "        y_one_hot[np.arange(y.shape[0]), np.uint(y)] = 1\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        labels = torch.tensor(y, dtype=torch.float32)\n",
    "        y = torch.tensor(y_one_hot)\n",
    "\n",
    "\n",
    "        p, r, f = [], [], []\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(kfold.split(X, labels)):\n",
    "            print(f\"=============== Dim {n_dim} Fold {fold_idx} ===============\")\n",
    "            # \"X[train_ix]\" will have to be modified to extract the relevant synthetic rows\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            labels_train, labels_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "            # Here you convert to PyTorch tensors, etc., and pass into your network\n",
    "            # metrics = train_and_evaluate_model() assuming it returns a dict or other\n",
    "            # performance data. Replace with the appropiate flow of your process.\n",
    "            settings['data_dim'] = X_train.shape[-1]\n",
    "            batch_shape = torch.Size([settings['data_dim']])\n",
    "            if load_saved_result is False:\n",
    "                model = create_LDGD_model(X_train, y_train, settings, batch_shape=batch_shape, x_init='pca')\n",
    "                losses, history_train = model.train_model(yn=X_train, ys=y_train,\n",
    "                                                          epochs=settings['num_epochs_train'],\n",
    "                                                          batch_size=settings['batch_size'],\n",
    "                                                          verbos=0)\n",
    "                if save_model is True:\n",
    "                    model.save_wights(path_save='./saved_models/', file_name=f\"model_synthetic_fold{fold_idx}_synthetic{2*n_dim}\")\n",
    "                predictions, metrics, history_test = model.evaluate(yn_test=X_test, ys_test=labels_test,\n",
    "                                                                    epochs=settings['num_epochs_test'],\n",
    "                                                                    verbos=0)\n",
    "\n",
    "                winsound.Beep(freq, duration)\n",
    "            else:\n",
    "                model = create_LDGD_model(X_train, y_train, settings)\n",
    "                model.load_weights(path_save='./saved_models/', file_name=f'model_synthetic_fold{fold_idx}_synthetic{2*n_dim}.pth')\n",
    "                predictions, metrics, history_test = model.evaluate(yn_test=X_test, ys_test=labels_test,\n",
    "                                                                    epochs=settings['num_epochs_test'],\n",
    "                                                                    verbos=0)\n",
    "\n",
    "            # Compute or accumulate measures (precision, recall, F1 score)\n",
    "            p.append(metrics['precision'])\n",
    "            r.append(metrics['recall'])\n",
    "            f.append(metrics['f1_score'])\n",
    "\n",
    "        # Form the list of dataframe rows for the round of n_dim rounds\n",
    "        measures = (np.mean(p), np.std(p), np.mean(r), np.std(r), np.mean(f), np.std(f))\n",
    "        round_result = {\"dataset\": f\"synthetic {2*n_dim}\", \"precision\": f\"{measures[0]:.2f} ± {measures[1]:.2f}\",\n",
    "                        \"recall\": f\"{measures[2]:.2f} ± {measures[3]:.2f}\",\n",
    "                        \"f score\": f\"{measures[4]:.2f} ± {measures[5]:.2f}\"}\n",
    "        performances.append(round_result)\n",
    "\n",
    "    # Creating DataFrame from performance data\n",
    "    df_performances = pd.DataFrame(performances)\n",
    "    print(df_performances)\n",
    "    return df_performances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T02:07:24.164662200Z",
     "start_time": "2024-04-26T02:07:23.992936900Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 5: Compare LDGD Results with VAE\n",
    "## 5.1 Settings:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model_settings = {\n",
    "    'latent_dim': 2,\n",
    "    'num_inducing_points_reg': 5,\n",
    "    'num_inducing_points_cls': 5,\n",
    "    'num_epochs_train': 10000,\n",
    "    'num_epochs_test': 5000,\n",
    "    'batch_size': 100,\n",
    "    'load_trained_model': False,\n",
    "    'load_tested_model': False,\n",
    "    'dataset': 'synthetic',\n",
    "    'shared_inducing_points': True,\n",
    "    'use_gpytorch': True,\n",
    "    'random_state': 54,\n",
    "    'test_size': 0.3,\n",
    "    'use_shared_kernel': False\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T02:07:24.334554200Z",
     "start_time": "2024-04-26T02:07:24.164662200Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Create Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "yn_train, yn_test, ys_train, ys_test, labels_train, labels_test, orig_dataset = create_dataset(num_dimension=10,\n",
    "                                                                                               random_state= model_settings['random_state'],\n",
    "                                                                                               test_size=model_settings['test_size'])\n",
    "\n",
    "print(f\"train size = {yn_train.shape[0]}\")\n",
    "print(f\"test size = {ys_test.shape[0]}\")\n",
    "\n",
    "list_size = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "load_saved_result = False\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T02:07:24.537933100Z",
     "start_time": "2024-04-26T02:07:24.334554200Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Training model\n",
    "# VAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "try:\n",
    "    with open('metric_vae_dict.json', 'r') as file:\n",
    "        metric_vae_dict = json.load(file)\n",
    "except:\n",
    "    batch_shape = torch.Size([yn_train.shape[-1]])\n",
    "    metric_vae_list = []\n",
    "    for train_size in list_size:\n",
    "        print(f\"Training for sample size: {train_size}\")\n",
    "        yn_train_limited, ys_train_limited, labels_train_limited = yn_train[:train_size], ys_train[:train_size], labels_train[:train_size]\n",
    "\n",
    "        # Train VAE Model\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = VAE(input_dim=yn_train_limited.shape[-1],\n",
    "                    hidden_dim=30,\n",
    "                    latent_dim=10,\n",
    "                    num_classes=len(np.unique(labels_train))).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        model.fit(x=yn_train_limited, y=labels_train_limited, x_test=yn_test, y_test=labels_test, optimizer=optimizer, epochs=2000, batch_size=500, patience=20)\n",
    "        x_hat, y_hat, mean, log_var, metrics = model.evaluate(yn_test, labels_test)\n",
    "\n",
    "        metric_vae_list.append(metrics)\n",
    "    winsound.Beep(freq, duration*3)\n",
    "    metric_vae_dict = dicts_to_dict_of_lists(metric_vae_list)\n",
    "    with open('metric_vae_dict.json', 'w') as file:\n",
    "        json.dump(metric_vae_dict, file, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:49:26.502527Z",
     "start_time": "2024-02-27T02:49:26.360126500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train LDGD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "try:\n",
    "    with open('./saved_results/metric_ldgd_dict.json', 'r') as file:\n",
    "        metric_ldgd_dict = json.load(file)\n",
    "except:\n",
    "    batch_shape = torch.Size([yn_train.shape[-1]])\n",
    "    metric_ldgd_list = []\n",
    "    for train_size in list_size:\n",
    "        model_settings['num_inducing_points_reg']= np.max([int(train_size/10) + 5, 25])\n",
    "        model_settings['num_inducing_points_cls']= np.max([int(train_size/10) + 5, 25])\n",
    "        yn_train_limited, ys_train_limited, labels_train_limited = yn_train[:train_size], ys_train[:train_size], labels_train[:train_size]\n",
    "        # Train LDGD Model\n",
    "        model = create_LDGD_model(yn_train_limited, ys_train_limited, model_settings)\n",
    "        if load_saved_result is False:\n",
    "            losses, history_train = model.train_model(yn=yn_train_limited, ys=ys_train_limited,\n",
    "                                                      epochs=model_settings['num_epochs_train'],\n",
    "                                                      batch_size=model_settings['batch_size'],\n",
    "                                                      early_stop=1e-6)\n",
    "            model.save_wights(path_save='', file_name=f\"model_ldgd_task3_{train_size}\")\n",
    "        else:\n",
    "            model.load_weights(path_save='', file_name=f\"model_ldgd_task3_{train_size}\")\n",
    "\n",
    "        predictions, metrics, history_test = model.evaluate(yn_test=yn_test, ys_test=labels_test,\n",
    "                                                        epochs=model_settings['num_epochs_test'])\n",
    "\n",
    "        metric_ldgd_list.append(metrics)\n",
    "    winsound.Beep(freq, duration*3)\n",
    "    metric_ldgd_dict = dicts_to_dict_of_lists(metric_ldgd_list)\n",
    "    with open('metric_ldgd_dict.json', 'w') as file:\n",
    "        json.dump(metric_ldgd_dict, file, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T02:08:18.490145300Z",
     "start_time": "2024-04-26T02:08:18.060209700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train FastLDGD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "try:\n",
    "    with open('./hsaved_results/metric_fastldgd_dict.json', 'r') as file:\n",
    "        metric_fastldgd_dict = json.load(file)\n",
    "except:\n",
    "    batch_shape = torch.Size([yn_train.shape[-1]])\n",
    "    metric_fastldgd_list = []\n",
    "    for train_size in list_size:\n",
    "        print(f\"\\n ===== train size - {train_size} ======\")\n",
    "        model_settings['num_inducing_points_reg']= np.max([int(train_size/10) + 5, 25])\n",
    "        model_settings['num_inducing_points_cls']= np.max([int(train_size/10) + 5, 25])\n",
    "        yn_train_limited, ys_train_limited, labels_train_limited = yn_train[:train_size], ys_train[:train_size], labels_train[:train_size]\n",
    "        # Train LDGD Model\n",
    "        model = create_FastLDGD_model(yn_train_limited, ys_train_limited, model_settings, batch_shape=batch_shape)\n",
    "        if load_saved_result is False:\n",
    "            losses, history_train = model.train_model(yn=yn_train_limited, ys=ys_train_limited,\n",
    "                                                      epochs=model_settings['num_epochs_train'],\n",
    "                                                      batch_size=model_settings['batch_size'])\n",
    "            model.save_wights(path_save='', file_name=f\"model_fldgd_task3_{train_size}\")\n",
    "        else:\n",
    "            try:\n",
    "                model.load_weights(path_save='', file_name=f\"model_fldgd_task3_{train_size}\")\n",
    "            except:\n",
    "                losses, history_train = model.train_model(yn=yn_train_limited, ys=ys_train_limited,\n",
    "                                                          epochs=model_settings['num_epochs_train'],\n",
    "                                                          batch_size=model_settings['batch_size'])\n",
    "                model.save_wights(path_save='', file_name=f\"model_fldgd_task3_{train_size}\")\n",
    "\n",
    "\n",
    "        predictions, metrics, history_test = model.evaluate(yn_test=yn_test, ys_test=labels_test,\n",
    "                                                        epochs=model_settings['num_epochs_test'])\n",
    "\n",
    "        metric_fastldgd_list.append(metrics)\n",
    "    winsound.Beep(freq, duration*3)\n",
    "    metric_fastldgd_dict = dicts_to_dict_of_lists(metric_fastldgd_list)\n",
    "    with open('metric_fastldgd_dict.json', 'w') as file:\n",
    "        json.dump(metric_fastldgd_dict, file, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T02:10:59.668101800Z",
     "start_time": "2024-04-26T02:10:39.092873700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\n",
    "AXIS_LABEL_FONTSIZE = 32\n",
    "TICKS_LABEL_FONTSIZE = 28\n",
    "LEGEND_FONTSIZE = 24\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(14, 5))\n",
    "# ax1.set_title('2D Latent Subspace Corresponding to 3 Phase Oilflow', fontsize=32)\n",
    "\n",
    "axes[0].plot(list_size, metric_vae_dict['accuracy'], label='VAE', marker='s')\n",
    "axes[0].plot(list_size, metric_ldgd_dict['accuracy'], label='LDGD', marker='d')\n",
    "axes[0].plot(list_size, metric_fastldgd_dict['accuracy'], label='FastLDGD', marker='o')\n",
    "\n",
    "axes[0].set_xlabel(f'Number of data points', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[0].set_ylabel(f'Accuracy', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[0].tick_params(axis='both', labelsize=TICKS_LABEL_FONTSIZE)\n",
    "# Applying consistent spines format\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].spines['left'].set_linewidth(1)\n",
    "axes[0].spines['bottom'].set_linewidth(1)\n",
    "#axes[0].legend(fontsize=LEGEND_FONTSIZE)\n",
    "axes[0].set_xscale('log')  # Making x-axis logarithmic for the accuracy plot\n",
    "\n",
    "\n",
    "axes[1].plot(list_size, metric_vae_dict['f1_score'], label='VAE', marker='s')\n",
    "axes[1].plot(list_size, metric_ldgd_dict['f1_score'], label='LDGD', marker='d')\n",
    "axes[1].plot(list_size, metric_fastldgd_dict['f1_score'], label='Fast LDGD', marker='o')\n",
    "\n",
    "axes[1].set_xlabel(f'Number of data points', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1].set_ylabel(f'F-measure', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1].tick_params(axis='both', labelsize=TICKS_LABEL_FONTSIZE)\n",
    "# Applying consistent spines format\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].spines['left'].set_linewidth(1)\n",
    "axes[1].spines['bottom'].set_linewidth(1)\n",
    "#axes[1].legend(fontsize=LEGEND_FONTSIZE)\n",
    "axes[1].set_xscale('log')  # Making x-axis logarithmic for the accuracy plot\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"./saved_results/figure5_comp_models.png\")\n",
    "fig.savefig(\"./saved_results/figure5_comp_models.svg\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T05:30:37.047275100Z",
     "start_time": "2024-02-27T05:30:35.553097600Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "yn_train, yn_test, ys_train, ys_test, labels_train, labels_test, orig_dataset = create_dataset(num_dimension=10,\n",
    "                                                                                               random_state= model_settings['random_state'],\n",
    "                                                                                               test_size=model_settings['test_size'],\n",
    "                                                                                               n_samples=500)\n",
    "\n",
    "print(f\"train size = {yn_train.shape[0]}\")\n",
    "print(f\"test size = {ys_test.shape[0]}\")\n",
    "\n",
    "load_saved_result = False\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T10:14:21.304578600Z",
     "start_time": "2024-02-21T10:14:20.993163Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(f\"Training for sample size: {train_size}\")\n",
    "\n",
    "# Train VAE Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VAE(input_dim=yn_train.shape[-1],\n",
    "            hidden_dim=30,\n",
    "            latent_dim=10,\n",
    "            num_classes=len(np.unique(labels_train))).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model.fit(x=yn_train, y=labels_train, x_test=yn_test, y_test=labels_test, optimizer=optimizer, epochs=2000, batch_size=500, patience=20)\n",
    "x_hat, y_hat, mean, log_var, metrics = model.evaluate(yn_test, labels_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T10:15:09.225649300Z",
     "start_time": "2024-02-21T10:14:53.799330500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "x_train_hat, y_hat, mean_train, log_var_train, metrics = model.evaluate(yn_train, labels_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T10:20:41.217726700Z",
     "start_time": "2024-02-21T10:20:41.091879600Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(16, 8))\n",
    "l1=0\n",
    "l2=1\n",
    "plot_scatter_gplvm(mean_train, labels_train, l1=l1, l2=l2, ax=axs[0], colors=['r', 'b', 'g'], show_errorbars=False, std=None)\n",
    "plot_scatter_gplvm(mean, labels_test, l1=l1, l2=l2, ax=axs[1], colors=['r', 'b', 'g'], show_errorbars=False, std=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T10:21:19.707535100Z",
     "start_time": "2024-02-21T10:21:19.270466200Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
