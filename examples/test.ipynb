{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-20T22:23:36.623835Z",
     "start_time": "2024-02-20T22:23:36.612925800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assuming X, y are numpy arrays\n",
    "def cross_validate_model(n_dim, settings, n_splits=5, load_saved_result=False, save_model=True, **kwargs):\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=model_settings['random_state'])\n",
    "\n",
    "    performances = []\n",
    "\n",
    "    for n_dim in n_dim:\n",
    "        # Code to generate data for different dimensional synthetic datasets\n",
    "        pattern = kwargs.get('pattern', 'moon')  # default pattern\n",
    "        n_samples = kwargs.get('n_samples', 1500)\n",
    "        noise = kwargs.get('noise', 0.1)\n",
    "        increase_method = kwargs.get('increase_method', 'linear')\n",
    "\n",
    "        X, y, orig_data = generate_data(pattern, n_samples, noise, n_dim, increase_method, random_state=model_settings['random_state'])\n",
    "        # One-hot encode the labels\n",
    "        y_one_hot = np.zeros((y.shape[0], len(np.unique(y))))\n",
    "        y_one_hot[np.arange(y.shape[0]), np.uint(y)] = 1\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y_one_hot, dtype=torch.float32)\n",
    "        labels = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        p, r, f = [], [], []\n",
    "        for train_idx, test_idx in kfold.split(X, y):\n",
    "            # \"X[train_ix]\" will have to be modified to extract the relevant synthetic rows\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            labels_train, labels_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "            # Here you convert to PyTorch tensors, etc., and pass into your network\n",
    "            # metrics = train_and_evaluate_model() assuming it returns a dict or other\n",
    "            # performance data. Replace with the appropiate flow of your process.\n",
    "            settings['data_dim'] = X_train.shape[-1]\n",
    "            batch_shape = torch.Size([settings['data_dim']])\n",
    "            if load_saved_result is False:\n",
    "                model = create_LDGD_model(X_train, y_train, settings, x_init='pca')\n",
    "\n",
    "                losses, history_train = model.train_model(yn=X_train, ys=y_train,\n",
    "                                                          epochs=settings['num_epochs_train'],\n",
    "                                                          batch_size=settings['batch_size'])\n",
    "                if save_model is True:\n",
    "                    model.save_wights(path_save='./saved_models/', file_name=f\"model_synthetic_{num_dimension}\")\n",
    "                predictions, metrics, history_test = model.evaluate(yn_test=X_test, ys_test=labels_test,\n",
    "                                                                epochs=settings['num_epochs_test'])\n",
    "\n",
    "                winsound.Beep(freq, duration)\n",
    "            else:\n",
    "                model = create_LDGD_model(X_train, y_train, settings)\n",
    "                model.load_weights(path_save='./saved_models/', file_name=f'model_synthetic_{num_dimension}.pth')\n",
    "                predictions, metrics, history_test = model.evaluate(yn_test=X_test, ys_test=labels_test,\n",
    "                                                                epochs=settings['num_epochs_test'])\n",
    "\n",
    "            # Compute or accumulate measures (precision, recall, F1 score)\n",
    "            p.append(metrics['precision'])\n",
    "            r.append(metrics['recall'])\n",
    "            f.append(metrics['f1_score'])\n",
    "\n",
    "        # Form the list of dataframe rows for the round of n_dim rounds\n",
    "        measures = (np.mean(p), np.std(p), np.mean(r), np.std(r), np.mean(f), np.std(f))\n",
    "        round_result = {\"dataset\": f\"synthetic {n_dim}\", \"precision\": f\"{measures[0]:.2f} ± {measures[1]:.2f}\",\n",
    "                        \"recall\": f\"{measures[2]:.2f} ± {measures[3]:.2f}\",\n",
    "                        \"f score\": f\"{measures[4]:.2f} ± {measures[5]:.2f}\"}\n",
    "        performances.append(round_result)\n",
    "\n",
    "    # Creating DataFrame from performance data\n",
    "    df_performances = pd.DataFrame(performances)\n",
    "    return df_performances"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
