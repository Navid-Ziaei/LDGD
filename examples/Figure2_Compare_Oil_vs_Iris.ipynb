{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from LDGD.model import ARDRBFKernel, LDGD\n",
    "from LDGD.model.experimental.GP_scratch import bGPLVM\n",
    "from LDGD.visualization import plot_box_plots\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.io import savemat, loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import winsound\n",
    "\n",
    "from LDGD.visualization.vizualize_utils import plot_heatmap, plot_2d_scatter, plot_ARD_gplvm\n",
    "from LDGD.visualization.vizualize_utils import plot_loss_gplvm, plot_scatter_gplvm, plot_box_plots"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T04:50:35.049030Z",
     "start_time": "2024-02-27T04:50:31.411053100Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T04:50:35.178372800Z",
     "start_time": "2024-02-27T04:50:35.049030Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def train_model(data_cont, data_cat, settings, filename):\n",
    "    num_points, data_dim = data_cont.shape\n",
    "    batch_shape = torch.Size([data_dim])\n",
    "    settings['use_gpytorch'] = True\n",
    "    if settings['use_gpytorch'] is False:\n",
    "        kernel_cls = ARDRBFKernel(input_dim=settings['latent_dim'])\n",
    "        kernel_reg = ARDRBFKernel(input_dim=settings['latent_dim'])\n",
    "    else:\n",
    "        kernel_reg = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=settings['latent_dim']))\n",
    "        kernel_cls = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=settings['latent_dim']))\n",
    "\n",
    "    likelihood_reg = GaussianLikelihood(batch_shape=batch_shape)\n",
    "    likelihood_cls = BernoulliLikelihood()\n",
    "\n",
    "\n",
    "    if settings['load_model'] is True:\n",
    "        with open(f'./saved_models/fig2_ldgd_{filename}_settings.json', 'r') as file:\n",
    "            settings = json.load(file)\n",
    "        model = LDGD(data_cont,\n",
    "                kernel_reg=kernel_reg,\n",
    "                kernel_cls=kernel_cls,\n",
    "                num_classes=data_cat.shape[-1],\n",
    "                num_inducing_points_cls=settings['num_inducing_points_cls'],\n",
    "                num_inducing_points_reg=settings['num_inducing_points_reg'],\n",
    "                latent_dim=settings['latent_dim'],\n",
    "                likelihood_reg=likelihood_reg,\n",
    "                likelihood_cls=likelihood_cls,\n",
    "                use_gpytorch=settings['use_gpytorch'],\n",
    "                shared_inducing_points=settings['shared_inducing_points'],\n",
    "                x_init=settings['x_init'])\n",
    "        model.load_weights(path_save='./saved_models/', file_name=f\"fig2_ldgd_{filename}.pth\")\n",
    "        history_train = model.history_train\n",
    "        losses = model.history_train['elbo_loss']\n",
    "    else:\n",
    "        model = LDGD(data_cont,\n",
    "                kernel_reg=kernel_reg,\n",
    "                kernel_cls=kernel_cls,\n",
    "                num_classes=data_cat.shape[-1],\n",
    "                num_inducing_points_cls=settings['num_inducing_points_cls'],\n",
    "                num_inducing_points_reg=settings['num_inducing_points_reg'],\n",
    "                latent_dim=settings['latent_dim'],\n",
    "                likelihood_reg=likelihood_reg,\n",
    "                likelihood_cls=likelihood_cls,\n",
    "                use_gpytorch=settings['use_gpytorch'],\n",
    "                shared_inducing_points=settings['shared_inducing_points'],\n",
    "                x_init=settings['x_init'])\n",
    "\n",
    "        losses, history_train = model.train_model(yn=data_cont,\n",
    "                                                  ys=data_cat,\n",
    "                                                  epochs=settings['num_epochs_train'],\n",
    "                                                  batch_size=settings['batch_size'])\n",
    "\n",
    "        if settings['save_model'] is True:\n",
    "            model.save_wights(path_save='./saved_models/', file_name=f\"fig2_ldgd_{filename}\")\n",
    "        with open(f'./saved_models/fig2_ldgd_{filename}_settings.json', 'w') as f:\n",
    "            json.dump(settings, f)\n",
    "    return model, losses, history_train, model_settings\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T04:50:35.303407100Z",
     "start_time": "2024-02-27T04:50:35.178372800Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Oil dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_data_oil = np.load('../data/train_data.npy', allow_pickle=True)\n",
    "test_data_oil = np.load('../data/test_data.npy', allow_pickle=True)\n",
    "\n",
    "yn_train_oil, ys_train_oil, labels_train_oil = train_data_oil.take(0)['yn_train'], train_data_oil.take(0)['ys_train'], train_data_oil.take(0)['labels_train']\n",
    "yn_test_oil, ys_test_oil, labels_test_oil = test_data_oil.take(0)['yn_test'], test_data_oil.take(0)['ys_test'], test_data_oil.take(0)['labels_test']\n",
    "\n",
    "yn_train_oil, ys_train_oil, labels_train_oil = torch.Tensor(yn_train_oil), torch.Tensor(ys_train_oil), torch.Tensor(labels_train_oil)\n",
    "yn_test_oil, ys_test_oil, labels_test_oil = torch.Tensor(yn_test_oil), torch.Tensor(ys_test_oil), torch.Tensor(labels_test_oil)\n",
    "\n",
    "print(f\"Train size : {yn_train_oil.shape[0]} Test size : {yn_test_oil.shape[0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T04:50:35.413147800Z",
     "start_time": "2024-02-27T04:50:35.303407100Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load IRIS dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_data_iris = np.load('../data/train_data_iris.npy', allow_pickle=True)\n",
    "test_data_iris = np.load('../data/test_data_iris.npy', allow_pickle=True)\n",
    "\n",
    "yn_train_iris, ys_train_iris, labels_train_iris = train_data_iris.take(0)['yn_train'], train_data_iris.take(0)['ys_train'], train_data_iris.take(0)['labels_train']\n",
    "yn_test_iris, ys_test_iris, labels_test_iris = test_data_iris.take(0)['yn_test'], test_data_iris.take(0)['ys_test'], test_data_iris.take(0)['labels_test']\n",
    "\n",
    "yn_train_iris, ys_train_iris, labels_train_iris = torch.Tensor(yn_train_iris), torch.Tensor(ys_train_iris), torch.Tensor(labels_train_iris)\n",
    "yn_test_iris, ys_test_iris, labels_test_iris = torch.Tensor(yn_test_iris), torch.Tensor(ys_test_iris), torch.Tensor(labels_test_iris)\n",
    "\n",
    "print(f\"Train size : {yn_train_iris.shape[0]} Test size : {yn_test_iris.shape[0]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T04:50:35.538170700Z",
     "start_time": "2024-02-27T04:50:35.413147800Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LDGD\n",
    "## Oil flow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "model_settings = {\n",
    "    'latent_dim': 7,\n",
    "    'num_inducing_points_reg': 25,\n",
    "    'num_inducing_points_cls': 25,\n",
    "    'num_epochs_train': 3000,\n",
    "    'num_epochs_test': 3000,\n",
    "    'batch_size': 2000,\n",
    "    'load_trained_model': False,\n",
    "    'load_tested_model': False,\n",
    "    'use_gpytorch': True,\n",
    "    'save_model': True,\n",
    "    'load_model':False,\n",
    "    'x_init': 'pca',\n",
    "    'shared_inducing_points': False\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T05:16:59.133005700Z",
     "start_time": "2024-02-27T05:16:58.971602400Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "\n",
    "model_oil, losses_oil, history_train_oil, model_settings = train_model(data_cont = yn_train_oil,\n",
    "                                                                       data_cat = ys_train_oil,\n",
    "                                                                       settings = model_settings,\n",
    "                                                                       filename = 'oil')\n",
    "winsound.Beep(freq, duration*3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T05:19:38.943322Z",
     "start_time": "2024-02-27T05:16:59.450420200Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "predictions_oil, metrics_oil, history_test = model_oil.evaluate(yn_test=yn_test_oil, ys_test=labels_test_oil, epochs=model_settings['num_epochs_test'])\n",
    "\n",
    "alpha_reg_oil = 1 / model_oil.kernel_reg.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "alpha_cls_oil = 1 / model_oil.kernel_cls.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "\n",
    "x_oil = model_oil.x.q_mu.cpu().detach().numpy()\n",
    "std_oil = torch.nn.functional.softplus(model_oil.x.q_log_sigma).cpu().detach().numpy()\n",
    "\n",
    "x_test_oil = model_oil.x_test.q_mu.cpu().detach().numpy()\n",
    "std_test_oil = torch.nn.functional.softplus(model_oil.x_test.q_log_sigma).cpu().detach().numpy()\n",
    "winsound.Beep(freq, duration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T05:20:36.390273500Z",
     "start_time": "2024-02-27T05:19:38.943322Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "latent_dim = x_oil.shape[-1]\n",
    "values, indices = torch.topk(torch.tensor(alpha_cls_oil), k=2, largest=True)\n",
    "l1 = indices.numpy().flatten()[0]\n",
    "l2 = indices.numpy().flatten()[1]\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(32, 8))\n",
    "\n",
    "\n",
    "plot_loss_gplvm(losses_oil, ax=axs[0])\n",
    "plot_ARD_gplvm(latent_dim, alpha_cls_oil, ax=axs[2])\n",
    "plot_ARD_gplvm(latent_dim, alpha_reg_oil, ax=axs[1])\n",
    "plot_scatter_gplvm(x_oil, labels_train_oil, l1=l1, l2=l2, ax=axs[3], colors=['r', 'b', 'g'], show_errorbars=True, std=np.sqrt(std_oil))\n",
    "plot_scatter_gplvm(x_test_oil, labels_test_oil, l1=l1, l2=l2, ax=axs[4], colors=['r', 'b', 'g'], show_errorbars=True, std=np.sqrt(std_test_oil))\n",
    "plt.tight_layout()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T05:20:37.406873100Z",
     "start_time": "2024-02-27T05:20:36.390273500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Iris"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model_settings = {\n",
    "    'latent_dim': 7,\n",
    "    'num_inducing_points_reg': 15,\n",
    "    'num_inducing_points_cls': 15,\n",
    "    'num_epochs_train': 2000,\n",
    "    'num_epochs_test': 2000,\n",
    "    'batch_size': 500,\n",
    "    'load_trained_model': False,\n",
    "    'load_tested_model': False,\n",
    "    'use_gpytorch': True,\n",
    "    'save_model': True,\n",
    "    'load_model':True,\n",
    "    'x_init': None,\n",
    "    'shared_inducing_points': True\n",
    "}\n",
    "\n",
    "model_iris, losses_iris, history_train_iris, model_settings = train_model(data_cont = yn_train_iris,\n",
    "                                                                          data_cat = ys_train_iris,\n",
    "                                                                          settings = model_settings,\n",
    "                                                                          filename = 'iris')\n",
    "winsound.Beep(freq, duration*2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T04:55:37.137357500Z",
     "start_time": "2024-02-27T04:54:03.517774400Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "predictions_iris, metrics_iris, history_test = model_iris.evaluate(yn_test=yn_test_iris, ys_test=labels_test_iris, epochs=2000)\n",
    "\n",
    "alpha_reg_iris = 1 / model_iris.kernel_reg.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "alpha_cls_iris = 1 / model_iris.kernel_cls.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "\n",
    "x_iris = model_iris.x.q_mu.cpu().detach().numpy()\n",
    "std_iris = torch.nn.functional.softplus(model_iris.x.q_log_sigma).cpu().detach().numpy()\n",
    "\n",
    "x_test_iris = model_iris.x_test.q_mu.cpu().detach().numpy()\n",
    "std_test_iris = torch.nn.functional.softplus(model_iris.x_test.q_log_sigma).cpu().detach().numpy()\n",
    "winsound.Beep(freq, duration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T04:56:14.855543900Z",
     "start_time": "2024-02-27T04:55:37.137357500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "latent_dim = x_iris.shape[-1]\n",
    "values, indices = torch.topk(torch.tensor(alpha_cls_iris), k=2, largest=True)\n",
    "l1 = indices.numpy().flatten()[0]\n",
    "l2 = indices.numpy().flatten()[1]\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(32, 8))\n",
    "\n",
    "\n",
    "plot_loss_gplvm(losses_iris, ax=axs[0])\n",
    "plot_ARD_gplvm(latent_dim, alpha_cls_iris, ax=axs[2])\n",
    "plot_ARD_gplvm(latent_dim, alpha_reg_iris, ax=axs[1])\n",
    "plot_scatter_gplvm(x_iris, labels_train_iris, l1=l1, l2=l2, ax=axs[3], colors=['r', 'b', 'g'], show_errorbars=True, std=std_iris)\n",
    "plot_scatter_gplvm(x_test_iris, labels_test_iris, l1=l1, l2=l2, ax=axs[4], colors=['r', 'b', 'g'], show_errorbars=True, std=std_test_iris)\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T04:56:15.739200500Z",
     "start_time": "2024-02-27T04:56:14.871154700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "fig, axs = plt.subplots(1,4, figsize=(32, 8))\n",
    "\n",
    "values, indices = torch.topk(torch.tensor(alpha_cls_iris), k=2, largest=True)\n",
    "l1 = indices.numpy().flatten()[0]\n",
    "l2 = indices.numpy().flatten()[1]\n",
    "\n",
    "plot_ARD_gplvm(x_iris.shape[-1], alpha_cls_iris, ax=axs[0])\n",
    "plot_scatter_gplvm(x_iris, labels_train_iris, l1=l1, l2=l2, ax=axs[1], colors=['r', 'b', 'g'], show_errorbars=True, std=std_iris)\n",
    "\n",
    "values, indices = torch.topk(torch.tensor(alpha_cls_oil), k=2, largest=True)\n",
    "l1 = indices.numpy().flatten()[0]\n",
    "l2 = indices.numpy().flatten()[1]\n",
    "\n",
    "plot_ARD_gplvm(x_oil.shape[-1], alpha_cls_oil, ax=axs[2])\n",
    "plot_scatter_gplvm(x_oil, labels_train_oil, l1=l1, l2=l2, ax=axs[3], colors=['r', 'b', 'g'], show_errorbars=True, std=np.sqrt(std_oil))\n",
    "\n",
    "fig.savefig(\"./saved_results/figure2.png\")\n",
    "fig.savefig(\"./saved_results/figure2.svg\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T05:56:29.292946800Z",
     "start_time": "2024-02-27T05:56:28.023747500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
