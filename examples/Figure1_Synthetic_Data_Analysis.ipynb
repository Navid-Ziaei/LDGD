{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import torch\n",
    "import winsound\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from LDGD.model import LDGD, FastLDGD, VAE\n",
    "from LDGD.visualization.vizualize_utils import plot_heatmap, plot_2d_scatter, plot_ARD_gplvm\n",
    "from LDGD.visualization.vizualize_utils import plot_loss_gplvm, plot_scatter_gplvm, plot_box_plots\n",
    "from LDGD.data.data_loader import generate_data\n",
    "\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "\n",
    "from LDGD.utils import dicts_to_dict_of_lists\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T02:01:06.509996Z",
     "start_time": "2024-02-27T02:01:03.872899700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compare_decoding_on_dataset.ipynb# Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1- Create Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def create_dataset(num_dimension, random_state, test_size, **kwargs):\n",
    "    # Extract parameters for synthetic data generation\n",
    "    pattern = kwargs.get('pattern', 'moon')  # default pattern\n",
    "    n_samples = kwargs.get('n_samples', 1500)\n",
    "    noise = kwargs.get('noise', 0.1)\n",
    "    increase_method = kwargs.get('increase_method', 'linear')\n",
    "\n",
    "    X, y, orig_data = generate_data(pattern, n_samples, noise, num_dimension, increase_method, random_state=random_state)\n",
    "    # One-hot encode the labels\n",
    "    y_one_hot = np.zeros((y.shape[0], len(np.unique(y))))\n",
    "    y_one_hot[np.arange(y.shape[0]), np.uint(y)] = 1\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test, y_train_labels, y_test_labels = train_test_split(X, y_one_hot, y,\n",
    "                                                                                       test_size=test_size,\n",
    "                                                                                       random_state=random_state)\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "    y_train_labels_tensor = torch.tensor(y_train_labels)\n",
    "    y_test_labels_tensor = torch.tensor(y_test_labels)\n",
    "\n",
    "    return X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, y_train_labels_tensor, y_test_labels_tensor, orig_data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T23:20:31.108019Z",
     "start_time": "2024-02-20T23:20:30.980251200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 - Create Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_LDGD_model(data_cont, data_cat, ldgd_settings, batch_shape, x_init='pca'):\n",
    "    kernel_reg = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=ldgd_settings['latent_dim']))\n",
    "    kernel_cls = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=ldgd_settings['latent_dim']))\n",
    "\n",
    "    likelihood_reg = GaussianLikelihood(batch_shape=batch_shape)\n",
    "    likelihood_cls = BernoulliLikelihood()\n",
    "    model = LDGD(data_cont,\n",
    "                 kernel_reg=kernel_reg,\n",
    "                 kernel_cls=kernel_cls,\n",
    "                 num_classes=data_cat.shape[-1],\n",
    "                 latent_dim=ldgd_settings['latent_dim'],\n",
    "                 num_inducing_points_cls=ldgd_settings['num_inducing_points_cls'],\n",
    "                 num_inducing_points_reg=ldgd_settings['num_inducing_points_reg'],\n",
    "                 likelihood_reg=likelihood_reg,\n",
    "                 likelihood_cls=likelihood_cls,\n",
    "                 use_gpytorch=ldgd_settings['use_gpytorch'],\n",
    "                 shared_inducing_points=ldgd_settings['shared_inducing_points'],\n",
    "                 use_shared_kernel=False,\n",
    "                 x_init=x_init,\n",
    "                 device=device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_FastLDGD_model(data_cont, data_cat, ldgd_settings, batch_shape):\n",
    "    kernel_reg = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=ldgd_settings['latent_dim']))\n",
    "    kernel_cls = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=ldgd_settings['latent_dim']))\n",
    "\n",
    "    likelihood_reg = GaussianLikelihood(batch_shape=batch_shape)\n",
    "    likelihood_cls = BernoulliLikelihood()\n",
    "    model = FastLDGD(data_cont,\n",
    "             kernel_reg=kernel_reg,\n",
    "             kernel_cls=kernel_cls,\n",
    "             num_classes=data_cat.shape[-1],\n",
    "             latent_dim=ldgd_settings['latent_dim'],\n",
    "             num_inducing_points_cls= ldgd_settings['num_inducing_points_cls'],\n",
    "             num_inducing_points_reg= ldgd_settings['num_inducing_points_reg'],\n",
    "             likelihood_reg=likelihood_reg,\n",
    "             likelihood_cls=likelihood_cls,\n",
    "             use_gpytorch=ldgd_settings['use_gpytorch'],\n",
    "             shared_inducing_points=ldgd_settings['shared_inducing_points'],\n",
    "             use_shared_kernel=False,\n",
    "             device=device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T23:20:31.238348300Z",
     "start_time": "2024-02-20T23:20:31.110072600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# Assuming X, y are numpy arrays\n",
    "def cross_validate_model(n_dim, settings, n_splits=5, load_saved_result=False, save_model=True, **kwargs):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=model_settings['random_state'])\n",
    "\n",
    "    performances = []\n",
    "\n",
    "    for n_dim in n_dim:\n",
    "        # Code to generate data for different dimensional synthetic datasets\n",
    "        pattern = kwargs.get('pattern', 'moon')  # default pattern\n",
    "        n_samples = kwargs.get('n_samples', 1500)\n",
    "        noise = kwargs.get('noise', 0.1)\n",
    "        increase_method = kwargs.get('increase_method', 'linear')\n",
    "\n",
    "        X, y, orig_data = generate_data(pattern, n_samples, noise, n_dim, increase_method,\n",
    "                                        random_state=model_settings['random_state'])\n",
    "        # One-hot encode the labels\n",
    "        y_one_hot = np.zeros((y.shape[0], len(np.unique(y))))\n",
    "        y_one_hot[np.arange(y.shape[0]), np.uint(y)] = 1\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        labels = torch.tensor(y, dtype=torch.float32)\n",
    "        y = torch.tensor(y_one_hot)\n",
    "\n",
    "\n",
    "        p, r, f = [], [], []\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(kfold.split(X, labels)):\n",
    "            print(f\"=============== Dim {n_dim} Fold {fold_idx} ===============\")\n",
    "            # \"X[train_ix]\" will have to be modified to extract the relevant synthetic rows\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            labels_train, labels_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "            # Here you convert to PyTorch tensors, etc., and pass into your network\n",
    "            # metrics = train_and_evaluate_model() assuming it returns a dict or other\n",
    "            # performance data. Replace with the appropiate flow of your process.\n",
    "            settings['data_dim'] = X_train.shape[-1]\n",
    "            batch_shape = torch.Size([settings['data_dim']])\n",
    "            if load_saved_result is False:\n",
    "                model = create_LDGD_model(X_train, y_train, settings, batch_shape=batch_shape, x_init='pca')\n",
    "                losses, history_train = model.train_model(yn=X_train, ys=y_train,\n",
    "                                                          epochs=settings['num_epochs_train'],\n",
    "                                                          batch_size=settings['batch_size'],\n",
    "                                                          verbos=0)\n",
    "                if save_model is True:\n",
    "                    model.save_wights(path_save='./saved_models/', file_name=f\"model_synthetic_fold{fold_idx}_synthetic{2*n_dim}\")\n",
    "                predictions, metrics, history_test = model.evaluate(yn_test=X_test, ys_test=labels_test,\n",
    "                                                                    epochs=settings['num_epochs_test'],\n",
    "                                                                    verbos=0)\n",
    "\n",
    "                winsound.Beep(freq, duration)\n",
    "            else:\n",
    "                model = create_LDGD_model(X_train, y_train, settings)\n",
    "                model.load_weights(path_save='./saved_models/', file_name=f'model_synthetic_fold{fold_idx}_synthetic{2*n_dim}.pth')\n",
    "                predictions, metrics, history_test = model.evaluate(yn_test=X_test, ys_test=labels_test,\n",
    "                                                                    epochs=settings['num_epochs_test'],\n",
    "                                                                    verbos=0)\n",
    "\n",
    "            # Compute or accumulate measures (precision, recall, F1 score)\n",
    "            p.append(metrics['precision'])\n",
    "            r.append(metrics['recall'])\n",
    "            f.append(metrics['f1_score'])\n",
    "\n",
    "        # Form the list of dataframe rows for the round of n_dim rounds\n",
    "        measures = (np.mean(p), np.std(p), np.mean(r), np.std(r), np.mean(f), np.std(f))\n",
    "        round_result = {\"dataset\": f\"synthetic {2*n_dim}\", \"precision\": f\"{measures[0]:.2f} ± {measures[1]:.2f}\",\n",
    "                        \"recall\": f\"{measures[2]:.2f} ± {measures[3]:.2f}\",\n",
    "                        \"f score\": f\"{measures[4]:.2f} ± {measures[5]:.2f}\"}\n",
    "        performances.append(round_result)\n",
    "\n",
    "    # Creating DataFrame from performance data\n",
    "    df_performances = pd.DataFrame(performances)\n",
    "    print(df_performances)\n",
    "    return df_performances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T23:20:31.363100Z",
     "start_time": "2024-02-20T23:20:31.239838Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1 : Evaluate model on different synthetic data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2a188c9a130>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_settings = {\n",
    "    'latent_dim': 2,\n",
    "    'num_inducing_points': 5,\n",
    "    'num_inducing_points_reg': 8,\n",
    "    'num_inducing_points_cls': 8,\n",
    "    'num_epochs_train': 2000,\n",
    "    'num_epochs_test': 2000,\n",
    "    'batch_size': 100,\n",
    "    'load_trained_model': False,\n",
    "    'load_tested_model': False,\n",
    "    'dataset': 'synthetic',\n",
    "    'shared_inducing_points': True,\n",
    "    'use_gpytorch': True,\n",
    "    'random_state': 65,\n",
    "    'test_size': 0.8,\n",
    "    'cls_weight': 1.0,\n",
    "    'reg_weight': 1.0,\n",
    "    'num_samples': 500,\n",
    "\n",
    "}\n",
    "np.random.seed(model_settings['random_state'])\n",
    "torch.manual_seed(model_settings['random_state'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T23:20:31.490422900Z",
     "start_time": "2024-02-20T23:20:31.363100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Loss: 1488.97216796875\n",
      "Epoch 11/2000, Loss: 1257.144775390625\n",
      "Epoch 21/2000, Loss: 1484.6121826171875\n",
      "Epoch 31/2000, Loss: 1470.1466064453125\n",
      "Epoch 41/2000, Loss: 1139.901123046875\n",
      "Epoch 51/2000, Loss: 1307.7239990234375\n",
      "Epoch 61/2000, Loss: 1235.8653564453125\n",
      "Epoch 71/2000, Loss: 963.896484375\n",
      "Epoch 81/2000, Loss: 1099.5157470703125\n",
      "Epoch 91/2000, Loss: 1204.2969970703125\n",
      "Epoch 101/2000, Loss: 1004.9822998046875\n",
      "Epoch 111/2000, Loss: 1296.137939453125\n",
      "Epoch 121/2000, Loss: 925.4276123046875\n",
      "Epoch 131/2000, Loss: 743.4650268554688\n",
      "Epoch 141/2000, Loss: 828.5338134765625\n",
      "Epoch 151/2000, Loss: 705.8910522460938\n",
      "Epoch 161/2000, Loss: 809.6154174804688\n",
      "Epoch 171/2000, Loss: 573.67578125\n",
      "Epoch 181/2000, Loss: 526.8336791992188\n",
      "Epoch 191/2000, Loss: 735.4547729492188\n",
      "Epoch 201/2000, Loss: 697.9366455078125\n",
      "Epoch 211/2000, Loss: 585.0035400390625\n",
      "Epoch 221/2000, Loss: 558.3077392578125\n",
      "Epoch 231/2000, Loss: 470.5807800292969\n",
      "Epoch 241/2000, Loss: 445.4139709472656\n",
      "Epoch 251/2000, Loss: 486.3566589355469\n",
      "Epoch 261/2000, Loss: 423.2536926269531\n",
      "Epoch 271/2000, Loss: 484.680908203125\n",
      "Epoch 281/2000, Loss: 470.8667297363281\n",
      "Epoch 291/2000, Loss: 518.4446411132812\n",
      "Epoch 301/2000, Loss: 476.1375732421875\n",
      "Epoch 311/2000, Loss: 363.1795654296875\n",
      "Epoch 321/2000, Loss: 379.5882873535156\n",
      "Epoch 331/2000, Loss: 355.6372985839844\n",
      "Epoch 341/2000, Loss: 271.6004943847656\n",
      "Epoch 351/2000, Loss: 286.80194091796875\n",
      "Epoch 361/2000, Loss: 322.2927551269531\n",
      "Epoch 371/2000, Loss: 254.9429931640625\n",
      "Epoch 381/2000, Loss: 329.3550720214844\n",
      "Epoch 391/2000, Loss: 281.3925476074219\n",
      "Epoch 401/2000, Loss: 249.33660888671875\n",
      "Epoch 411/2000, Loss: 208.56895446777344\n",
      "Epoch 421/2000, Loss: 300.87225341796875\n",
      "Epoch 431/2000, Loss: 250.69920349121094\n",
      "Epoch 441/2000, Loss: 214.4054718017578\n",
      "Epoch 451/2000, Loss: 278.1333923339844\n",
      "Epoch 461/2000, Loss: 200.14962768554688\n",
      "Epoch 471/2000, Loss: 217.94432067871094\n",
      "Epoch 481/2000, Loss: 230.55154418945312\n",
      "Epoch 491/2000, Loss: 195.9910430908203\n",
      "Epoch 501/2000, Loss: 207.15521240234375\n",
      "Epoch 511/2000, Loss: 155.28253173828125\n",
      "Epoch 521/2000, Loss: 187.69065856933594\n",
      "Epoch 531/2000, Loss: 175.4720916748047\n",
      "Epoch 541/2000, Loss: 177.23968505859375\n",
      "Epoch 551/2000, Loss: 212.55711364746094\n",
      "Epoch 561/2000, Loss: 189.4166259765625\n",
      "Epoch 571/2000, Loss: 181.14239501953125\n",
      "Epoch 581/2000, Loss: 181.11468505859375\n",
      "Epoch 591/2000, Loss: 181.43455505371094\n",
      "Epoch 601/2000, Loss: 182.97463989257812\n",
      "Epoch 611/2000, Loss: 164.5100860595703\n",
      "Epoch 621/2000, Loss: 116.74769592285156\n",
      "Epoch 631/2000, Loss: 165.6342010498047\n",
      "Epoch 641/2000, Loss: 106.11770629882812\n",
      "Epoch 651/2000, Loss: 129.66427612304688\n",
      "Epoch 661/2000, Loss: 121.30191040039062\n",
      "Epoch 671/2000, Loss: 95.50888061523438\n",
      "Epoch 681/2000, Loss: 106.94550323486328\n",
      "Epoch 691/2000, Loss: 93.29777526855469\n",
      "Epoch 701/2000, Loss: 99.99846649169922\n",
      "Epoch 711/2000, Loss: 106.37215423583984\n",
      "Epoch 721/2000, Loss: 102.51476287841797\n",
      "Epoch 731/2000, Loss: 114.63911437988281\n",
      "Epoch 741/2000, Loss: 90.17806243896484\n",
      "Epoch 751/2000, Loss: 99.35458374023438\n",
      "Epoch 761/2000, Loss: 76.82710266113281\n",
      "Epoch 771/2000, Loss: 114.03697204589844\n",
      "Epoch 781/2000, Loss: 89.24003601074219\n",
      "Epoch 791/2000, Loss: 87.15882873535156\n",
      "Epoch 801/2000, Loss: 91.18587493896484\n",
      "Epoch 811/2000, Loss: 90.86908721923828\n",
      "Epoch 821/2000, Loss: 84.50140380859375\n",
      "Epoch 831/2000, Loss: 68.23272705078125\n",
      "Epoch 841/2000, Loss: 81.6128921508789\n",
      "Epoch 851/2000, Loss: 67.24935150146484\n",
      "Epoch 861/2000, Loss: 69.9582748413086\n",
      "Epoch 871/2000, Loss: 70.47859954833984\n",
      "Epoch 881/2000, Loss: 72.93347930908203\n",
      "Epoch 891/2000, Loss: 55.18062210083008\n",
      "Epoch 901/2000, Loss: 53.33083724975586\n",
      "Epoch 911/2000, Loss: 66.3864974975586\n",
      "Epoch 921/2000, Loss: 57.22163391113281\n",
      "Epoch 931/2000, Loss: 74.35809326171875\n",
      "Epoch 941/2000, Loss: 42.0804328918457\n",
      "Epoch 951/2000, Loss: 65.21317291259766\n",
      "Epoch 961/2000, Loss: 45.24432373046875\n",
      "Epoch 971/2000, Loss: 56.6094970703125\n",
      "Epoch 981/2000, Loss: 48.36407470703125\n",
      "Epoch 991/2000, Loss: 60.01216506958008\n",
      "Epoch 1001/2000, Loss: 57.282283782958984\n",
      "Epoch 1011/2000, Loss: 60.074790954589844\n",
      "Epoch 1021/2000, Loss: 46.03047561645508\n",
      "Epoch 1031/2000, Loss: 59.981842041015625\n",
      "Epoch 1041/2000, Loss: 63.442562103271484\n",
      "Epoch 1051/2000, Loss: 37.90007781982422\n",
      "Epoch 1061/2000, Loss: 49.41282272338867\n",
      "Epoch 1071/2000, Loss: 57.698726654052734\n",
      "Epoch 1081/2000, Loss: 24.115516662597656\n",
      "Epoch 1091/2000, Loss: 49.56915283203125\n",
      "Epoch 1101/2000, Loss: 57.41756057739258\n",
      "Epoch 1111/2000, Loss: 43.08670425415039\n",
      "Epoch 1121/2000, Loss: 45.76875305175781\n",
      "Epoch 1131/2000, Loss: 34.89583206176758\n",
      "Epoch 1141/2000, Loss: 28.871122360229492\n",
      "Epoch 1151/2000, Loss: 51.99363327026367\n",
      "Epoch 1161/2000, Loss: 35.453369140625\n",
      "Epoch 1171/2000, Loss: 34.25598907470703\n",
      "Epoch 1181/2000, Loss: 43.84446334838867\n",
      "Epoch 1191/2000, Loss: 35.040157318115234\n",
      "Epoch 1201/2000, Loss: 30.17236328125\n",
      "Epoch 1211/2000, Loss: 36.06373977661133\n",
      "Epoch 1221/2000, Loss: 33.54411697387695\n",
      "Epoch 1231/2000, Loss: 31.79962158203125\n",
      "Epoch 1241/2000, Loss: 28.499874114990234\n",
      "Epoch 1251/2000, Loss: 20.625343322753906\n",
      "Epoch 1261/2000, Loss: 19.302701950073242\n",
      "Epoch 1271/2000, Loss: 32.17431640625\n",
      "Epoch 1281/2000, Loss: 37.17764663696289\n",
      "Epoch 1291/2000, Loss: 28.19772720336914\n",
      "Epoch 1301/2000, Loss: 22.595903396606445\n",
      "Epoch 1311/2000, Loss: 51.68280792236328\n",
      "Epoch 1321/2000, Loss: 25.50473976135254\n",
      "Epoch 1331/2000, Loss: 26.169946670532227\n",
      "Epoch 1341/2000, Loss: 33.71672058105469\n",
      "Epoch 1351/2000, Loss: 37.236122131347656\n",
      "Epoch 1361/2000, Loss: 15.033878326416016\n",
      "Epoch 1371/2000, Loss: 41.9501953125\n",
      "Epoch 1381/2000, Loss: 25.26372528076172\n",
      "Epoch 1391/2000, Loss: 15.385526657104492\n",
      "Epoch 1401/2000, Loss: 16.92224884033203\n",
      "Epoch 1411/2000, Loss: 14.027228355407715\n",
      "Epoch 1421/2000, Loss: 24.681753158569336\n",
      "Epoch 1431/2000, Loss: 14.585517883300781\n",
      "Epoch 1441/2000, Loss: 17.220535278320312\n",
      "Epoch 1451/2000, Loss: 20.533971786499023\n",
      "Epoch 1461/2000, Loss: 15.063793182373047\n",
      "Epoch 1471/2000, Loss: 22.329818725585938\n",
      "Epoch 1481/2000, Loss: 18.670347213745117\n",
      "Epoch 1491/2000, Loss: 16.677536010742188\n",
      "Epoch 1501/2000, Loss: 25.553571701049805\n",
      "Epoch 1511/2000, Loss: 13.329418182373047\n",
      "Epoch 1521/2000, Loss: 21.627599716186523\n",
      "Epoch 1531/2000, Loss: 16.55445671081543\n",
      "Epoch 1541/2000, Loss: 23.96039581298828\n",
      "Epoch 1551/2000, Loss: 22.72293472290039\n",
      "Epoch 1561/2000, Loss: 18.90332794189453\n",
      "Epoch 1571/2000, Loss: 10.260313987731934\n",
      "Epoch 1581/2000, Loss: 15.448887825012207\n",
      "Epoch 1591/2000, Loss: 14.489158630371094\n",
      "Epoch 1601/2000, Loss: 19.139291763305664\n",
      "Epoch 1611/2000, Loss: 8.303901672363281\n",
      "Epoch 1621/2000, Loss: 13.50149154663086\n",
      "Epoch 1631/2000, Loss: 10.628018379211426\n",
      "Epoch 1641/2000, Loss: 11.95992660522461\n",
      "Epoch 1651/2000, Loss: 9.643714904785156\n",
      "Epoch 1661/2000, Loss: 7.9605393409729\n",
      "Epoch 1671/2000, Loss: 10.626066207885742\n",
      "Epoch 1681/2000, Loss: 15.0892333984375\n",
      "Epoch 1691/2000, Loss: 17.418148040771484\n",
      "Epoch 1701/2000, Loss: 16.366024017333984\n",
      "Epoch 1711/2000, Loss: 14.227320671081543\n",
      "Epoch 1721/2000, Loss: 9.603263854980469\n",
      "Epoch 1731/2000, Loss: 18.516687393188477\n",
      "Epoch 1741/2000, Loss: 13.465505599975586\n",
      "Epoch 1751/2000, Loss: 10.184803009033203\n",
      "Epoch 1761/2000, Loss: 6.482680320739746\n",
      "Epoch 1771/2000, Loss: 9.28836727142334\n",
      "Epoch 1781/2000, Loss: 5.880981922149658\n",
      "Epoch 1791/2000, Loss: 11.730766296386719\n",
      "Epoch 1801/2000, Loss: 12.214211463928223\n",
      "Epoch 1811/2000, Loss: 8.396843910217285\n",
      "Epoch 1821/2000, Loss: 16.74677276611328\n",
      "Epoch 1831/2000, Loss: 5.89376163482666\n",
      "Epoch 1841/2000, Loss: 15.088262557983398\n",
      "Epoch 1851/2000, Loss: 4.2941670417785645\n",
      "Epoch 1861/2000, Loss: 11.546738624572754\n",
      "Epoch 1871/2000, Loss: 7.647771835327148\n",
      "Epoch 1881/2000, Loss: 8.264937400817871\n",
      "Epoch 1891/2000, Loss: 5.40401554107666\n",
      "Epoch 1901/2000, Loss: 2.8820712566375732\n",
      "Epoch 1911/2000, Loss: 9.588068962097168\n",
      "Epoch 1921/2000, Loss: 5.214689254760742\n",
      "Epoch 1931/2000, Loss: 2.6623668670654297\n",
      "Epoch 1941/2000, Loss: 6.682159423828125\n",
      "Epoch 1951/2000, Loss: 7.881987571716309\n",
      "Epoch 1961/2000, Loss: 3.980337381362915\n",
      "Epoch 1971/2000, Loss: 2.7157111167907715\n",
      "Epoch 1981/2000, Loss: 6.557764053344727\n",
      "Epoch 1991/2000, Loss: 5.364398956298828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       203\n",
      "           1       0.98      0.98      0.98       197\n",
      "\n",
      "    accuracy                           0.98       400\n",
      "   macro avg       0.98      0.98      0.98       400\n",
      "weighted avg       0.98      0.98      0.98       400\n",
      "\n",
      "Epoch 1/2000, Loss: 5385.30908203125\n",
      "Epoch 11/2000, Loss: 4841.498046875\n",
      "Epoch 21/2000, Loss: 5089.12060546875\n",
      "Epoch 31/2000, Loss: 4615.38330078125\n",
      "Epoch 41/2000, Loss: 4889.2734375\n",
      "Epoch 51/2000, Loss: 4393.6875\n",
      "Epoch 61/2000, Loss: 4431.98291015625\n",
      "Epoch 71/2000, Loss: 4111.6044921875\n",
      "Epoch 81/2000, Loss: 3833.572998046875\n",
      "Epoch 91/2000, Loss: 3195.50830078125\n",
      "Epoch 101/2000, Loss: 3710.364013671875\n",
      "Epoch 111/2000, Loss: 3707.55712890625\n",
      "Epoch 121/2000, Loss: 3971.4111328125\n",
      "Epoch 131/2000, Loss: 3625.98681640625\n",
      "Epoch 141/2000, Loss: 3099.703125\n",
      "Epoch 151/2000, Loss: 2345.888671875\n",
      "Epoch 161/2000, Loss: 2842.1162109375\n",
      "Epoch 171/2000, Loss: 2632.381591796875\n",
      "Epoch 181/2000, Loss: 2747.785888671875\n",
      "Epoch 191/2000, Loss: 2485.04443359375\n",
      "Epoch 201/2000, Loss: 1997.981689453125\n",
      "Epoch 211/2000, Loss: 2764.155517578125\n",
      "Epoch 221/2000, Loss: 2460.640869140625\n",
      "Epoch 231/2000, Loss: 2083.849609375\n",
      "Epoch 241/2000, Loss: 1831.9095458984375\n",
      "Epoch 251/2000, Loss: 2492.202392578125\n",
      "Epoch 261/2000, Loss: 1320.49169921875\n",
      "Epoch 271/2000, Loss: 1693.5626220703125\n",
      "Epoch 281/2000, Loss: 1892.2423095703125\n",
      "Epoch 291/2000, Loss: 1637.980224609375\n",
      "Epoch 301/2000, Loss: 1456.5859375\n",
      "Epoch 311/2000, Loss: 1094.8795166015625\n",
      "Epoch 321/2000, Loss: 1284.2828369140625\n",
      "Epoch 331/2000, Loss: 1604.8997802734375\n",
      "Epoch 341/2000, Loss: 1340.4822998046875\n",
      "Epoch 351/2000, Loss: 1747.8814697265625\n",
      "Epoch 361/2000, Loss: 1418.0941162109375\n",
      "Epoch 371/2000, Loss: 885.7666625976562\n",
      "Epoch 381/2000, Loss: 903.2513427734375\n",
      "Epoch 391/2000, Loss: 844.5841064453125\n",
      "Epoch 401/2000, Loss: 808.4525146484375\n",
      "Epoch 411/2000, Loss: 1199.4156494140625\n",
      "Epoch 421/2000, Loss: 717.58203125\n",
      "Epoch 431/2000, Loss: 1032.499755859375\n",
      "Epoch 441/2000, Loss: 753.9385375976562\n",
      "Epoch 451/2000, Loss: 978.53173828125\n",
      "Epoch 461/2000, Loss: 825.4343872070312\n",
      "Epoch 471/2000, Loss: 754.2442626953125\n",
      "Epoch 481/2000, Loss: 807.1002807617188\n",
      "Epoch 491/2000, Loss: 695.201904296875\n",
      "Epoch 501/2000, Loss: 695.5546875\n",
      "Epoch 511/2000, Loss: 726.4963989257812\n",
      "Epoch 521/2000, Loss: 789.1784057617188\n",
      "Epoch 531/2000, Loss: 764.4762573242188\n",
      "Epoch 541/2000, Loss: 537.2649536132812\n",
      "Epoch 551/2000, Loss: 396.3204650878906\n",
      "Epoch 561/2000, Loss: 266.78765869140625\n",
      "Epoch 571/2000, Loss: 500.6353454589844\n",
      "Epoch 581/2000, Loss: 394.47198486328125\n",
      "Epoch 591/2000, Loss: 453.06256103515625\n",
      "Epoch 601/2000, Loss: 460.4377136230469\n",
      "Epoch 611/2000, Loss: 363.430908203125\n",
      "Epoch 621/2000, Loss: 355.1074523925781\n",
      "Epoch 631/2000, Loss: 356.2559814453125\n",
      "Epoch 641/2000, Loss: 332.6241760253906\n",
      "Epoch 651/2000, Loss: 414.8856506347656\n",
      "Epoch 661/2000, Loss: 291.9292297363281\n",
      "Epoch 671/2000, Loss: 298.6498718261719\n",
      "Epoch 681/2000, Loss: 348.74395751953125\n",
      "Epoch 691/2000, Loss: 255.2135772705078\n",
      "Epoch 701/2000, Loss: 244.24232482910156\n",
      "Epoch 711/2000, Loss: 209.05702209472656\n",
      "Epoch 721/2000, Loss: 269.3035888671875\n",
      "Epoch 731/2000, Loss: 274.2713928222656\n",
      "Epoch 741/2000, Loss: 273.1814270019531\n",
      "Epoch 751/2000, Loss: 265.19390869140625\n",
      "Epoch 761/2000, Loss: 303.78997802734375\n",
      "Epoch 771/2000, Loss: 312.2457275390625\n",
      "Epoch 781/2000, Loss: 274.06097412109375\n",
      "Epoch 791/2000, Loss: 210.73294067382812\n",
      "Epoch 801/2000, Loss: 213.37132263183594\n",
      "Epoch 811/2000, Loss: 222.26202392578125\n",
      "Epoch 821/2000, Loss: 291.79656982421875\n",
      "Epoch 831/2000, Loss: 268.1794128417969\n",
      "Epoch 841/2000, Loss: 183.85186767578125\n",
      "Epoch 851/2000, Loss: 203.0284881591797\n",
      "Epoch 861/2000, Loss: 233.95433044433594\n",
      "Epoch 871/2000, Loss: 215.0502471923828\n",
      "Epoch 881/2000, Loss: 257.74139404296875\n",
      "Epoch 891/2000, Loss: 163.04489135742188\n",
      "Epoch 901/2000, Loss: 221.07786560058594\n",
      "Epoch 911/2000, Loss: 213.70986938476562\n",
      "Epoch 921/2000, Loss: 142.4099884033203\n",
      "Epoch 931/2000, Loss: 183.29286193847656\n",
      "Epoch 941/2000, Loss: 147.0505828857422\n",
      "Epoch 951/2000, Loss: 162.67098999023438\n",
      "Epoch 961/2000, Loss: 171.5563507080078\n",
      "Epoch 971/2000, Loss: 140.97872924804688\n",
      "Epoch 981/2000, Loss: 210.5880889892578\n",
      "Epoch 991/2000, Loss: 139.71661376953125\n",
      "Epoch 1001/2000, Loss: 120.97808074951172\n",
      "Epoch 1011/2000, Loss: 147.6407012939453\n",
      "Epoch 1021/2000, Loss: 153.27783203125\n",
      "Epoch 1031/2000, Loss: 122.3970947265625\n",
      "Epoch 1041/2000, Loss: 147.99237060546875\n",
      "Epoch 1051/2000, Loss: 124.57450866699219\n",
      "Epoch 1061/2000, Loss: 154.53517150878906\n",
      "Epoch 1071/2000, Loss: 141.2305908203125\n",
      "Epoch 1081/2000, Loss: 134.9903106689453\n",
      "Epoch 1091/2000, Loss: 150.3256072998047\n",
      "Epoch 1101/2000, Loss: 96.468017578125\n",
      "Epoch 1111/2000, Loss: 121.1042709350586\n",
      "Epoch 1121/2000, Loss: 134.95169067382812\n",
      "Epoch 1131/2000, Loss: 117.55704498291016\n",
      "Epoch 1141/2000, Loss: 99.9719467163086\n",
      "Epoch 1151/2000, Loss: 107.3895263671875\n",
      "Epoch 1161/2000, Loss: 100.32575988769531\n",
      "Epoch 1171/2000, Loss: 107.7162094116211\n",
      "Epoch 1181/2000, Loss: 60.53506088256836\n",
      "Epoch 1191/2000, Loss: 141.49172973632812\n",
      "Epoch 1201/2000, Loss: 127.24136352539062\n",
      "Epoch 1211/2000, Loss: 120.24974060058594\n",
      "Epoch 1221/2000, Loss: 100.8764877319336\n",
      "Epoch 1231/2000, Loss: 89.31646728515625\n",
      "Epoch 1241/2000, Loss: 88.50890350341797\n",
      "Epoch 1251/2000, Loss: 109.21924591064453\n",
      "Epoch 1261/2000, Loss: 66.4572982788086\n",
      "Epoch 1271/2000, Loss: 107.0475082397461\n",
      "Epoch 1281/2000, Loss: 82.01295471191406\n",
      "Epoch 1291/2000, Loss: 70.70223999023438\n",
      "Epoch 1301/2000, Loss: 79.79161071777344\n",
      "Epoch 1311/2000, Loss: 93.0997085571289\n",
      "Epoch 1321/2000, Loss: 86.70771789550781\n",
      "Epoch 1331/2000, Loss: 66.80821228027344\n",
      "Epoch 1341/2000, Loss: 69.22547149658203\n",
      "Epoch 1351/2000, Loss: 88.70234680175781\n",
      "Epoch 1361/2000, Loss: 50.072757720947266\n",
      "Epoch 1371/2000, Loss: 101.42506408691406\n",
      "Epoch 1381/2000, Loss: 98.0726089477539\n",
      "Epoch 1391/2000, Loss: 57.558597564697266\n",
      "Epoch 1401/2000, Loss: 75.51433563232422\n",
      "Epoch 1411/2000, Loss: 43.549991607666016\n",
      "Epoch 1421/2000, Loss: 59.07197189331055\n",
      "Epoch 1431/2000, Loss: 86.744384765625\n",
      "Epoch 1441/2000, Loss: 55.520751953125\n",
      "Epoch 1451/2000, Loss: 77.37907409667969\n",
      "Epoch 1461/2000, Loss: 56.340065002441406\n",
      "Epoch 1471/2000, Loss: 56.051544189453125\n",
      "Epoch 1481/2000, Loss: 76.55976104736328\n",
      "Epoch 1491/2000, Loss: 61.67568588256836\n",
      "Epoch 1501/2000, Loss: 92.29444885253906\n",
      "Epoch 1511/2000, Loss: 73.1912612915039\n",
      "Epoch 1521/2000, Loss: 58.99399948120117\n",
      "Epoch 1531/2000, Loss: 70.13053131103516\n",
      "Epoch 1541/2000, Loss: 37.73881912231445\n",
      "Epoch 1551/2000, Loss: 30.40586280822754\n",
      "Epoch 1561/2000, Loss: 88.83145141601562\n",
      "Epoch 1571/2000, Loss: 46.56569290161133\n",
      "Epoch 1581/2000, Loss: 36.818031311035156\n",
      "Epoch 1591/2000, Loss: 48.50528335571289\n",
      "Epoch 1601/2000, Loss: 41.22380828857422\n",
      "Epoch 1611/2000, Loss: 47.04043960571289\n",
      "Epoch 1621/2000, Loss: 39.574066162109375\n",
      "Epoch 1631/2000, Loss: 39.01408767700195\n",
      "Epoch 1641/2000, Loss: 36.51404571533203\n",
      "Epoch 1651/2000, Loss: 24.5225830078125\n",
      "Epoch 1661/2000, Loss: 44.59450149536133\n",
      "Epoch 1671/2000, Loss: 57.42668914794922\n",
      "Epoch 1681/2000, Loss: 78.45317077636719\n",
      "Epoch 1691/2000, Loss: 41.372249603271484\n",
      "Epoch 1701/2000, Loss: 35.80221939086914\n",
      "Epoch 1711/2000, Loss: 39.92239761352539\n",
      "Epoch 1721/2000, Loss: 36.10123062133789\n",
      "Epoch 1731/2000, Loss: 43.3910026550293\n",
      "Epoch 1741/2000, Loss: 47.00535202026367\n",
      "Epoch 1751/2000, Loss: 36.17338562011719\n",
      "Epoch 1761/2000, Loss: 36.77717590332031\n",
      "Epoch 1771/2000, Loss: 31.105710983276367\n",
      "Epoch 1781/2000, Loss: 27.21120834350586\n",
      "Epoch 1791/2000, Loss: 30.645172119140625\n",
      "Epoch 1801/2000, Loss: 21.002098083496094\n",
      "Epoch 1811/2000, Loss: 45.26960372924805\n",
      "Epoch 1821/2000, Loss: 28.334501266479492\n",
      "Epoch 1831/2000, Loss: 42.640525817871094\n",
      "Epoch 1841/2000, Loss: 33.630775451660156\n",
      "Epoch 1851/2000, Loss: 35.59131622314453\n",
      "Epoch 1861/2000, Loss: 25.128658294677734\n",
      "Epoch 1871/2000, Loss: 19.917943954467773\n",
      "Epoch 1881/2000, Loss: 28.027530670166016\n",
      "Epoch 1891/2000, Loss: 16.846446990966797\n",
      "Epoch 1901/2000, Loss: 25.724533081054688\n",
      "Epoch 1911/2000, Loss: 24.813968658447266\n",
      "Epoch 1921/2000, Loss: 25.120521545410156\n",
      "Epoch 1931/2000, Loss: 25.12636375427246\n",
      "Epoch 1941/2000, Loss: 20.3789005279541\n",
      "Epoch 1951/2000, Loss: 32.79059600830078\n",
      "Epoch 1961/2000, Loss: 21.998271942138672\n",
      "Epoch 1971/2000, Loss: 23.378131866455078\n",
      "Epoch 1981/2000, Loss: 30.519668579101562\n",
      "Epoch 1991/2000, Loss: 32.79018020629883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       203\n",
      "           1       0.99      0.98      0.99       197\n",
      "\n",
      "    accuracy                           0.99       400\n",
      "   macro avg       0.99      0.99      0.99       400\n",
      "weighted avg       0.99      0.99      0.99       400\n",
      "\n",
      "Epoch 1/2000, Loss: 14049.1259765625\n",
      "Epoch 11/2000, Loss: 13335.50390625\n",
      "Epoch 21/2000, Loss: 11968.6435546875\n",
      "Epoch 31/2000, Loss: 13611.52734375\n",
      "Epoch 41/2000, Loss: 10385.2216796875\n",
      "Epoch 51/2000, Loss: 10093.814453125\n",
      "Epoch 61/2000, Loss: 10065.5654296875\n",
      "Epoch 71/2000, Loss: 9918.197265625\n",
      "Epoch 81/2000, Loss: 9188.044921875\n",
      "Epoch 91/2000, Loss: 10461.208984375\n",
      "Epoch 101/2000, Loss: 9655.15625\n",
      "Epoch 111/2000, Loss: 8479.8349609375\n",
      "Epoch 121/2000, Loss: 8625.751953125\n",
      "Epoch 131/2000, Loss: 8878.046875\n",
      "Epoch 141/2000, Loss: 8350.1240234375\n",
      "Epoch 151/2000, Loss: 7490.2138671875\n",
      "Epoch 161/2000, Loss: 8051.01611328125\n",
      "Epoch 171/2000, Loss: 6625.677734375\n",
      "Epoch 181/2000, Loss: 7084.787109375\n",
      "Epoch 191/2000, Loss: 7912.2158203125\n",
      "Epoch 201/2000, Loss: 7179.48095703125\n",
      "Epoch 211/2000, Loss: 6486.7255859375\n",
      "Epoch 221/2000, Loss: 5046.37060546875\n",
      "Epoch 231/2000, Loss: 5443.2294921875\n",
      "Epoch 241/2000, Loss: 6616.93603515625\n",
      "Epoch 251/2000, Loss: 5276.0966796875\n",
      "Epoch 261/2000, Loss: 5418.412109375\n",
      "Epoch 271/2000, Loss: 3682.87451171875\n",
      "Epoch 281/2000, Loss: 4437.49658203125\n",
      "Epoch 291/2000, Loss: 2989.96044921875\n",
      "Epoch 301/2000, Loss: 5188.771484375\n",
      "Epoch 311/2000, Loss: 3174.36669921875\n",
      "Epoch 321/2000, Loss: 3468.4541015625\n",
      "Epoch 331/2000, Loss: 3937.810791015625\n",
      "Epoch 341/2000, Loss: 3150.4638671875\n",
      "Epoch 351/2000, Loss: 2376.085205078125\n",
      "Epoch 361/2000, Loss: 3073.14404296875\n",
      "Epoch 371/2000, Loss: 3031.976318359375\n",
      "Epoch 381/2000, Loss: 2273.517578125\n",
      "Epoch 391/2000, Loss: 2733.533447265625\n",
      "Epoch 401/2000, Loss: 2163.419189453125\n",
      "Epoch 411/2000, Loss: 2781.7763671875\n",
      "Epoch 421/2000, Loss: 2562.928955078125\n",
      "Epoch 431/2000, Loss: 2920.04443359375\n",
      "Epoch 441/2000, Loss: 1855.37890625\n",
      "Epoch 451/2000, Loss: 2509.34326171875\n",
      "Epoch 461/2000, Loss: 1914.409912109375\n",
      "Epoch 471/2000, Loss: 2108.058349609375\n",
      "Epoch 481/2000, Loss: 2318.952880859375\n",
      "Epoch 491/2000, Loss: 1991.05029296875\n",
      "Epoch 501/2000, Loss: 1726.0350341796875\n",
      "Epoch 511/2000, Loss: 1617.56982421875\n",
      "Epoch 521/2000, Loss: 1682.4781494140625\n",
      "Epoch 531/2000, Loss: 1799.81396484375\n",
      "Epoch 541/2000, Loss: 1657.3978271484375\n",
      "Epoch 551/2000, Loss: 1166.1541748046875\n",
      "Epoch 561/2000, Loss: 1790.7255859375\n",
      "Epoch 571/2000, Loss: 1724.7244873046875\n",
      "Epoch 581/2000, Loss: 1680.3619384765625\n",
      "Epoch 591/2000, Loss: 1370.5106201171875\n",
      "Epoch 601/2000, Loss: 1552.278076171875\n",
      "Epoch 611/2000, Loss: 1242.6451416015625\n",
      "Epoch 621/2000, Loss: 1283.6539306640625\n",
      "Epoch 631/2000, Loss: 1247.135498046875\n",
      "Epoch 641/2000, Loss: 1498.4462890625\n",
      "Epoch 651/2000, Loss: 977.486572265625\n",
      "Epoch 661/2000, Loss: 945.5867919921875\n",
      "Epoch 671/2000, Loss: 851.4573974609375\n",
      "Epoch 681/2000, Loss: 906.9623413085938\n",
      "Epoch 691/2000, Loss: 805.9122314453125\n",
      "Epoch 701/2000, Loss: 834.5402221679688\n",
      "Epoch 711/2000, Loss: 754.0123291015625\n",
      "Epoch 721/2000, Loss: 1371.089599609375\n",
      "Epoch 731/2000, Loss: 804.705078125\n",
      "Epoch 741/2000, Loss: 911.734375\n",
      "Epoch 751/2000, Loss: 823.19970703125\n",
      "Epoch 761/2000, Loss: 604.1776733398438\n",
      "Epoch 771/2000, Loss: 658.5818481445312\n",
      "Epoch 781/2000, Loss: 892.8837280273438\n",
      "Epoch 791/2000, Loss: 928.0783081054688\n",
      "Epoch 801/2000, Loss: 861.3734741210938\n",
      "Epoch 811/2000, Loss: 615.4052124023438\n",
      "Epoch 821/2000, Loss: 734.4024658203125\n",
      "Epoch 831/2000, Loss: 605.5350952148438\n",
      "Epoch 841/2000, Loss: 734.9374389648438\n",
      "Epoch 851/2000, Loss: 668.9986572265625\n",
      "Epoch 861/2000, Loss: 1014.9949340820312\n",
      "Epoch 871/2000, Loss: 520.0271606445312\n",
      "Epoch 881/2000, Loss: 574.4366455078125\n",
      "Epoch 891/2000, Loss: 663.5366821289062\n",
      "Epoch 901/2000, Loss: 463.637939453125\n",
      "Epoch 911/2000, Loss: 346.1556701660156\n",
      "Epoch 921/2000, Loss: 380.7975158691406\n",
      "Epoch 931/2000, Loss: 464.1957702636719\n",
      "Epoch 941/2000, Loss: 439.5831298828125\n",
      "Epoch 951/2000, Loss: 490.0967102050781\n",
      "Epoch 961/2000, Loss: 460.67816162109375\n",
      "Epoch 971/2000, Loss: 591.82275390625\n",
      "Epoch 981/2000, Loss: 458.7549743652344\n",
      "Epoch 991/2000, Loss: 425.46405029296875\n",
      "Epoch 1001/2000, Loss: 428.0075378417969\n",
      "Epoch 1011/2000, Loss: 328.3838195800781\n",
      "Epoch 1021/2000, Loss: 365.906982421875\n",
      "Epoch 1031/2000, Loss: 314.70281982421875\n",
      "Epoch 1041/2000, Loss: 436.4497985839844\n",
      "Epoch 1051/2000, Loss: 421.7582702636719\n",
      "Epoch 1061/2000, Loss: 407.9828796386719\n",
      "Epoch 1071/2000, Loss: 782.9656372070312\n",
      "Epoch 1081/2000, Loss: 281.6208190917969\n",
      "Epoch 1091/2000, Loss: 485.1162414550781\n",
      "Epoch 1101/2000, Loss: 317.41058349609375\n",
      "Epoch 1111/2000, Loss: 227.3523712158203\n",
      "Epoch 1121/2000, Loss: 401.2521057128906\n",
      "Epoch 1131/2000, Loss: 288.870361328125\n",
      "Epoch 1141/2000, Loss: 545.6051025390625\n",
      "Epoch 1151/2000, Loss: 319.0887145996094\n",
      "Epoch 1161/2000, Loss: 465.2930603027344\n",
      "Epoch 1171/2000, Loss: 233.37501525878906\n",
      "Epoch 1181/2000, Loss: 295.39276123046875\n",
      "Epoch 1191/2000, Loss: 304.15594482421875\n",
      "Epoch 1201/2000, Loss: 231.54559326171875\n",
      "Epoch 1211/2000, Loss: 228.29525756835938\n",
      "Epoch 1221/2000, Loss: 284.78802490234375\n",
      "Epoch 1231/2000, Loss: 270.54486083984375\n",
      "Epoch 1241/2000, Loss: 192.4846954345703\n",
      "Epoch 1251/2000, Loss: 435.7315673828125\n",
      "Epoch 1261/2000, Loss: 246.5579376220703\n",
      "Epoch 1271/2000, Loss: 208.8079376220703\n",
      "Epoch 1281/2000, Loss: 241.25439453125\n",
      "Epoch 1291/2000, Loss: 184.62939453125\n",
      "Epoch 1301/2000, Loss: 567.16845703125\n",
      "Epoch 1311/2000, Loss: 172.72821044921875\n",
      "Epoch 1321/2000, Loss: 240.4814453125\n",
      "Epoch 1331/2000, Loss: 233.33815002441406\n",
      "Epoch 1341/2000, Loss: 267.1772766113281\n",
      "Epoch 1351/2000, Loss: 411.7064514160156\n",
      "Epoch 1361/2000, Loss: 181.38211059570312\n",
      "Epoch 1371/2000, Loss: 202.54356384277344\n",
      "Epoch 1381/2000, Loss: 333.9091491699219\n",
      "Epoch 1391/2000, Loss: 355.6788330078125\n",
      "Epoch 1401/2000, Loss: 211.95718383789062\n",
      "Epoch 1411/2000, Loss: 225.53892517089844\n",
      "Epoch 1421/2000, Loss: 371.4459533691406\n",
      "Epoch 1431/2000, Loss: 560.3663330078125\n",
      "Epoch 1441/2000, Loss: 220.19004821777344\n",
      "Epoch 1451/2000, Loss: 197.0266571044922\n",
      "Epoch 1461/2000, Loss: 469.9945983886719\n",
      "Epoch 1471/2000, Loss: 143.5186309814453\n",
      "Epoch 1481/2000, Loss: 232.71902465820312\n",
      "Epoch 1491/2000, Loss: 493.334228515625\n",
      "Epoch 1501/2000, Loss: 204.50401306152344\n",
      "Epoch 1511/2000, Loss: 240.82032775878906\n",
      "Epoch 1521/2000, Loss: 415.00921630859375\n",
      "Epoch 1531/2000, Loss: 218.38197326660156\n",
      "Epoch 1541/2000, Loss: 166.30162048339844\n",
      "Epoch 1551/2000, Loss: 105.60041046142578\n",
      "Epoch 1561/2000, Loss: 165.1538543701172\n",
      "Epoch 1571/2000, Loss: 97.38816833496094\n",
      "Epoch 1581/2000, Loss: 171.3306427001953\n",
      "Epoch 1591/2000, Loss: 426.0337219238281\n",
      "Epoch 1601/2000, Loss: 162.478271484375\n",
      "Epoch 1611/2000, Loss: 306.4425964355469\n",
      "Epoch 1621/2000, Loss: 202.1402587890625\n",
      "Epoch 1631/2000, Loss: 127.47268676757812\n",
      "Epoch 1641/2000, Loss: 167.26690673828125\n",
      "Epoch 1651/2000, Loss: 259.2273864746094\n",
      "Epoch 1661/2000, Loss: 209.5280303955078\n",
      "Epoch 1671/2000, Loss: 137.07901000976562\n",
      "Epoch 1681/2000, Loss: 146.4068603515625\n",
      "Epoch 1691/2000, Loss: 106.68611907958984\n",
      "Epoch 1701/2000, Loss: 116.3388442993164\n",
      "Epoch 1711/2000, Loss: 126.84611511230469\n",
      "Epoch 1721/2000, Loss: 65.7525863647461\n",
      "Epoch 1731/2000, Loss: 113.072998046875\n",
      "Epoch 1741/2000, Loss: 98.16206359863281\n",
      "Epoch 1751/2000, Loss: 197.29249572753906\n",
      "Epoch 1761/2000, Loss: 114.73230743408203\n",
      "Epoch 1771/2000, Loss: 117.82722473144531\n",
      "Epoch 1781/2000, Loss: 77.52359771728516\n",
      "Epoch 1791/2000, Loss: 280.1910095214844\n",
      "Epoch 1801/2000, Loss: 77.29718017578125\n",
      "Epoch 1811/2000, Loss: 55.390506744384766\n",
      "Epoch 1821/2000, Loss: 190.49578857421875\n",
      "Epoch 1831/2000, Loss: 439.0535583496094\n",
      "Epoch 1841/2000, Loss: 59.453617095947266\n",
      "Epoch 1851/2000, Loss: 73.94527435302734\n",
      "Epoch 1861/2000, Loss: 77.70411682128906\n",
      "Epoch 1871/2000, Loss: 73.11656951904297\n",
      "Epoch 1881/2000, Loss: 142.31858825683594\n",
      "Epoch 1891/2000, Loss: 364.32867431640625\n",
      "Epoch 1901/2000, Loss: 117.57157897949219\n",
      "Epoch 1911/2000, Loss: 392.5680847167969\n",
      "Epoch 1921/2000, Loss: 98.72525787353516\n",
      "Epoch 1931/2000, Loss: 436.0068664550781\n",
      "Epoch 1941/2000, Loss: 125.63147735595703\n",
      "Epoch 1951/2000, Loss: 48.720977783203125\n",
      "Epoch 1961/2000, Loss: 77.52764892578125\n",
      "Epoch 1971/2000, Loss: 225.71347045898438\n",
      "Epoch 1981/2000, Loss: 67.03248596191406\n",
      "Epoch 1991/2000, Loss: 80.4708023071289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       203\n",
      "           1       0.98      0.98      0.98       197\n",
      "\n",
      "    accuracy                           0.98       400\n",
      "   macro avg       0.98      0.98      0.98       400\n",
      "weighted avg       0.98      0.98      0.98       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_saved_result = True\n",
    "save_model = False\n",
    "model_list = []\n",
    "for num_dimension in [5, 10, 20]:\n",
    "    yn_train, yn_test, ys_train, ys_test, labels_train, labels_test, orig_dataset = create_dataset(num_dimension=num_dimension,\n",
    "                                                                                                   random_state= model_settings['random_state'],\n",
    "                                                                                                   test_size=model_settings['test_size'],\n",
    "                                                                                                   n_samples=model_settings['num_samples'])\n",
    "    model_settings['data_dim'] = yn_train.shape[-1]\n",
    "    batch_shape = torch.Size([model_settings['data_dim']])\n",
    "    if load_saved_result is False:\n",
    "        model = create_LDGD_model(yn_train, ys_train, model_settings, batch_shape=batch_shape, x_init='pca')\n",
    "\n",
    "        losses, history_train = model.train_model(yn=yn_train, ys=ys_train,\n",
    "                                                  epochs=model_settings['num_epochs_train'],\n",
    "                                                  batch_size=model_settings['batch_size'])\n",
    "        if save_model is True:\n",
    "            model.save_wights(path_save='./saved_models/', file_name=f\"model_synthetic_{num_dimension}\")\n",
    "        predictions, metrics, history_test = model.evaluate(yn_test=yn_test, ys_test=labels_test,\n",
    "                                                        epochs=model_settings['num_epochs_test'])\n",
    "\n",
    "        winsound.Beep(freq, duration)\n",
    "    else:\n",
    "        model = create_LDGD_model(yn_train, ys_train, model_settings, batch_shape=batch_shape)\n",
    "        model.load_weights(path_save='./saved_models/', file_name=f'model_synthetic_{num_dimension}.pth')\n",
    "        predictions, metrics, history_test = model.evaluate(yn_test=yn_test, ys_test=labels_test,\n",
    "                                                        epochs=model_settings['num_epochs_test'])\n",
    "    model_list.append(model)\n",
    "\n",
    "winsound.Beep(freq, duration*3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T23:23:29.688198500Z",
     "start_time": "2024-02-20T23:21:27.730297Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 visualize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " D:\\Navid\\Projects\\LDGD\\src\\LDGD\\visualization\\vizualize_utils.py:298: UserWarning:The following kwargs were not used by contour: 'label'\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 3200x800 with 7 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,4, figsize=(32, 8))\n",
    "x_org, y_org = orig_dataset\n",
    "plot_2d_scatter(x_org, y_org, ax = axs[0])\n",
    "# [left, bottom, width, height]\n",
    "for idx , model in enumerate(model_list):\n",
    "    alpha_reg = 1 / model.kernel_reg.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "    alpha_cls = 1 / model.kernel_cls.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "\n",
    "    x = model.x.q_mu.cpu().detach().numpy()\n",
    "    std = torch.nn.functional.softplus(model.x.q_log_sigma).cpu().detach().numpy()\n",
    "\n",
    "    x_test = model.x_test.q_mu.cpu().detach().numpy()\n",
    "    std_test = torch.nn.functional.softplus(model.x_test.q_log_sigma).cpu().detach().numpy()\n",
    "\n",
    "    inducing_points = (history_test['z_list_reg'][-1], history_test['z_list_cls'][-1])\n",
    "\n",
    "    plot_heatmap(x, labels_train, model, alpha_cls, cmap='binary', range_scale=1.2,\n",
    "             file_name='latent_heatmap_train', inducing_points=inducing_points, ax1=axs[idx+1], fig=fig, heat_map_mode='std')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"./saved_results/Compare_synthetic.png\")\n",
    "fig.savefig(\"./saved_results/Compare_synthetic.svg\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T23:23:32.374809300Z",
     "start_time": "2024-02-20T23:23:29.689213100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross validation on Synthetic data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Dim 5 Fold 0 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00       159\n",
      "         1.0       0.99      1.00      1.00       141\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 5 Fold 1 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       157\n",
      "         1.0       1.00      1.00      1.00       143\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 5 Fold 2 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       154\n",
      "         1.0       1.00      1.00      1.00       146\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 5 Fold 3 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       150\n",
      "         1.0       1.00      0.99      1.00       150\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 5 Fold 4 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       130\n",
      "         1.0       1.00      0.99      1.00       170\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 10 Fold 0 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       159\n",
      "         1.0       1.00      1.00      1.00       141\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 10 Fold 1 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       157\n",
      "         1.0       1.00      1.00      1.00       143\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 10 Fold 2 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00       154\n",
      "         1.0       0.99      1.00      1.00       146\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 10 Fold 3 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       150\n",
      "         1.0       1.00      0.99      1.00       150\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 10 Fold 4 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       130\n",
      "         1.0       1.00      0.99      1.00       170\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 20 Fold 0 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       159\n",
      "         1.0       1.00      1.00      1.00       141\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 20 Fold 1 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00       157\n",
      "         1.0       0.99      1.00      1.00       143\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 20 Fold 2 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00       154\n",
      "         1.0       0.99      1.00      1.00       146\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 20 Fold 3 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       150\n",
      "         1.0       1.00      1.00      1.00       150\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "=============== Dim 20 Fold 4 ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       130\n",
      "         1.0       1.00      0.99      1.00       170\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "        dataset    precision       recall      f score\n",
      "0  synthetic 10  1.00 ± 0.00  1.00 ± 0.00  1.00 ± 0.00\n",
      "1  synthetic 20  1.00 ± 0.00  1.00 ± 0.00  1.00 ± 0.00\n",
      "2  synthetic 40  1.00 ± 0.00  1.00 ± 0.00  1.00 ± 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": "        dataset    precision       recall      f score\n0  synthetic 10  1.00 ± 0.00  1.00 ± 0.00  1.00 ± 0.00\n1  synthetic 20  1.00 ± 0.00  1.00 ± 0.00  1.00 ± 0.00\n2  synthetic 40  1.00 ± 0.00  1.00 ± 0.00  1.00 ± 0.00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>synthetic 10</td>\n      <td>1.00 ± 0.00</td>\n      <td>1.00 ± 0.00</td>\n      <td>1.00 ± 0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>synthetic 20</td>\n      <td>1.00 ± 0.00</td>\n      <td>1.00 ± 0.00</td>\n      <td>1.00 ± 0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>synthetic 40</td>\n      <td>1.00 ± 0.00</td>\n      <td>1.00 ± 0.00</td>\n      <td>1.00 ± 0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_settings = {\n",
    "    'latent_dim': 2,\n",
    "    'num_inducing_points': 5,\n",
    "    'num_inducing_points_reg': 8,\n",
    "    'num_inducing_points_cls': 8,\n",
    "    'num_epochs_train': 7000,\n",
    "    'num_epochs_test': 5000,\n",
    "    'batch_size': 100,\n",
    "    'load_trained_model': False,\n",
    "    'load_tested_model': False,\n",
    "    'dataset': 'synthetic',\n",
    "    'shared_inducing_points': True,\n",
    "    'use_gpytorch': True,\n",
    "    'random_state': 65,\n",
    "    'test_size': 0.8,\n",
    "    'cls_weight': 1.0,\n",
    "    'reg_weight': 1.0,\n",
    "    'num_samples': 500,\n",
    "\n",
    "}\n",
    "cross_validate_model(n_dim=[5, 10, 20], settings=model_settings, n_splits=5, load_saved_result=False, save_model=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T01:02:05.417711400Z",
     "start_time": "2024-02-20T23:24:57.129192800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2: Train Model with larger Latent Dimension\n",
    "## 2.1 Settings:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model_settings = {\n",
    "    'latent_dim': 10,\n",
    "    'num_inducing_points_reg': 25,\n",
    "    'num_inducing_points_cls': 25,\n",
    "    'num_epochs_train': 20000,\n",
    "    'num_epochs_test': 20000,\n",
    "    'batch_size': 100,\n",
    "    'load_trained_model': False,\n",
    "    'load_tested_model': False,\n",
    "    'dataset': 'synthetic',\n",
    "    'shared_inducing_points': False,\n",
    "    'use_gpytorch': True,\n",
    "    'random_state': 54,\n",
    "    'test_size': 0.2\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T23:24:34.873380700Z",
     "start_time": "2024-02-20T23:24:34.479995900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.2 Training model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "load_saved_result = True\n",
    "yn_train, yn_test, ys_train, ys_test, labels_train, labels_test, orig_dataset = create_dataset(num_dimension=10,\n",
    "                                                                                               random_state= model_settings['random_state'],\n",
    "                                                                                               test_size=model_settings['test_size'])\n",
    "model_settings['data_dim'] = yn_train.shape[-1]\n",
    "model_settings['latent_dim'] = 10\n",
    "batch_shape = torch.Size([model_settings['data_dim']])\n",
    "\n",
    "\n",
    "model = create_LDGD_model(yn_train, ys_train, model_settings, x_init='pca')\n",
    "\n",
    "if load_saved_result is False:\n",
    "    losses, history_train = model.train_model(yn=yn_train, ys=ys_train,\n",
    "                                              epochs=model_settings['num_epochs_train'],\n",
    "                                              batch_size=model_settings['batch_size'])\n",
    "    winsound.Beep(freq, duration*3)\n",
    "    model.save_wights(path_save='', file_name=f'model_task2.pth')\n",
    "else:\n",
    "    model.load_weights(path_save='', file_name=f'model_task2.pth')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Evaluating model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "predictions, metrics, history_test = model.evaluate(yn_test=yn_test, ys_test=labels_test,\n",
    "                                                epochs=5000)\n",
    "\n",
    "alpha_reg = 1 / model.kernel_reg.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "alpha_cls = 1 / model.kernel_cls.base_kernel.lengthscale.cpu().detach().numpy()\n",
    "\n",
    "x = model.x.q_mu.cpu().detach().numpy()\n",
    "std = torch.nn.functional.softplus(model.x.q_log_sigma).cpu().detach().numpy()\n",
    "\n",
    "x_test = model.x_test.q_mu.cpu().detach().numpy()\n",
    "std_test = torch.nn.functional.softplus(model.x_test.q_log_sigma).cpu().detach().numpy()\n",
    "winsound.Beep(freq, duration*3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 Visualizing results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = x.shape[-1]\n",
    "values, indices = torch.topk(torch.tensor(alpha_cls), k=2, largest=True)\n",
    "l1 = indices.numpy().flatten()[0]\n",
    "l2 = indices.numpy().flatten()[1]\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(32, 8))\n",
    "\n",
    "\n",
    "plot_loss_gplvm(losses, ax=axs[0])\n",
    "plot_ARD_gplvm(latent_dim, alpha_cls, ax=axs[2])\n",
    "plot_ARD_gplvm(latent_dim, alpha_reg, ax=axs[1])\n",
    "plot_scatter_gplvm(x, labels_train, l1=l1, l2=l2, ax=axs[3], colors=['r', 'b', 'g'], show_errorbars=True, std=std)\n",
    "plot_scatter_gplvm(x_test, labels_test, l1=l1, l2=l2, ax=axs[4], colors=['r', 'b', 'g'], show_errorbars=True, std=std_test)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"ARD_synthetic.png\")\n",
    "fig.savefig(\"ARD_synthetic.svg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3: Compare LDGD Results with VAE\n",
    "## 3.1 Settings:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model_settings = {\n",
    "    'latent_dim': 2,\n",
    "    'num_inducing_points_reg': 5,\n",
    "    'num_inducing_points_cls': 5,\n",
    "    'num_epochs_train': 10000,\n",
    "    'num_epochs_test': 5000,\n",
    "    'batch_size': 100,\n",
    "    'load_trained_model': False,\n",
    "    'load_tested_model': False,\n",
    "    'dataset': 'synthetic',\n",
    "    'shared_inducing_points': True,\n",
    "    'use_gpytorch': True,\n",
    "    'random_state': 54,\n",
    "    'test_size': 0.3,\n",
    "    'use_shared_kernel': False\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T01:36:11.326080500Z",
     "start_time": "2024-02-21T01:36:11.199078Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Create Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 1050\n",
      "test size = 450\n"
     ]
    }
   ],
   "source": [
    "yn_train, yn_test, ys_train, ys_test, labels_train, labels_test, orig_dataset = create_dataset(num_dimension=10,\n",
    "                                                                                               random_state= model_settings['random_state'],\n",
    "                                                                                               test_size=model_settings['test_size'])\n",
    "\n",
    "print(f\"train size = {yn_train.shape[0]}\")\n",
    "print(f\"test size = {ys_test.shape[0]}\")\n",
    "\n",
    "list_size = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "load_saved_result = False\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T01:36:13.005368100Z",
     "start_time": "2024-02-21T01:36:12.878832Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Training model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for sample size: 10\n",
      "\tEpoch 1: \tAverage Loss:  0.08857818603515626\t ACC train:  0.5\t ACC test:  0.4866666666666667\n",
      "\tEpoch 2: \tAverage Loss:  0.0881296844482422\t ACC train:  0.5\t ACC test:  0.4866666666666667\n",
      "\tEpoch 3: \tAverage Loss:  0.08747561645507812\t ACC train:  0.5\t ACC test:  0.4866666666666667\n",
      "\tEpoch 4: \tAverage Loss:  0.08674281311035156\t ACC train:  0.5\t ACC test:  0.4866666666666667\n",
      "\tEpoch 5: \tAverage Loss:  0.08614359283447266\t ACC train:  0.5\t ACC test:  0.48444444444444446\n",
      "\tEpoch 6: \tAverage Loss:  0.08537873840332032\t ACC train:  0.5\t ACC test:  0.4822222222222222\n",
      "\tEpoch 7: \tAverage Loss:  0.08533122253417968\t ACC train:  0.5\t ACC test:  0.4866666666666667\n",
      "\tEpoch 8: \tAverage Loss:  0.08432003784179687\t ACC train:  0.7\t ACC test:  0.5\n",
      "\tEpoch 9: \tAverage Loss:  0.08438599395751953\t ACC train:  0.5\t ACC test:  0.48444444444444446\n",
      "\tEpoch 10: \tAverage Loss:  0.08345024108886719\t ACC train:  0.3\t ACC test:  0.5022222222222222\n",
      "\tEpoch 11: \tAverage Loss:  0.0833746337890625\t ACC train:  0.5\t ACC test:  0.4822222222222222\n",
      "\tEpoch 12: \tAverage Loss:  0.08328465270996094\t ACC train:  0.1\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  0.08239570617675782\t ACC train:  0.5\t ACC test:  0.5044444444444445\n",
      "\tEpoch 14: \tAverage Loss:  0.08211361694335938\t ACC train:  0.2\t ACC test:  0.4955555555555556\n",
      "\tEpoch 15: \tAverage Loss:  0.08182412719726563\t ACC train:  0.6\t ACC test:  0.4822222222222222\n",
      "\tEpoch 16: \tAverage Loss:  0.08153717041015625\t ACC train:  0.7\t ACC test:  0.49777777777777776\n",
      "\tEpoch 17: \tAverage Loss:  0.08109638214111328\t ACC train:  0.6\t ACC test:  0.5\n",
      "\tEpoch 18: \tAverage Loss:  0.08084404754638672\t ACC train:  0.7\t ACC test:  0.5111111111111111\n",
      "\tEpoch 19: \tAverage Loss:  0.08113169097900391\t ACC train:  0.6\t ACC test:  0.5355555555555556\n",
      "\tEpoch 20: \tAverage Loss:  0.08021520233154297\t ACC train:  0.5\t ACC test:  0.52\n",
      "\tEpoch 21: \tAverage Loss:  0.08021223449707031\t ACC train:  0.4\t ACC test:  0.5066666666666667\n",
      "\tEpoch 22: \tAverage Loss:  0.07984158325195312\t ACC train:  0.4\t ACC test:  0.47555555555555556\n",
      "\tEpoch 23: \tAverage Loss:  0.07959612274169922\t ACC train:  0.4\t ACC test:  0.5111111111111111\n",
      "\tEpoch 24: \tAverage Loss:  0.07992603302001954\t ACC train:  0.6\t ACC test:  0.49777777777777776\n",
      "\tEpoch 25: \tAverage Loss:  0.0794033432006836\t ACC train:  0.7\t ACC test:  0.5088888888888888\n",
      "\tEpoch 26: \tAverage Loss:  0.07904290771484375\t ACC train:  0.4\t ACC test:  0.5311111111111111\n",
      "\tEpoch 27: \tAverage Loss:  0.07904121398925781\t ACC train:  0.5\t ACC test:  0.4911111111111111\n",
      "\tEpoch 28: \tAverage Loss:  0.0792390594482422\t ACC train:  0.5\t ACC test:  0.4955555555555556\n",
      "\tEpoch 29: \tAverage Loss:  0.07886472320556641\t ACC train:  0.6\t ACC test:  0.5044444444444445\n",
      "\tEpoch 30: \tAverage Loss:  0.07838361358642579\t ACC train:  0.3\t ACC test:  0.5022222222222222\n",
      "\tEpoch 31: \tAverage Loss:  0.07850070190429688\t ACC train:  0.4\t ACC test:  0.5044444444444445\n",
      "\tEpoch 32: \tAverage Loss:  0.07795662689208985\t ACC train:  0.7\t ACC test:  0.5044444444444445\n",
      "\tEpoch 33: \tAverage Loss:  0.07823837280273438\t ACC train:  0.4\t ACC test:  0.5044444444444445\n",
      "\tEpoch 34: \tAverage Loss:  0.07787611389160157\t ACC train:  0.5\t ACC test:  0.5333333333333333\n",
      "\tEpoch 35: \tAverage Loss:  0.07756926727294922\t ACC train:  0.4\t ACC test:  0.5133333333333333\n",
      "\tEpoch 36: \tAverage Loss:  0.0779283447265625\t ACC train:  0.6\t ACC test:  0.5355555555555556\n",
      "\tEpoch 37: \tAverage Loss:  0.07782378387451172\t ACC train:  0.5\t ACC test:  0.5133333333333333\n",
      "\tEpoch 38: \tAverage Loss:  0.07738151550292968\t ACC train:  0.5\t ACC test:  0.5177777777777778\n",
      "\tEpoch 39: \tAverage Loss:  0.07731587219238281\t ACC train:  0.6\t ACC test:  0.5155555555555555\n",
      "\tEpoch 40: \tAverage Loss:  0.07729238891601563\t ACC train:  0.7\t ACC test:  0.5355555555555556\n",
      "\tEpoch 41: \tAverage Loss:  0.07720095825195313\t ACC train:  0.5\t ACC test:  0.5111111111111111\n",
      "\tEpoch 42: \tAverage Loss:  0.07693832397460937\t ACC train:  0.2\t ACC test:  0.4822222222222222\n",
      "\tEpoch 43: \tAverage Loss:  0.07692858123779298\t ACC train:  0.6\t ACC test:  0.4688888888888889\n",
      "\tEpoch 44: \tAverage Loss:  0.07674322509765626\t ACC train:  0.3\t ACC test:  0.48444444444444446\n",
      "\tEpoch 45: \tAverage Loss:  0.07664354705810547\t ACC train:  0.6\t ACC test:  0.5266666666666666\n",
      "\tEpoch 46: \tAverage Loss:  0.07662871551513672\t ACC train:  0.4\t ACC test:  0.5111111111111111\n",
      "\tEpoch 47: \tAverage Loss:  0.07647764587402343\t ACC train:  0.3\t ACC test:  0.5377777777777778\n",
      "\tEpoch 48: \tAverage Loss:  0.07610160064697266\t ACC train:  0.4\t ACC test:  0.45111111111111113\n",
      "\tEpoch 49: \tAverage Loss:  0.07649691772460937\t ACC train:  0.4\t ACC test:  0.5155555555555555\n",
      "\tEpoch 50: \tAverage Loss:  0.07622510528564454\t ACC train:  0.6\t ACC test:  0.4711111111111111\n",
      "\tEpoch 51: \tAverage Loss:  0.07586373901367187\t ACC train:  0.6\t ACC test:  0.49333333333333335\n",
      "\tEpoch 52: \tAverage Loss:  0.07582372283935547\t ACC train:  0.4\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.0759852523803711\t ACC train:  0.2\t ACC test:  0.5022222222222222\n",
      "\tEpoch 54: \tAverage Loss:  0.07572307586669921\t ACC train:  0.4\t ACC test:  0.5\n",
      "\tEpoch 55: \tAverage Loss:  0.07558943939208984\t ACC train:  0.6\t ACC test:  0.5\n",
      "\tEpoch 56: \tAverage Loss:  0.07583480072021484\t ACC train:  0.8\t ACC test:  0.5044444444444445\n",
      "\tEpoch 57: \tAverage Loss:  0.07551083374023437\t ACC train:  0.4\t ACC test:  0.5044444444444445\n",
      "\tEpoch 58: \tAverage Loss:  0.07567427825927735\t ACC train:  0.5\t ACC test:  0.4711111111111111\n",
      "\tEpoch 59: \tAverage Loss:  0.07538092041015625\t ACC train:  0.4\t ACC test:  0.52\n",
      "\tEpoch 60: \tAverage Loss:  0.07523088836669922\t ACC train:  0.7\t ACC test:  0.5155555555555555\n",
      "\tEpoch 61: \tAverage Loss:  0.075182861328125\t ACC train:  0.4\t ACC test:  0.5\n",
      "\tEpoch 62: \tAverage Loss:  0.07474177551269531\t ACC train:  0.6\t ACC test:  0.5155555555555555\n",
      "\tEpoch 63: \tAverage Loss:  0.07514290618896484\t ACC train:  0.6\t ACC test:  0.5177777777777778\n",
      "\tEpoch 64: \tAverage Loss:  0.07514675903320313\t ACC train:  0.4\t ACC test:  0.5\n",
      "\tEpoch 65: \tAverage Loss:  0.07533645629882812\t ACC train:  0.3\t ACC test:  0.5066666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.07479955291748047\t ACC train:  0.6\t ACC test:  0.5288888888888889\n",
      "\tEpoch 67: \tAverage Loss:  0.0751393585205078\t ACC train:  0.3\t ACC test:  0.5088888888888888\n",
      "\tEpoch 68: \tAverage Loss:  0.07476845550537109\t ACC train:  0.9\t ACC test:  0.5\n",
      "\tEpoch 69: \tAverage Loss:  0.07446726226806641\t ACC train:  0.3\t ACC test:  0.5377777777777778\n",
      "\tEpoch 70: \tAverage Loss:  0.075072021484375\t ACC train:  0.5\t ACC test:  0.5022222222222222\n",
      "\tEpoch 71: \tAverage Loss:  0.07459153747558593\t ACC train:  0.4\t ACC test:  0.49777777777777776\n",
      "\tEpoch 72: \tAverage Loss:  0.07492730712890625\t ACC train:  0.4\t ACC test:  0.5155555555555555\n",
      "\tEpoch 73: \tAverage Loss:  0.07481918334960938\t ACC train:  0.8\t ACC test:  0.5288888888888889\n",
      "\tEpoch 74: \tAverage Loss:  0.07431417846679687\t ACC train:  0.4\t ACC test:  0.5222222222222223\n",
      "\tEpoch 75: \tAverage Loss:  0.07393115234375\t ACC train:  0.3\t ACC test:  0.5\n",
      "\tEpoch 76: \tAverage Loss:  0.07462139892578125\t ACC train:  0.4\t ACC test:  0.5022222222222222\n",
      "\tEpoch 77: \tAverage Loss:  0.07436512756347656\t ACC train:  0.4\t ACC test:  0.5022222222222222\n",
      "\tEpoch 78: \tAverage Loss:  0.07367408752441407\t ACC train:  0.7\t ACC test:  0.5111111111111111\n",
      "\tEpoch 79: \tAverage Loss:  0.07423554992675781\t ACC train:  0.5\t ACC test:  0.5066666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.0741694107055664\t ACC train:  0.7\t ACC test:  0.5466666666666666\n",
      "\tEpoch 81: \tAverage Loss:  0.07406700897216797\t ACC train:  0.4\t ACC test:  0.5311111111111111\n",
      "\tEpoch 82: \tAverage Loss:  0.07396054077148438\t ACC train:  0.4\t ACC test:  0.5177777777777778\n",
      "\tEpoch 83: \tAverage Loss:  0.07383529663085937\t ACC train:  0.7\t ACC test:  0.5444444444444444\n",
      "\tEpoch 84: \tAverage Loss:  0.07407761383056641\t ACC train:  0.5\t ACC test:  0.5244444444444445\n",
      "\tEpoch 85: \tAverage Loss:  0.0735285873413086\t ACC train:  0.3\t ACC test:  0.5133333333333333\n",
      "\tEpoch 86: \tAverage Loss:  0.07383287048339844\t ACC train:  0.4\t ACC test:  0.5266666666666666\n",
      "\tEpoch 87: \tAverage Loss:  0.07373131561279297\t ACC train:  0.7\t ACC test:  0.5\n",
      "\tEpoch 88: \tAverage Loss:  0.07339517974853516\t ACC train:  0.3\t ACC test:  0.5511111111111111\n",
      "\tEpoch 89: \tAverage Loss:  0.07403907775878907\t ACC train:  0.5\t ACC test:  0.5\n",
      "\tEpoch 90: \tAverage Loss:  0.07358319091796875\t ACC train:  0.6\t ACC test:  0.52\n",
      "\tEpoch 91: \tAverage Loss:  0.0732188949584961\t ACC train:  0.6\t ACC test:  0.5177777777777778\n",
      "\tEpoch 92: \tAverage Loss:  0.07320413970947266\t ACC train:  0.5\t ACC test:  0.5288888888888889\n",
      "\tEpoch 93: \tAverage Loss:  0.07344209289550781\t ACC train:  0.5\t ACC test:  0.5355555555555556\n",
      "\tEpoch 94: \tAverage Loss:  0.07356317901611328\t ACC train:  0.6\t ACC test:  0.54\n",
      "\tEpoch 95: \tAverage Loss:  0.07361760711669922\t ACC train:  0.2\t ACC test:  0.5444444444444444\n",
      "\tEpoch 96: \tAverage Loss:  0.0732821044921875\t ACC train:  0.5\t ACC test:  0.5288888888888889\n",
      "\tEpoch 97: \tAverage Loss:  0.07336365509033203\t ACC train:  0.7\t ACC test:  0.5311111111111111\n",
      "\tEpoch 98: \tAverage Loss:  0.07339098358154297\t ACC train:  0.4\t ACC test:  0.49777777777777776\n",
      "\tEpoch 99: \tAverage Loss:  0.07293656158447266\t ACC train:  0.4\t ACC test:  0.54\n",
      "\tEpoch 100: \tAverage Loss:  0.07271977233886719\t ACC train:  0.5\t ACC test:  0.5288888888888889\n",
      "\tEpoch 101: \tAverage Loss:  0.07325289916992188\t ACC train:  0.6\t ACC test:  0.5133333333333333\n",
      "\tEpoch 102: \tAverage Loss:  0.0731848373413086\t ACC train:  0.5\t ACC test:  0.5222222222222223\n",
      "\tEpoch 103: \tAverage Loss:  0.07277749633789063\t ACC train:  0.7\t ACC test:  0.5\n",
      "\tEpoch 104: \tAverage Loss:  0.07266647338867188\t ACC train:  0.5\t ACC test:  0.5377777777777778\n",
      "\tEpoch 105: \tAverage Loss:  0.07312278747558594\t ACC train:  0.7\t ACC test:  0.5022222222222222\n",
      "\tEpoch 106: \tAverage Loss:  0.07270162200927735\t ACC train:  0.4\t ACC test:  0.5044444444444445\n",
      "\tEpoch 107: \tAverage Loss:  0.07300691986083985\t ACC train:  0.4\t ACC test:  0.5177777777777778\n",
      "\tEpoch 108: \tAverage Loss:  0.07298926544189453\t ACC train:  0.5\t ACC test:  0.5133333333333333\n",
      "\tEpoch 109: \tAverage Loss:  0.0730819320678711\t ACC train:  0.5\t ACC test:  0.52\n",
      "\tEpoch 110: \tAverage Loss:  0.07261888885498047\t ACC train:  0.5\t ACC test:  0.5088888888888888\n",
      "\tEpoch 111: \tAverage Loss:  0.07239244842529297\t ACC train:  0.4\t ACC test:  0.5377777777777778\n",
      "\tEpoch 112: \tAverage Loss:  0.0728241729736328\t ACC train:  0.4\t ACC test:  0.5177777777777778\n",
      "\tEpoch 113: \tAverage Loss:  0.07229001617431641\t ACC train:  0.6\t ACC test:  0.4888888888888889\n",
      "\tEpoch 114: \tAverage Loss:  0.07291975402832031\t ACC train:  0.5\t ACC test:  0.4888888888888889\n",
      "\tEpoch 115: \tAverage Loss:  0.07238507843017578\t ACC train:  0.4\t ACC test:  0.5177777777777778\n",
      "\tEpoch 116: \tAverage Loss:  0.07260531616210937\t ACC train:  0.5\t ACC test:  0.5\n",
      "\tEpoch 117: \tAverage Loss:  0.07236988830566406\t ACC train:  0.7\t ACC test:  0.5022222222222222\n",
      "\tEpoch 118: \tAverage Loss:  0.07218551635742188\t ACC train:  0.7\t ACC test:  0.5222222222222223\n",
      "\tEpoch 119: \tAverage Loss:  0.0721498565673828\t ACC train:  0.7\t ACC test:  0.49777777777777776\n",
      "\tEpoch 120: \tAverage Loss:  0.07255592346191406\t ACC train:  0.6\t ACC test:  0.49777777777777776\n",
      "\tEpoch 121: \tAverage Loss:  0.07224015045166016\t ACC train:  0.5\t ACC test:  0.4822222222222222\n",
      "\tEpoch 122: \tAverage Loss:  0.07213546752929688\t ACC train:  0.6\t ACC test:  0.5111111111111111\n",
      "\tEpoch 123: \tAverage Loss:  0.07180149078369141\t ACC train:  0.6\t ACC test:  0.5111111111111111\n",
      "\tEpoch 124: \tAverage Loss:  0.07212419128417968\t ACC train:  0.7\t ACC test:  0.5111111111111111\n",
      "\tEpoch 125: \tAverage Loss:  0.07220936584472656\t ACC train:  0.5\t ACC test:  0.4888888888888889\n",
      "\tEpoch 126: \tAverage Loss:  0.07200013732910156\t ACC train:  0.6\t ACC test:  0.49777777777777776\n",
      "\tEpoch 127: \tAverage Loss:  0.07160683441162109\t ACC train:  0.3\t ACC test:  0.45111111111111113\n",
      "\tEpoch 128: \tAverage Loss:  0.07105208587646485\t ACC train:  0.4\t ACC test:  0.47333333333333333\n",
      "\tEpoch 129: \tAverage Loss:  0.07229582214355469\t ACC train:  0.5\t ACC test:  0.47555555555555556\n",
      "\tEpoch 130: \tAverage Loss:  0.07272052001953125\t ACC train:  0.5\t ACC test:  0.4711111111111111\n",
      "\tEpoch 131: \tAverage Loss:  0.07119950866699219\t ACC train:  0.5\t ACC test:  0.49777777777777776\n",
      "\tEpoch 132: \tAverage Loss:  0.07211003875732422\t ACC train:  0.7\t ACC test:  0.47333333333333333\n",
      "\tEpoch 133: \tAverage Loss:  0.07212618255615234\t ACC train:  0.4\t ACC test:  0.44666666666666666\n",
      "\tEpoch 134: \tAverage Loss:  0.07134003448486329\t ACC train:  0.8\t ACC test:  0.4666666666666667\n",
      "\tEpoch 135: \tAverage Loss:  0.07203092193603515\t ACC train:  0.4\t ACC test:  0.49333333333333335\n",
      "\tEpoch 136: \tAverage Loss:  0.07176318359375\t ACC train:  0.3\t ACC test:  0.4488888888888889\n",
      "\tEpoch 137: \tAverage Loss:  0.07192733001708984\t ACC train:  0.5\t ACC test:  0.48444444444444446\n",
      "\tEpoch 138: \tAverage Loss:  0.07093513488769532\t ACC train:  0.5\t ACC test:  0.48444444444444446\n",
      "\tEpoch 139: \tAverage Loss:  0.07090769958496093\t ACC train:  0.4\t ACC test:  0.49333333333333335\n",
      "\tEpoch 140: \tAverage Loss:  0.07111576843261719\t ACC train:  0.6\t ACC test:  0.4777777777777778\n",
      "\tEpoch 141: \tAverage Loss:  0.07228150939941407\t ACC train:  0.4\t ACC test:  0.4711111111111111\n",
      "\tEpoch 142: \tAverage Loss:  0.07121910095214844\t ACC train:  0.3\t ACC test:  0.5177777777777778\n",
      "\tEpoch 143: \tAverage Loss:  0.071998779296875\t ACC train:  0.5\t ACC test:  0.4288888888888889\n",
      "\tEpoch 144: \tAverage Loss:  0.07153338623046875\t ACC train:  0.8\t ACC test:  0.43333333333333335\n",
      "\tEpoch 145: \tAverage Loss:  0.07063551330566406\t ACC train:  0.5\t ACC test:  0.48444444444444446\n",
      "\tEpoch 146: \tAverage Loss:  0.07136282348632812\t ACC train:  0.6\t ACC test:  0.4622222222222222\n",
      "\tEpoch 147: \tAverage Loss:  0.07047688293457031\t ACC train:  0.4\t ACC test:  0.4777777777777778\n",
      "\tEpoch 148: \tAverage Loss:  0.07157355499267579\t ACC train:  0.3\t ACC test:  0.4711111111111111\n",
      "\tEpoch 149: \tAverage Loss:  0.07064722442626953\t ACC train:  0.6\t ACC test:  0.4777777777777778\n",
      "\tEpoch 150: \tAverage Loss:  0.07025616455078125\t ACC train:  0.6\t ACC test:  0.48444444444444446\n",
      "\tEpoch 151: \tAverage Loss:  0.07126669311523437\t ACC train:  0.4\t ACC test:  0.48444444444444446\n",
      "\tEpoch 152: \tAverage Loss:  0.0700470733642578\t ACC train:  0.5\t ACC test:  0.5044444444444445\n",
      "\tEpoch 153: \tAverage Loss:  0.0705947494506836\t ACC train:  0.6\t ACC test:  0.5133333333333333\n",
      "\tEpoch 154: \tAverage Loss:  0.0709791259765625\t ACC train:  0.5\t ACC test:  0.4822222222222222\n",
      "\tEpoch 155: \tAverage Loss:  0.07189474487304688\t ACC train:  0.3\t ACC test:  0.5111111111111111\n",
      "\tEpoch 156: \tAverage Loss:  0.06983495330810546\t ACC train:  0.6\t ACC test:  0.45555555555555555\n",
      "\tEpoch 157: \tAverage Loss:  0.06930681610107423\t ACC train:  0.5\t ACC test:  0.5155555555555555\n",
      "\tEpoch 158: \tAverage Loss:  0.070261962890625\t ACC train:  0.4\t ACC test:  0.4822222222222222\n",
      "\tEpoch 159: \tAverage Loss:  0.07008916473388672\t ACC train:  0.5\t ACC test:  0.4911111111111111\n",
      "\tEpoch 160: \tAverage Loss:  0.06937173461914062\t ACC train:  0.4\t ACC test:  0.5066666666666667\n",
      "\tEpoch 161: \tAverage Loss:  0.06978749847412109\t ACC train:  0.4\t ACC test:  0.5\n",
      "\tEpoch 162: \tAverage Loss:  0.07037413787841797\t ACC train:  0.7\t ACC test:  0.5155555555555555\n",
      "\tEpoch 163: \tAverage Loss:  0.0690309066772461\t ACC train:  0.7\t ACC test:  0.4866666666666667\n",
      "\tEpoch 164: \tAverage Loss:  0.07010645294189453\t ACC train:  0.5\t ACC test:  0.5022222222222222\n",
      "\tEpoch 165: \tAverage Loss:  0.07033154296875\t ACC train:  0.7\t ACC test:  0.48444444444444446\n",
      "\tEpoch 166: \tAverage Loss:  0.06933038330078126\t ACC train:  0.5\t ACC test:  0.48444444444444446\n",
      "\tEpoch 167: \tAverage Loss:  0.07060856628417969\t ACC train:  0.8\t ACC test:  0.4866666666666667\n",
      "\tEpoch 168: \tAverage Loss:  0.06781527709960937\t ACC train:  0.5\t ACC test:  0.4711111111111111\n",
      "\tEpoch 169: \tAverage Loss:  0.07048088836669922\t ACC train:  0.4\t ACC test:  0.5222222222222223\n",
      "\tEpoch 170: \tAverage Loss:  0.07188111877441407\t ACC train:  0.5\t ACC test:  0.5066666666666667\n",
      "\tEpoch 171: \tAverage Loss:  0.06912334442138672\t ACC train:  0.6\t ACC test:  0.4955555555555556\n",
      "\tEpoch 172: \tAverage Loss:  0.07026995086669922\t ACC train:  0.5\t ACC test:  0.5066666666666667\n",
      "\tEpoch 173: \tAverage Loss:  0.06857186889648438\t ACC train:  0.6\t ACC test:  0.5244444444444445\n",
      "\tEpoch 174: \tAverage Loss:  0.06963020324707031\t ACC train:  0.4\t ACC test:  0.5088888888888888\n",
      "\tEpoch 175: \tAverage Loss:  0.0705455322265625\t ACC train:  0.4\t ACC test:  0.5355555555555556\n",
      "\tEpoch 176: \tAverage Loss:  0.06943472290039063\t ACC train:  0.6\t ACC test:  0.5488888888888889\n",
      "\tEpoch 177: \tAverage Loss:  0.07058137512207031\t ACC train:  0.5\t ACC test:  0.5244444444444445\n",
      "\tEpoch 178: \tAverage Loss:  0.0686265869140625\t ACC train:  0.5\t ACC test:  0.5355555555555556\n",
      "\tEpoch 179: \tAverage Loss:  0.06766545104980469\t ACC train:  0.6\t ACC test:  0.4955555555555556\n",
      "\tEpoch 180: \tAverage Loss:  0.06991170501708985\t ACC train:  0.4\t ACC test:  0.54\n",
      "\tEpoch 181: \tAverage Loss:  0.0684959487915039\t ACC train:  0.5\t ACC test:  0.5044444444444445\n",
      "\tEpoch 182: \tAverage Loss:  0.06718898773193359\t ACC train:  0.8\t ACC test:  0.5444444444444444\n",
      "\tEpoch 183: \tAverage Loss:  0.06752369689941407\t ACC train:  0.6\t ACC test:  0.5088888888888888\n",
      "\tEpoch 184: \tAverage Loss:  0.06671450805664063\t ACC train:  0.6\t ACC test:  0.5111111111111111\n",
      "\tEpoch 185: \tAverage Loss:  0.06583375549316406\t ACC train:  0.7\t ACC test:  0.56\n",
      "\tEpoch 186: \tAverage Loss:  0.06685482025146484\t ACC train:  0.6\t ACC test:  0.5266666666666666\n",
      "\tEpoch 187: \tAverage Loss:  0.06663106536865235\t ACC train:  0.5\t ACC test:  0.5355555555555556\n",
      "\tEpoch 188: \tAverage Loss:  0.06629180908203125\t ACC train:  0.5\t ACC test:  0.5466666666666666\n",
      "\tEpoch 189: \tAverage Loss:  0.06592964935302735\t ACC train:  0.8\t ACC test:  0.5555555555555556\n",
      "\tEpoch 190: \tAverage Loss:  0.06575777435302735\t ACC train:  0.5\t ACC test:  0.5355555555555556\n",
      "\tEpoch 191: \tAverage Loss:  0.06723355865478516\t ACC train:  0.7\t ACC test:  0.5244444444444445\n",
      "\tEpoch 192: \tAverage Loss:  0.06658260345458984\t ACC train:  0.4\t ACC test:  0.5355555555555556\n",
      "\tEpoch 193: \tAverage Loss:  0.06648994445800781\t ACC train:  0.7\t ACC test:  0.5466666666666666\n",
      "\tEpoch 194: \tAverage Loss:  0.06467314910888672\t ACC train:  0.7\t ACC test:  0.5844444444444444\n",
      "\tEpoch 195: \tAverage Loss:  0.06216973114013672\t ACC train:  0.5\t ACC test:  0.56\n",
      "\tEpoch 196: \tAverage Loss:  0.06257034683227539\t ACC train:  0.6\t ACC test:  0.5733333333333334\n",
      "\tEpoch 197: \tAverage Loss:  0.06571793365478516\t ACC train:  0.6\t ACC test:  0.5533333333333333\n",
      "\tEpoch 198: \tAverage Loss:  0.06183646392822266\t ACC train:  0.5\t ACC test:  0.5733333333333334\n",
      "\tEpoch 199: \tAverage Loss:  0.0626708984375\t ACC train:  0.6\t ACC test:  0.58\n",
      "\tEpoch 200: \tAverage Loss:  0.06217397689819336\t ACC train:  0.5\t ACC test:  0.5488888888888889\n",
      "\tEpoch 201: \tAverage Loss:  0.06560598754882813\t ACC train:  0.6\t ACC test:  0.5488888888888889\n",
      "\tEpoch 202: \tAverage Loss:  0.06194291687011719\t ACC train:  0.5\t ACC test:  0.58\n",
      "\tEpoch 203: \tAverage Loss:  0.06631678009033203\t ACC train:  0.7\t ACC test:  0.5577777777777778\n",
      "\tEpoch 204: \tAverage Loss:  0.059708736419677735\t ACC train:  0.7\t ACC test:  0.5533333333333333\n",
      "\tEpoch 205: \tAverage Loss:  0.060981182098388674\t ACC train:  0.7\t ACC test:  0.5644444444444444\n",
      "\tEpoch 206: \tAverage Loss:  0.06205230712890625\t ACC train:  0.7\t ACC test:  0.58\n",
      "\tEpoch 207: \tAverage Loss:  0.06078596496582031\t ACC train:  0.5\t ACC test:  0.5644444444444444\n",
      "\tEpoch 208: \tAverage Loss:  0.056776813507080075\t ACC train:  0.6\t ACC test:  0.5822222222222222\n",
      "\tEpoch 209: \tAverage Loss:  0.058239921569824216\t ACC train:  0.6\t ACC test:  0.5733333333333334\n",
      "\tEpoch 210: \tAverage Loss:  0.06047873306274414\t ACC train:  0.5\t ACC test:  0.5622222222222222\n",
      "\tEpoch 211: \tAverage Loss:  0.058188282012939456\t ACC train:  0.6\t ACC test:  0.5733333333333334\n",
      "\tEpoch 212: \tAverage Loss:  0.058430164337158204\t ACC train:  0.7\t ACC test:  0.5711111111111111\n",
      "\tEpoch 213: \tAverage Loss:  0.05916546249389648\t ACC train:  0.6\t ACC test:  0.5688888888888889\n",
      "\tEpoch 214: \tAverage Loss:  0.0587887954711914\t ACC train:  0.6\t ACC test:  0.5733333333333334\n",
      "\tEpoch 215: \tAverage Loss:  0.0566761474609375\t ACC train:  0.7\t ACC test:  0.5711111111111111\n",
      "\tEpoch 216: \tAverage Loss:  0.05732177352905273\t ACC train:  0.7\t ACC test:  0.5711111111111111\n",
      "\tEpoch 217: \tAverage Loss:  0.0560947265625\t ACC train:  0.6\t ACC test:  0.5711111111111111\n",
      "\tEpoch 218: \tAverage Loss:  0.0576508560180664\t ACC train:  0.6\t ACC test:  0.5733333333333334\n",
      "\tEpoch 219: \tAverage Loss:  0.05590723419189453\t ACC train:  0.6\t ACC test:  0.5822222222222222\n",
      "\tEpoch 220: \tAverage Loss:  0.05669537353515625\t ACC train:  0.6\t ACC test:  0.5888888888888889\n",
      "\tEpoch 221: \tAverage Loss:  0.05400263214111328\t ACC train:  0.7\t ACC test:  0.5755555555555556\n",
      "\tEpoch 222: \tAverage Loss:  0.05364814376831055\t ACC train:  0.7\t ACC test:  0.5822222222222222\n",
      "\tEpoch 223: \tAverage Loss:  0.05533363342285156\t ACC train:  0.5\t ACC test:  0.5866666666666667\n",
      "\tEpoch 224: \tAverage Loss:  0.05569314193725586\t ACC train:  0.6\t ACC test:  0.6044444444444445\n",
      "\tEpoch 225: \tAverage Loss:  0.055093681335449216\t ACC train:  0.6\t ACC test:  0.5822222222222222\n",
      "\tEpoch 226: \tAverage Loss:  0.054904678344726565\t ACC train:  0.6\t ACC test:  0.5866666666666667\n",
      "\tEpoch 227: \tAverage Loss:  0.052571083068847654\t ACC train:  0.7\t ACC test:  0.6022222222222222\n",
      "\tEpoch 228: \tAverage Loss:  0.055999420166015626\t ACC train:  0.7\t ACC test:  0.5844444444444444\n",
      "\tEpoch 229: \tAverage Loss:  0.052659542083740234\t ACC train:  0.6\t ACC test:  0.5844444444444444\n",
      "\tEpoch 230: \tAverage Loss:  0.05345037841796875\t ACC train:  0.7\t ACC test:  0.5866666666666667\n",
      "\tEpoch 231: \tAverage Loss:  0.05209663391113281\t ACC train:  0.7\t ACC test:  0.5977777777777777\n",
      "\tEpoch 232: \tAverage Loss:  0.05161915969848633\t ACC train:  0.7\t ACC test:  0.5911111111111111\n",
      "\tEpoch 233: \tAverage Loss:  0.054029129028320313\t ACC train:  0.6\t ACC test:  0.5866666666666667\n",
      "\tEpoch 234: \tAverage Loss:  0.05380459213256836\t ACC train:  0.6\t ACC test:  0.5777777777777777\n",
      "\tEpoch 235: \tAverage Loss:  0.05179978179931641\t ACC train:  0.7\t ACC test:  0.5866666666666667\n",
      "\tEpoch 236: \tAverage Loss:  0.052089912414550785\t ACC train:  0.6\t ACC test:  0.5888888888888889\n",
      "\tEpoch 237: \tAverage Loss:  0.05123284149169922\t ACC train:  0.6\t ACC test:  0.5844444444444444\n",
      "\tEpoch 238: \tAverage Loss:  0.05273329544067383\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 239: \tAverage Loss:  0.05194137573242188\t ACC train:  0.6\t ACC test:  0.5933333333333334\n",
      "\tEpoch 240: \tAverage Loss:  0.05081964111328125\t ACC train:  0.7\t ACC test:  0.5866666666666667\n",
      "\tEpoch 241: \tAverage Loss:  0.05171449661254883\t ACC train:  0.6\t ACC test:  0.5911111111111111\n",
      "\tEpoch 242: \tAverage Loss:  0.05079846572875977\t ACC train:  0.7\t ACC test:  0.6\n",
      "\tEpoch 243: \tAverage Loss:  0.05019245147705078\t ACC train:  0.7\t ACC test:  0.5955555555555555\n",
      "\tEpoch 244: \tAverage Loss:  0.05094284057617188\t ACC train:  0.6\t ACC test:  0.6\n",
      "\tEpoch 245: \tAverage Loss:  0.04969765853881836\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 246: \tAverage Loss:  0.050007301330566405\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 247: \tAverage Loss:  0.050630142211914066\t ACC train:  0.6\t ACC test:  0.5888888888888889\n",
      "\tEpoch 248: \tAverage Loss:  0.0497379150390625\t ACC train:  0.7\t ACC test:  0.5822222222222222\n",
      "\tEpoch 249: \tAverage Loss:  0.05077824783325195\t ACC train:  0.7\t ACC test:  0.5933333333333334\n",
      "\tEpoch 250: \tAverage Loss:  0.050214874267578126\t ACC train:  0.7\t ACC test:  0.5933333333333334\n",
      "\tEpoch 251: \tAverage Loss:  0.05045552062988281\t ACC train:  0.6\t ACC test:  0.6\n",
      "\tEpoch 252: \tAverage Loss:  0.05072245407104492\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 253: \tAverage Loss:  0.04988679504394531\t ACC train:  0.6\t ACC test:  0.6066666666666667\n",
      "\tEpoch 254: \tAverage Loss:  0.04943937683105469\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 255: \tAverage Loss:  0.05023516082763672\t ACC train:  0.7\t ACC test:  0.5977777777777777\n",
      "\tEpoch 256: \tAverage Loss:  0.0490831184387207\t ACC train:  0.6\t ACC test:  0.6022222222222222\n",
      "\tEpoch 257: \tAverage Loss:  0.04874752807617187\t ACC train:  0.7\t ACC test:  0.5933333333333334\n",
      "\tEpoch 258: \tAverage Loss:  0.04878017807006836\t ACC train:  0.5\t ACC test:  0.5977777777777777\n",
      "\tEpoch 259: \tAverage Loss:  0.04879928588867188\t ACC train:  0.7\t ACC test:  0.6022222222222222\n",
      "\tEpoch 260: \tAverage Loss:  0.05028067398071289\t ACC train:  0.7\t ACC test:  0.5911111111111111\n",
      "\tEpoch 261: \tAverage Loss:  0.04885973358154297\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 262: \tAverage Loss:  0.0490910758972168\t ACC train:  0.6\t ACC test:  0.6022222222222222\n",
      "\tEpoch 263: \tAverage Loss:  0.04798024368286133\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 264: \tAverage Loss:  0.048266426086425784\t ACC train:  0.6\t ACC test:  0.5933333333333334\n",
      "\tEpoch 265: \tAverage Loss:  0.04928370666503906\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 266: \tAverage Loss:  0.0482088623046875\t ACC train:  0.6\t ACC test:  0.6111111111111112\n",
      "\tEpoch 267: \tAverage Loss:  0.048099845886230466\t ACC train:  0.6\t ACC test:  0.6088888888888889\n",
      "\tEpoch 268: \tAverage Loss:  0.0480047607421875\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 269: \tAverage Loss:  0.048088619232177734\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 270: \tAverage Loss:  0.04778469467163086\t ACC train:  0.6\t ACC test:  0.6066666666666667\n",
      "\tEpoch 271: \tAverage Loss:  0.047245857238769534\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 272: \tAverage Loss:  0.04808296203613281\t ACC train:  0.7\t ACC test:  0.5933333333333334\n",
      "\tEpoch 273: \tAverage Loss:  0.04780608749389648\t ACC train:  0.7\t ACC test:  0.5977777777777777\n",
      "\tEpoch 274: \tAverage Loss:  0.04789175033569336\t ACC train:  0.7\t ACC test:  0.5911111111111111\n",
      "\tEpoch 275: \tAverage Loss:  0.04787758255004883\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 276: \tAverage Loss:  0.04776076126098633\t ACC train:  0.7\t ACC test:  0.5955555555555555\n",
      "\tEpoch 277: \tAverage Loss:  0.0475384407043457\t ACC train:  0.6\t ACC test:  0.6022222222222222\n",
      "\tEpoch 278: \tAverage Loss:  0.047352493286132814\t ACC train:  0.7\t ACC test:  0.6022222222222222\n",
      "\tEpoch 279: \tAverage Loss:  0.047680744171142576\t ACC train:  0.6\t ACC test:  0.6111111111111112\n",
      "\tEpoch 280: \tAverage Loss:  0.046913280487060546\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 281: \tAverage Loss:  0.046660537719726565\t ACC train:  0.6\t ACC test:  0.6266666666666667\n",
      "\tEpoch 282: \tAverage Loss:  0.04745955657958984\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 283: \tAverage Loss:  0.046925704956054685\t ACC train:  0.7\t ACC test:  0.5977777777777777\n",
      "\tEpoch 284: \tAverage Loss:  0.047685874938964846\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 285: \tAverage Loss:  0.04662944030761719\t ACC train:  0.6\t ACC test:  0.6222222222222222\n",
      "\tEpoch 286: \tAverage Loss:  0.04655364990234375\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 287: \tAverage Loss:  0.046518348693847654\t ACC train:  0.8\t ACC test:  0.6111111111111112\n",
      "\tEpoch 288: \tAverage Loss:  0.046315692901611326\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 289: \tAverage Loss:  0.047881828308105466\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 290: \tAverage Loss:  0.04646652984619141\t ACC train:  0.7\t ACC test:  0.6\n",
      "\tEpoch 291: \tAverage Loss:  0.04649171447753906\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 292: \tAverage Loss:  0.04663947296142578\t ACC train:  0.6\t ACC test:  0.6066666666666667\n",
      "\tEpoch 293: \tAverage Loss:  0.04660674285888672\t ACC train:  0.6\t ACC test:  0.6133333333333333\n",
      "\tEpoch 294: \tAverage Loss:  0.046312255859375\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 295: \tAverage Loss:  0.045900901794433596\t ACC train:  0.7\t ACC test:  0.6022222222222222\n",
      "\tEpoch 296: \tAverage Loss:  0.04625323104858398\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 297: \tAverage Loss:  0.04600115585327148\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 298: \tAverage Loss:  0.04604362869262695\t ACC train:  0.7\t ACC test:  0.6022222222222222\n",
      "\tEpoch 299: \tAverage Loss:  0.04638817596435547\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 300: \tAverage Loss:  0.04610048294067383\t ACC train:  0.6\t ACC test:  0.6111111111111112\n",
      "\tEpoch 301: \tAverage Loss:  0.04559865188598633\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 302: \tAverage Loss:  0.04576704025268555\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 303: \tAverage Loss:  0.046453773498535154\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 304: \tAverage Loss:  0.04564042282104492\t ACC train:  0.6\t ACC test:  0.6066666666666667\n",
      "\tEpoch 305: \tAverage Loss:  0.045474067687988284\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 306: \tAverage Loss:  0.04614304733276367\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 307: \tAverage Loss:  0.04567511367797852\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 308: \tAverage Loss:  0.04526334381103515\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 309: \tAverage Loss:  0.0452432861328125\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 310: \tAverage Loss:  0.04570424652099609\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 311: \tAverage Loss:  0.045718711853027345\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 312: \tAverage Loss:  0.04545092010498047\t ACC train:  0.6\t ACC test:  0.6244444444444445\n",
      "\tEpoch 313: \tAverage Loss:  0.04546104049682617\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 314: \tAverage Loss:  0.04517000961303711\t ACC train:  0.6\t ACC test:  0.6\n",
      "\tEpoch 315: \tAverage Loss:  0.045384414672851564\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 316: \tAverage Loss:  0.04606791305541992\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 317: \tAverage Loss:  0.045332004547119144\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 318: \tAverage Loss:  0.045190444946289064\t ACC train:  0.6\t ACC test:  0.6111111111111112\n",
      "\tEpoch 319: \tAverage Loss:  0.04505913162231445\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 320: \tAverage Loss:  0.04515971374511719\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 321: \tAverage Loss:  0.045466182708740234\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 322: \tAverage Loss:  0.04490895080566406\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 323: \tAverage Loss:  0.04455710601806641\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 324: \tAverage Loss:  0.04524011611938476\t ACC train:  0.6\t ACC test:  0.6111111111111112\n",
      "\tEpoch 325: \tAverage Loss:  0.04466803359985352\t ACC train:  0.6\t ACC test:  0.6133333333333333\n",
      "\tEpoch 326: \tAverage Loss:  0.04504290008544922\t ACC train:  0.7\t ACC test:  0.5977777777777777\n",
      "\tEpoch 327: \tAverage Loss:  0.04488653182983399\t ACC train:  0.6\t ACC test:  0.6088888888888889\n",
      "\tEpoch 328: \tAverage Loss:  0.04463290405273437\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 329: \tAverage Loss:  0.04446538925170898\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 330: \tAverage Loss:  0.044850719451904296\t ACC train:  0.6\t ACC test:  0.5977777777777777\n",
      "\tEpoch 331: \tAverage Loss:  0.04449394989013672\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 332: \tAverage Loss:  0.04461919403076172\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 333: \tAverage Loss:  0.04479595947265625\t ACC train:  0.6\t ACC test:  0.6088888888888889\n",
      "\tEpoch 334: \tAverage Loss:  0.04524649047851562\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 335: \tAverage Loss:  0.044826286315917965\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 336: \tAverage Loss:  0.044627288818359374\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 337: \tAverage Loss:  0.04406859970092773\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 338: \tAverage Loss:  0.044506988525390624\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 339: \tAverage Loss:  0.04418402099609375\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 340: \tAverage Loss:  0.0443648452758789\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 341: \tAverage Loss:  0.044244564056396485\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 342: \tAverage Loss:  0.04444906234741211\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 343: \tAverage Loss:  0.04428302001953125\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 344: \tAverage Loss:  0.04395249938964844\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 345: \tAverage Loss:  0.04397781753540039\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 346: \tAverage Loss:  0.04421800994873047\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 347: \tAverage Loss:  0.04392677307128906\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 348: \tAverage Loss:  0.04410179138183594\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 349: \tAverage Loss:  0.044153877258300785\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 350: \tAverage Loss:  0.0442467041015625\t ACC train:  0.6\t ACC test:  0.62\n",
      "\tEpoch 351: \tAverage Loss:  0.043967269897460935\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 352: \tAverage Loss:  0.04387945175170899\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 353: \tAverage Loss:  0.04367052459716797\t ACC train:  0.6\t ACC test:  0.6177777777777778\n",
      "\tEpoch 354: \tAverage Loss:  0.04379736709594727\t ACC train:  0.6\t ACC test:  0.62\n",
      "\tEpoch 355: \tAverage Loss:  0.04357527923583984\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 356: \tAverage Loss:  0.04379788589477539\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 357: \tAverage Loss:  0.04375334930419922\t ACC train:  0.6\t ACC test:  0.6266666666666667\n",
      "\tEpoch 358: \tAverage Loss:  0.043753402709960934\t ACC train:  0.7\t ACC test:  0.6222222222222222\n",
      "\tEpoch 359: \tAverage Loss:  0.04399567413330078\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 360: \tAverage Loss:  0.04390828704833984\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 361: \tAverage Loss:  0.04341206741333008\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 362: \tAverage Loss:  0.04354788208007813\t ACC train:  0.6\t ACC test:  0.6177777777777778\n",
      "\tEpoch 363: \tAverage Loss:  0.04339623260498047\t ACC train:  0.6\t ACC test:  0.6288888888888889\n",
      "\tEpoch 364: \tAverage Loss:  0.04341119384765625\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 365: \tAverage Loss:  0.043428298950195315\t ACC train:  0.6\t ACC test:  0.6288888888888889\n",
      "\tEpoch 366: \tAverage Loss:  0.04351466751098633\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 367: \tAverage Loss:  0.04309383010864258\t ACC train:  0.6\t ACC test:  0.6177777777777778\n",
      "\tEpoch 368: \tAverage Loss:  0.043334251403808595\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 369: \tAverage Loss:  0.043547313690185545\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 370: \tAverage Loss:  0.043532569885253905\t ACC train:  0.7\t ACC test:  0.6222222222222222\n",
      "\tEpoch 371: \tAverage Loss:  0.043121368408203124\t ACC train:  0.6\t ACC test:  0.6288888888888889\n",
      "\tEpoch 372: \tAverage Loss:  0.04304247665405273\t ACC train:  0.8\t ACC test:  0.62\n",
      "\tEpoch 373: \tAverage Loss:  0.0428824348449707\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 374: \tAverage Loss:  0.04324205017089844\t ACC train:  0.6\t ACC test:  0.6222222222222222\n",
      "\tEpoch 375: \tAverage Loss:  0.04308364868164063\t ACC train:  0.7\t ACC test:  0.6222222222222222\n",
      "\tEpoch 376: \tAverage Loss:  0.04282003021240234\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 377: \tAverage Loss:  0.04328465270996094\t ACC train:  0.6\t ACC test:  0.6311111111111111\n",
      "\tEpoch 378: \tAverage Loss:  0.04306277465820312\t ACC train:  0.6\t ACC test:  0.6288888888888889\n",
      "\tEpoch 379: \tAverage Loss:  0.04300814819335937\t ACC train:  0.6\t ACC test:  0.6355555555555555\n",
      "\tEpoch 380: \tAverage Loss:  0.04291659927368164\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 381: \tAverage Loss:  0.04302514266967773\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 382: \tAverage Loss:  0.04285760116577148\t ACC train:  0.6\t ACC test:  0.6288888888888889\n",
      "\tEpoch 383: \tAverage Loss:  0.042858989715576175\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 384: \tAverage Loss:  0.04295522308349609\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 385: \tAverage Loss:  0.04287115097045899\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 386: \tAverage Loss:  0.04285829544067383\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 387: \tAverage Loss:  0.04309183883666992\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 388: \tAverage Loss:  0.04252126312255859\t ACC train:  0.6\t ACC test:  0.62\n",
      "\tEpoch 389: \tAverage Loss:  0.042727333068847656\t ACC train:  0.6\t ACC test:  0.6244444444444445\n",
      "\tEpoch 390: \tAverage Loss:  0.04271748733520508\t ACC train:  0.6\t ACC test:  0.6333333333333333\n",
      "\tEpoch 391: \tAverage Loss:  0.04248965454101562\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 392: \tAverage Loss:  0.042713294982910155\t ACC train:  0.6\t ACC test:  0.6222222222222222\n",
      "\tEpoch 393: \tAverage Loss:  0.04271741104125976\t ACC train:  0.6\t ACC test:  0.6111111111111112\n",
      "\tEpoch 394: \tAverage Loss:  0.04272444152832031\t ACC train:  0.6\t ACC test:  0.6333333333333333\n",
      "\tEpoch 395: \tAverage Loss:  0.042358604431152344\t ACC train:  0.6\t ACC test:  0.6244444444444445\n",
      "\tEpoch 396: \tAverage Loss:  0.04229174041748047\t ACC train:  0.6\t ACC test:  0.62\n",
      "\tEpoch 397: \tAverage Loss:  0.04222833633422852\t ACC train:  0.6\t ACC test:  0.6266666666666667\n",
      "\tEpoch 398: \tAverage Loss:  0.04226210021972656\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 399: \tAverage Loss:  0.04250482177734375\t ACC train:  0.6\t ACC test:  0.64\n",
      "\tEpoch 400: \tAverage Loss:  0.04257533645629883\t ACC train:  0.6\t ACC test:  0.6333333333333333\n",
      "\tEpoch 401: \tAverage Loss:  0.04223683547973633\t ACC train:  0.6\t ACC test:  0.6333333333333333\n",
      "\tEpoch 402: \tAverage Loss:  0.04249018478393555\t ACC train:  0.7\t ACC test:  0.62\n",
      "Stopping early at epoch 402. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 20\n",
      "\tEpoch 1: \tAverage Loss:  0.18453829956054688\t ACC train:  0.4\t ACC test:  0.5133333333333333\n",
      "\tEpoch 2: \tAverage Loss:  0.18396926879882813\t ACC train:  0.4\t ACC test:  0.5133333333333333\n",
      "\tEpoch 3: \tAverage Loss:  0.18331277465820311\t ACC train:  0.4\t ACC test:  0.5155555555555555\n",
      "\tEpoch 4: \tAverage Loss:  0.18279954528808592\t ACC train:  0.4\t ACC test:  0.5133333333333333\n",
      "\tEpoch 5: \tAverage Loss:  0.18203204345703125\t ACC train:  0.4\t ACC test:  0.5155555555555555\n",
      "\tEpoch 6: \tAverage Loss:  0.18136430358886718\t ACC train:  0.4\t ACC test:  0.5111111111111111\n",
      "\tEpoch 7: \tAverage Loss:  0.18064981079101564\t ACC train:  0.4\t ACC test:  0.5133333333333333\n",
      "\tEpoch 8: \tAverage Loss:  0.1801287384033203\t ACC train:  0.4\t ACC test:  0.5155555555555555\n",
      "\tEpoch 9: \tAverage Loss:  0.1794124298095703\t ACC train:  0.35\t ACC test:  0.5111111111111111\n",
      "\tEpoch 10: \tAverage Loss:  0.17905029296875\t ACC train:  0.55\t ACC test:  0.49777777777777776\n",
      "\tEpoch 11: \tAverage Loss:  0.17832740783691406\t ACC train:  0.25\t ACC test:  0.58\n",
      "\tEpoch 12: \tAverage Loss:  0.1781460266113281\t ACC train:  0.7\t ACC test:  0.5066666666666667\n",
      "\tEpoch 13: \tAverage Loss:  0.17742727661132812\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  0.17693743896484376\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  0.1765715789794922\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  0.176166015625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  0.17548776245117187\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  0.17509793090820314\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  0.17464573669433595\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  0.17416012573242187\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  0.1738323974609375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  0.17342533874511717\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  0.17276820373535157\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  0.17264390563964843\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  0.17207861328125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  0.17178987121582032\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  0.1714878387451172\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  0.17092935180664062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  0.17067219543457032\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  0.17030635070800781\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  0.17000894165039063\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  0.1693839111328125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  0.16931449890136718\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  0.16891336059570314\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  0.16857444763183593\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  0.1684363250732422\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  0.16796815490722655\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  0.1677386016845703\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  0.16767471313476562\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  0.1671834259033203\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  0.16706568908691405\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  0.16665524291992187\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  0.1661246795654297\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  0.16609422302246094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  0.16575750732421876\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  0.1655496063232422\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  0.165143798828125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  0.16493211364746094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  0.16465411376953126\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  0.1641776123046875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  0.1640767059326172\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  0.16400444030761718\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.16378482055664062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  0.16328765869140624\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  0.16326844787597655\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  0.16306979370117186\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  0.1627032928466797\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  0.16284974670410157\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  0.16236968994140624\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  0.16231088256835938\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  0.16196481323242187\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  0.16189472961425783\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  0.16179612731933593\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  0.16150973510742186\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  0.16115992736816406\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.16124179077148437\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  0.16104524230957032\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  0.1607233123779297\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  0.16088832092285157\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  0.16060771179199218\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  0.16027703857421874\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  0.16004083251953125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  0.16008607482910156\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  0.16017433166503905\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  0.15981597900390626\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  0.1596856231689453\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  0.15967799377441405\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  0.15926800537109376\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  0.15918655395507814\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.1591570587158203\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  0.15918275451660155\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  0.15859500122070314\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  0.15868634033203124\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 84: \tAverage Loss:  0.15860147094726562\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 85: \tAverage Loss:  0.15863665771484375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 86: \tAverage Loss:  0.15829519653320312\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 87: \tAverage Loss:  0.1583229217529297\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 88: \tAverage Loss:  0.15835906982421874\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 89: \tAverage Loss:  0.15808543395996094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 90: \tAverage Loss:  0.1580774688720703\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 91: \tAverage Loss:  0.15775056457519532\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 92: \tAverage Loss:  0.15780961608886718\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 93: \tAverage Loss:  0.15795570373535156\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 94: \tAverage Loss:  0.15762239074707032\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 95: \tAverage Loss:  0.15749139404296875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 96: \tAverage Loss:  0.1573394775390625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 97: \tAverage Loss:  0.1573827667236328\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 98: \tAverage Loss:  0.157274658203125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 99: \tAverage Loss:  0.1570517578125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 100: \tAverage Loss:  0.15713125610351564\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  0.15709132385253907\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 102: \tAverage Loss:  0.15696029663085936\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 103: \tAverage Loss:  0.1569859619140625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 104: \tAverage Loss:  0.15699533081054687\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 105: \tAverage Loss:  0.15660435485839844\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 106: \tAverage Loss:  0.15680503845214844\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 107: \tAverage Loss:  0.15652993774414062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 108: \tAverage Loss:  0.15649058532714843\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 109: \tAverage Loss:  0.15647242736816405\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 110: \tAverage Loss:  0.15640336608886718\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 111: \tAverage Loss:  0.15617622375488283\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 112: \tAverage Loss:  0.15654783630371094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 113: \tAverage Loss:  0.1563706817626953\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 114: \tAverage Loss:  0.15616571044921876\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 115: \tAverage Loss:  0.15604148864746092\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 116: \tAverage Loss:  0.15603404235839843\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 117: \tAverage Loss:  0.1561643524169922\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 118: \tAverage Loss:  0.15592512512207032\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 119: \tAverage Loss:  0.1558578643798828\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 120: \tAverage Loss:  0.15609913635253905\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 121: \tAverage Loss:  0.15585527038574218\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 122: \tAverage Loss:  0.15600791931152344\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 123: \tAverage Loss:  0.1555913848876953\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 124: \tAverage Loss:  0.15552171325683595\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 125: \tAverage Loss:  0.1558099365234375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 126: \tAverage Loss:  0.15566278076171874\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 127: \tAverage Loss:  0.155778564453125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 128: \tAverage Loss:  0.15582879638671876\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 129: \tAverage Loss:  0.1552984619140625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 130: \tAverage Loss:  0.15541030883789062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 131: \tAverage Loss:  0.15559866333007813\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 132: \tAverage Loss:  0.15538475036621094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 133: \tAverage Loss:  0.15565086364746095\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 134: \tAverage Loss:  0.15529127502441406\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 135: \tAverage Loss:  0.15543612670898438\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 136: \tAverage Loss:  0.15531556701660157\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 137: \tAverage Loss:  0.15561428833007812\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 138: \tAverage Loss:  0.15554037475585938\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 139: \tAverage Loss:  0.155433837890625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 140: \tAverage Loss:  0.15541873168945314\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 141: \tAverage Loss:  0.1554897155761719\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 142: \tAverage Loss:  0.15529891967773438\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 143: \tAverage Loss:  0.15541775512695313\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 144: \tAverage Loss:  0.15529393005371095\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 145: \tAverage Loss:  0.15528889465332033\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 146: \tAverage Loss:  0.15522085571289063\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 147: \tAverage Loss:  0.15511199951171875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 148: \tAverage Loss:  0.15556398010253905\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 149: \tAverage Loss:  0.155297607421875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 150: \tAverage Loss:  0.15516921997070313\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 151: \tAverage Loss:  0.15521559143066407\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 152: \tAverage Loss:  0.1550105438232422\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 153: \tAverage Loss:  0.15515081787109375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 154: \tAverage Loss:  0.15499497985839844\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 155: \tAverage Loss:  0.15508592224121093\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 156: \tAverage Loss:  0.15493942260742188\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 157: \tAverage Loss:  0.15506915283203124\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 158: \tAverage Loss:  0.15467153930664063\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 159: \tAverage Loss:  0.15519306945800782\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 160: \tAverage Loss:  0.15473506164550782\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 161: \tAverage Loss:  0.15515003967285157\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 162: \tAverage Loss:  0.15490646362304689\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 163: \tAverage Loss:  0.15446629333496092\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 164: \tAverage Loss:  0.1547015380859375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 165: \tAverage Loss:  0.15469363403320313\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 166: \tAverage Loss:  0.15451670837402343\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 167: \tAverage Loss:  0.15482649230957032\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 168: \tAverage Loss:  0.15378575134277345\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 169: \tAverage Loss:  0.1548742218017578\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 170: \tAverage Loss:  0.15451852416992187\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 171: \tAverage Loss:  0.1543291015625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 172: \tAverage Loss:  0.15526449584960939\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 173: \tAverage Loss:  0.15447763061523437\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 174: \tAverage Loss:  0.15457211303710938\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 175: \tAverage Loss:  0.15238102722167968\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 176: \tAverage Loss:  0.15250180053710938\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 177: \tAverage Loss:  0.15590113830566407\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 178: \tAverage Loss:  0.15138720703125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 179: \tAverage Loss:  0.1548071594238281\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 180: \tAverage Loss:  0.151094970703125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 181: \tAverage Loss:  0.15642092895507811\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 182: \tAverage Loss:  0.15446243286132813\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 183: \tAverage Loss:  0.15170477294921875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 184: \tAverage Loss:  0.15274839782714844\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 185: \tAverage Loss:  0.15861404418945313\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 186: \tAverage Loss:  0.156729248046875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 187: \tAverage Loss:  0.14127127075195312\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 188: \tAverage Loss:  0.14044998168945313\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 189: \tAverage Loss:  0.1491760711669922\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 190: \tAverage Loss:  0.15030723571777344\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 191: \tAverage Loss:  0.15052084350585937\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 192: \tAverage Loss:  0.1331000213623047\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 193: \tAverage Loss:  0.15711802673339845\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 194: \tAverage Loss:  0.1457868194580078\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 195: \tAverage Loss:  0.13162913513183594\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 196: \tAverage Loss:  0.15504444885253907\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 197: \tAverage Loss:  0.15048431396484374\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 198: \tAverage Loss:  0.15917903137207032\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 199: \tAverage Loss:  0.13173187255859375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 200: \tAverage Loss:  0.15942459106445311\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 201: \tAverage Loss:  0.13626438903808594\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 202: \tAverage Loss:  0.13495579528808593\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 203: \tAverage Loss:  0.14128944396972656\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 204: \tAverage Loss:  0.14499227905273437\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 205: \tAverage Loss:  0.1595211181640625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 206: \tAverage Loss:  0.14597262573242187\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 207: \tAverage Loss:  0.15002774047851564\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 208: \tAverage Loss:  0.12855857849121094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 209: \tAverage Loss:  0.13064979553222655\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 210: \tAverage Loss:  0.1383877410888672\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 211: \tAverage Loss:  0.14247207641601561\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 212: \tAverage Loss:  0.1558270263671875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 213: \tAverage Loss:  0.14010955810546874\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 214: \tAverage Loss:  0.12483576965332031\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 215: \tAverage Loss:  0.14094895935058593\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 216: \tAverage Loss:  0.13040689086914062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 217: \tAverage Loss:  0.1382257080078125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 218: \tAverage Loss:  0.13922079467773438\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 219: \tAverage Loss:  0.1269588165283203\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 220: \tAverage Loss:  0.12633094024658204\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 221: \tAverage Loss:  0.1269063720703125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 222: \tAverage Loss:  0.1355646057128906\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 223: \tAverage Loss:  0.13558203125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 224: \tAverage Loss:  0.13263992309570313\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 225: \tAverage Loss:  0.12555085754394532\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 226: \tAverage Loss:  0.1479195098876953\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 227: \tAverage Loss:  0.11421366119384765\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 228: \tAverage Loss:  0.1239377670288086\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 229: \tAverage Loss:  0.14364920043945312\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 230: \tAverage Loss:  0.12903474426269532\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 231: \tAverage Loss:  0.12193482208251953\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 232: \tAverage Loss:  0.13981951904296874\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 233: \tAverage Loss:  0.13097344970703126\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 234: \tAverage Loss:  0.1309781951904297\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 235: \tAverage Loss:  0.12384591674804687\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 236: \tAverage Loss:  0.12017832946777343\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 237: \tAverage Loss:  0.12289730834960938\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 238: \tAverage Loss:  0.11898664093017577\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 239: \tAverage Loss:  0.11739051818847657\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 240: \tAverage Loss:  0.11785037994384766\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 241: \tAverage Loss:  0.12038761901855469\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 242: \tAverage Loss:  0.11236676025390625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 243: \tAverage Loss:  0.12584803009033202\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 244: \tAverage Loss:  0.11387421417236328\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 245: \tAverage Loss:  0.11148773193359375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 246: \tAverage Loss:  0.11110243225097656\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 247: \tAverage Loss:  0.1235844497680664\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 248: \tAverage Loss:  0.11630687713623047\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 249: \tAverage Loss:  0.1144410858154297\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 250: \tAverage Loss:  0.11291935729980469\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 251: \tAverage Loss:  0.11326393890380859\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 252: \tAverage Loss:  0.11180204010009766\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 253: \tAverage Loss:  0.11282891082763671\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 254: \tAverage Loss:  0.1257340545654297\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 255: \tAverage Loss:  0.10807444763183593\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 256: \tAverage Loss:  0.10592967224121094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 257: \tAverage Loss:  0.11152031707763672\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 258: \tAverage Loss:  0.13602456665039062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 259: \tAverage Loss:  0.1257878875732422\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 260: \tAverage Loss:  0.11184481811523438\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 261: \tAverage Loss:  0.11922667694091797\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 262: \tAverage Loss:  0.11469334411621093\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 263: \tAverage Loss:  0.11406101989746094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 264: \tAverage Loss:  0.11042524719238281\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 265: \tAverage Loss:  0.10733998107910156\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 266: \tAverage Loss:  0.10694657897949218\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 267: \tAverage Loss:  0.11099282836914062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 268: \tAverage Loss:  0.1081234130859375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 269: \tAverage Loss:  0.10626441192626954\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 270: \tAverage Loss:  0.10978727722167969\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 271: \tAverage Loss:  0.11052797698974609\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 272: \tAverage Loss:  0.10714056396484375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 273: \tAverage Loss:  0.10729650115966796\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 274: \tAverage Loss:  0.10860610198974609\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 275: \tAverage Loss:  0.10842533874511719\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 276: \tAverage Loss:  0.10591328430175781\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 277: \tAverage Loss:  0.10597367095947266\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 278: \tAverage Loss:  0.1052726821899414\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 279: \tAverage Loss:  0.1045407257080078\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 280: \tAverage Loss:  0.10574728393554687\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 281: \tAverage Loss:  0.1037821044921875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 282: \tAverage Loss:  0.1057711410522461\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 283: \tAverage Loss:  0.10863302612304687\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 284: \tAverage Loss:  0.10733344268798828\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 285: \tAverage Loss:  0.10523977661132812\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 286: \tAverage Loss:  0.10434146118164063\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 287: \tAverage Loss:  0.10674444580078125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 288: \tAverage Loss:  0.104734619140625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 289: \tAverage Loss:  0.10313426971435546\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 290: \tAverage Loss:  0.10334282684326172\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 291: \tAverage Loss:  0.1032677764892578\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 292: \tAverage Loss:  0.10440982818603516\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 293: \tAverage Loss:  0.10397342681884765\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 294: \tAverage Loss:  0.10563594818115235\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 295: \tAverage Loss:  0.10093328094482422\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 296: \tAverage Loss:  0.10438197326660156\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 297: \tAverage Loss:  0.10253057861328126\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 298: \tAverage Loss:  0.10253706359863281\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 299: \tAverage Loss:  0.10162523651123047\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 300: \tAverage Loss:  0.10278107452392578\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 301: \tAverage Loss:  0.10331201171875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 302: \tAverage Loss:  0.10282714080810547\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 303: \tAverage Loss:  0.1013549041748047\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 304: \tAverage Loss:  0.10038817596435547\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 305: \tAverage Loss:  0.10225601196289062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 306: \tAverage Loss:  0.10453726959228515\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 307: \tAverage Loss:  0.10171527862548828\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 308: \tAverage Loss:  0.10043272399902343\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 309: \tAverage Loss:  0.10196273803710937\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 310: \tAverage Loss:  0.10257720184326172\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 311: \tAverage Loss:  0.10073113250732423\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 312: \tAverage Loss:  0.1005330810546875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 313: \tAverage Loss:  0.09882506561279297\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 314: \tAverage Loss:  0.10017510986328125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 315: \tAverage Loss:  0.10148545837402344\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 316: \tAverage Loss:  0.10004606628417968\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 317: \tAverage Loss:  0.10002748870849609\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 318: \tAverage Loss:  0.10063564300537109\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 319: \tAverage Loss:  0.10077949523925782\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 320: \tAverage Loss:  0.10042435455322266\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 321: \tAverage Loss:  0.10185041046142577\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 322: \tAverage Loss:  0.09908538055419921\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 323: \tAverage Loss:  0.09995624542236328\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 324: \tAverage Loss:  0.1004908676147461\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 325: \tAverage Loss:  0.09925135040283203\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 326: \tAverage Loss:  0.0993755874633789\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 327: \tAverage Loss:  0.09946595764160156\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 328: \tAverage Loss:  0.10093000793457031\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 329: \tAverage Loss:  0.10052944183349609\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 330: \tAverage Loss:  0.09918113708496094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 331: \tAverage Loss:  0.09956076049804688\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 332: \tAverage Loss:  0.1004581298828125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 333: \tAverage Loss:  0.10000978088378906\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 334: \tAverage Loss:  0.09943340301513671\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 335: \tAverage Loss:  0.09858490753173828\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 336: \tAverage Loss:  0.09912638092041015\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 337: \tAverage Loss:  0.10045343017578125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 338: \tAverage Loss:  0.09879019165039063\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 339: \tAverage Loss:  0.10188851165771484\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 340: \tAverage Loss:  0.09809069061279296\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 341: \tAverage Loss:  0.10020804595947265\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 342: \tAverage Loss:  0.09777318572998046\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 343: \tAverage Loss:  0.09854550933837891\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 344: \tAverage Loss:  0.09726351165771484\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 345: \tAverage Loss:  0.09920195007324219\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 346: \tAverage Loss:  0.09907489013671875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 347: \tAverage Loss:  0.09806704711914062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 348: \tAverage Loss:  0.0987921142578125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 349: \tAverage Loss:  0.09807646179199218\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 350: \tAverage Loss:  0.09879645538330079\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 351: \tAverage Loss:  0.09834944152832031\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 352: \tAverage Loss:  0.09844186401367187\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 353: \tAverage Loss:  0.09739997863769531\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 354: \tAverage Loss:  0.0973723602294922\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 355: \tAverage Loss:  0.09783824157714843\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 356: \tAverage Loss:  0.09782903289794923\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 357: \tAverage Loss:  0.09756510925292969\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 358: \tAverage Loss:  0.09771434783935547\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 359: \tAverage Loss:  0.09865581512451171\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 360: \tAverage Loss:  0.09886253356933594\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 361: \tAverage Loss:  0.09749939727783204\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 362: \tAverage Loss:  0.09726873779296875\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 363: \tAverage Loss:  0.097325927734375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 364: \tAverage Loss:  0.10140792846679687\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 365: \tAverage Loss:  0.09648932647705079\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 366: \tAverage Loss:  0.0965691680908203\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 367: \tAverage Loss:  0.09705803680419922\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 368: \tAverage Loss:  0.09700179290771484\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 369: \tAverage Loss:  0.09719896697998047\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 370: \tAverage Loss:  0.09753838348388671\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 371: \tAverage Loss:  0.09888843536376953\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 372: \tAverage Loss:  0.09756918334960937\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 373: \tAverage Loss:  0.09739320373535157\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 374: \tAverage Loss:  0.09707144165039062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 375: \tAverage Loss:  0.09662521362304688\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 376: \tAverage Loss:  0.10031044006347656\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 377: \tAverage Loss:  0.09767369079589844\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 378: \tAverage Loss:  0.09671417999267579\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 379: \tAverage Loss:  0.09665193939208984\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 380: \tAverage Loss:  0.09639009094238281\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 381: \tAverage Loss:  0.09699568176269531\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 382: \tAverage Loss:  0.09661871337890625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 383: \tAverage Loss:  0.09770420837402344\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 384: \tAverage Loss:  0.095931640625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 385: \tAverage Loss:  0.09660589599609375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 386: \tAverage Loss:  0.09662107849121093\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 387: \tAverage Loss:  0.09725690460205078\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 388: \tAverage Loss:  0.09646751403808594\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 389: \tAverage Loss:  0.09675919342041016\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 390: \tAverage Loss:  0.09646967315673828\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 391: \tAverage Loss:  0.09580062103271485\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 392: \tAverage Loss:  0.09630352020263672\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 393: \tAverage Loss:  0.0965272674560547\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 394: \tAverage Loss:  0.09656248474121094\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 395: \tAverage Loss:  0.09629964447021484\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 396: \tAverage Loss:  0.09575677490234374\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 397: \tAverage Loss:  0.09566064453125\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 398: \tAverage Loss:  0.09598365020751953\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 399: \tAverage Loss:  0.09587858581542968\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 400: \tAverage Loss:  0.09642237091064453\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 401: \tAverage Loss:  0.09590189361572266\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 402: \tAverage Loss:  0.09567921447753906\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 403: \tAverage Loss:  0.09533879089355468\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 404: \tAverage Loss:  0.09656683349609375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 405: \tAverage Loss:  0.09552198028564453\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 406: \tAverage Loss:  0.09606934356689453\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 407: \tAverage Loss:  0.0961446762084961\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 408: \tAverage Loss:  0.09721721649169922\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 409: \tAverage Loss:  0.09575144195556641\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 410: \tAverage Loss:  0.09562857055664062\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 411: \tAverage Loss:  0.09579940032958985\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 412: \tAverage Loss:  0.09506433868408203\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 413: \tAverage Loss:  0.09515840148925782\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 414: \tAverage Loss:  0.09571080780029297\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 415: \tAverage Loss:  0.09537670135498047\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 416: \tAverage Loss:  0.09495635223388672\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 417: \tAverage Loss:  0.09694612121582032\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 418: \tAverage Loss:  0.09549229431152344\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 419: \tAverage Loss:  0.09498140716552735\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 420: \tAverage Loss:  0.09443032836914063\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 421: \tAverage Loss:  0.09584126281738281\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 422: \tAverage Loss:  0.09581751251220703\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 423: \tAverage Loss:  0.09479925537109375\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 424: \tAverage Loss:  0.09519889068603515\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 425: \tAverage Loss:  0.09582347106933593\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 426: \tAverage Loss:  0.09452497100830078\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 427: \tAverage Loss:  0.0949263916015625\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 428: \tAverage Loss:  0.0940860366821289\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 429: \tAverage Loss:  0.09555056762695313\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 430: \tAverage Loss:  0.09470833587646485\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 431: \tAverage Loss:  0.0943228530883789\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 432: \tAverage Loss:  0.09506779479980469\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 433: \tAverage Loss:  0.09495057678222656\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 434: \tAverage Loss:  0.09476428985595703\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "\tEpoch 435: \tAverage Loss:  0.09531270599365234\t ACC train:  0.6\t ACC test:  0.4866666666666667\n",
      "Stopping early at epoch 435. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 30\n",
      "\tEpoch 1: \tAverage Loss:  0.29942205810546874\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 2: \tAverage Loss:  0.29824169921875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 3: \tAverage Loss:  0.2957568969726562\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 4: \tAverage Loss:  0.29525845336914064\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 5: \tAverage Loss:  0.29425180053710936\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 6: \tAverage Loss:  0.2928145751953125\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 7: \tAverage Loss:  0.2928191833496094\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 8: \tAverage Loss:  0.2913836975097656\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 9: \tAverage Loss:  0.28994265747070314\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 10: \tAverage Loss:  0.2894466552734375\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  0.28902999877929686\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  0.2875174865722656\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  0.2866295166015625\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  0.2855807800292969\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  0.2846000061035156\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  0.2836412353515625\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  0.2824175109863281\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  0.2816005859375\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  0.28112451171875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  0.27996096801757814\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  0.27942733764648436\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  0.2789051208496094\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  0.2777273864746094\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  0.2765997619628906\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  0.2760557556152344\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  0.2757339782714844\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  0.27518917846679686\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  0.27432806396484377\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  0.2738312072753906\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  0.2728397216796875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  0.2723981323242187\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  0.2719460144042969\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  0.27134033203125\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  0.27065869140625\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  0.270180908203125\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  0.269477783203125\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  0.26855752563476565\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  0.26840603637695315\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  0.26773187255859376\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  0.267167236328125\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  0.266529052734375\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  0.26665792846679687\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  0.2657994079589844\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  0.2651198425292969\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  0.2647198181152344\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  0.26412030029296873\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  0.26393359375\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  0.26353146362304686\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  0.26335189819335936\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  0.2626702575683594\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  0.2619403076171875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  0.2616358947753906\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.2616680603027344\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  0.2607147216796875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  0.26107763671875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  0.26032568359375\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  0.26007827758789065\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  0.25955203247070313\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  0.2593316345214844\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  0.25898275756835937\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  0.25871173095703126\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  0.2580748596191406\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  0.25820462036132813\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  0.257496337890625\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  0.2574413757324219\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.2571148071289063\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  0.25662127685546876\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  0.25671710205078124\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  0.25633209228515624\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  0.2561704406738281\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  0.2558120574951172\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  0.2555628509521484\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  0.2554964141845703\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  0.25502236938476563\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  0.2549460144042969\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  0.2549125213623047\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  0.2546557006835938\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  0.2544040985107422\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  0.2541513366699219\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.2540839996337891\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  0.2540406036376953\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  0.25378569030761716\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  0.2537272644042969\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 84: \tAverage Loss:  0.25346017456054687\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 85: \tAverage Loss:  0.2533706207275391\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 86: \tAverage Loss:  0.25304939270019533\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 87: \tAverage Loss:  0.2530466918945313\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 88: \tAverage Loss:  0.2529845428466797\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 89: \tAverage Loss:  0.252781005859375\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 90: \tAverage Loss:  0.25268292236328127\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 91: \tAverage Loss:  0.2525780029296875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 92: \tAverage Loss:  0.2525125427246094\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 93: \tAverage Loss:  0.2523173370361328\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 94: \tAverage Loss:  0.25221067810058595\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 95: \tAverage Loss:  0.2521424865722656\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 96: \tAverage Loss:  0.25206440734863284\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 97: \tAverage Loss:  0.25182012939453124\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 98: \tAverage Loss:  0.2518083953857422\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 99: \tAverage Loss:  0.251781005859375\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 100: \tAverage Loss:  0.2517225646972656\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  0.2515167999267578\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 102: \tAverage Loss:  0.25148126220703126\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 103: \tAverage Loss:  0.2513863525390625\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 104: \tAverage Loss:  0.2512900390625\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 105: \tAverage Loss:  0.2513141174316406\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 106: \tAverage Loss:  0.25116136169433595\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 107: \tAverage Loss:  0.2510279541015625\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 108: \tAverage Loss:  0.25097792053222656\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 109: \tAverage Loss:  0.2508484191894531\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 110: \tAverage Loss:  0.25089091491699217\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 111: \tAverage Loss:  0.25079420471191405\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 112: \tAverage Loss:  0.2508313903808594\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 113: \tAverage Loss:  0.2507812652587891\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 114: \tAverage Loss:  0.2505667419433594\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 115: \tAverage Loss:  0.2506539611816406\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 116: \tAverage Loss:  0.25057623291015624\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 117: \tAverage Loss:  0.25025277709960936\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 118: \tAverage Loss:  0.2504276123046875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 119: \tAverage Loss:  0.25037159729003905\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 120: \tAverage Loss:  0.2501212005615234\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 121: \tAverage Loss:  0.25030567932128905\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 122: \tAverage Loss:  0.25011590576171877\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 123: \tAverage Loss:  0.2502081604003906\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 124: \tAverage Loss:  0.24998564147949218\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 125: \tAverage Loss:  0.2500718078613281\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 126: \tAverage Loss:  0.2499109344482422\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 127: \tAverage Loss:  0.24983015441894532\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 128: \tAverage Loss:  0.2498983612060547\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 129: \tAverage Loss:  0.2496109619140625\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 130: \tAverage Loss:  0.24978761291503906\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 131: \tAverage Loss:  0.24991244506835938\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 132: \tAverage Loss:  0.249674560546875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 133: \tAverage Loss:  0.24959329223632812\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 134: \tAverage Loss:  0.24996971130371093\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 135: \tAverage Loss:  0.24979612731933593\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 136: \tAverage Loss:  0.2495057373046875\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 137: \tAverage Loss:  0.2494339599609375\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 138: \tAverage Loss:  0.24930384826660157\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 139: \tAverage Loss:  0.2493400421142578\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 140: \tAverage Loss:  0.24892680358886718\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 141: \tAverage Loss:  0.24908648681640624\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 142: \tAverage Loss:  0.24923194885253908\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 143: \tAverage Loss:  0.2492384033203125\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 144: \tAverage Loss:  0.24884371948242187\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 145: \tAverage Loss:  0.2489510192871094\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 146: \tAverage Loss:  0.2493172302246094\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 147: \tAverage Loss:  0.2489873504638672\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 148: \tAverage Loss:  0.24906748962402345\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 149: \tAverage Loss:  0.24923451232910157\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 150: \tAverage Loss:  0.24927873229980468\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 151: \tAverage Loss:  0.24922514343261717\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 152: \tAverage Loss:  0.24889833068847655\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 153: \tAverage Loss:  0.24851409912109376\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 154: \tAverage Loss:  0.24923797607421874\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 155: \tAverage Loss:  0.24839175415039064\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 156: \tAverage Loss:  0.24874220275878905\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 157: \tAverage Loss:  0.24856698608398436\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 158: \tAverage Loss:  0.24824259948730468\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 159: \tAverage Loss:  0.24821847534179686\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 160: \tAverage Loss:  0.2480821075439453\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 161: \tAverage Loss:  0.24818684387207032\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 162: \tAverage Loss:  0.24820037841796874\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 163: \tAverage Loss:  0.24812083435058593\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 164: \tAverage Loss:  0.24786355590820314\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 165: \tAverage Loss:  0.24786282348632813\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 166: \tAverage Loss:  0.24820335388183593\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 167: \tAverage Loss:  0.24787252807617188\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 168: \tAverage Loss:  0.24839054870605468\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 169: \tAverage Loss:  0.2477086944580078\t ACC train:  0.5666666666666667\t ACC test:  0.4911111111111111\n",
      "\tEpoch 170: \tAverage Loss:  0.24788963317871093\t ACC train:  0.5666666666666667\t ACC test:  0.4888888888888889\n",
      "\tEpoch 171: \tAverage Loss:  0.2484553680419922\t ACC train:  0.5666666666666667\t ACC test:  0.4888888888888889\n",
      "\tEpoch 172: \tAverage Loss:  0.24747750854492187\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 173: \tAverage Loss:  0.24754074096679687\t ACC train:  0.5666666666666667\t ACC test:  0.4888888888888889\n",
      "\tEpoch 174: \tAverage Loss:  0.24722727966308594\t ACC train:  0.5666666666666667\t ACC test:  0.4911111111111111\n",
      "\tEpoch 175: \tAverage Loss:  0.2475556640625\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 176: \tAverage Loss:  0.24786082458496095\t ACC train:  0.5666666666666667\t ACC test:  0.4866666666666667\n",
      "\tEpoch 177: \tAverage Loss:  0.24764205932617187\t ACC train:  0.6\t ACC test:  0.49333333333333335\n",
      "\tEpoch 178: \tAverage Loss:  0.24699374389648437\t ACC train:  0.5666666666666667\t ACC test:  0.49333333333333335\n",
      "\tEpoch 179: \tAverage Loss:  0.24713629150390626\t ACC train:  0.5666666666666667\t ACC test:  0.4888888888888889\n",
      "\tEpoch 180: \tAverage Loss:  0.24732962036132813\t ACC train:  0.5666666666666667\t ACC test:  0.4888888888888889\n",
      "\tEpoch 181: \tAverage Loss:  0.2465553894042969\t ACC train:  0.5666666666666667\t ACC test:  0.4911111111111111\n",
      "\tEpoch 182: \tAverage Loss:  0.24722669982910156\t ACC train:  0.5666666666666667\t ACC test:  0.4888888888888889\n",
      "\tEpoch 183: \tAverage Loss:  0.24705752563476563\t ACC train:  0.5666666666666667\t ACC test:  0.49333333333333335\n",
      "\tEpoch 184: \tAverage Loss:  0.24695550537109376\t ACC train:  0.5666666666666667\t ACC test:  0.48444444444444446\n",
      "\tEpoch 185: \tAverage Loss:  0.24718087768554686\t ACC train:  0.5666666666666667\t ACC test:  0.49333333333333335\n",
      "\tEpoch 186: \tAverage Loss:  0.24611825561523437\t ACC train:  0.5666666666666667\t ACC test:  0.5022222222222222\n",
      "\tEpoch 187: \tAverage Loss:  0.24651402282714843\t ACC train:  0.5666666666666667\t ACC test:  0.5\n",
      "\tEpoch 188: \tAverage Loss:  0.24616374206542968\t ACC train:  0.5666666666666667\t ACC test:  0.49333333333333335\n",
      "\tEpoch 189: \tAverage Loss:  0.24618118286132812\t ACC train:  0.6333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 190: \tAverage Loss:  0.24617692565917967\t ACC train:  0.5666666666666667\t ACC test:  0.49333333333333335\n",
      "\tEpoch 191: \tAverage Loss:  0.24608465576171876\t ACC train:  0.5666666666666667\t ACC test:  0.49333333333333335\n",
      "\tEpoch 192: \tAverage Loss:  0.24558778381347657\t ACC train:  0.5666666666666667\t ACC test:  0.5044444444444445\n",
      "\tEpoch 193: \tAverage Loss:  0.24457655334472655\t ACC train:  0.5666666666666667\t ACC test:  0.52\n",
      "\tEpoch 194: \tAverage Loss:  0.2450260009765625\t ACC train:  0.6\t ACC test:  0.5155555555555555\n",
      "\tEpoch 195: \tAverage Loss:  0.24459608459472656\t ACC train:  0.5666666666666667\t ACC test:  0.52\n",
      "\tEpoch 196: \tAverage Loss:  0.24537738037109375\t ACC train:  0.6\t ACC test:  0.5177777777777778\n",
      "\tEpoch 197: \tAverage Loss:  0.24455250549316407\t ACC train:  0.6333333333333333\t ACC test:  0.5177777777777778\n",
      "\tEpoch 198: \tAverage Loss:  0.24552125549316406\t ACC train:  0.6\t ACC test:  0.5244444444444445\n",
      "\tEpoch 199: \tAverage Loss:  0.24408824157714842\t ACC train:  0.6\t ACC test:  0.52\n",
      "\tEpoch 200: \tAverage Loss:  0.2441539764404297\t ACC train:  0.6333333333333333\t ACC test:  0.5244444444444445\n",
      "\tEpoch 201: \tAverage Loss:  0.24442343139648437\t ACC train:  0.6666666666666666\t ACC test:  0.5355555555555556\n",
      "\tEpoch 202: \tAverage Loss:  0.24412434387207033\t ACC train:  0.6333333333333333\t ACC test:  0.5377777777777778\n",
      "\tEpoch 203: \tAverage Loss:  0.2434559326171875\t ACC train:  0.6333333333333333\t ACC test:  0.5244444444444445\n",
      "\tEpoch 204: \tAverage Loss:  0.24331709289550782\t ACC train:  0.6333333333333333\t ACC test:  0.5355555555555556\n",
      "\tEpoch 205: \tAverage Loss:  0.2411573486328125\t ACC train:  0.6\t ACC test:  0.5333333333333333\n",
      "\tEpoch 206: \tAverage Loss:  0.24294284057617188\t ACC train:  0.6333333333333333\t ACC test:  0.54\n",
      "\tEpoch 207: \tAverage Loss:  0.24349020385742187\t ACC train:  0.7\t ACC test:  0.5244444444444445\n",
      "\tEpoch 208: \tAverage Loss:  0.2425428009033203\t ACC train:  0.7\t ACC test:  0.5355555555555556\n",
      "\tEpoch 209: \tAverage Loss:  0.24145619201660157\t ACC train:  0.5666666666666667\t ACC test:  0.5466666666666666\n",
      "\tEpoch 210: \tAverage Loss:  0.24065020751953126\t ACC train:  0.6333333333333333\t ACC test:  0.54\n",
      "\tEpoch 211: \tAverage Loss:  0.24140858459472656\t ACC train:  0.6\t ACC test:  0.5422222222222223\n",
      "\tEpoch 212: \tAverage Loss:  0.23914431762695312\t ACC train:  0.5333333333333333\t ACC test:  0.54\n",
      "\tEpoch 213: \tAverage Loss:  0.23912867736816407\t ACC train:  0.6\t ACC test:  0.5488888888888889\n",
      "\tEpoch 214: \tAverage Loss:  0.24045181274414062\t ACC train:  0.5666666666666667\t ACC test:  0.5444444444444444\n",
      "\tEpoch 215: \tAverage Loss:  0.23963267517089842\t ACC train:  0.7\t ACC test:  0.5533333333333333\n",
      "\tEpoch 216: \tAverage Loss:  0.23911669921875\t ACC train:  0.6\t ACC test:  0.5444444444444444\n",
      "\tEpoch 217: \tAverage Loss:  0.2358798370361328\t ACC train:  0.7\t ACC test:  0.5688888888888889\n",
      "\tEpoch 218: \tAverage Loss:  0.235194091796875\t ACC train:  0.6333333333333333\t ACC test:  0.5755555555555556\n",
      "\tEpoch 219: \tAverage Loss:  0.23725389099121094\t ACC train:  0.6666666666666666\t ACC test:  0.5488888888888889\n",
      "\tEpoch 220: \tAverage Loss:  0.23706419372558593\t ACC train:  0.6\t ACC test:  0.5777777777777777\n",
      "\tEpoch 221: \tAverage Loss:  0.23652711486816405\t ACC train:  0.6666666666666666\t ACC test:  0.6111111111111112\n",
      "\tEpoch 222: \tAverage Loss:  0.23566702270507814\t ACC train:  0.6666666666666666\t ACC test:  0.5866666666666667\n",
      "\tEpoch 223: \tAverage Loss:  0.23206565856933595\t ACC train:  0.6333333333333333\t ACC test:  0.5711111111111111\n",
      "\tEpoch 224: \tAverage Loss:  0.23239631652832032\t ACC train:  0.6333333333333333\t ACC test:  0.5733333333333334\n",
      "\tEpoch 225: \tAverage Loss:  0.23058909606933595\t ACC train:  0.7666666666666667\t ACC test:  0.5577777777777778\n",
      "\tEpoch 226: \tAverage Loss:  0.23038517761230468\t ACC train:  0.7\t ACC test:  0.5755555555555556\n",
      "\tEpoch 227: \tAverage Loss:  0.2256707763671875\t ACC train:  0.6666666666666666\t ACC test:  0.5755555555555556\n",
      "\tEpoch 228: \tAverage Loss:  0.22908004760742187\t ACC train:  0.6666666666666666\t ACC test:  0.6066666666666667\n",
      "\tEpoch 229: \tAverage Loss:  0.22873390197753907\t ACC train:  0.7\t ACC test:  0.5866666666666667\n",
      "\tEpoch 230: \tAverage Loss:  0.22387745666503905\t ACC train:  0.7333333333333333\t ACC test:  0.5866666666666667\n",
      "\tEpoch 231: \tAverage Loss:  0.22590301513671876\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 232: \tAverage Loss:  0.2220579833984375\t ACC train:  0.7333333333333333\t ACC test:  0.5955555555555555\n",
      "\tEpoch 233: \tAverage Loss:  0.22212425231933594\t ACC train:  0.6666666666666666\t ACC test:  0.6022222222222222\n",
      "\tEpoch 234: \tAverage Loss:  0.21548336791992187\t ACC train:  0.6666666666666666\t ACC test:  0.6\n",
      "\tEpoch 235: \tAverage Loss:  0.21423199462890624\t ACC train:  0.6\t ACC test:  0.5911111111111111\n",
      "\tEpoch 236: \tAverage Loss:  0.21328985595703126\t ACC train:  0.5666666666666667\t ACC test:  0.5955555555555555\n",
      "\tEpoch 237: \tAverage Loss:  0.21747023010253907\t ACC train:  0.5666666666666667\t ACC test:  0.6088888888888889\n",
      "\tEpoch 238: \tAverage Loss:  0.21196537780761718\t ACC train:  0.6666666666666666\t ACC test:  0.6066666666666667\n",
      "\tEpoch 239: \tAverage Loss:  0.20388600158691406\t ACC train:  0.6\t ACC test:  0.5933333333333334\n",
      "\tEpoch 240: \tAverage Loss:  0.20485191345214843\t ACC train:  0.5\t ACC test:  0.5822222222222222\n",
      "\tEpoch 241: \tAverage Loss:  0.2031381072998047\t ACC train:  0.5666666666666667\t ACC test:  0.6177777777777778\n",
      "\tEpoch 242: \tAverage Loss:  0.20599397277832032\t ACC train:  0.7666666666666667\t ACC test:  0.6044444444444445\n",
      "\tEpoch 243: \tAverage Loss:  0.20507473754882813\t ACC train:  0.7\t ACC test:  0.5733333333333334\n",
      "\tEpoch 244: \tAverage Loss:  0.1982894287109375\t ACC train:  0.6333333333333333\t ACC test:  0.56\n",
      "\tEpoch 245: \tAverage Loss:  0.19273320007324218\t ACC train:  0.7333333333333333\t ACC test:  0.5844444444444444\n",
      "\tEpoch 246: \tAverage Loss:  0.19622496032714845\t ACC train:  0.5666666666666667\t ACC test:  0.5844444444444444\n",
      "\tEpoch 247: \tAverage Loss:  0.19367520141601563\t ACC train:  0.5666666666666667\t ACC test:  0.5888888888888889\n",
      "\tEpoch 248: \tAverage Loss:  0.19008653259277344\t ACC train:  0.7\t ACC test:  0.5888888888888889\n",
      "\tEpoch 249: \tAverage Loss:  0.18584461975097658\t ACC train:  0.5666666666666667\t ACC test:  0.5933333333333334\n",
      "\tEpoch 250: \tAverage Loss:  0.19047769165039063\t ACC train:  0.6\t ACC test:  0.6133333333333333\n",
      "\tEpoch 251: \tAverage Loss:  0.18246966552734376\t ACC train:  0.6333333333333333\t ACC test:  0.5977777777777777\n",
      "\tEpoch 252: \tAverage Loss:  0.18138243103027343\t ACC train:  0.7333333333333333\t ACC test:  0.5911111111111111\n",
      "\tEpoch 253: \tAverage Loss:  0.18215745544433593\t ACC train:  0.6666666666666666\t ACC test:  0.5955555555555555\n",
      "\tEpoch 254: \tAverage Loss:  0.180306396484375\t ACC train:  0.7333333333333333\t ACC test:  0.6155555555555555\n",
      "\tEpoch 255: \tAverage Loss:  0.17926095581054688\t ACC train:  0.7333333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 256: \tAverage Loss:  0.1785935516357422\t ACC train:  0.6666666666666666\t ACC test:  0.6155555555555555\n",
      "\tEpoch 257: \tAverage Loss:  0.17502696228027342\t ACC train:  0.7333333333333333\t ACC test:  0.6488888888888888\n",
      "\tEpoch 258: \tAverage Loss:  0.17460687255859375\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 259: \tAverage Loss:  0.17407147216796875\t ACC train:  0.8\t ACC test:  0.6377777777777778\n",
      "\tEpoch 260: \tAverage Loss:  0.17410305786132813\t ACC train:  0.7666666666666667\t ACC test:  0.6422222222222222\n",
      "\tEpoch 261: \tAverage Loss:  0.17177496337890624\t ACC train:  0.7333333333333333\t ACC test:  0.6666666666666666\n",
      "\tEpoch 262: \tAverage Loss:  0.17329933166503905\t ACC train:  0.7333333333333333\t ACC test:  0.6644444444444444\n",
      "\tEpoch 263: \tAverage Loss:  0.17307167053222655\t ACC train:  0.7666666666666667\t ACC test:  0.6577777777777778\n",
      "\tEpoch 264: \tAverage Loss:  0.1669913330078125\t ACC train:  0.8\t ACC test:  0.6444444444444445\n",
      "\tEpoch 265: \tAverage Loss:  0.16897756958007812\t ACC train:  0.8333333333333334\t ACC test:  0.6733333333333333\n",
      "\tEpoch 266: \tAverage Loss:  0.16801821899414063\t ACC train:  0.8333333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 267: \tAverage Loss:  0.16809539794921874\t ACC train:  0.7\t ACC test:  0.6688888888888889\n",
      "\tEpoch 268: \tAverage Loss:  0.16513478088378905\t ACC train:  0.7333333333333333\t ACC test:  0.6688888888888889\n",
      "\tEpoch 269: \tAverage Loss:  0.16396817016601561\t ACC train:  0.8333333333333334\t ACC test:  0.6955555555555556\n",
      "\tEpoch 270: \tAverage Loss:  0.16429598999023437\t ACC train:  0.7666666666666667\t ACC test:  0.6977777777777778\n",
      "\tEpoch 271: \tAverage Loss:  0.16418560791015624\t ACC train:  0.8\t ACC test:  0.6644444444444444\n",
      "\tEpoch 272: \tAverage Loss:  0.16347445678710937\t ACC train:  0.9\t ACC test:  0.6755555555555556\n",
      "\tEpoch 273: \tAverage Loss:  0.16255152893066407\t ACC train:  0.8\t ACC test:  0.6777777777777778\n",
      "\tEpoch 274: \tAverage Loss:  0.16368017578125\t ACC train:  0.8333333333333334\t ACC test:  0.6733333333333333\n",
      "\tEpoch 275: \tAverage Loss:  0.1612210693359375\t ACC train:  0.7666666666666667\t ACC test:  0.6666666666666666\n",
      "\tEpoch 276: \tAverage Loss:  0.16046255493164063\t ACC train:  0.7\t ACC test:  0.6466666666666666\n",
      "\tEpoch 277: \tAverage Loss:  0.15897412109375\t ACC train:  0.7666666666666667\t ACC test:  0.6533333333333333\n",
      "\tEpoch 278: \tAverage Loss:  0.1606339874267578\t ACC train:  0.7666666666666667\t ACC test:  0.6555555555555556\n",
      "\tEpoch 279: \tAverage Loss:  0.15822471618652345\t ACC train:  0.7333333333333333\t ACC test:  0.6444444444444445\n",
      "\tEpoch 280: \tAverage Loss:  0.1593568572998047\t ACC train:  0.8333333333333334\t ACC test:  0.66\n",
      "\tEpoch 281: \tAverage Loss:  0.1586777801513672\t ACC train:  0.9\t ACC test:  0.6933333333333334\n",
      "\tEpoch 282: \tAverage Loss:  0.1582287139892578\t ACC train:  0.9\t ACC test:  0.6888888888888889\n",
      "\tEpoch 283: \tAverage Loss:  0.15706278991699218\t ACC train:  0.8666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 284: \tAverage Loss:  0.15562930297851563\t ACC train:  0.8\t ACC test:  0.7155555555555555\n",
      "\tEpoch 285: \tAverage Loss:  0.15712942504882813\t ACC train:  0.8666666666666667\t ACC test:  0.7288888888888889\n",
      "\tEpoch 286: \tAverage Loss:  0.156239501953125\t ACC train:  0.8333333333333334\t ACC test:  0.6977777777777778\n",
      "\tEpoch 287: \tAverage Loss:  0.15548696899414063\t ACC train:  0.8333333333333334\t ACC test:  0.6866666666666666\n",
      "\tEpoch 288: \tAverage Loss:  0.15655514526367187\t ACC train:  0.9666666666666667\t ACC test:  0.7044444444444444\n",
      "\tEpoch 289: \tAverage Loss:  0.15577366638183593\t ACC train:  0.8666666666666667\t ACC test:  0.7066666666666667\n",
      "\tEpoch 290: \tAverage Loss:  0.1548686981201172\t ACC train:  0.9333333333333333\t ACC test:  0.7333333333333333\n",
      "\tEpoch 291: \tAverage Loss:  0.15378163146972657\t ACC train:  0.8666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 292: \tAverage Loss:  0.15235804748535156\t ACC train:  0.9333333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 293: \tAverage Loss:  0.1507802276611328\t ACC train:  0.9333333333333333\t ACC test:  0.7\n",
      "\tEpoch 294: \tAverage Loss:  0.15350660705566407\t ACC train:  0.9333333333333333\t ACC test:  0.6844444444444444\n",
      "\tEpoch 295: \tAverage Loss:  0.1522769012451172\t ACC train:  0.9\t ACC test:  0.7133333333333334\n",
      "\tEpoch 296: \tAverage Loss:  0.15246536254882812\t ACC train:  0.8666666666666667\t ACC test:  0.72\n",
      "\tEpoch 297: \tAverage Loss:  0.15300282287597655\t ACC train:  0.9\t ACC test:  0.7266666666666667\n",
      "\tEpoch 298: \tAverage Loss:  0.15071693420410157\t ACC train:  0.8666666666666667\t ACC test:  0.7355555555555555\n",
      "\tEpoch 299: \tAverage Loss:  0.1504915771484375\t ACC train:  0.9\t ACC test:  0.7444444444444445\n",
      "\tEpoch 300: \tAverage Loss:  0.15072618103027344\t ACC train:  0.9666666666666667\t ACC test:  0.7444444444444445\n",
      "\tEpoch 301: \tAverage Loss:  0.1488744812011719\t ACC train:  0.9333333333333333\t ACC test:  0.7333333333333333\n",
      "\tEpoch 302: \tAverage Loss:  0.1511880340576172\t ACC train:  0.9\t ACC test:  0.7311111111111112\n",
      "\tEpoch 303: \tAverage Loss:  0.15051394653320313\t ACC train:  0.9\t ACC test:  0.74\n",
      "\tEpoch 304: \tAverage Loss:  0.14933705139160156\t ACC train:  0.9333333333333333\t ACC test:  0.76\n",
      "\tEpoch 305: \tAverage Loss:  0.14753634643554686\t ACC train:  0.9\t ACC test:  0.7666666666666667\n",
      "\tEpoch 306: \tAverage Loss:  0.14791253662109374\t ACC train:  0.8666666666666667\t ACC test:  0.7711111111111111\n",
      "\tEpoch 307: \tAverage Loss:  0.1486432342529297\t ACC train:  0.9333333333333333\t ACC test:  0.7511111111111111\n",
      "\tEpoch 308: \tAverage Loss:  0.1498040008544922\t ACC train:  0.9666666666666667\t ACC test:  0.74\n",
      "\tEpoch 309: \tAverage Loss:  0.14893695068359375\t ACC train:  0.9666666666666667\t ACC test:  0.7666666666666667\n",
      "\tEpoch 310: \tAverage Loss:  0.14932528686523439\t ACC train:  0.8333333333333334\t ACC test:  0.7488888888888889\n",
      "\tEpoch 311: \tAverage Loss:  0.14867552185058594\t ACC train:  0.9\t ACC test:  0.7555555555555555\n",
      "\tEpoch 312: \tAverage Loss:  0.1505220184326172\t ACC train:  0.9\t ACC test:  0.7533333333333333\n",
      "\tEpoch 313: \tAverage Loss:  0.1512487335205078\t ACC train:  0.9333333333333333\t ACC test:  0.7466666666666667\n",
      "\tEpoch 314: \tAverage Loss:  0.14571176147460937\t ACC train:  0.9666666666666667\t ACC test:  0.7488888888888889\n",
      "\tEpoch 315: \tAverage Loss:  0.14558352661132812\t ACC train:  0.9\t ACC test:  0.7644444444444445\n",
      "\tEpoch 316: \tAverage Loss:  0.1451735076904297\t ACC train:  0.8666666666666667\t ACC test:  0.76\n",
      "\tEpoch 317: \tAverage Loss:  0.144910400390625\t ACC train:  0.9333333333333333\t ACC test:  0.7644444444444445\n",
      "\tEpoch 318: \tAverage Loss:  0.1450443115234375\t ACC train:  0.9333333333333333\t ACC test:  0.7555555555555555\n",
      "\tEpoch 319: \tAverage Loss:  0.14579974365234374\t ACC train:  0.9\t ACC test:  0.7644444444444445\n",
      "\tEpoch 320: \tAverage Loss:  0.148056640625\t ACC train:  0.7666666666666667\t ACC test:  0.7555555555555555\n",
      "\tEpoch 321: \tAverage Loss:  0.1463004150390625\t ACC train:  0.9333333333333333\t ACC test:  0.7511111111111111\n",
      "\tEpoch 322: \tAverage Loss:  0.1453878173828125\t ACC train:  0.9333333333333333\t ACC test:  0.7311111111111112\n",
      "\tEpoch 323: \tAverage Loss:  0.14467031860351562\t ACC train:  0.8666666666666667\t ACC test:  0.7377777777777778\n",
      "\tEpoch 324: \tAverage Loss:  0.1435328826904297\t ACC train:  0.9\t ACC test:  0.7355555555555555\n",
      "\tEpoch 325: \tAverage Loss:  0.14830227661132814\t ACC train:  0.9\t ACC test:  0.7488888888888889\n",
      "\tEpoch 326: \tAverage Loss:  0.1433663330078125\t ACC train:  0.8666666666666667\t ACC test:  0.7511111111111111\n",
      "\tEpoch 327: \tAverage Loss:  0.14540350341796876\t ACC train:  0.9333333333333333\t ACC test:  0.7555555555555555\n",
      "\tEpoch 328: \tAverage Loss:  0.14446601867675782\t ACC train:  0.9333333333333333\t ACC test:  0.7622222222222222\n",
      "\tEpoch 329: \tAverage Loss:  0.14065589904785156\t ACC train:  0.9333333333333333\t ACC test:  0.7688888888888888\n",
      "\tEpoch 330: \tAverage Loss:  0.14398565673828126\t ACC train:  0.9333333333333333\t ACC test:  0.7911111111111111\n",
      "\tEpoch 331: \tAverage Loss:  0.14299151611328126\t ACC train:  0.8333333333333334\t ACC test:  0.8022222222222222\n",
      "\tEpoch 332: \tAverage Loss:  0.14503306579589845\t ACC train:  0.9333333333333333\t ACC test:  0.8088888888888889\n",
      "\tEpoch 333: \tAverage Loss:  0.14358563232421875\t ACC train:  0.9\t ACC test:  0.8\n",
      "\tEpoch 334: \tAverage Loss:  0.1413476867675781\t ACC train:  0.9666666666666667\t ACC test:  0.8022222222222222\n",
      "\tEpoch 335: \tAverage Loss:  0.1442498474121094\t ACC train:  0.9333333333333333\t ACC test:  0.8022222222222222\n",
      "\tEpoch 336: \tAverage Loss:  0.1429099884033203\t ACC train:  0.9666666666666667\t ACC test:  0.7977777777777778\n",
      "\tEpoch 337: \tAverage Loss:  0.14172201538085938\t ACC train:  0.9333333333333333\t ACC test:  0.8066666666666666\n",
      "\tEpoch 338: \tAverage Loss:  0.14360401916503907\t ACC train:  1.0\t ACC test:  0.7844444444444445\n",
      "\tEpoch 339: \tAverage Loss:  0.14210858154296874\t ACC train:  0.9333333333333333\t ACC test:  0.7911111111111111\n",
      "\tEpoch 340: \tAverage Loss:  0.14213912963867187\t ACC train:  0.9666666666666667\t ACC test:  0.7733333333333333\n",
      "\tEpoch 341: \tAverage Loss:  0.14119204711914063\t ACC train:  0.9333333333333333\t ACC test:  0.78\n",
      "\tEpoch 342: \tAverage Loss:  0.13990452575683593\t ACC train:  0.9666666666666667\t ACC test:  0.7844444444444445\n",
      "\tEpoch 343: \tAverage Loss:  0.14018728637695313\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 344: \tAverage Loss:  0.14119001770019532\t ACC train:  0.9666666666666667\t ACC test:  0.7911111111111111\n",
      "\tEpoch 345: \tAverage Loss:  0.14037223815917968\t ACC train:  0.9666666666666667\t ACC test:  0.78\n",
      "\tEpoch 346: \tAverage Loss:  0.14124853515625\t ACC train:  0.9666666666666667\t ACC test:  0.7933333333333333\n",
      "\tEpoch 347: \tAverage Loss:  0.13998155212402344\t ACC train:  0.9333333333333333\t ACC test:  0.8111111111111111\n",
      "\tEpoch 348: \tAverage Loss:  0.14154032897949217\t ACC train:  0.9333333333333333\t ACC test:  0.7977777777777778\n",
      "\tEpoch 349: \tAverage Loss:  0.14130987548828125\t ACC train:  0.9666666666666667\t ACC test:  0.7933333333333333\n",
      "\tEpoch 350: \tAverage Loss:  0.14008114624023438\t ACC train:  0.9666666666666667\t ACC test:  0.7911111111111111\n",
      "\tEpoch 351: \tAverage Loss:  0.13887881469726562\t ACC train:  0.9333333333333333\t ACC test:  0.8066666666666666\n",
      "\tEpoch 352: \tAverage Loss:  0.14225233459472655\t ACC train:  0.9\t ACC test:  0.7844444444444445\n",
      "\tEpoch 353: \tAverage Loss:  0.14011503601074218\t ACC train:  0.9333333333333333\t ACC test:  0.7888888888888889\n",
      "\tEpoch 354: \tAverage Loss:  0.13912362670898437\t ACC train:  0.9666666666666667\t ACC test:  0.7977777777777778\n",
      "\tEpoch 355: \tAverage Loss:  0.140153564453125\t ACC train:  0.9333333333333333\t ACC test:  0.7688888888888888\n",
      "\tEpoch 356: \tAverage Loss:  0.13761607360839845\t ACC train:  0.9\t ACC test:  0.7666666666666667\n",
      "\tEpoch 357: \tAverage Loss:  0.13960697937011718\t ACC train:  0.9\t ACC test:  0.7688888888888888\n",
      "\tEpoch 358: \tAverage Loss:  0.13933876037597656\t ACC train:  0.9666666666666667\t ACC test:  0.78\n",
      "\tEpoch 359: \tAverage Loss:  0.1392537384033203\t ACC train:  0.9666666666666667\t ACC test:  0.7933333333333333\n",
      "\tEpoch 360: \tAverage Loss:  0.13748138427734374\t ACC train:  0.9666666666666667\t ACC test:  0.8\n",
      "\tEpoch 361: \tAverage Loss:  0.13869627380371094\t ACC train:  0.9666666666666667\t ACC test:  0.82\n",
      "\tEpoch 362: \tAverage Loss:  0.13729156494140626\t ACC train:  0.9666666666666667\t ACC test:  0.8288888888888889\n",
      "\tEpoch 363: \tAverage Loss:  0.1391331329345703\t ACC train:  0.9\t ACC test:  0.8355555555555556\n",
      "\tEpoch 364: \tAverage Loss:  0.13876463317871093\t ACC train:  1.0\t ACC test:  0.8222222222222222\n",
      "\tEpoch 365: \tAverage Loss:  0.13982594299316406\t ACC train:  1.0\t ACC test:  0.8288888888888889\n",
      "\tEpoch 366: \tAverage Loss:  0.14143386840820313\t ACC train:  0.9333333333333333\t ACC test:  0.8088888888888889\n",
      "\tEpoch 367: \tAverage Loss:  0.1374019775390625\t ACC train:  0.9666666666666667\t ACC test:  0.8266666666666667\n",
      "\tEpoch 368: \tAverage Loss:  0.13659153747558594\t ACC train:  1.0\t ACC test:  0.8155555555555556\n",
      "\tEpoch 369: \tAverage Loss:  0.13691569519042968\t ACC train:  0.9666666666666667\t ACC test:  0.8066666666666666\n",
      "\tEpoch 370: \tAverage Loss:  0.14046401977539064\t ACC train:  1.0\t ACC test:  0.82\n",
      "\tEpoch 371: \tAverage Loss:  0.13966151428222656\t ACC train:  1.0\t ACC test:  0.8222222222222222\n",
      "Stopping early at epoch 371. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 40\n",
      "\tEpoch 1: \tAverage Loss:  0.39757107543945314\t ACC train:  0.425\t ACC test:  0.5133333333333333\n",
      "\tEpoch 2: \tAverage Loss:  0.3950840148925781\t ACC train:  0.425\t ACC test:  0.5133333333333333\n",
      "\tEpoch 3: \tAverage Loss:  0.39257418823242185\t ACC train:  0.425\t ACC test:  0.5133333333333333\n",
      "\tEpoch 4: \tAverage Loss:  0.3900804138183594\t ACC train:  0.425\t ACC test:  0.5133333333333333\n",
      "\tEpoch 5: \tAverage Loss:  0.38765081787109373\t ACC train:  0.425\t ACC test:  0.5133333333333333\n",
      "\tEpoch 6: \tAverage Loss:  0.38526028442382815\t ACC train:  0.425\t ACC test:  0.5133333333333333\n",
      "\tEpoch 7: \tAverage Loss:  0.38297946166992186\t ACC train:  0.375\t ACC test:  0.4888888888888889\n",
      "\tEpoch 8: \tAverage Loss:  0.3808060913085938\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 9: \tAverage Loss:  0.37867156982421873\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 10: \tAverage Loss:  0.37667193603515625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  0.3748061218261719\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  0.373065673828125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  0.3714283447265625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  0.3699339294433594\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  0.36846395874023435\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  0.3671094360351562\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  0.3658903503417969\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  0.3647251892089844\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  0.3636678466796875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  0.3626582336425781\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  0.36176486206054687\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  0.3609063720703125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  0.36009521484375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  0.35934054565429685\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  0.3586519470214844\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  0.35800634765625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  0.3573418884277344\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  0.35670147705078126\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  0.35610427856445315\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  0.35546170043945313\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  0.35490631103515624\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  0.3542623291015625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  0.3536990966796875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  0.353085205078125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  0.3525139465332031\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  0.35192279052734377\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  0.3513578186035156\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  0.35081192016601564\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  0.35029867553710936\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  0.34979312133789064\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  0.34930767822265624\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  0.34883804321289064\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  0.3484313354492187\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  0.3479822692871094\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  0.34755279541015627\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  0.34718655395507814\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  0.3467643127441406\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  0.34640386962890624\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  0.3460618896484375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  0.34571548461914064\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  0.3453963317871094\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  0.34507083129882815\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.34473513793945315\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  0.34442807006835935\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  0.3441680603027344\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  0.3438489990234375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  0.343552978515625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  0.3432709045410156\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  0.34301312255859373\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  0.34272576904296875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  0.3424964294433594\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  0.3422201538085938\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  0.3419886779785156\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  0.34174365234375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  0.34153903198242186\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.341281982421875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  0.34108270263671875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  0.34085955810546875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  0.34065850830078126\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  0.3404862976074219\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  0.3403005676269531\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  0.34008648681640624\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  0.3398896179199219\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  0.3397829895019531\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  0.33953863525390626\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  0.33939706420898436\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  0.3392195129394531\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  0.3390352783203125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  0.3389288940429688\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.33878662109375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  0.338596435546875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  0.3384659423828125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  0.33831396484375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 84: \tAverage Loss:  0.33818524169921876\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 85: \tAverage Loss:  0.3380447998046875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 86: \tAverage Loss:  0.33791763305664063\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 87: \tAverage Loss:  0.33780108642578127\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 88: \tAverage Loss:  0.33768438720703126\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 89: \tAverage Loss:  0.33759536743164065\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 90: \tAverage Loss:  0.33746292114257814\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 91: \tAverage Loss:  0.33732998657226565\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 92: \tAverage Loss:  0.33726217651367185\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 93: \tAverage Loss:  0.3371480102539062\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 94: \tAverage Loss:  0.3370349426269531\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 95: \tAverage Loss:  0.336934326171875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 96: \tAverage Loss:  0.33686453247070314\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 97: \tAverage Loss:  0.33675579833984376\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 98: \tAverage Loss:  0.33664813232421875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 99: \tAverage Loss:  0.3365598449707031\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 100: \tAverage Loss:  0.3364776916503906\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  0.3363812255859375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 102: \tAverage Loss:  0.3362841491699219\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 103: \tAverage Loss:  0.33624490356445313\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 104: \tAverage Loss:  0.3361424560546875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 105: \tAverage Loss:  0.336095947265625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 106: \tAverage Loss:  0.33600296020507814\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 107: \tAverage Loss:  0.3359559326171875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 108: \tAverage Loss:  0.3358621826171875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 109: \tAverage Loss:  0.33577273559570314\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 110: \tAverage Loss:  0.33574810791015625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 111: \tAverage Loss:  0.3356788635253906\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 112: \tAverage Loss:  0.3356071166992188\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 113: \tAverage Loss:  0.33556509399414064\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 114: \tAverage Loss:  0.33550946044921875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 115: \tAverage Loss:  0.33544464111328126\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 116: \tAverage Loss:  0.335383056640625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 117: \tAverage Loss:  0.33533941650390625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 118: \tAverage Loss:  0.33528024291992187\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 119: \tAverage Loss:  0.33523016357421875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 120: \tAverage Loss:  0.33521609497070315\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 121: \tAverage Loss:  0.33514181518554687\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 122: \tAverage Loss:  0.33509820556640624\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 123: \tAverage Loss:  0.3350531616210938\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 124: \tAverage Loss:  0.3349863891601563\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 125: \tAverage Loss:  0.3349926452636719\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 126: \tAverage Loss:  0.33491949462890624\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 127: \tAverage Loss:  0.3349064636230469\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 128: \tAverage Loss:  0.3348451843261719\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 129: \tAverage Loss:  0.3348238525390625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 130: \tAverage Loss:  0.33477325439453126\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 131: \tAverage Loss:  0.3347518005371094\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 132: \tAverage Loss:  0.33469476318359376\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 133: \tAverage Loss:  0.3346680603027344\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 134: \tAverage Loss:  0.33463937377929687\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 135: \tAverage Loss:  0.3346003723144531\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 136: \tAverage Loss:  0.33457662963867185\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 137: \tAverage Loss:  0.3345457458496094\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 138: \tAverage Loss:  0.3345179138183594\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 139: \tAverage Loss:  0.3344874877929688\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 140: \tAverage Loss:  0.33445498657226563\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 141: \tAverage Loss:  0.3344564514160156\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 142: \tAverage Loss:  0.33440093994140624\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 143: \tAverage Loss:  0.33438619995117186\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 144: \tAverage Loss:  0.33437353515625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 145: \tAverage Loss:  0.33438241577148436\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 146: \tAverage Loss:  0.3343339538574219\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 147: \tAverage Loss:  0.3342628173828125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 148: \tAverage Loss:  0.3342783203125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 149: \tAverage Loss:  0.33424078369140625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 150: \tAverage Loss:  0.33420751953125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 151: \tAverage Loss:  0.33422982788085936\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 152: \tAverage Loss:  0.33421438598632813\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 153: \tAverage Loss:  0.33418487548828124\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 154: \tAverage Loss:  0.33416204833984375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 155: \tAverage Loss:  0.3341315612792969\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 156: \tAverage Loss:  0.33408120727539065\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 157: \tAverage Loss:  0.33408700561523436\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 158: \tAverage Loss:  0.3340466003417969\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 159: \tAverage Loss:  0.3340675048828125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 160: \tAverage Loss:  0.3340837707519531\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 161: \tAverage Loss:  0.3340352172851562\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 162: \tAverage Loss:  0.33400299072265627\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 163: \tAverage Loss:  0.33403076171875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 164: \tAverage Loss:  0.3339405212402344\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 165: \tAverage Loss:  0.3339873046875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 166: \tAverage Loss:  0.3339880676269531\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 167: \tAverage Loss:  0.33395306396484375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 168: \tAverage Loss:  0.33392529296875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 169: \tAverage Loss:  0.33391476440429685\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 170: \tAverage Loss:  0.33390634155273435\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 171: \tAverage Loss:  0.3338839721679687\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 172: \tAverage Loss:  0.333844482421875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 173: \tAverage Loss:  0.3338650207519531\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 174: \tAverage Loss:  0.3338553161621094\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 175: \tAverage Loss:  0.3338646545410156\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 176: \tAverage Loss:  0.33384832763671873\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 177: \tAverage Loss:  0.33382440185546874\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 178: \tAverage Loss:  0.3337831420898438\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 179: \tAverage Loss:  0.3337516174316406\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 180: \tAverage Loss:  0.3337811279296875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 181: \tAverage Loss:  0.33376455688476564\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 182: \tAverage Loss:  0.33376666259765625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 183: \tAverage Loss:  0.33374273681640626\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 184: \tAverage Loss:  0.3337359619140625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 185: \tAverage Loss:  0.33370822143554685\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 186: \tAverage Loss:  0.33373590087890626\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 187: \tAverage Loss:  0.33374896240234375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 188: \tAverage Loss:  0.333720947265625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 189: \tAverage Loss:  0.33362725830078127\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 190: \tAverage Loss:  0.3336356201171875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 191: \tAverage Loss:  0.33360995483398437\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 192: \tAverage Loss:  0.3336673583984375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 193: \tAverage Loss:  0.3335849304199219\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 194: \tAverage Loss:  0.3335581359863281\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 195: \tAverage Loss:  0.3336634521484375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 196: \tAverage Loss:  0.33363278198242186\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 197: \tAverage Loss:  0.33362673950195315\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 198: \tAverage Loss:  0.33358984375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 199: \tAverage Loss:  0.33358724975585935\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 200: \tAverage Loss:  0.3335093994140625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 201: \tAverage Loss:  0.3334794921875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 202: \tAverage Loss:  0.33353854370117186\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 203: \tAverage Loss:  0.3335068054199219\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 204: \tAverage Loss:  0.3335041809082031\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 205: \tAverage Loss:  0.3334915466308594\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 206: \tAverage Loss:  0.3334398193359375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 207: \tAverage Loss:  0.33344674682617187\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 208: \tAverage Loss:  0.333408447265625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 209: \tAverage Loss:  0.3333726806640625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 210: \tAverage Loss:  0.33346243286132815\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 211: \tAverage Loss:  0.33350885009765624\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 212: \tAverage Loss:  0.33337643432617187\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 213: \tAverage Loss:  0.3333325500488281\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 214: \tAverage Loss:  0.3333505859375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 215: \tAverage Loss:  0.33324801635742185\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 216: \tAverage Loss:  0.33333029174804685\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 217: \tAverage Loss:  0.33328863525390623\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 218: \tAverage Loss:  0.3332314758300781\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 219: \tAverage Loss:  0.33322979736328123\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 220: \tAverage Loss:  0.33313674926757814\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 221: \tAverage Loss:  0.33319415283203124\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 222: \tAverage Loss:  0.33316189575195315\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 223: \tAverage Loss:  0.3331887512207031\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 224: \tAverage Loss:  0.33313262939453125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 225: \tAverage Loss:  0.33307168579101565\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 226: \tAverage Loss:  0.3331249084472656\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 227: \tAverage Loss:  0.3330653991699219\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 228: \tAverage Loss:  0.33303955078125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 229: \tAverage Loss:  0.3329731750488281\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 230: \tAverage Loss:  0.33323818969726565\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 231: \tAverage Loss:  0.3327315673828125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 232: \tAverage Loss:  0.33287246704101564\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 233: \tAverage Loss:  0.33282650756835935\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 234: \tAverage Loss:  0.33291537475585936\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 235: \tAverage Loss:  0.3325415344238281\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 236: \tAverage Loss:  0.33290771484375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 237: \tAverage Loss:  0.33281414794921876\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 238: \tAverage Loss:  0.33262451171875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 239: \tAverage Loss:  0.3325800476074219\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 240: \tAverage Loss:  0.3327334899902344\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 241: \tAverage Loss:  0.33242523193359375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 242: \tAverage Loss:  0.33239498901367187\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 243: \tAverage Loss:  0.33229791259765623\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 244: \tAverage Loss:  0.3323547058105469\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 245: \tAverage Loss:  0.33226629638671873\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 246: \tAverage Loss:  0.33216845703125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 247: \tAverage Loss:  0.33196957397460936\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 248: \tAverage Loss:  0.33187896728515626\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 249: \tAverage Loss:  0.3323255615234375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 250: \tAverage Loss:  0.33164340209960935\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 251: \tAverage Loss:  0.3319683532714844\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 252: \tAverage Loss:  0.33176220703125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 253: \tAverage Loss:  0.3316612243652344\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 254: \tAverage Loss:  0.33139276123046874\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 255: \tAverage Loss:  0.33127719116210935\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 256: \tAverage Loss:  0.3309466857910156\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 257: \tAverage Loss:  0.33111358642578126\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 258: \tAverage Loss:  0.33175588989257815\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 259: \tAverage Loss:  0.3310572509765625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 260: \tAverage Loss:  0.33071954345703125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 261: \tAverage Loss:  0.330435791015625\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 262: \tAverage Loss:  0.33028033447265626\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 263: \tAverage Loss:  0.33031033325195314\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 264: \tAverage Loss:  0.330272216796875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 265: \tAverage Loss:  0.33045379638671873\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 266: \tAverage Loss:  0.32941030883789063\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 267: \tAverage Loss:  0.32928204345703127\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 268: \tAverage Loss:  0.3301178283691406\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 269: \tAverage Loss:  0.3290127258300781\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 270: \tAverage Loss:  0.32665066528320313\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 271: \tAverage Loss:  0.3281673889160156\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 272: \tAverage Loss:  0.32821481323242185\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 273: \tAverage Loss:  0.3220797424316406\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 274: \tAverage Loss:  0.324648193359375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 275: \tAverage Loss:  0.3232665710449219\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 276: \tAverage Loss:  0.32125982666015623\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 277: \tAverage Loss:  0.3075425109863281\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 278: \tAverage Loss:  0.31145974731445314\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 279: \tAverage Loss:  0.3139603271484375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 280: \tAverage Loss:  0.30208908081054686\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 281: \tAverage Loss:  0.30387704467773435\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 282: \tAverage Loss:  0.29781533813476563\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 283: \tAverage Loss:  0.30035910034179686\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 284: \tAverage Loss:  0.29259283447265627\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 285: \tAverage Loss:  0.2941439514160156\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 286: \tAverage Loss:  0.29251434326171877\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 287: \tAverage Loss:  0.28823300170898436\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 288: \tAverage Loss:  0.292513671875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 289: \tAverage Loss:  0.2815993347167969\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 290: \tAverage Loss:  0.2864501953125\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 291: \tAverage Loss:  0.2737843322753906\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 292: \tAverage Loss:  0.2690927734375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 293: \tAverage Loss:  0.2764900817871094\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 294: \tAverage Loss:  0.27098046875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 295: \tAverage Loss:  0.2721391296386719\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 296: \tAverage Loss:  0.2669133911132813\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 297: \tAverage Loss:  0.26329904174804686\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 298: \tAverage Loss:  0.2679997863769531\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 299: \tAverage Loss:  0.258328857421875\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 300: \tAverage Loss:  0.25965530395507813\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 301: \tAverage Loss:  0.253669677734375\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 302: \tAverage Loss:  0.253964599609375\t ACC train:  0.575\t ACC test:  0.49333333333333335\n",
      "\tEpoch 303: \tAverage Loss:  0.2513531951904297\t ACC train:  0.575\t ACC test:  0.4911111111111111\n",
      "\tEpoch 304: \tAverage Loss:  0.24977182006835938\t ACC train:  0.575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 305: \tAverage Loss:  0.24915158081054686\t ACC train:  0.575\t ACC test:  0.4888888888888889\n",
      "\tEpoch 306: \tAverage Loss:  0.24589616394042968\t ACC train:  0.575\t ACC test:  0.4955555555555556\n",
      "\tEpoch 307: \tAverage Loss:  0.24378738403320313\t ACC train:  0.575\t ACC test:  0.5044444444444445\n",
      "\tEpoch 308: \tAverage Loss:  0.243935546875\t ACC train:  0.575\t ACC test:  0.5111111111111111\n",
      "\tEpoch 309: \tAverage Loss:  0.24345223999023438\t ACC train:  0.575\t ACC test:  0.5\n",
      "\tEpoch 310: \tAverage Loss:  0.2415699920654297\t ACC train:  0.6\t ACC test:  0.5133333333333333\n",
      "\tEpoch 311: \tAverage Loss:  0.23846046447753907\t ACC train:  0.575\t ACC test:  0.5022222222222222\n",
      "\tEpoch 312: \tAverage Loss:  0.23827276611328124\t ACC train:  0.6\t ACC test:  0.5088888888888888\n",
      "\tEpoch 313: \tAverage Loss:  0.2371205291748047\t ACC train:  0.6\t ACC test:  0.5266666666666666\n",
      "\tEpoch 314: \tAverage Loss:  0.23630160522460938\t ACC train:  0.6\t ACC test:  0.5244444444444445\n",
      "\tEpoch 315: \tAverage Loss:  0.2357740936279297\t ACC train:  0.575\t ACC test:  0.5311111111111111\n",
      "\tEpoch 316: \tAverage Loss:  0.2354571075439453\t ACC train:  0.575\t ACC test:  0.5155555555555555\n",
      "\tEpoch 317: \tAverage Loss:  0.234924560546875\t ACC train:  0.575\t ACC test:  0.5266666666666666\n",
      "\tEpoch 318: \tAverage Loss:  0.2309039306640625\t ACC train:  0.625\t ACC test:  0.5311111111111111\n",
      "\tEpoch 319: \tAverage Loss:  0.23202204895019532\t ACC train:  0.625\t ACC test:  0.5377777777777778\n",
      "\tEpoch 320: \tAverage Loss:  0.23167657470703126\t ACC train:  0.6\t ACC test:  0.5444444444444444\n",
      "\tEpoch 321: \tAverage Loss:  0.23275201416015626\t ACC train:  0.6\t ACC test:  0.5377777777777778\n",
      "\tEpoch 322: \tAverage Loss:  0.23000640869140626\t ACC train:  0.625\t ACC test:  0.5533333333333333\n",
      "\tEpoch 323: \tAverage Loss:  0.22749685668945313\t ACC train:  0.6\t ACC test:  0.5488888888888889\n",
      "\tEpoch 324: \tAverage Loss:  0.2264377746582031\t ACC train:  0.6\t ACC test:  0.5577777777777778\n",
      "\tEpoch 325: \tAverage Loss:  0.2308419189453125\t ACC train:  0.6\t ACC test:  0.56\n",
      "\tEpoch 326: \tAverage Loss:  0.2280863494873047\t ACC train:  0.7\t ACC test:  0.5577777777777778\n",
      "\tEpoch 327: \tAverage Loss:  0.2249349365234375\t ACC train:  0.65\t ACC test:  0.5666666666666667\n",
      "\tEpoch 328: \tAverage Loss:  0.2244367218017578\t ACC train:  0.625\t ACC test:  0.5688888888888889\n",
      "\tEpoch 329: \tAverage Loss:  0.22296441650390625\t ACC train:  0.675\t ACC test:  0.56\n",
      "\tEpoch 330: \tAverage Loss:  0.22400941467285157\t ACC train:  0.65\t ACC test:  0.5711111111111111\n",
      "\tEpoch 331: \tAverage Loss:  0.22276629638671874\t ACC train:  0.7\t ACC test:  0.5777777777777777\n",
      "\tEpoch 332: \tAverage Loss:  0.2196122589111328\t ACC train:  0.625\t ACC test:  0.5555555555555556\n",
      "\tEpoch 333: \tAverage Loss:  0.2214791717529297\t ACC train:  0.65\t ACC test:  0.5488888888888889\n",
      "\tEpoch 334: \tAverage Loss:  0.2201524200439453\t ACC train:  0.65\t ACC test:  0.5733333333333334\n",
      "\tEpoch 335: \tAverage Loss:  0.22177212524414064\t ACC train:  0.65\t ACC test:  0.5644444444444444\n",
      "\tEpoch 336: \tAverage Loss:  0.22091094970703126\t ACC train:  0.625\t ACC test:  0.58\n",
      "\tEpoch 337: \tAverage Loss:  0.21780291748046876\t ACC train:  0.675\t ACC test:  0.5666666666666667\n",
      "\tEpoch 338: \tAverage Loss:  0.21769198608398438\t ACC train:  0.7\t ACC test:  0.5755555555555556\n",
      "\tEpoch 339: \tAverage Loss:  0.219240478515625\t ACC train:  0.625\t ACC test:  0.5666666666666667\n",
      "\tEpoch 340: \tAverage Loss:  0.21747972106933594\t ACC train:  0.675\t ACC test:  0.5844444444444444\n",
      "\tEpoch 341: \tAverage Loss:  0.21727561950683594\t ACC train:  0.625\t ACC test:  0.5733333333333334\n",
      "\tEpoch 342: \tAverage Loss:  0.215728271484375\t ACC train:  0.65\t ACC test:  0.5733333333333334\n",
      "\tEpoch 343: \tAverage Loss:  0.21711126708984374\t ACC train:  0.725\t ACC test:  0.5711111111111111\n",
      "\tEpoch 344: \tAverage Loss:  0.2170875244140625\t ACC train:  0.675\t ACC test:  0.5711111111111111\n",
      "\tEpoch 345: \tAverage Loss:  0.21545501708984374\t ACC train:  0.7\t ACC test:  0.5733333333333334\n",
      "\tEpoch 346: \tAverage Loss:  0.21454710388183593\t ACC train:  0.675\t ACC test:  0.5777777777777777\n",
      "\tEpoch 347: \tAverage Loss:  0.21436492919921876\t ACC train:  0.725\t ACC test:  0.5822222222222222\n",
      "\tEpoch 348: \tAverage Loss:  0.213293212890625\t ACC train:  0.7\t ACC test:  0.5644444444444444\n",
      "\tEpoch 349: \tAverage Loss:  0.21532244873046874\t ACC train:  0.675\t ACC test:  0.5733333333333334\n",
      "\tEpoch 350: \tAverage Loss:  0.21262901306152343\t ACC train:  0.725\t ACC test:  0.5822222222222222\n",
      "\tEpoch 351: \tAverage Loss:  0.21176148986816407\t ACC train:  0.725\t ACC test:  0.5844444444444444\n",
      "\tEpoch 352: \tAverage Loss:  0.21082948303222657\t ACC train:  0.75\t ACC test:  0.5955555555555555\n",
      "\tEpoch 353: \tAverage Loss:  0.21010931396484375\t ACC train:  0.725\t ACC test:  0.5688888888888889\n",
      "\tEpoch 354: \tAverage Loss:  0.21240794372558594\t ACC train:  0.65\t ACC test:  0.5755555555555556\n",
      "\tEpoch 355: \tAverage Loss:  0.211523193359375\t ACC train:  0.75\t ACC test:  0.5955555555555555\n",
      "\tEpoch 356: \tAverage Loss:  0.20830703735351563\t ACC train:  0.7\t ACC test:  0.58\n",
      "\tEpoch 357: \tAverage Loss:  0.20792941284179686\t ACC train:  0.7\t ACC test:  0.58\n",
      "\tEpoch 358: \tAverage Loss:  0.20886709594726563\t ACC train:  0.725\t ACC test:  0.5933333333333334\n",
      "\tEpoch 359: \tAverage Loss:  0.20839132690429688\t ACC train:  0.725\t ACC test:  0.58\n",
      "\tEpoch 360: \tAverage Loss:  0.20995643615722656\t ACC train:  0.7\t ACC test:  0.58\n",
      "\tEpoch 361: \tAverage Loss:  0.20836744689941405\t ACC train:  0.75\t ACC test:  0.5844444444444444\n",
      "\tEpoch 362: \tAverage Loss:  0.207206787109375\t ACC train:  0.725\t ACC test:  0.5933333333333334\n",
      "\tEpoch 363: \tAverage Loss:  0.206782470703125\t ACC train:  0.725\t ACC test:  0.5955555555555555\n",
      "\tEpoch 364: \tAverage Loss:  0.2066388702392578\t ACC train:  0.725\t ACC test:  0.5888888888888889\n",
      "\tEpoch 365: \tAverage Loss:  0.20795741271972656\t ACC train:  0.675\t ACC test:  0.5977777777777777\n",
      "\tEpoch 366: \tAverage Loss:  0.2060023651123047\t ACC train:  0.725\t ACC test:  0.5911111111111111\n",
      "\tEpoch 367: \tAverage Loss:  0.20443397521972656\t ACC train:  0.725\t ACC test:  0.5888888888888889\n",
      "\tEpoch 368: \tAverage Loss:  0.20943241882324218\t ACC train:  0.675\t ACC test:  0.5955555555555555\n",
      "\tEpoch 369: \tAverage Loss:  0.20593531799316406\t ACC train:  0.7\t ACC test:  0.5977777777777777\n",
      "\tEpoch 370: \tAverage Loss:  0.20502476501464845\t ACC train:  0.75\t ACC test:  0.5888888888888889\n",
      "\tEpoch 371: \tAverage Loss:  0.2066224670410156\t ACC train:  0.725\t ACC test:  0.5977777777777777\n",
      "\tEpoch 372: \tAverage Loss:  0.204785400390625\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 373: \tAverage Loss:  0.20621568298339843\t ACC train:  0.725\t ACC test:  0.5955555555555555\n",
      "\tEpoch 374: \tAverage Loss:  0.20484756469726562\t ACC train:  0.7\t ACC test:  0.5866666666666667\n",
      "\tEpoch 375: \tAverage Loss:  0.20393910217285155\t ACC train:  0.725\t ACC test:  0.5955555555555555\n",
      "\tEpoch 376: \tAverage Loss:  0.20351023864746093\t ACC train:  0.725\t ACC test:  0.5977777777777777\n",
      "\tEpoch 377: \tAverage Loss:  0.20317745971679688\t ACC train:  0.675\t ACC test:  0.6022222222222222\n",
      "\tEpoch 378: \tAverage Loss:  0.2029239501953125\t ACC train:  0.75\t ACC test:  0.5955555555555555\n",
      "\tEpoch 379: \tAverage Loss:  0.20251437377929687\t ACC train:  0.725\t ACC test:  0.5911111111111111\n",
      "\tEpoch 380: \tAverage Loss:  0.20273356628417968\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 381: \tAverage Loss:  0.20043760681152345\t ACC train:  0.75\t ACC test:  0.5955555555555555\n",
      "\tEpoch 382: \tAverage Loss:  0.20114968872070313\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 383: \tAverage Loss:  0.20189381408691406\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 384: \tAverage Loss:  0.20230921936035157\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 385: \tAverage Loss:  0.200632080078125\t ACC train:  0.75\t ACC test:  0.5933333333333334\n",
      "\tEpoch 386: \tAverage Loss:  0.2019017333984375\t ACC train:  0.725\t ACC test:  0.6022222222222222\n",
      "\tEpoch 387: \tAverage Loss:  0.20132937622070313\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 388: \tAverage Loss:  0.20099765014648438\t ACC train:  0.725\t ACC test:  0.6022222222222222\n",
      "\tEpoch 389: \tAverage Loss:  0.19999188232421874\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 390: \tAverage Loss:  0.20080679321289063\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 391: \tAverage Loss:  0.20136915588378906\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 392: \tAverage Loss:  0.19985858154296876\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 393: \tAverage Loss:  0.19928532409667968\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 394: \tAverage Loss:  0.198654052734375\t ACC train:  0.725\t ACC test:  0.6044444444444445\n",
      "\tEpoch 395: \tAverage Loss:  0.19919528198242187\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 396: \tAverage Loss:  0.19833204650878905\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 397: \tAverage Loss:  0.19833303833007812\t ACC train:  0.725\t ACC test:  0.6044444444444445\n",
      "\tEpoch 398: \tAverage Loss:  0.1975472869873047\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 399: \tAverage Loss:  0.198143310546875\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 400: \tAverage Loss:  0.19872691345214843\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 401: \tAverage Loss:  0.19715965270996094\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 402: \tAverage Loss:  0.19647198486328124\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 403: \tAverage Loss:  0.19704725646972657\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 404: \tAverage Loss:  0.19698942565917968\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 405: \tAverage Loss:  0.19835488891601563\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 406: \tAverage Loss:  0.19709332275390626\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 407: \tAverage Loss:  0.19701220703125\t ACC train:  0.725\t ACC test:  0.6022222222222222\n",
      "\tEpoch 408: \tAverage Loss:  0.1963769073486328\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 409: \tAverage Loss:  0.19675912475585938\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 410: \tAverage Loss:  0.19674545288085937\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 411: \tAverage Loss:  0.19559637451171874\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 412: \tAverage Loss:  0.19607553100585937\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 413: \tAverage Loss:  0.1958317108154297\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 414: \tAverage Loss:  0.19522598266601562\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 415: \tAverage Loss:  0.19592372131347657\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 416: \tAverage Loss:  0.19491380310058593\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 417: \tAverage Loss:  0.1955741424560547\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 418: \tAverage Loss:  0.19477304077148438\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 419: \tAverage Loss:  0.19505838012695312\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 420: \tAverage Loss:  0.1943133544921875\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 421: \tAverage Loss:  0.19451118469238282\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 422: \tAverage Loss:  0.19482745361328124\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 423: \tAverage Loss:  0.1943676300048828\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 424: \tAverage Loss:  0.19418527221679688\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 425: \tAverage Loss:  0.19402151489257813\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 426: \tAverage Loss:  0.19461016845703125\t ACC train:  0.725\t ACC test:  0.6066666666666667\n",
      "\tEpoch 427: \tAverage Loss:  0.19333602905273437\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 428: \tAverage Loss:  0.19392350769042968\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 429: \tAverage Loss:  0.1943370361328125\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 430: \tAverage Loss:  0.19330921936035156\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 431: \tAverage Loss:  0.19325323486328125\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 432: \tAverage Loss:  0.193580078125\t ACC train:  0.75\t ACC test:  0.6133333333333333\n",
      "\tEpoch 433: \tAverage Loss:  0.19315196228027343\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 434: \tAverage Loss:  0.19305169677734374\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 435: \tAverage Loss:  0.192876220703125\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 436: \tAverage Loss:  0.19269345092773438\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 437: \tAverage Loss:  0.19259873962402344\t ACC train:  0.75\t ACC test:  0.6133333333333333\n",
      "\tEpoch 438: \tAverage Loss:  0.19305416870117187\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 439: \tAverage Loss:  0.1925565948486328\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 440: \tAverage Loss:  0.19253672790527343\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 441: \tAverage Loss:  0.1925016326904297\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 442: \tAverage Loss:  0.19156784057617188\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 443: \tAverage Loss:  0.19216558837890624\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 444: \tAverage Loss:  0.19220091247558593\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 445: \tAverage Loss:  0.1919517364501953\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 446: \tAverage Loss:  0.19124441528320313\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 447: \tAverage Loss:  0.1914481506347656\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 448: \tAverage Loss:  0.1916060028076172\t ACC train:  0.75\t ACC test:  0.6133333333333333\n",
      "\tEpoch 449: \tAverage Loss:  0.19148562622070311\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 450: \tAverage Loss:  0.1919331817626953\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 451: \tAverage Loss:  0.19122421264648437\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 452: \tAverage Loss:  0.19099249267578125\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 453: \tAverage Loss:  0.19136935424804688\t ACC train:  0.75\t ACC test:  0.6133333333333333\n",
      "\tEpoch 454: \tAverage Loss:  0.19138009643554688\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 455: \tAverage Loss:  0.19125894165039062\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 456: \tAverage Loss:  0.19106292724609375\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 457: \tAverage Loss:  0.19066574096679687\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 458: \tAverage Loss:  0.19092764282226563\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 459: \tAverage Loss:  0.19076319885253906\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 460: \tAverage Loss:  0.19056539916992188\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 461: \tAverage Loss:  0.19046502685546876\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 462: \tAverage Loss:  0.19030747985839844\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 463: \tAverage Loss:  0.19025419616699218\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 464: \tAverage Loss:  0.19063731384277344\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 465: \tAverage Loss:  0.19028677368164063\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 466: \tAverage Loss:  0.19022271728515625\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 467: \tAverage Loss:  0.19002761840820312\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 468: \tAverage Loss:  0.1899171600341797\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 469: \tAverage Loss:  0.18967926025390625\t ACC train:  0.75\t ACC test:  0.6133333333333333\n",
      "\tEpoch 470: \tAverage Loss:  0.18982046508789063\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 471: \tAverage Loss:  0.1898170166015625\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 472: \tAverage Loss:  0.19009591674804688\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 473: \tAverage Loss:  0.18938772583007812\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 474: \tAverage Loss:  0.18945248413085938\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 475: \tAverage Loss:  0.1894823455810547\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 476: \tAverage Loss:  0.1892468719482422\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 477: \tAverage Loss:  0.18935816955566406\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 478: \tAverage Loss:  0.18890066528320312\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 479: \tAverage Loss:  0.18912034606933595\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 480: \tAverage Loss:  0.1890360870361328\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 481: \tAverage Loss:  0.18909931945800781\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 482: \tAverage Loss:  0.18873529052734375\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 483: \tAverage Loss:  0.1890081329345703\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 484: \tAverage Loss:  0.1889888916015625\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 485: \tAverage Loss:  0.18855947875976561\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 486: \tAverage Loss:  0.18870620727539061\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 487: \tAverage Loss:  0.18887184143066407\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 488: \tAverage Loss:  0.18857333374023438\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 489: \tAverage Loss:  0.1887625732421875\t ACC train:  0.75\t ACC test:  0.6133333333333333\n",
      "\tEpoch 490: \tAverage Loss:  0.18864016723632812\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 491: \tAverage Loss:  0.18812298583984374\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 492: \tAverage Loss:  0.18803224182128905\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 493: \tAverage Loss:  0.18848138427734376\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 494: \tAverage Loss:  0.18799006652832032\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 495: \tAverage Loss:  0.18796432495117188\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 496: \tAverage Loss:  0.18818650817871094\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 497: \tAverage Loss:  0.18836013793945314\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 498: \tAverage Loss:  0.1879269104003906\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 499: \tAverage Loss:  0.18773573303222657\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 500: \tAverage Loss:  0.1875972442626953\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 501: \tAverage Loss:  0.18743994140625\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 502: \tAverage Loss:  0.1876827392578125\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 503: \tAverage Loss:  0.1875742645263672\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 504: \tAverage Loss:  0.18778775024414063\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 505: \tAverage Loss:  0.1877935333251953\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 506: \tAverage Loss:  0.18754464721679687\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 507: \tAverage Loss:  0.18778892517089843\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 508: \tAverage Loss:  0.18722354125976562\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 509: \tAverage Loss:  0.187723876953125\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 510: \tAverage Loss:  0.18737701416015626\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 511: \tAverage Loss:  0.18699432373046876\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 512: \tAverage Loss:  0.18723291015625\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 513: \tAverage Loss:  0.18698756408691405\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 514: \tAverage Loss:  0.18683967590332032\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 515: \tAverage Loss:  0.1871410369873047\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 516: \tAverage Loss:  0.1865078887939453\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 517: \tAverage Loss:  0.18691018676757812\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 518: \tAverage Loss:  0.1869632873535156\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 519: \tAverage Loss:  0.18643153381347657\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 520: \tAverage Loss:  0.1866604309082031\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 521: \tAverage Loss:  0.18637420654296874\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 522: \tAverage Loss:  0.18656190490722657\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 523: \tAverage Loss:  0.18674220275878906\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 524: \tAverage Loss:  0.186353759765625\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 525: \tAverage Loss:  0.1863095245361328\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 526: \tAverage Loss:  0.18648599243164063\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 527: \tAverage Loss:  0.18650770568847655\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 528: \tAverage Loss:  0.18620487976074218\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 529: \tAverage Loss:  0.1860923614501953\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 530: \tAverage Loss:  0.18628424072265626\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 531: \tAverage Loss:  0.18600054931640625\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 532: \tAverage Loss:  0.18589253234863282\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 533: \tAverage Loss:  0.1862346649169922\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 534: \tAverage Loss:  0.18560118103027343\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 535: \tAverage Loss:  0.18581845092773439\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 536: \tAverage Loss:  0.18584115600585938\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 537: \tAverage Loss:  0.185644775390625\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 538: \tAverage Loss:  0.1858915557861328\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 539: \tAverage Loss:  0.18601666259765626\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 540: \tAverage Loss:  0.18570773315429687\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 541: \tAverage Loss:  0.18551512145996094\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 542: \tAverage Loss:  0.18540008544921874\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 543: \tAverage Loss:  0.1854936828613281\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 544: \tAverage Loss:  0.18541441345214843\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 545: \tAverage Loss:  0.18542787170410155\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 546: \tAverage Loss:  0.18518093872070313\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 547: \tAverage Loss:  0.18528445434570312\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 548: \tAverage Loss:  0.18547555541992186\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 549: \tAverage Loss:  0.18525433349609374\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 550: \tAverage Loss:  0.1852465057373047\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 551: \tAverage Loss:  0.1850888671875\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 552: \tAverage Loss:  0.18513479614257813\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 553: \tAverage Loss:  0.1851813507080078\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 554: \tAverage Loss:  0.1848934326171875\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 555: \tAverage Loss:  0.18494300842285155\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 556: \tAverage Loss:  0.1848724365234375\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 557: \tAverage Loss:  0.1850355682373047\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 558: \tAverage Loss:  0.18479605102539062\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 559: \tAverage Loss:  0.18475270080566406\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 560: \tAverage Loss:  0.1847410888671875\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 561: \tAverage Loss:  0.1847830047607422\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 562: \tAverage Loss:  0.18449227905273438\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 563: \tAverage Loss:  0.18453366088867187\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 564: \tAverage Loss:  0.18453662109375\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 565: \tAverage Loss:  0.18443399047851564\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 566: \tAverage Loss:  0.18480723571777344\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 567: \tAverage Loss:  0.18444960021972656\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 568: \tAverage Loss:  0.18440591430664063\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 569: \tAverage Loss:  0.18437857055664061\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 570: \tAverage Loss:  0.1843421630859375\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 571: \tAverage Loss:  0.18448561096191407\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 572: \tAverage Loss:  0.18415510559082032\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 573: \tAverage Loss:  0.1842349853515625\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 574: \tAverage Loss:  0.18441293334960937\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 575: \tAverage Loss:  0.18410330200195313\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 576: \tAverage Loss:  0.18409085083007812\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 577: \tAverage Loss:  0.18397796630859375\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 578: \tAverage Loss:  0.18421572875976563\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 579: \tAverage Loss:  0.18392890930175781\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 580: \tAverage Loss:  0.1839971923828125\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 581: \tAverage Loss:  0.18399790954589842\t ACC train:  0.75\t ACC test:  0.6111111111111112\n",
      "\tEpoch 582: \tAverage Loss:  0.1839137725830078\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 583: \tAverage Loss:  0.18417965698242186\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 584: \tAverage Loss:  0.1837741241455078\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 585: \tAverage Loss:  0.18376216125488282\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 586: \tAverage Loss:  0.18375787353515624\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 587: \tAverage Loss:  0.18360458374023436\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 588: \tAverage Loss:  0.18379643249511718\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 589: \tAverage Loss:  0.18380271911621093\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 590: \tAverage Loss:  0.18382806396484375\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 591: \tAverage Loss:  0.18365931701660157\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 592: \tAverage Loss:  0.18375814819335937\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 593: \tAverage Loss:  0.183677978515625\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 594: \tAverage Loss:  0.18359344482421874\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 595: \tAverage Loss:  0.1836231231689453\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 596: \tAverage Loss:  0.18350399780273438\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 597: \tAverage Loss:  0.18341261291503907\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 598: \tAverage Loss:  0.1832963409423828\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 599: \tAverage Loss:  0.18320112609863282\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 600: \tAverage Loss:  0.18334893798828125\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 601: \tAverage Loss:  0.18337664794921876\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 602: \tAverage Loss:  0.1834050750732422\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 603: \tAverage Loss:  0.18318260192871094\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 604: \tAverage Loss:  0.18323307800292968\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 605: \tAverage Loss:  0.1833034210205078\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 606: \tAverage Loss:  0.18316123962402345\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 607: \tAverage Loss:  0.18285733032226562\t ACC train:  0.75\t ACC test:  0.6088888888888889\n",
      "\tEpoch 608: \tAverage Loss:  0.18284837341308594\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 609: \tAverage Loss:  0.18291383361816407\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 610: \tAverage Loss:  0.18287464904785156\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 611: \tAverage Loss:  0.18290374755859376\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 612: \tAverage Loss:  0.1827079315185547\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 613: \tAverage Loss:  0.1826735382080078\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 614: \tAverage Loss:  0.1828946533203125\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 615: \tAverage Loss:  0.1826983642578125\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 616: \tAverage Loss:  0.18277957153320312\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 617: \tAverage Loss:  0.18265753173828125\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 618: \tAverage Loss:  0.18257177734375\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 619: \tAverage Loss:  0.18254554748535157\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 620: \tAverage Loss:  0.18249594116210938\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 621: \tAverage Loss:  0.18250445556640624\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 622: \tAverage Loss:  0.1824696960449219\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 623: \tAverage Loss:  0.18241586303710938\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 624: \tAverage Loss:  0.1823543701171875\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 625: \tAverage Loss:  0.1823224334716797\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 626: \tAverage Loss:  0.1822302703857422\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 627: \tAverage Loss:  0.182160400390625\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 628: \tAverage Loss:  0.1821321105957031\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 629: \tAverage Loss:  0.18222962951660157\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 630: \tAverage Loss:  0.1822660675048828\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 631: \tAverage Loss:  0.18219239807128906\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 632: \tAverage Loss:  0.182087646484375\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 633: \tAverage Loss:  0.18200971984863282\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 634: \tAverage Loss:  0.1820072479248047\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 635: \tAverage Loss:  0.18212480163574218\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 636: \tAverage Loss:  0.1819878692626953\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 637: \tAverage Loss:  0.18198046875\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 638: \tAverage Loss:  0.18214056396484374\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 639: \tAverage Loss:  0.18182815551757814\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 640: \tAverage Loss:  0.1821175537109375\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 641: \tAverage Loss:  0.18193705749511718\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 642: \tAverage Loss:  0.18182902526855468\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 643: \tAverage Loss:  0.18183538818359374\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 644: \tAverage Loss:  0.1818939971923828\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 645: \tAverage Loss:  0.18168940734863281\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 646: \tAverage Loss:  0.1815624237060547\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 647: \tAverage Loss:  0.18163078308105468\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 648: \tAverage Loss:  0.18160894775390626\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 649: \tAverage Loss:  0.18178001403808594\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 650: \tAverage Loss:  0.18148175048828125\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 651: \tAverage Loss:  0.1814818115234375\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 652: \tAverage Loss:  0.1815756378173828\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 653: \tAverage Loss:  0.1813755340576172\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 654: \tAverage Loss:  0.18151133728027344\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 655: \tAverage Loss:  0.18152352905273436\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 656: \tAverage Loss:  0.18133685302734376\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 657: \tAverage Loss:  0.18144711303710936\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 658: \tAverage Loss:  0.18123878479003908\t ACC train:  0.75\t ACC test:  0.6066666666666667\n",
      "\tEpoch 659: \tAverage Loss:  0.18128517150878906\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 660: \tAverage Loss:  0.18108905029296876\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 661: \tAverage Loss:  0.18128025817871093\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 662: \tAverage Loss:  0.18119735717773439\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 663: \tAverage Loss:  0.18122882080078126\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 664: \tAverage Loss:  0.18110748291015624\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 665: \tAverage Loss:  0.18137799072265626\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 666: \tAverage Loss:  0.1810517578125\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 667: \tAverage Loss:  0.18128131103515624\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 668: \tAverage Loss:  0.18098614501953125\t ACC train:  0.75\t ACC test:  0.6044444444444445\n",
      "\tEpoch 669: \tAverage Loss:  0.18094279479980468\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 670: \tAverage Loss:  0.18085165405273437\t ACC train:  0.75\t ACC test:  0.6022222222222222\n",
      "\tEpoch 671: \tAverage Loss:  0.18094284057617188\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 672: \tAverage Loss:  0.18088162231445312\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 673: \tAverage Loss:  0.1811150360107422\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 674: \tAverage Loss:  0.18091139221191407\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 675: \tAverage Loss:  0.1808108367919922\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 676: \tAverage Loss:  0.18085897827148437\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 677: \tAverage Loss:  0.18077839660644532\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 678: \tAverage Loss:  0.18072879028320313\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 679: \tAverage Loss:  0.18070037841796874\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 680: \tAverage Loss:  0.18069496154785156\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 681: \tAverage Loss:  0.1806304931640625\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 682: \tAverage Loss:  0.1805313262939453\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 683: \tAverage Loss:  0.18070565795898438\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 684: \tAverage Loss:  0.18046580505371093\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 685: \tAverage Loss:  0.18052877807617188\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 686: \tAverage Loss:  0.180525146484375\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 687: \tAverage Loss:  0.18058970642089844\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 688: \tAverage Loss:  0.1804400177001953\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 689: \tAverage Loss:  0.18049317932128905\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 690: \tAverage Loss:  0.18041989135742187\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 691: \tAverage Loss:  0.1805282440185547\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 692: \tAverage Loss:  0.180244140625\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 693: \tAverage Loss:  0.18065347290039063\t ACC train:  0.75\t ACC test:  0.6\n",
      "\tEpoch 694: \tAverage Loss:  0.18018638610839843\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 695: \tAverage Loss:  0.18030989074707032\t ACC train:  0.75\t ACC test:  0.5933333333333334\n",
      "\tEpoch 696: \tAverage Loss:  0.18022520446777343\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 697: \tAverage Loss:  0.1801649169921875\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "\tEpoch 698: \tAverage Loss:  0.18017507934570312\t ACC train:  0.75\t ACC test:  0.5977777777777777\n",
      "Stopping early at epoch 698. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 50\n",
      "\tEpoch 1: \tAverage Loss:  0.4731683349609375\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 2: \tAverage Loss:  0.4714481201171875\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 3: \tAverage Loss:  0.4696332397460937\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 4: \tAverage Loss:  0.46881210327148437\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 5: \tAverage Loss:  0.46705908203125\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 6: \tAverage Loss:  0.46606399536132814\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 7: \tAverage Loss:  0.4646918334960938\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 8: \tAverage Loss:  0.4631574401855469\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 9: \tAverage Loss:  0.461810546875\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 10: \tAverage Loss:  0.46038671875\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 11: \tAverage Loss:  0.459495361328125\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 12: \tAverage Loss:  0.45846588134765626\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 13: \tAverage Loss:  0.45725042724609377\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 14: \tAverage Loss:  0.4569145812988281\t ACC train:  0.46\t ACC test:  0.5133333333333333\n",
      "\tEpoch 15: \tAverage Loss:  0.4548056335449219\t ACC train:  0.5\t ACC test:  0.4622222222222222\n",
      "\tEpoch 16: \tAverage Loss:  0.45369525146484374\t ACC train:  0.44\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  0.45291619873046873\t ACC train:  0.42\t ACC test:  0.49777777777777776\n",
      "\tEpoch 18: \tAverage Loss:  0.45143145751953123\t ACC train:  0.4\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  0.45190914916992186\t ACC train:  0.56\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  0.4493621826171875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  0.4488614501953125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  0.4474264831542969\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  0.44704656982421875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  0.44527554321289065\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  0.44473248291015627\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  0.44382763671875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  0.4430766296386719\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  0.44316351318359376\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  0.440537841796875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  0.44130117797851565\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  0.4406423645019531\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  0.438590087890625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  0.437012939453125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  0.4370708923339844\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  0.43576593017578125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  0.43480563354492185\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  0.43442919921875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  0.433074951171875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  0.432333984375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  0.4318056945800781\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  0.43252362060546873\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  0.4315518798828125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  0.4300745849609375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  0.429775634765625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  0.42899667358398436\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  0.42889865112304687\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  0.42714859008789063\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  0.4260765380859375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  0.42633206176757815\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  0.4253348388671875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  0.42477618408203127\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  0.42542391967773435\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.42311849975585936\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  0.4225919189453125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  0.4244577941894531\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  0.4225609130859375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  0.42091015625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  0.420196044921875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  0.42069622802734374\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  0.4180791931152344\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  0.41952578735351564\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  0.4215538330078125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  0.4160572509765625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  0.41955645751953125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  0.4150816345214844\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.4163959045410156\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  0.41733383178710937\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  0.41713235473632815\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  0.4149548645019531\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  0.4168421325683594\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  0.4172276306152344\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  0.4154058532714844\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  0.4130648498535156\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  0.41282254028320314\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  0.4093799743652344\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  0.4130324096679687\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  0.41046636962890626\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  0.4141009521484375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  0.4096463012695313\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.409430908203125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  0.40662469482421876\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  0.409612548828125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  0.4056444396972656\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 84: \tAverage Loss:  0.405556640625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 85: \tAverage Loss:  0.4051005249023438\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 86: \tAverage Loss:  0.4047476806640625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 87: \tAverage Loss:  0.4027341613769531\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 88: \tAverage Loss:  0.40541229248046873\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 89: \tAverage Loss:  0.40696432495117185\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 90: \tAverage Loss:  0.40383782958984377\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 91: \tAverage Loss:  0.40511114501953127\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 92: \tAverage Loss:  0.3996612243652344\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 93: \tAverage Loss:  0.4029614562988281\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 94: \tAverage Loss:  0.4065417785644531\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 95: \tAverage Loss:  0.4035875549316406\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 96: \tAverage Loss:  0.4053823547363281\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 97: \tAverage Loss:  0.39979522705078124\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 98: \tAverage Loss:  0.3988908996582031\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 99: \tAverage Loss:  0.4018020935058594\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 100: \tAverage Loss:  0.40041680908203126\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  0.39272808837890627\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 102: \tAverage Loss:  0.39558651733398437\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 103: \tAverage Loss:  0.39828692626953127\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 104: \tAverage Loss:  0.3937865905761719\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 105: \tAverage Loss:  0.39004757690429687\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 106: \tAverage Loss:  0.39065521240234374\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 107: \tAverage Loss:  0.38976702880859376\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 108: \tAverage Loss:  0.38777630615234376\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 109: \tAverage Loss:  0.39606341552734375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 110: \tAverage Loss:  0.3860595092773437\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 111: \tAverage Loss:  0.39165826416015626\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 112: \tAverage Loss:  0.386340576171875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 113: \tAverage Loss:  0.38810699462890624\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 114: \tAverage Loss:  0.38108282470703125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 115: \tAverage Loss:  0.38420928955078126\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 116: \tAverage Loss:  0.3799255676269531\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 117: \tAverage Loss:  0.3846557922363281\t ACC train:  0.54\t ACC test:  0.4888888888888889\n",
      "\tEpoch 118: \tAverage Loss:  0.37797021484375\t ACC train:  0.54\t ACC test:  0.49333333333333335\n",
      "\tEpoch 119: \tAverage Loss:  0.38235433959960935\t ACC train:  0.54\t ACC test:  0.49777777777777776\n",
      "\tEpoch 120: \tAverage Loss:  0.3800835266113281\t ACC train:  0.54\t ACC test:  0.5111111111111111\n",
      "\tEpoch 121: \tAverage Loss:  0.375998046875\t ACC train:  0.54\t ACC test:  0.52\n",
      "\tEpoch 122: \tAverage Loss:  0.37669012451171874\t ACC train:  0.56\t ACC test:  0.5222222222222223\n",
      "\tEpoch 123: \tAverage Loss:  0.37380160522460937\t ACC train:  0.56\t ACC test:  0.5222222222222223\n",
      "\tEpoch 124: \tAverage Loss:  0.3755552978515625\t ACC train:  0.56\t ACC test:  0.5355555555555556\n",
      "\tEpoch 125: \tAverage Loss:  0.37559005737304685\t ACC train:  0.54\t ACC test:  0.5466666666666666\n",
      "\tEpoch 126: \tAverage Loss:  0.3701615905761719\t ACC train:  0.6\t ACC test:  0.5444444444444444\n",
      "\tEpoch 127: \tAverage Loss:  0.37026416015625\t ACC train:  0.6\t ACC test:  0.5466666666666666\n",
      "\tEpoch 128: \tAverage Loss:  0.36870144653320314\t ACC train:  0.58\t ACC test:  0.5555555555555556\n",
      "\tEpoch 129: \tAverage Loss:  0.3655830383300781\t ACC train:  0.62\t ACC test:  0.5444444444444444\n",
      "\tEpoch 130: \tAverage Loss:  0.36989627075195314\t ACC train:  0.58\t ACC test:  0.5622222222222222\n",
      "\tEpoch 131: \tAverage Loss:  0.36604421997070313\t ACC train:  0.62\t ACC test:  0.5666666666666667\n",
      "\tEpoch 132: \tAverage Loss:  0.36239694213867185\t ACC train:  0.64\t ACC test:  0.5711111111111111\n",
      "\tEpoch 133: \tAverage Loss:  0.3589356079101563\t ACC train:  0.6\t ACC test:  0.5755555555555556\n",
      "\tEpoch 134: \tAverage Loss:  0.35932608032226565\t ACC train:  0.62\t ACC test:  0.5733333333333334\n",
      "\tEpoch 135: \tAverage Loss:  0.357952392578125\t ACC train:  0.64\t ACC test:  0.5755555555555556\n",
      "\tEpoch 136: \tAverage Loss:  0.3538954772949219\t ACC train:  0.68\t ACC test:  0.5844444444444444\n",
      "\tEpoch 137: \tAverage Loss:  0.3535111083984375\t ACC train:  0.62\t ACC test:  0.5866666666666667\n",
      "\tEpoch 138: \tAverage Loss:  0.35263259887695314\t ACC train:  0.64\t ACC test:  0.5844444444444444\n",
      "\tEpoch 139: \tAverage Loss:  0.352357421875\t ACC train:  0.64\t ACC test:  0.5844444444444444\n",
      "\tEpoch 140: \tAverage Loss:  0.34813150024414063\t ACC train:  0.68\t ACC test:  0.5822222222222222\n",
      "\tEpoch 141: \tAverage Loss:  0.3458937377929687\t ACC train:  0.68\t ACC test:  0.5866666666666667\n",
      "\tEpoch 142: \tAverage Loss:  0.3489991455078125\t ACC train:  0.68\t ACC test:  0.5888888888888889\n",
      "\tEpoch 143: \tAverage Loss:  0.34356005859375\t ACC train:  0.66\t ACC test:  0.5911111111111111\n",
      "\tEpoch 144: \tAverage Loss:  0.34373831176757813\t ACC train:  0.7\t ACC test:  0.5888888888888889\n",
      "\tEpoch 145: \tAverage Loss:  0.342900146484375\t ACC train:  0.64\t ACC test:  0.5933333333333334\n",
      "\tEpoch 146: \tAverage Loss:  0.33916986083984374\t ACC train:  0.68\t ACC test:  0.5888888888888889\n",
      "\tEpoch 147: \tAverage Loss:  0.3427584533691406\t ACC train:  0.66\t ACC test:  0.5844444444444444\n",
      "\tEpoch 148: \tAverage Loss:  0.33625332641601563\t ACC train:  0.68\t ACC test:  0.5866666666666667\n",
      "\tEpoch 149: \tAverage Loss:  0.3364054565429688\t ACC train:  0.62\t ACC test:  0.5933333333333334\n",
      "\tEpoch 150: \tAverage Loss:  0.3339383544921875\t ACC train:  0.64\t ACC test:  0.5911111111111111\n",
      "\tEpoch 151: \tAverage Loss:  0.3317254638671875\t ACC train:  0.62\t ACC test:  0.5955555555555555\n",
      "\tEpoch 152: \tAverage Loss:  0.3323547973632813\t ACC train:  0.68\t ACC test:  0.5888888888888889\n",
      "\tEpoch 153: \tAverage Loss:  0.33292333984375\t ACC train:  0.68\t ACC test:  0.5933333333333334\n",
      "\tEpoch 154: \tAverage Loss:  0.33024627685546876\t ACC train:  0.66\t ACC test:  0.5977777777777777\n",
      "\tEpoch 155: \tAverage Loss:  0.3268567504882812\t ACC train:  0.66\t ACC test:  0.6133333333333333\n",
      "\tEpoch 156: \tAverage Loss:  0.32661288452148435\t ACC train:  0.64\t ACC test:  0.6\n",
      "\tEpoch 157: \tAverage Loss:  0.3261018981933594\t ACC train:  0.62\t ACC test:  0.5911111111111111\n",
      "\tEpoch 158: \tAverage Loss:  0.32202056884765623\t ACC train:  0.64\t ACC test:  0.6088888888888889\n",
      "\tEpoch 159: \tAverage Loss:  0.32023843383789063\t ACC train:  0.66\t ACC test:  0.5955555555555555\n",
      "\tEpoch 160: \tAverage Loss:  0.3210690307617188\t ACC train:  0.62\t ACC test:  0.6088888888888889\n",
      "\tEpoch 161: \tAverage Loss:  0.3154984130859375\t ACC train:  0.64\t ACC test:  0.6066666666666667\n",
      "\tEpoch 162: \tAverage Loss:  0.3157314758300781\t ACC train:  0.6\t ACC test:  0.6133333333333333\n",
      "\tEpoch 163: \tAverage Loss:  0.3149128112792969\t ACC train:  0.64\t ACC test:  0.6133333333333333\n",
      "\tEpoch 164: \tAverage Loss:  0.3147156982421875\t ACC train:  0.66\t ACC test:  0.6066666666666667\n",
      "\tEpoch 165: \tAverage Loss:  0.31337149047851565\t ACC train:  0.62\t ACC test:  0.6066666666666667\n",
      "\tEpoch 166: \tAverage Loss:  0.30974343872070315\t ACC train:  0.66\t ACC test:  0.62\n",
      "\tEpoch 167: \tAverage Loss:  0.308943359375\t ACC train:  0.64\t ACC test:  0.6133333333333333\n",
      "\tEpoch 168: \tAverage Loss:  0.3074378662109375\t ACC train:  0.64\t ACC test:  0.6311111111111111\n",
      "\tEpoch 169: \tAverage Loss:  0.306052001953125\t ACC train:  0.66\t ACC test:  0.6111111111111112\n",
      "\tEpoch 170: \tAverage Loss:  0.30519308471679685\t ACC train:  0.64\t ACC test:  0.6177777777777778\n",
      "\tEpoch 171: \tAverage Loss:  0.30547677612304686\t ACC train:  0.64\t ACC test:  0.6288888888888889\n",
      "\tEpoch 172: \tAverage Loss:  0.30390679931640624\t ACC train:  0.62\t ACC test:  0.6266666666666667\n",
      "\tEpoch 173: \tAverage Loss:  0.3016704711914063\t ACC train:  0.68\t ACC test:  0.6222222222222222\n",
      "\tEpoch 174: \tAverage Loss:  0.3020189819335938\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 175: \tAverage Loss:  0.30050286865234377\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 176: \tAverage Loss:  0.29859930419921876\t ACC train:  0.64\t ACC test:  0.6244444444444445\n",
      "\tEpoch 177: \tAverage Loss:  0.2991900634765625\t ACC train:  0.64\t ACC test:  0.6177777777777778\n",
      "\tEpoch 178: \tAverage Loss:  0.2959277648925781\t ACC train:  0.66\t ACC test:  0.6222222222222222\n",
      "\tEpoch 179: \tAverage Loss:  0.2956370849609375\t ACC train:  0.68\t ACC test:  0.6177777777777778\n",
      "\tEpoch 180: \tAverage Loss:  0.2928946533203125\t ACC train:  0.66\t ACC test:  0.6066666666666667\n",
      "\tEpoch 181: \tAverage Loss:  0.2954305725097656\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 182: \tAverage Loss:  0.29366818237304687\t ACC train:  0.66\t ACC test:  0.6222222222222222\n",
      "\tEpoch 183: \tAverage Loss:  0.2939830322265625\t ACC train:  0.68\t ACC test:  0.6044444444444445\n",
      "\tEpoch 184: \tAverage Loss:  0.2925398864746094\t ACC train:  0.66\t ACC test:  0.6244444444444445\n",
      "\tEpoch 185: \tAverage Loss:  0.2882552185058594\t ACC train:  0.64\t ACC test:  0.6044444444444445\n",
      "\tEpoch 186: \tAverage Loss:  0.28870501708984375\t ACC train:  0.64\t ACC test:  0.6111111111111112\n",
      "\tEpoch 187: \tAverage Loss:  0.28806658935546875\t ACC train:  0.64\t ACC test:  0.6066666666666667\n",
      "\tEpoch 188: \tAverage Loss:  0.29171224975585935\t ACC train:  0.64\t ACC test:  0.6155555555555555\n",
      "\tEpoch 189: \tAverage Loss:  0.2872563171386719\t ACC train:  0.66\t ACC test:  0.6044444444444445\n",
      "\tEpoch 190: \tAverage Loss:  0.2907471008300781\t ACC train:  0.66\t ACC test:  0.6\n",
      "\tEpoch 191: \tAverage Loss:  0.285575439453125\t ACC train:  0.66\t ACC test:  0.5977777777777777\n",
      "\tEpoch 192: \tAverage Loss:  0.28584042358398437\t ACC train:  0.64\t ACC test:  0.6111111111111112\n",
      "\tEpoch 193: \tAverage Loss:  0.2818622131347656\t ACC train:  0.66\t ACC test:  0.6066666666666667\n",
      "\tEpoch 194: \tAverage Loss:  0.28246337890625\t ACC train:  0.64\t ACC test:  0.6111111111111112\n",
      "\tEpoch 195: \tAverage Loss:  0.28332318115234373\t ACC train:  0.64\t ACC test:  0.6088888888888889\n",
      "\tEpoch 196: \tAverage Loss:  0.28102947998046873\t ACC train:  0.66\t ACC test:  0.6022222222222222\n",
      "\tEpoch 197: \tAverage Loss:  0.28032608032226564\t ACC train:  0.64\t ACC test:  0.6177777777777778\n",
      "\tEpoch 198: \tAverage Loss:  0.2822755432128906\t ACC train:  0.66\t ACC test:  0.6044444444444445\n",
      "\tEpoch 199: \tAverage Loss:  0.2789530944824219\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 200: \tAverage Loss:  0.27949560546875\t ACC train:  0.68\t ACC test:  0.6155555555555555\n",
      "\tEpoch 201: \tAverage Loss:  0.2785899963378906\t ACC train:  0.66\t ACC test:  0.6088888888888889\n",
      "\tEpoch 202: \tAverage Loss:  0.27704638671875\t ACC train:  0.66\t ACC test:  0.6133333333333333\n",
      "\tEpoch 203: \tAverage Loss:  0.27808749389648435\t ACC train:  0.64\t ACC test:  0.6066666666666667\n",
      "\tEpoch 204: \tAverage Loss:  0.27717742919921873\t ACC train:  0.64\t ACC test:  0.6044444444444445\n",
      "\tEpoch 205: \tAverage Loss:  0.27491107177734375\t ACC train:  0.66\t ACC test:  0.6022222222222222\n",
      "\tEpoch 206: \tAverage Loss:  0.2767024536132813\t ACC train:  0.64\t ACC test:  0.6022222222222222\n",
      "\tEpoch 207: \tAverage Loss:  0.276074951171875\t ACC train:  0.66\t ACC test:  0.6111111111111112\n",
      "\tEpoch 208: \tAverage Loss:  0.2766070556640625\t ACC train:  0.66\t ACC test:  0.6066666666666667\n",
      "\tEpoch 209: \tAverage Loss:  0.2749569091796875\t ACC train:  0.66\t ACC test:  0.6088888888888889\n",
      "\tEpoch 210: \tAverage Loss:  0.27269464111328123\t ACC train:  0.66\t ACC test:  0.6022222222222222\n",
      "\tEpoch 211: \tAverage Loss:  0.2740695190429687\t ACC train:  0.68\t ACC test:  0.6022222222222222\n",
      "\tEpoch 212: \tAverage Loss:  0.2724398498535156\t ACC train:  0.66\t ACC test:  0.6044444444444445\n",
      "\tEpoch 213: \tAverage Loss:  0.27148837280273436\t ACC train:  0.62\t ACC test:  0.6044444444444445\n",
      "\tEpoch 214: \tAverage Loss:  0.271499755859375\t ACC train:  0.66\t ACC test:  0.6022222222222222\n",
      "\tEpoch 215: \tAverage Loss:  0.2712020568847656\t ACC train:  0.6\t ACC test:  0.6088888888888889\n",
      "\tEpoch 216: \tAverage Loss:  0.2705902404785156\t ACC train:  0.64\t ACC test:  0.6022222222222222\n",
      "\tEpoch 217: \tAverage Loss:  0.2696865539550781\t ACC train:  0.64\t ACC test:  0.5977777777777777\n",
      "\tEpoch 218: \tAverage Loss:  0.2673048095703125\t ACC train:  0.68\t ACC test:  0.6155555555555555\n",
      "\tEpoch 219: \tAverage Loss:  0.2685921325683594\t ACC train:  0.68\t ACC test:  0.6088888888888889\n",
      "\tEpoch 220: \tAverage Loss:  0.2690132751464844\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 221: \tAverage Loss:  0.2688666687011719\t ACC train:  0.6\t ACC test:  0.6088888888888889\n",
      "\tEpoch 222: \tAverage Loss:  0.26637179565429686\t ACC train:  0.64\t ACC test:  0.6066666666666667\n",
      "\tEpoch 223: \tAverage Loss:  0.26685140991210937\t ACC train:  0.64\t ACC test:  0.6111111111111112\n",
      "\tEpoch 224: \tAverage Loss:  0.2660645751953125\t ACC train:  0.66\t ACC test:  0.6066666666666667\n",
      "\tEpoch 225: \tAverage Loss:  0.2660740966796875\t ACC train:  0.66\t ACC test:  0.6133333333333333\n",
      "\tEpoch 226: \tAverage Loss:  0.2665968017578125\t ACC train:  0.64\t ACC test:  0.6155555555555555\n",
      "\tEpoch 227: \tAverage Loss:  0.26441598510742187\t ACC train:  0.66\t ACC test:  0.6088888888888889\n",
      "\tEpoch 228: \tAverage Loss:  0.2639112854003906\t ACC train:  0.64\t ACC test:  0.6155555555555555\n",
      "\tEpoch 229: \tAverage Loss:  0.26387527465820315\t ACC train:  0.66\t ACC test:  0.6088888888888889\n",
      "\tEpoch 230: \tAverage Loss:  0.26311187744140624\t ACC train:  0.66\t ACC test:  0.6\n",
      "\tEpoch 231: \tAverage Loss:  0.2647524719238281\t ACC train:  0.68\t ACC test:  0.6111111111111112\n",
      "\tEpoch 232: \tAverage Loss:  0.2629404602050781\t ACC train:  0.68\t ACC test:  0.62\n",
      "\tEpoch 233: \tAverage Loss:  0.262949951171875\t ACC train:  0.68\t ACC test:  0.6155555555555555\n",
      "\tEpoch 234: \tAverage Loss:  0.2650268859863281\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 235: \tAverage Loss:  0.26211785888671874\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 236: \tAverage Loss:  0.2628272705078125\t ACC train:  0.64\t ACC test:  0.6044444444444445\n",
      "\tEpoch 237: \tAverage Loss:  0.2613016357421875\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 238: \tAverage Loss:  0.2605147705078125\t ACC train:  0.66\t ACC test:  0.6111111111111112\n",
      "\tEpoch 239: \tAverage Loss:  0.2596238098144531\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 240: \tAverage Loss:  0.260398681640625\t ACC train:  0.66\t ACC test:  0.6111111111111112\n",
      "\tEpoch 241: \tAverage Loss:  0.2606031799316406\t ACC train:  0.66\t ACC test:  0.62\n",
      "\tEpoch 242: \tAverage Loss:  0.2593569030761719\t ACC train:  0.68\t ACC test:  0.6266666666666667\n",
      "\tEpoch 243: \tAverage Loss:  0.2612657470703125\t ACC train:  0.68\t ACC test:  0.6111111111111112\n",
      "\tEpoch 244: \tAverage Loss:  0.25978582763671876\t ACC train:  0.72\t ACC test:  0.6222222222222222\n",
      "\tEpoch 245: \tAverage Loss:  0.25843621826171875\t ACC train:  0.66\t ACC test:  0.6333333333333333\n",
      "\tEpoch 246: \tAverage Loss:  0.2577313232421875\t ACC train:  0.68\t ACC test:  0.6288888888888889\n",
      "\tEpoch 247: \tAverage Loss:  0.25775234985351564\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 248: \tAverage Loss:  0.25761572265625\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 249: \tAverage Loss:  0.2572958984375\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 250: \tAverage Loss:  0.25788507080078127\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 251: \tAverage Loss:  0.2593147888183594\t ACC train:  0.66\t ACC test:  0.6222222222222222\n",
      "\tEpoch 252: \tAverage Loss:  0.25630502319335935\t ACC train:  0.66\t ACC test:  0.6088888888888889\n",
      "\tEpoch 253: \tAverage Loss:  0.256238037109375\t ACC train:  0.66\t ACC test:  0.6266666666666667\n",
      "\tEpoch 254: \tAverage Loss:  0.25704107666015624\t ACC train:  0.64\t ACC test:  0.6222222222222222\n",
      "\tEpoch 255: \tAverage Loss:  0.2568402099609375\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 256: \tAverage Loss:  0.2559740905761719\t ACC train:  0.68\t ACC test:  0.6355555555555555\n",
      "\tEpoch 257: \tAverage Loss:  0.2546612091064453\t ACC train:  0.74\t ACC test:  0.6288888888888889\n",
      "\tEpoch 258: \tAverage Loss:  0.25579440307617185\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 259: \tAverage Loss:  0.25456106567382814\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 260: \tAverage Loss:  0.25479827880859374\t ACC train:  0.68\t ACC test:  0.6266666666666667\n",
      "\tEpoch 261: \tAverage Loss:  0.2548418273925781\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 262: \tAverage Loss:  0.25507167053222657\t ACC train:  0.68\t ACC test:  0.6311111111111111\n",
      "\tEpoch 263: \tAverage Loss:  0.2550225830078125\t ACC train:  0.66\t ACC test:  0.6222222222222222\n",
      "\tEpoch 264: \tAverage Loss:  0.2541732482910156\t ACC train:  0.68\t ACC test:  0.62\n",
      "\tEpoch 265: \tAverage Loss:  0.25367930603027344\t ACC train:  0.68\t ACC test:  0.6111111111111112\n",
      "\tEpoch 266: \tAverage Loss:  0.2534669494628906\t ACC train:  0.66\t ACC test:  0.62\n",
      "\tEpoch 267: \tAverage Loss:  0.25328334045410156\t ACC train:  0.7\t ACC test:  0.6222222222222222\n",
      "\tEpoch 268: \tAverage Loss:  0.2550247802734375\t ACC train:  0.68\t ACC test:  0.6244444444444445\n",
      "\tEpoch 269: \tAverage Loss:  0.25227845764160156\t ACC train:  0.66\t ACC test:  0.6266666666666667\n",
      "\tEpoch 270: \tAverage Loss:  0.2527715911865234\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 271: \tAverage Loss:  0.2520677490234375\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 272: \tAverage Loss:  0.25251150512695314\t ACC train:  0.68\t ACC test:  0.6266666666666667\n",
      "\tEpoch 273: \tAverage Loss:  0.2516555023193359\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 274: \tAverage Loss:  0.25190330505371095\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 275: \tAverage Loss:  0.2515869598388672\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 276: \tAverage Loss:  0.25100021362304686\t ACC train:  0.7\t ACC test:  0.6311111111111111\n",
      "\tEpoch 277: \tAverage Loss:  0.2525555877685547\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 278: \tAverage Loss:  0.25117518615722656\t ACC train:  0.66\t ACC test:  0.6288888888888889\n",
      "\tEpoch 279: \tAverage Loss:  0.25060989379882814\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 280: \tAverage Loss:  0.2502742309570313\t ACC train:  0.68\t ACC test:  0.6311111111111111\n",
      "\tEpoch 281: \tAverage Loss:  0.24983787536621094\t ACC train:  0.66\t ACC test:  0.6288888888888889\n",
      "\tEpoch 282: \tAverage Loss:  0.2519846038818359\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 283: \tAverage Loss:  0.24973248291015626\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 284: \tAverage Loss:  0.25056703186035156\t ACC train:  0.72\t ACC test:  0.6244444444444445\n",
      "\tEpoch 285: \tAverage Loss:  0.24926852416992187\t ACC train:  0.66\t ACC test:  0.6333333333333333\n",
      "\tEpoch 286: \tAverage Loss:  0.2503642120361328\t ACC train:  0.72\t ACC test:  0.6288888888888889\n",
      "\tEpoch 287: \tAverage Loss:  0.24923374938964843\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 288: \tAverage Loss:  0.2502271575927734\t ACC train:  0.68\t ACC test:  0.6288888888888889\n",
      "\tEpoch 289: \tAverage Loss:  0.2492726287841797\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 290: \tAverage Loss:  0.24837026977539062\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 291: \tAverage Loss:  0.24867460632324218\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 292: \tAverage Loss:  0.24926571655273438\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 293: \tAverage Loss:  0.24882742309570313\t ACC train:  0.72\t ACC test:  0.6244444444444445\n",
      "\tEpoch 294: \tAverage Loss:  0.24879736328125\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 295: \tAverage Loss:  0.2477648010253906\t ACC train:  0.7\t ACC test:  0.6355555555555555\n",
      "\tEpoch 296: \tAverage Loss:  0.24808091735839843\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 297: \tAverage Loss:  0.2481573028564453\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 298: \tAverage Loss:  0.24845755004882814\t ACC train:  0.72\t ACC test:  0.6244444444444445\n",
      "\tEpoch 299: \tAverage Loss:  0.24678152465820313\t ACC train:  0.72\t ACC test:  0.6266666666666667\n",
      "\tEpoch 300: \tAverage Loss:  0.2480033416748047\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 301: \tAverage Loss:  0.24704298400878907\t ACC train:  0.74\t ACC test:  0.6244444444444445\n",
      "\tEpoch 302: \tAverage Loss:  0.24735194396972657\t ACC train:  0.68\t ACC test:  0.6311111111111111\n",
      "\tEpoch 303: \tAverage Loss:  0.24665458679199218\t ACC train:  0.72\t ACC test:  0.6266666666666667\n",
      "\tEpoch 304: \tAverage Loss:  0.24724960327148438\t ACC train:  0.7\t ACC test:  0.6311111111111111\n",
      "\tEpoch 305: \tAverage Loss:  0.24602035522460938\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 306: \tAverage Loss:  0.24695790100097656\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 307: \tAverage Loss:  0.2463391571044922\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 308: \tAverage Loss:  0.24621693420410157\t ACC train:  0.7\t ACC test:  0.6311111111111111\n",
      "\tEpoch 309: \tAverage Loss:  0.2458097686767578\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 310: \tAverage Loss:  0.24672552490234376\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 311: \tAverage Loss:  0.24571141052246093\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 312: \tAverage Loss:  0.2457032165527344\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 313: \tAverage Loss:  0.24596563720703124\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 314: \tAverage Loss:  0.24486578369140624\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 315: \tAverage Loss:  0.24549139404296874\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 316: \tAverage Loss:  0.24471263122558592\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 317: \tAverage Loss:  0.24471327209472657\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 318: \tAverage Loss:  0.2448582000732422\t ACC train:  0.72\t ACC test:  0.6244444444444445\n",
      "\tEpoch 319: \tAverage Loss:  0.24428463745117188\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 320: \tAverage Loss:  0.24569232177734374\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 321: \tAverage Loss:  0.24551644897460936\t ACC train:  0.72\t ACC test:  0.6288888888888889\n",
      "\tEpoch 322: \tAverage Loss:  0.24437747192382814\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 323: \tAverage Loss:  0.2438542938232422\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 324: \tAverage Loss:  0.243614990234375\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 325: \tAverage Loss:  0.24447412109375\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 326: \tAverage Loss:  0.24427574157714843\t ACC train:  0.74\t ACC test:  0.6311111111111111\n",
      "\tEpoch 327: \tAverage Loss:  0.24397439575195312\t ACC train:  0.74\t ACC test:  0.6288888888888889\n",
      "\tEpoch 328: \tAverage Loss:  0.2428744812011719\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 329: \tAverage Loss:  0.2436988067626953\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 330: \tAverage Loss:  0.2430284423828125\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 331: \tAverage Loss:  0.2432431640625\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 332: \tAverage Loss:  0.24334979248046876\t ACC train:  0.68\t ACC test:  0.6377777777777778\n",
      "\tEpoch 333: \tAverage Loss:  0.2427427978515625\t ACC train:  0.7\t ACC test:  0.6311111111111111\n",
      "\tEpoch 334: \tAverage Loss:  0.24265753173828125\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 335: \tAverage Loss:  0.2428310546875\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 336: \tAverage Loss:  0.24327345275878906\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 337: \tAverage Loss:  0.24322471618652344\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 338: \tAverage Loss:  0.24321409606933594\t ACC train:  0.68\t ACC test:  0.6266666666666667\n",
      "\tEpoch 339: \tAverage Loss:  0.24238473510742187\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 340: \tAverage Loss:  0.24260726928710938\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 341: \tAverage Loss:  0.2414432373046875\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 342: \tAverage Loss:  0.24252325439453126\t ACC train:  0.74\t ACC test:  0.6311111111111111\n",
      "\tEpoch 343: \tAverage Loss:  0.2430404357910156\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 344: \tAverage Loss:  0.24204562377929686\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 345: \tAverage Loss:  0.24154859924316407\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 346: \tAverage Loss:  0.24117518615722655\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 347: \tAverage Loss:  0.24126547241210938\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 348: \tAverage Loss:  0.24114695739746095\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 349: \tAverage Loss:  0.2417962646484375\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 350: \tAverage Loss:  0.24240936279296876\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 351: \tAverage Loss:  0.24122059631347656\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 352: \tAverage Loss:  0.24098590087890626\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 353: \tAverage Loss:  0.24094320678710937\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 354: \tAverage Loss:  0.24079049682617187\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 355: \tAverage Loss:  0.24130078125\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 356: \tAverage Loss:  0.24060543823242186\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 357: \tAverage Loss:  0.24107058715820312\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 358: \tAverage Loss:  0.24139234924316405\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 359: \tAverage Loss:  0.23999038696289063\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 360: \tAverage Loss:  0.24136898803710938\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 361: \tAverage Loss:  0.24062982177734374\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 362: \tAverage Loss:  0.2405372314453125\t ACC train:  0.68\t ACC test:  0.6288888888888889\n",
      "\tEpoch 363: \tAverage Loss:  0.2404455108642578\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 364: \tAverage Loss:  0.2405748748779297\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 365: \tAverage Loss:  0.23985931396484375\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 366: \tAverage Loss:  0.2398040771484375\t ACC train:  0.72\t ACC test:  0.6288888888888889\n",
      "\tEpoch 367: \tAverage Loss:  0.23972006225585937\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 368: \tAverage Loss:  0.24003111267089844\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 369: \tAverage Loss:  0.24046931457519533\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 370: \tAverage Loss:  0.23956455993652342\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 371: \tAverage Loss:  0.23970323181152345\t ACC train:  0.72\t ACC test:  0.6288888888888889\n",
      "\tEpoch 372: \tAverage Loss:  0.23946771240234374\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 373: \tAverage Loss:  0.24038433837890624\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 374: \tAverage Loss:  0.23925218200683593\t ACC train:  0.74\t ACC test:  0.6311111111111111\n",
      "\tEpoch 375: \tAverage Loss:  0.23915103149414063\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 376: \tAverage Loss:  0.23868130493164064\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 377: \tAverage Loss:  0.2387127227783203\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 378: \tAverage Loss:  0.2390465087890625\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 379: \tAverage Loss:  0.23818107604980468\t ACC train:  0.72\t ACC test:  0.6422222222222222\n",
      "\tEpoch 380: \tAverage Loss:  0.23887362670898438\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 381: \tAverage Loss:  0.23921353149414062\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 382: \tAverage Loss:  0.2392713623046875\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 383: \tAverage Loss:  0.239946533203125\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 384: \tAverage Loss:  0.23813641357421875\t ACC train:  0.72\t ACC test:  0.6444444444444445\n",
      "\tEpoch 385: \tAverage Loss:  0.2389740905761719\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 386: \tAverage Loss:  0.23766921997070312\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 387: \tAverage Loss:  0.23809837341308593\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 388: \tAverage Loss:  0.23818196105957032\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 389: \tAverage Loss:  0.23838014221191406\t ACC train:  0.74\t ACC test:  0.6311111111111111\n",
      "\tEpoch 390: \tAverage Loss:  0.23828392028808593\t ACC train:  0.7\t ACC test:  0.6311111111111111\n",
      "\tEpoch 391: \tAverage Loss:  0.23748095703125\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 392: \tAverage Loss:  0.23777166748046874\t ACC train:  0.7\t ACC test:  0.6377777777777778\n",
      "\tEpoch 393: \tAverage Loss:  0.23794590759277343\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 394: \tAverage Loss:  0.23733047485351563\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 395: \tAverage Loss:  0.23818710327148437\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 396: \tAverage Loss:  0.23728337097167967\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 397: \tAverage Loss:  0.2371563720703125\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 398: \tAverage Loss:  0.2374921875\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 399: \tAverage Loss:  0.23814482116699218\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 400: \tAverage Loss:  0.23680950927734376\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 401: \tAverage Loss:  0.23698368835449218\t ACC train:  0.74\t ACC test:  0.6311111111111111\n",
      "\tEpoch 402: \tAverage Loss:  0.23802992248535157\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 403: \tAverage Loss:  0.2377213592529297\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 404: \tAverage Loss:  0.23768678283691405\t ACC train:  0.74\t ACC test:  0.6288888888888889\n",
      "\tEpoch 405: \tAverage Loss:  0.23672859191894532\t ACC train:  0.74\t ACC test:  0.6311111111111111\n",
      "\tEpoch 406: \tAverage Loss:  0.2375055389404297\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 407: \tAverage Loss:  0.23677813720703125\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 408: \tAverage Loss:  0.23657875061035155\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 409: \tAverage Loss:  0.2370577392578125\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 410: \tAverage Loss:  0.23611161804199218\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 411: \tAverage Loss:  0.23639378356933594\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 412: \tAverage Loss:  0.23661190795898437\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 413: \tAverage Loss:  0.23596615600585938\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 414: \tAverage Loss:  0.23686099243164063\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 415: \tAverage Loss:  0.2366215057373047\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 416: \tAverage Loss:  0.23593045043945313\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 417: \tAverage Loss:  0.23669960021972655\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 418: \tAverage Loss:  0.2358101348876953\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 419: \tAverage Loss:  0.23586639404296875\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 420: \tAverage Loss:  0.23718434143066405\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 421: \tAverage Loss:  0.2352535400390625\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 422: \tAverage Loss:  0.2361106262207031\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 423: \tAverage Loss:  0.23567710876464842\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 424: \tAverage Loss:  0.23687879943847656\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 425: \tAverage Loss:  0.23620196533203125\t ACC train:  0.74\t ACC test:  0.6311111111111111\n",
      "\tEpoch 426: \tAverage Loss:  0.23603196716308594\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 427: \tAverage Loss:  0.2366963195800781\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 428: \tAverage Loss:  0.23682426452636718\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 429: \tAverage Loss:  0.2352998809814453\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 430: \tAverage Loss:  0.23492835998535155\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 431: \tAverage Loss:  0.23595436096191405\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 432: \tAverage Loss:  0.23519677734375\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 433: \tAverage Loss:  0.23541064453125\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 434: \tAverage Loss:  0.23506317138671876\t ACC train:  0.72\t ACC test:  0.6422222222222222\n",
      "\tEpoch 435: \tAverage Loss:  0.23474427795410155\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 436: \tAverage Loss:  0.23515950012207032\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 437: \tAverage Loss:  0.23564573669433594\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 438: \tAverage Loss:  0.2345152587890625\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 439: \tAverage Loss:  0.23451113891601563\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 440: \tAverage Loss:  0.23428271484375\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 441: \tAverage Loss:  0.23497222900390624\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 442: \tAverage Loss:  0.23448478698730468\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 443: \tAverage Loss:  0.23512995910644532\t ACC train:  0.74\t ACC test:  0.6311111111111111\n",
      "\tEpoch 444: \tAverage Loss:  0.23399484252929686\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 445: \tAverage Loss:  0.23508116149902344\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 446: \tAverage Loss:  0.2344954376220703\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 447: \tAverage Loss:  0.23356390380859374\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 448: \tAverage Loss:  0.23511410522460938\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 449: \tAverage Loss:  0.23405596923828126\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 450: \tAverage Loss:  0.23432081604003907\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 451: \tAverage Loss:  0.23350885009765626\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 452: \tAverage Loss:  0.23422389221191406\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 453: \tAverage Loss:  0.23383677673339845\t ACC train:  0.72\t ACC test:  0.6444444444444445\n",
      "\tEpoch 454: \tAverage Loss:  0.23333882141113282\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 455: \tAverage Loss:  0.23362176513671876\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 456: \tAverage Loss:  0.233306640625\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 457: \tAverage Loss:  0.23332569885253907\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 458: \tAverage Loss:  0.23328692626953124\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 459: \tAverage Loss:  0.2336411895751953\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 460: \tAverage Loss:  0.2329906005859375\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 461: \tAverage Loss:  0.23386094665527343\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 462: \tAverage Loss:  0.23409315490722657\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 463: \tAverage Loss:  0.23414753723144532\t ACC train:  0.72\t ACC test:  0.6422222222222222\n",
      "\tEpoch 464: \tAverage Loss:  0.23281077575683592\t ACC train:  0.7\t ACC test:  0.6377777777777778\n",
      "\tEpoch 465: \tAverage Loss:  0.23268521118164062\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 466: \tAverage Loss:  0.23428099060058594\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 467: \tAverage Loss:  0.23225009155273438\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 468: \tAverage Loss:  0.23287663269042969\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 469: \tAverage Loss:  0.23283404541015626\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 470: \tAverage Loss:  0.23353952026367186\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 471: \tAverage Loss:  0.23232052612304688\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 472: \tAverage Loss:  0.23186790466308593\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 473: \tAverage Loss:  0.23241476440429687\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 474: \tAverage Loss:  0.23229884338378906\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 475: \tAverage Loss:  0.23241598510742187\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 476: \tAverage Loss:  0.23242910766601563\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 477: \tAverage Loss:  0.23270347595214844\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 478: \tAverage Loss:  0.23355860900878905\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 479: \tAverage Loss:  0.23237240600585937\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 480: \tAverage Loss:  0.2329250030517578\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 481: \tAverage Loss:  0.23148068237304686\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 482: \tAverage Loss:  0.23170106506347657\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 483: \tAverage Loss:  0.23196435546875\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 484: \tAverage Loss:  0.23154031372070313\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 485: \tAverage Loss:  0.23207406616210938\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 486: \tAverage Loss:  0.23190251159667968\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 487: \tAverage Loss:  0.2317625427246094\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 488: \tAverage Loss:  0.23199171447753905\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 489: \tAverage Loss:  0.23220506286621093\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 490: \tAverage Loss:  0.23230105590820313\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 491: \tAverage Loss:  0.23217572021484376\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 492: \tAverage Loss:  0.23154261779785157\t ACC train:  0.74\t ACC test:  0.6311111111111111\n",
      "\tEpoch 493: \tAverage Loss:  0.23149287414550782\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 494: \tAverage Loss:  0.2319554443359375\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 495: \tAverage Loss:  0.23150927734375\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 496: \tAverage Loss:  0.2319192657470703\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 497: \tAverage Loss:  0.23072662353515624\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 498: \tAverage Loss:  0.23123348999023438\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 499: \tAverage Loss:  0.23147442626953124\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 500: \tAverage Loss:  0.23098976135253907\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 501: \tAverage Loss:  0.23149012756347656\t ACC train:  0.74\t ACC test:  0.6511111111111111\n",
      "\tEpoch 502: \tAverage Loss:  0.23212684631347658\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 503: \tAverage Loss:  0.2308279571533203\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 504: \tAverage Loss:  0.23090594482421875\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 505: \tAverage Loss:  0.23034494018554688\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 506: \tAverage Loss:  0.23167550659179686\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 507: \tAverage Loss:  0.2309588623046875\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 508: \tAverage Loss:  0.23107247924804689\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 509: \tAverage Loss:  0.23151507568359375\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 510: \tAverage Loss:  0.2316114501953125\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 511: \tAverage Loss:  0.23087619018554686\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 512: \tAverage Loss:  0.2312303009033203\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 513: \tAverage Loss:  0.2309964599609375\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 514: \tAverage Loss:  0.23094232177734375\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 515: \tAverage Loss:  0.23074118041992187\t ACC train:  0.72\t ACC test:  0.6488888888888888\n",
      "\tEpoch 516: \tAverage Loss:  0.23036962890625\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 517: \tAverage Loss:  0.23050323486328125\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 518: \tAverage Loss:  0.23034445190429687\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 519: \tAverage Loss:  0.23094351196289062\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 520: \tAverage Loss:  0.230846435546875\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 521: \tAverage Loss:  0.2301193084716797\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 522: \tAverage Loss:  0.23057966613769532\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 523: \tAverage Loss:  0.2302658233642578\t ACC train:  0.72\t ACC test:  0.6422222222222222\n",
      "\tEpoch 524: \tAverage Loss:  0.23040931701660156\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 525: \tAverage Loss:  0.23044354248046875\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 526: \tAverage Loss:  0.23002525329589843\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 527: \tAverage Loss:  0.2310791778564453\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 528: \tAverage Loss:  0.23078369140625\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 529: \tAverage Loss:  0.23099507141113282\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 530: \tAverage Loss:  0.2299651641845703\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 531: \tAverage Loss:  0.23070207214355468\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 532: \tAverage Loss:  0.23096308898925783\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 533: \tAverage Loss:  0.23032987976074218\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 534: \tAverage Loss:  0.229370361328125\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 535: \tAverage Loss:  0.23026089477539063\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 536: \tAverage Loss:  0.23006443786621095\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 537: \tAverage Loss:  0.23065718078613281\t ACC train:  0.74\t ACC test:  0.6333333333333333\n",
      "\tEpoch 538: \tAverage Loss:  0.2300934295654297\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 539: \tAverage Loss:  0.23045419311523438\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 540: \tAverage Loss:  0.22983502197265626\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 541: \tAverage Loss:  0.2298385009765625\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 542: \tAverage Loss:  0.22941188049316405\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 543: \tAverage Loss:  0.2290299530029297\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 544: \tAverage Loss:  0.2292407989501953\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 545: \tAverage Loss:  0.2303458251953125\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 546: \tAverage Loss:  0.23035113525390624\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 547: \tAverage Loss:  0.22954893493652342\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 548: \tAverage Loss:  0.22930857849121095\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 549: \tAverage Loss:  0.22905088806152343\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 550: \tAverage Loss:  0.2295863037109375\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 551: \tAverage Loss:  0.22975291442871093\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 552: \tAverage Loss:  0.22976089477539063\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 553: \tAverage Loss:  0.22919313049316406\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 554: \tAverage Loss:  0.2286998291015625\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 555: \tAverage Loss:  0.22909039306640624\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 556: \tAverage Loss:  0.22905307006835937\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 557: \tAverage Loss:  0.22868692016601563\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 558: \tAverage Loss:  0.22876605224609375\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 559: \tAverage Loss:  0.22900556945800782\t ACC train:  0.74\t ACC test:  0.6511111111111111\n",
      "\tEpoch 560: \tAverage Loss:  0.22858424377441405\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 561: \tAverage Loss:  0.22875643920898436\t ACC train:  0.74\t ACC test:  0.6488888888888888\n",
      "\tEpoch 562: \tAverage Loss:  0.22931564331054688\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 563: \tAverage Loss:  0.22831211853027344\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 564: \tAverage Loss:  0.22903857421875\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 565: \tAverage Loss:  0.22897264099121092\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 566: \tAverage Loss:  0.22753379821777345\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 567: \tAverage Loss:  0.22823471069335938\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 568: \tAverage Loss:  0.22828924560546876\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 569: \tAverage Loss:  0.22798501586914063\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 570: \tAverage Loss:  0.2282963104248047\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 571: \tAverage Loss:  0.2284896240234375\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 572: \tAverage Loss:  0.22763290405273437\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 573: \tAverage Loss:  0.22809054565429687\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 574: \tAverage Loss:  0.22823489379882814\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 575: \tAverage Loss:  0.22796220397949218\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 576: \tAverage Loss:  0.2279959716796875\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 577: \tAverage Loss:  0.2272269744873047\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 578: \tAverage Loss:  0.22785464477539064\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 579: \tAverage Loss:  0.22926687622070313\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 580: \tAverage Loss:  0.22833790588378905\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 581: \tAverage Loss:  0.22829362487792967\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 582: \tAverage Loss:  0.22830902099609374\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 583: \tAverage Loss:  0.22768748474121095\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 584: \tAverage Loss:  0.22753240966796875\t ACC train:  0.74\t ACC test:  0.6488888888888888\n",
      "\tEpoch 585: \tAverage Loss:  0.22742227172851562\t ACC train:  0.74\t ACC test:  0.6377777777777778\n",
      "\tEpoch 586: \tAverage Loss:  0.2278364715576172\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 587: \tAverage Loss:  0.2278312225341797\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 588: \tAverage Loss:  0.22773611450195314\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 589: \tAverage Loss:  0.22803131103515625\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 590: \tAverage Loss:  0.22763088989257813\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 591: \tAverage Loss:  0.22787240600585937\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 592: \tAverage Loss:  0.22786802673339843\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 593: \tAverage Loss:  0.22705909729003906\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 594: \tAverage Loss:  0.2271647186279297\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 595: \tAverage Loss:  0.22709512329101564\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 596: \tAverage Loss:  0.22745562744140624\t ACC train:  0.72\t ACC test:  0.6422222222222222\n",
      "\tEpoch 597: \tAverage Loss:  0.22806121826171874\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 598: \tAverage Loss:  0.22729447937011718\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 599: \tAverage Loss:  0.22757952880859375\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 600: \tAverage Loss:  0.2271669464111328\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 601: \tAverage Loss:  0.22710099792480468\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 602: \tAverage Loss:  0.227277099609375\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 603: \tAverage Loss:  0.22641482543945313\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 604: \tAverage Loss:  0.22751751708984375\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 605: \tAverage Loss:  0.226694580078125\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 606: \tAverage Loss:  0.2273114776611328\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 607: \tAverage Loss:  0.22725970458984374\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 608: \tAverage Loss:  0.22706636047363282\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 609: \tAverage Loss:  0.22629632568359376\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 610: \tAverage Loss:  0.22670126342773436\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 611: \tAverage Loss:  0.22741746520996095\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 612: \tAverage Loss:  0.22662742614746093\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 613: \tAverage Loss:  0.22685369873046876\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 614: \tAverage Loss:  0.22698432922363282\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 615: \tAverage Loss:  0.22644441223144532\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 616: \tAverage Loss:  0.22613198852539063\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 617: \tAverage Loss:  0.2267096405029297\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 618: \tAverage Loss:  0.22629010009765624\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 619: \tAverage Loss:  0.22649034118652345\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 620: \tAverage Loss:  0.22726014709472656\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 621: \tAverage Loss:  0.22720204162597657\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 622: \tAverage Loss:  0.22592605590820314\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 623: \tAverage Loss:  0.22654684448242188\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 624: \tAverage Loss:  0.22688946533203125\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 625: \tAverage Loss:  0.22643556213378907\t ACC train:  0.74\t ACC test:  0.6355555555555555\n",
      "\tEpoch 626: \tAverage Loss:  0.22604769897460938\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 627: \tAverage Loss:  0.22592445373535155\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 628: \tAverage Loss:  0.22620437622070313\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 629: \tAverage Loss:  0.22706642150878906\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 630: \tAverage Loss:  0.22607093811035156\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 631: \tAverage Loss:  0.22561697387695312\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 632: \tAverage Loss:  0.22609600830078125\t ACC train:  0.74\t ACC test:  0.6488888888888888\n",
      "\tEpoch 633: \tAverage Loss:  0.2264861602783203\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 634: \tAverage Loss:  0.22597859191894532\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 635: \tAverage Loss:  0.22611032104492187\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 636: \tAverage Loss:  0.22579782104492188\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 637: \tAverage Loss:  0.22542713928222657\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 638: \tAverage Loss:  0.22552064514160156\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 639: \tAverage Loss:  0.22647433471679687\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 640: \tAverage Loss:  0.22606100463867188\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 641: \tAverage Loss:  0.22567127990722657\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 642: \tAverage Loss:  0.2260828857421875\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 643: \tAverage Loss:  0.22543585205078126\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 644: \tAverage Loss:  0.22557002258300782\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 645: \tAverage Loss:  0.22557530212402344\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 646: \tAverage Loss:  0.22579505920410156\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 647: \tAverage Loss:  0.224726806640625\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 648: \tAverage Loss:  0.22549351501464843\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 649: \tAverage Loss:  0.22566358947753906\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 650: \tAverage Loss:  0.2255767059326172\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 651: \tAverage Loss:  0.22559596252441405\t ACC train:  0.74\t ACC test:  0.6488888888888888\n",
      "\tEpoch 652: \tAverage Loss:  0.22524728393554688\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 653: \tAverage Loss:  0.22487466430664063\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 654: \tAverage Loss:  0.22528875732421874\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 655: \tAverage Loss:  0.22502867126464843\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 656: \tAverage Loss:  0.2249735107421875\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 657: \tAverage Loss:  0.22499185180664064\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 658: \tAverage Loss:  0.224627685546875\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 659: \tAverage Loss:  0.22476341247558593\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 660: \tAverage Loss:  0.22480244445800782\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 661: \tAverage Loss:  0.22465017700195314\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 662: \tAverage Loss:  0.2250730438232422\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 663: \tAverage Loss:  0.22494723510742187\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 664: \tAverage Loss:  0.22505941772460938\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 665: \tAverage Loss:  0.22532760620117187\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 666: \tAverage Loss:  0.22432296752929687\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 667: \tAverage Loss:  0.22455607604980468\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 668: \tAverage Loss:  0.2251787109375\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 669: \tAverage Loss:  0.22459974670410157\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 670: \tAverage Loss:  0.2243477020263672\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 671: \tAverage Loss:  0.2247103271484375\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 672: \tAverage Loss:  0.2244369659423828\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 673: \tAverage Loss:  0.22461735534667968\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 674: \tAverage Loss:  0.22540110778808595\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 675: \tAverage Loss:  0.22478961181640625\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 676: \tAverage Loss:  0.22444569396972655\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 677: \tAverage Loss:  0.22454713439941407\t ACC train:  0.74\t ACC test:  0.6488888888888888\n",
      "\tEpoch 678: \tAverage Loss:  0.22462869262695312\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 679: \tAverage Loss:  0.22438197326660156\t ACC train:  0.74\t ACC test:  0.6488888888888888\n",
      "\tEpoch 680: \tAverage Loss:  0.22414024353027343\t ACC train:  0.74\t ACC test:  0.6466666666666666\n",
      "\tEpoch 681: \tAverage Loss:  0.22404132080078126\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 682: \tAverage Loss:  0.22412403869628905\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 683: \tAverage Loss:  0.22437596130371093\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 684: \tAverage Loss:  0.22398341369628907\t ACC train:  0.74\t ACC test:  0.64\n",
      "\tEpoch 685: \tAverage Loss:  0.22437899780273438\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 686: \tAverage Loss:  0.22398648071289062\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 687: \tAverage Loss:  0.2235555877685547\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 688: \tAverage Loss:  0.2245622100830078\t ACC train:  0.74\t ACC test:  0.6511111111111111\n",
      "\tEpoch 689: \tAverage Loss:  0.22391091918945313\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 690: \tAverage Loss:  0.22379148864746093\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 691: \tAverage Loss:  0.22385328674316407\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 692: \tAverage Loss:  0.2232676544189453\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 693: \tAverage Loss:  0.22375654602050782\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 694: \tAverage Loss:  0.22361685180664062\t ACC train:  0.74\t ACC test:  0.6422222222222222\n",
      "\tEpoch 695: \tAverage Loss:  0.22320382690429688\t ACC train:  0.74\t ACC test:  0.6444444444444445\n",
      "\tEpoch 696: \tAverage Loss:  0.22312983703613282\t ACC train:  0.74\t ACC test:  0.64\n",
      "Stopping early at epoch 696. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 60\n",
      "\tEpoch 1: \tAverage Loss:  0.5987267456054688\t ACC train:  0.43333333333333335\t ACC test:  0.5244444444444445\n",
      "\tEpoch 2: \tAverage Loss:  0.596376220703125\t ACC train:  0.48333333333333334\t ACC test:  0.4866666666666667\n",
      "\tEpoch 3: \tAverage Loss:  0.5934046630859375\t ACC train:  0.5\t ACC test:  0.49333333333333335\n",
      "\tEpoch 4: \tAverage Loss:  0.5923953247070313\t ACC train:  0.43333333333333335\t ACC test:  0.43333333333333335\n",
      "\tEpoch 5: \tAverage Loss:  0.59062890625\t ACC train:  0.5\t ACC test:  0.5111111111111111\n",
      "\tEpoch 6: \tAverage Loss:  0.589389404296875\t ACC train:  0.5833333333333334\t ACC test:  0.4822222222222222\n",
      "\tEpoch 7: \tAverage Loss:  0.5873480834960938\t ACC train:  0.5166666666666667\t ACC test:  0.48444444444444446\n",
      "\tEpoch 8: \tAverage Loss:  0.58488134765625\t ACC train:  0.55\t ACC test:  0.47333333333333333\n",
      "\tEpoch 9: \tAverage Loss:  0.58394775390625\t ACC train:  0.5333333333333333\t ACC test:  0.4822222222222222\n",
      "\tEpoch 10: \tAverage Loss:  0.582075927734375\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  0.5817765502929687\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  0.5799171752929687\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  0.5766036987304688\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  0.5771063842773437\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  0.5752026977539062\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  0.5744055786132812\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  0.571802490234375\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  0.5690263061523437\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  0.5688477783203125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  0.56814013671875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  0.5668458862304687\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  0.5637186279296875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  0.56416357421875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  0.562633544921875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  0.56127978515625\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  0.561529052734375\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  0.5555867309570313\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  0.5584299926757812\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  0.5560618286132812\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  0.5547841796875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  0.5514476928710937\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  0.5536804809570313\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  0.5506754760742187\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  0.5516168823242188\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  0.5508534545898438\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  0.5483764038085938\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  0.5490491333007812\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  0.5461528930664062\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  0.5449406127929688\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  0.5462481689453125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  0.5430039672851562\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  0.5397645874023438\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  0.5421516723632812\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  0.5383280639648438\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  0.537142822265625\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  0.5400360107421875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  0.540867919921875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  0.5356401977539063\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  0.5367886352539063\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  0.5373421020507813\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  0.535954833984375\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  0.5384213256835938\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.5351189575195312\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  0.5346170654296875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  0.5294697875976563\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  0.5311490478515625\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  0.5290789794921875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  0.5278720703125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  0.5292335205078125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  0.5274598388671875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  0.523239990234375\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  0.5294421997070312\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  0.5228587036132812\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  0.5211780395507812\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  0.5261036987304688\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.522449951171875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  0.52307080078125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  0.52182958984375\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  0.5197362670898438\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  0.5153035278320313\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  0.5192388916015624\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  0.5157398071289062\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  0.518737060546875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  0.513444580078125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  0.5154774780273438\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  0.5123096313476563\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  0.5130635986328125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  0.5133819580078125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  0.5110128173828125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.50977880859375\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  0.5099559631347657\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  0.5127518310546875\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  0.5041623840332031\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 84: \tAverage Loss:  0.508866455078125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 85: \tAverage Loss:  0.5094388427734375\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 86: \tAverage Loss:  0.5020362854003906\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 87: \tAverage Loss:  0.5040205688476562\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 88: \tAverage Loss:  0.5058133850097656\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 89: \tAverage Loss:  0.5019846801757812\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 90: \tAverage Loss:  0.49953851318359377\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 91: \tAverage Loss:  0.4995326232910156\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 92: \tAverage Loss:  0.49652212524414063\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 93: \tAverage Loss:  0.49590859985351565\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 94: \tAverage Loss:  0.49961703491210935\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 95: \tAverage Loss:  0.4952393798828125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 96: \tAverage Loss:  0.49167355346679686\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 97: \tAverage Loss:  0.49041085815429686\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 98: \tAverage Loss:  0.49008203125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 99: \tAverage Loss:  0.48441220092773435\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 100: \tAverage Loss:  0.48780584716796876\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  0.48875778198242187\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 102: \tAverage Loss:  0.4835541381835938\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 103: \tAverage Loss:  0.4838203735351562\t ACC train:  0.5333333333333333\t ACC test:  0.4888888888888889\n",
      "\tEpoch 104: \tAverage Loss:  0.48258267211914063\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 105: \tAverage Loss:  0.4824070434570312\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 106: \tAverage Loss:  0.48484445190429687\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 107: \tAverage Loss:  0.47824267578125\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 108: \tAverage Loss:  0.4756884765625\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 109: \tAverage Loss:  0.4689659729003906\t ACC train:  0.5333333333333333\t ACC test:  0.4888888888888889\n",
      "\tEpoch 110: \tAverage Loss:  0.4731897888183594\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 111: \tAverage Loss:  0.47483786010742185\t ACC train:  0.5333333333333333\t ACC test:  0.4888888888888889\n",
      "\tEpoch 112: \tAverage Loss:  0.467782958984375\t ACC train:  0.5333333333333333\t ACC test:  0.4888888888888889\n",
      "\tEpoch 113: \tAverage Loss:  0.46993203735351563\t ACC train:  0.5333333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 114: \tAverage Loss:  0.4683963317871094\t ACC train:  0.5333333333333333\t ACC test:  0.49333333333333335\n",
      "\tEpoch 115: \tAverage Loss:  0.4639793701171875\t ACC train:  0.5333333333333333\t ACC test:  0.49333333333333335\n",
      "\tEpoch 116: \tAverage Loss:  0.4656679992675781\t ACC train:  0.5333333333333333\t ACC test:  0.4911111111111111\n",
      "\tEpoch 117: \tAverage Loss:  0.46054400634765624\t ACC train:  0.5333333333333333\t ACC test:  0.4955555555555556\n",
      "\tEpoch 118: \tAverage Loss:  0.46184747314453123\t ACC train:  0.55\t ACC test:  0.49333333333333335\n",
      "\tEpoch 119: \tAverage Loss:  0.4617346496582031\t ACC train:  0.5333333333333333\t ACC test:  0.5\n",
      "\tEpoch 120: \tAverage Loss:  0.45157388305664065\t ACC train:  0.55\t ACC test:  0.5022222222222222\n",
      "\tEpoch 121: \tAverage Loss:  0.4572994995117188\t ACC train:  0.5333333333333333\t ACC test:  0.5088888888888888\n",
      "\tEpoch 122: \tAverage Loss:  0.44673065185546873\t ACC train:  0.5333333333333333\t ACC test:  0.5133333333333333\n",
      "\tEpoch 123: \tAverage Loss:  0.4570592041015625\t ACC train:  0.5666666666666667\t ACC test:  0.52\n",
      "\tEpoch 124: \tAverage Loss:  0.447174072265625\t ACC train:  0.55\t ACC test:  0.5244444444444445\n",
      "\tEpoch 125: \tAverage Loss:  0.4405552978515625\t ACC train:  0.5666666666666667\t ACC test:  0.5288888888888889\n",
      "\tEpoch 126: \tAverage Loss:  0.44443701171875\t ACC train:  0.5833333333333334\t ACC test:  0.5222222222222223\n",
      "\tEpoch 127: \tAverage Loss:  0.4413483276367188\t ACC train:  0.5666666666666667\t ACC test:  0.5311111111111111\n",
      "\tEpoch 128: \tAverage Loss:  0.4391125183105469\t ACC train:  0.5666666666666667\t ACC test:  0.5244444444444445\n",
      "\tEpoch 129: \tAverage Loss:  0.44057412719726563\t ACC train:  0.55\t ACC test:  0.5422222222222223\n",
      "\tEpoch 130: \tAverage Loss:  0.4314193115234375\t ACC train:  0.6166666666666667\t ACC test:  0.5244444444444445\n",
      "\tEpoch 131: \tAverage Loss:  0.42884442138671874\t ACC train:  0.65\t ACC test:  0.5422222222222223\n",
      "\tEpoch 132: \tAverage Loss:  0.424712158203125\t ACC train:  0.6\t ACC test:  0.5422222222222223\n",
      "\tEpoch 133: \tAverage Loss:  0.4297948913574219\t ACC train:  0.5833333333333334\t ACC test:  0.56\n",
      "\tEpoch 134: \tAverage Loss:  0.4268056945800781\t ACC train:  0.6\t ACC test:  0.5533333333333333\n",
      "\tEpoch 135: \tAverage Loss:  0.4238172302246094\t ACC train:  0.5833333333333334\t ACC test:  0.5488888888888889\n",
      "\tEpoch 136: \tAverage Loss:  0.41647802734375\t ACC train:  0.65\t ACC test:  0.5511111111111111\n",
      "\tEpoch 137: \tAverage Loss:  0.41753506469726565\t ACC train:  0.6\t ACC test:  0.5422222222222223\n",
      "\tEpoch 138: \tAverage Loss:  0.41929022216796874\t ACC train:  0.5833333333333334\t ACC test:  0.5644444444444444\n",
      "\tEpoch 139: \tAverage Loss:  0.4071371765136719\t ACC train:  0.55\t ACC test:  0.56\n",
      "\tEpoch 140: \tAverage Loss:  0.414221923828125\t ACC train:  0.6166666666666667\t ACC test:  0.5333333333333333\n",
      "\tEpoch 141: \tAverage Loss:  0.41273297119140623\t ACC train:  0.6\t ACC test:  0.5622222222222222\n",
      "\tEpoch 142: \tAverage Loss:  0.41388134765625\t ACC train:  0.6666666666666666\t ACC test:  0.5555555555555556\n",
      "\tEpoch 143: \tAverage Loss:  0.396813232421875\t ACC train:  0.6166666666666667\t ACC test:  0.5622222222222222\n",
      "\tEpoch 144: \tAverage Loss:  0.415662841796875\t ACC train:  0.5833333333333334\t ACC test:  0.5511111111111111\n",
      "\tEpoch 145: \tAverage Loss:  0.4034440612792969\t ACC train:  0.5833333333333334\t ACC test:  0.5644444444444444\n",
      "\tEpoch 146: \tAverage Loss:  0.398456298828125\t ACC train:  0.6333333333333333\t ACC test:  0.5533333333333333\n",
      "\tEpoch 147: \tAverage Loss:  0.3951768493652344\t ACC train:  0.6333333333333333\t ACC test:  0.5711111111111111\n",
      "\tEpoch 148: \tAverage Loss:  0.39983065795898437\t ACC train:  0.6\t ACC test:  0.56\n",
      "\tEpoch 149: \tAverage Loss:  0.39466741943359374\t ACC train:  0.6333333333333333\t ACC test:  0.5511111111111111\n",
      "\tEpoch 150: \tAverage Loss:  0.3932216796875\t ACC train:  0.6666666666666666\t ACC test:  0.5444444444444444\n",
      "\tEpoch 151: \tAverage Loss:  0.39286822509765623\t ACC train:  0.5333333333333333\t ACC test:  0.5444444444444444\n",
      "\tEpoch 152: \tAverage Loss:  0.3897144470214844\t ACC train:  0.65\t ACC test:  0.5444444444444444\n",
      "\tEpoch 153: \tAverage Loss:  0.38506927490234377\t ACC train:  0.65\t ACC test:  0.5355555555555556\n",
      "\tEpoch 154: \tAverage Loss:  0.38473626708984376\t ACC train:  0.6\t ACC test:  0.5444444444444444\n",
      "\tEpoch 155: \tAverage Loss:  0.37864511108398435\t ACC train:  0.6\t ACC test:  0.5466666666666666\n",
      "\tEpoch 156: \tAverage Loss:  0.3810611267089844\t ACC train:  0.65\t ACC test:  0.5422222222222223\n",
      "\tEpoch 157: \tAverage Loss:  0.38448931884765625\t ACC train:  0.6\t ACC test:  0.5355555555555556\n",
      "\tEpoch 158: \tAverage Loss:  0.3801020812988281\t ACC train:  0.6333333333333333\t ACC test:  0.5444444444444444\n",
      "\tEpoch 159: \tAverage Loss:  0.3766013488769531\t ACC train:  0.65\t ACC test:  0.5488888888888889\n",
      "\tEpoch 160: \tAverage Loss:  0.3809599304199219\t ACC train:  0.5833333333333334\t ACC test:  0.5488888888888889\n",
      "\tEpoch 161: \tAverage Loss:  0.3765983581542969\t ACC train:  0.6333333333333333\t ACC test:  0.5422222222222223\n",
      "\tEpoch 162: \tAverage Loss:  0.374357666015625\t ACC train:  0.6333333333333333\t ACC test:  0.5333333333333333\n",
      "\tEpoch 163: \tAverage Loss:  0.3704268798828125\t ACC train:  0.5833333333333334\t ACC test:  0.5222222222222223\n",
      "\tEpoch 164: \tAverage Loss:  0.3658717956542969\t ACC train:  0.5833333333333334\t ACC test:  0.5555555555555556\n",
      "\tEpoch 165: \tAverage Loss:  0.372213134765625\t ACC train:  0.6166666666666667\t ACC test:  0.5577777777777778\n",
      "\tEpoch 166: \tAverage Loss:  0.3649681396484375\t ACC train:  0.5833333333333334\t ACC test:  0.5444444444444444\n",
      "\tEpoch 167: \tAverage Loss:  0.3710962829589844\t ACC train:  0.5333333333333333\t ACC test:  0.5377777777777778\n",
      "\tEpoch 168: \tAverage Loss:  0.3646014404296875\t ACC train:  0.6166666666666667\t ACC test:  0.5422222222222223\n",
      "\tEpoch 169: \tAverage Loss:  0.36540777587890627\t ACC train:  0.5833333333333334\t ACC test:  0.54\n",
      "\tEpoch 170: \tAverage Loss:  0.3620328979492187\t ACC train:  0.6\t ACC test:  0.5333333333333333\n",
      "\tEpoch 171: \tAverage Loss:  0.3648263549804687\t ACC train:  0.55\t ACC test:  0.5422222222222223\n",
      "\tEpoch 172: \tAverage Loss:  0.3585994873046875\t ACC train:  0.6\t ACC test:  0.5511111111111111\n",
      "\tEpoch 173: \tAverage Loss:  0.3596961059570313\t ACC train:  0.5666666666666667\t ACC test:  0.5466666666666666\n",
      "\tEpoch 174: \tAverage Loss:  0.36034030151367186\t ACC train:  0.5833333333333334\t ACC test:  0.5355555555555556\n",
      "\tEpoch 175: \tAverage Loss:  0.3561357421875\t ACC train:  0.55\t ACC test:  0.5355555555555556\n",
      "\tEpoch 176: \tAverage Loss:  0.35682858276367185\t ACC train:  0.6\t ACC test:  0.5422222222222223\n",
      "\tEpoch 177: \tAverage Loss:  0.3558598937988281\t ACC train:  0.55\t ACC test:  0.5377777777777778\n",
      "\tEpoch 178: \tAverage Loss:  0.3501924133300781\t ACC train:  0.65\t ACC test:  0.5266666666666666\n",
      "\tEpoch 179: \tAverage Loss:  0.3482234191894531\t ACC train:  0.5833333333333334\t ACC test:  0.5311111111111111\n",
      "\tEpoch 180: \tAverage Loss:  0.3575364379882813\t ACC train:  0.6\t ACC test:  0.5444444444444444\n",
      "\tEpoch 181: \tAverage Loss:  0.34890597534179685\t ACC train:  0.6166666666666667\t ACC test:  0.5488888888888889\n",
      "\tEpoch 182: \tAverage Loss:  0.3496159362792969\t ACC train:  0.6166666666666667\t ACC test:  0.5577777777777778\n",
      "\tEpoch 183: \tAverage Loss:  0.3488739929199219\t ACC train:  0.6666666666666666\t ACC test:  0.54\n",
      "\tEpoch 184: \tAverage Loss:  0.34430929565429685\t ACC train:  0.6\t ACC test:  0.5533333333333333\n",
      "\tEpoch 185: \tAverage Loss:  0.344831298828125\t ACC train:  0.6\t ACC test:  0.54\n",
      "\tEpoch 186: \tAverage Loss:  0.34700216674804685\t ACC train:  0.5833333333333334\t ACC test:  0.5688888888888889\n",
      "\tEpoch 187: \tAverage Loss:  0.3430411071777344\t ACC train:  0.6333333333333333\t ACC test:  0.5555555555555556\n",
      "\tEpoch 188: \tAverage Loss:  0.3434461669921875\t ACC train:  0.6\t ACC test:  0.56\n",
      "\tEpoch 189: \tAverage Loss:  0.3462333679199219\t ACC train:  0.6333333333333333\t ACC test:  0.5622222222222222\n",
      "\tEpoch 190: \tAverage Loss:  0.3421890869140625\t ACC train:  0.6333333333333333\t ACC test:  0.5555555555555556\n",
      "\tEpoch 191: \tAverage Loss:  0.34351953125\t ACC train:  0.6\t ACC test:  0.5688888888888889\n",
      "\tEpoch 192: \tAverage Loss:  0.34152777099609377\t ACC train:  0.6\t ACC test:  0.5533333333333333\n",
      "\tEpoch 193: \tAverage Loss:  0.3409320068359375\t ACC train:  0.6\t ACC test:  0.5511111111111111\n",
      "\tEpoch 194: \tAverage Loss:  0.341052978515625\t ACC train:  0.6166666666666667\t ACC test:  0.5577777777777778\n",
      "\tEpoch 195: \tAverage Loss:  0.33643292236328126\t ACC train:  0.6166666666666667\t ACC test:  0.5555555555555556\n",
      "\tEpoch 196: \tAverage Loss:  0.3366824035644531\t ACC train:  0.6166666666666667\t ACC test:  0.5533333333333333\n",
      "\tEpoch 197: \tAverage Loss:  0.3375052795410156\t ACC train:  0.6166666666666667\t ACC test:  0.5488888888888889\n",
      "\tEpoch 198: \tAverage Loss:  0.34018145751953127\t ACC train:  0.6166666666666667\t ACC test:  0.5666666666666667\n",
      "\tEpoch 199: \tAverage Loss:  0.3380643005371094\t ACC train:  0.6166666666666667\t ACC test:  0.5666666666666667\n",
      "\tEpoch 200: \tAverage Loss:  0.3363482360839844\t ACC train:  0.6\t ACC test:  0.58\n",
      "\tEpoch 201: \tAverage Loss:  0.33429263305664064\t ACC train:  0.65\t ACC test:  0.5711111111111111\n",
      "\tEpoch 202: \tAverage Loss:  0.333439208984375\t ACC train:  0.6\t ACC test:  0.5688888888888889\n",
      "\tEpoch 203: \tAverage Loss:  0.33144805908203123\t ACC train:  0.6666666666666666\t ACC test:  0.5577777777777778\n",
      "\tEpoch 204: \tAverage Loss:  0.33236758422851564\t ACC train:  0.6333333333333333\t ACC test:  0.5422222222222223\n",
      "\tEpoch 205: \tAverage Loss:  0.331715087890625\t ACC train:  0.65\t ACC test:  0.5533333333333333\n",
      "\tEpoch 206: \tAverage Loss:  0.3338562316894531\t ACC train:  0.5833333333333334\t ACC test:  0.5688888888888889\n",
      "\tEpoch 207: \tAverage Loss:  0.3301924438476562\t ACC train:  0.6166666666666667\t ACC test:  0.5511111111111111\n",
      "\tEpoch 208: \tAverage Loss:  0.33121151733398435\t ACC train:  0.5833333333333334\t ACC test:  0.5622222222222222\n",
      "\tEpoch 209: \tAverage Loss:  0.32862783813476565\t ACC train:  0.6\t ACC test:  0.58\n",
      "\tEpoch 210: \tAverage Loss:  0.32992852783203125\t ACC train:  0.65\t ACC test:  0.56\n",
      "\tEpoch 211: \tAverage Loss:  0.32966610717773437\t ACC train:  0.6166666666666667\t ACC test:  0.56\n",
      "\tEpoch 212: \tAverage Loss:  0.3282679748535156\t ACC train:  0.6333333333333333\t ACC test:  0.5577777777777778\n",
      "\tEpoch 213: \tAverage Loss:  0.3264963684082031\t ACC train:  0.6333333333333333\t ACC test:  0.5688888888888889\n",
      "\tEpoch 214: \tAverage Loss:  0.3288086242675781\t ACC train:  0.5666666666666667\t ACC test:  0.5577777777777778\n",
      "\tEpoch 215: \tAverage Loss:  0.3261344299316406\t ACC train:  0.6666666666666666\t ACC test:  0.5577777777777778\n",
      "\tEpoch 216: \tAverage Loss:  0.3241090698242188\t ACC train:  0.5833333333333334\t ACC test:  0.5488888888888889\n",
      "\tEpoch 217: \tAverage Loss:  0.32630047607421875\t ACC train:  0.5833333333333334\t ACC test:  0.56\n",
      "\tEpoch 218: \tAverage Loss:  0.3255435791015625\t ACC train:  0.6333333333333333\t ACC test:  0.5666666666666667\n",
      "\tEpoch 219: \tAverage Loss:  0.3259718017578125\t ACC train:  0.6\t ACC test:  0.5622222222222222\n",
      "\tEpoch 220: \tAverage Loss:  0.32602117919921875\t ACC train:  0.6333333333333333\t ACC test:  0.5666666666666667\n",
      "\tEpoch 221: \tAverage Loss:  0.32368585205078126\t ACC train:  0.5833333333333334\t ACC test:  0.5844444444444444\n",
      "\tEpoch 222: \tAverage Loss:  0.3241113586425781\t ACC train:  0.6166666666666667\t ACC test:  0.5666666666666667\n",
      "\tEpoch 223: \tAverage Loss:  0.32580856323242186\t ACC train:  0.6\t ACC test:  0.56\n",
      "\tEpoch 224: \tAverage Loss:  0.32259109497070315\t ACC train:  0.6166666666666667\t ACC test:  0.5711111111111111\n",
      "\tEpoch 225: \tAverage Loss:  0.3237518615722656\t ACC train:  0.55\t ACC test:  0.5822222222222222\n",
      "\tEpoch 226: \tAverage Loss:  0.32162564086914064\t ACC train:  0.6833333333333333\t ACC test:  0.5555555555555556\n",
      "\tEpoch 227: \tAverage Loss:  0.31985137939453123\t ACC train:  0.6\t ACC test:  0.5555555555555556\n",
      "\tEpoch 228: \tAverage Loss:  0.3227087097167969\t ACC train:  0.6333333333333333\t ACC test:  0.5555555555555556\n",
      "\tEpoch 229: \tAverage Loss:  0.32078311157226563\t ACC train:  0.65\t ACC test:  0.56\n",
      "\tEpoch 230: \tAverage Loss:  0.32149786376953127\t ACC train:  0.6\t ACC test:  0.5577777777777778\n",
      "\tEpoch 231: \tAverage Loss:  0.32053958129882815\t ACC train:  0.65\t ACC test:  0.56\n",
      "\tEpoch 232: \tAverage Loss:  0.32003341674804686\t ACC train:  0.6166666666666667\t ACC test:  0.5688888888888889\n",
      "\tEpoch 233: \tAverage Loss:  0.32113735961914064\t ACC train:  0.65\t ACC test:  0.5644444444444444\n",
      "\tEpoch 234: \tAverage Loss:  0.31815966796875\t ACC train:  0.6166666666666667\t ACC test:  0.5644444444444444\n",
      "\tEpoch 235: \tAverage Loss:  0.31923794555664065\t ACC train:  0.6333333333333333\t ACC test:  0.5577777777777778\n",
      "\tEpoch 236: \tAverage Loss:  0.3188150634765625\t ACC train:  0.6166666666666667\t ACC test:  0.5555555555555556\n",
      "\tEpoch 237: \tAverage Loss:  0.3179704895019531\t ACC train:  0.6166666666666667\t ACC test:  0.5555555555555556\n",
      "\tEpoch 238: \tAverage Loss:  0.3168943786621094\t ACC train:  0.5833333333333334\t ACC test:  0.5733333333333334\n",
      "\tEpoch 239: \tAverage Loss:  0.3171443176269531\t ACC train:  0.6\t ACC test:  0.5666666666666667\n",
      "\tEpoch 240: \tAverage Loss:  0.3182046203613281\t ACC train:  0.65\t ACC test:  0.5711111111111111\n",
      "\tEpoch 241: \tAverage Loss:  0.3163887023925781\t ACC train:  0.6\t ACC test:  0.5777777777777777\n",
      "\tEpoch 242: \tAverage Loss:  0.3161473388671875\t ACC train:  0.6166666666666667\t ACC test:  0.5777777777777777\n",
      "\tEpoch 243: \tAverage Loss:  0.3183941040039063\t ACC train:  0.65\t ACC test:  0.5777777777777777\n",
      "\tEpoch 244: \tAverage Loss:  0.3159698181152344\t ACC train:  0.6333333333333333\t ACC test:  0.5577777777777778\n",
      "\tEpoch 245: \tAverage Loss:  0.31769049072265626\t ACC train:  0.6\t ACC test:  0.5577777777777778\n",
      "\tEpoch 246: \tAverage Loss:  0.3154667053222656\t ACC train:  0.6333333333333333\t ACC test:  0.5777777777777777\n",
      "\tEpoch 247: \tAverage Loss:  0.31659283447265624\t ACC train:  0.65\t ACC test:  0.5622222222222222\n",
      "\tEpoch 248: \tAverage Loss:  0.3160570068359375\t ACC train:  0.65\t ACC test:  0.56\n",
      "\tEpoch 249: \tAverage Loss:  0.31500482177734374\t ACC train:  0.6\t ACC test:  0.5755555555555556\n",
      "\tEpoch 250: \tAverage Loss:  0.3143382263183594\t ACC train:  0.6166666666666667\t ACC test:  0.5888888888888889\n",
      "\tEpoch 251: \tAverage Loss:  0.314419921875\t ACC train:  0.6166666666666667\t ACC test:  0.5733333333333334\n",
      "\tEpoch 252: \tAverage Loss:  0.3141017456054688\t ACC train:  0.6\t ACC test:  0.5755555555555556\n",
      "\tEpoch 253: \tAverage Loss:  0.31394927978515624\t ACC train:  0.6833333333333333\t ACC test:  0.5733333333333334\n",
      "\tEpoch 254: \tAverage Loss:  0.31333599853515626\t ACC train:  0.6333333333333333\t ACC test:  0.5733333333333334\n",
      "\tEpoch 255: \tAverage Loss:  0.31362042236328125\t ACC train:  0.6\t ACC test:  0.5711111111111111\n",
      "\tEpoch 256: \tAverage Loss:  0.31362042236328125\t ACC train:  0.5833333333333334\t ACC test:  0.5755555555555556\n",
      "\tEpoch 257: \tAverage Loss:  0.31364309692382814\t ACC train:  0.6\t ACC test:  0.5822222222222222\n",
      "\tEpoch 258: \tAverage Loss:  0.31158740234375\t ACC train:  0.6\t ACC test:  0.6044444444444445\n",
      "\tEpoch 259: \tAverage Loss:  0.3140097961425781\t ACC train:  0.6\t ACC test:  0.5844444444444444\n",
      "\tEpoch 260: \tAverage Loss:  0.31254425048828127\t ACC train:  0.6333333333333333\t ACC test:  0.5888888888888889\n",
      "\tEpoch 261: \tAverage Loss:  0.3129141845703125\t ACC train:  0.6333333333333333\t ACC test:  0.58\n",
      "\tEpoch 262: \tAverage Loss:  0.3123397216796875\t ACC train:  0.6333333333333333\t ACC test:  0.5688888888888889\n",
      "\tEpoch 263: \tAverage Loss:  0.31173995971679686\t ACC train:  0.65\t ACC test:  0.5888888888888889\n",
      "\tEpoch 264: \tAverage Loss:  0.311244384765625\t ACC train:  0.6\t ACC test:  0.5822222222222222\n",
      "\tEpoch 265: \tAverage Loss:  0.3130000915527344\t ACC train:  0.5833333333333334\t ACC test:  0.5577777777777778\n",
      "\tEpoch 266: \tAverage Loss:  0.31215728759765626\t ACC train:  0.6\t ACC test:  0.5822222222222222\n",
      "\tEpoch 267: \tAverage Loss:  0.31108401489257814\t ACC train:  0.5833333333333334\t ACC test:  0.5777777777777777\n",
      "\tEpoch 268: \tAverage Loss:  0.31026519775390626\t ACC train:  0.6666666666666666\t ACC test:  0.5755555555555556\n",
      "\tEpoch 269: \tAverage Loss:  0.3101007385253906\t ACC train:  0.6\t ACC test:  0.5755555555555556\n",
      "\tEpoch 270: \tAverage Loss:  0.30883203125\t ACC train:  0.6666666666666666\t ACC test:  0.5711111111111111\n",
      "\tEpoch 271: \tAverage Loss:  0.30928887939453126\t ACC train:  0.6166666666666667\t ACC test:  0.5711111111111111\n",
      "\tEpoch 272: \tAverage Loss:  0.31045513916015627\t ACC train:  0.6666666666666666\t ACC test:  0.58\n",
      "\tEpoch 273: \tAverage Loss:  0.30894247436523437\t ACC train:  0.6333333333333333\t ACC test:  0.5755555555555556\n",
      "\tEpoch 274: \tAverage Loss:  0.30823043823242186\t ACC train:  0.6333333333333333\t ACC test:  0.58\n",
      "\tEpoch 275: \tAverage Loss:  0.3075443420410156\t ACC train:  0.6333333333333333\t ACC test:  0.5711111111111111\n",
      "\tEpoch 276: \tAverage Loss:  0.3090245361328125\t ACC train:  0.6166666666666667\t ACC test:  0.5955555555555555\n",
      "\tEpoch 277: \tAverage Loss:  0.3079296875\t ACC train:  0.65\t ACC test:  0.5777777777777777\n",
      "\tEpoch 278: \tAverage Loss:  0.30854693603515626\t ACC train:  0.6666666666666666\t ACC test:  0.58\n",
      "\tEpoch 279: \tAverage Loss:  0.3075431823730469\t ACC train:  0.6666666666666666\t ACC test:  0.5866666666666667\n",
      "\tEpoch 280: \tAverage Loss:  0.3080040588378906\t ACC train:  0.7\t ACC test:  0.5866666666666667\n",
      "\tEpoch 281: \tAverage Loss:  0.30814654541015624\t ACC train:  0.6333333333333333\t ACC test:  0.5822222222222222\n",
      "\tEpoch 282: \tAverage Loss:  0.30707760620117186\t ACC train:  0.6166666666666667\t ACC test:  0.5822222222222222\n",
      "\tEpoch 283: \tAverage Loss:  0.3074186706542969\t ACC train:  0.6166666666666667\t ACC test:  0.5933333333333334\n",
      "\tEpoch 284: \tAverage Loss:  0.30825775146484374\t ACC train:  0.6333333333333333\t ACC test:  0.5866666666666667\n",
      "\tEpoch 285: \tAverage Loss:  0.30674334716796875\t ACC train:  0.6333333333333333\t ACC test:  0.5733333333333334\n",
      "\tEpoch 286: \tAverage Loss:  0.3060850830078125\t ACC train:  0.6666666666666666\t ACC test:  0.58\n",
      "\tEpoch 287: \tAverage Loss:  0.3077705078125\t ACC train:  0.6\t ACC test:  0.6\n",
      "\tEpoch 288: \tAverage Loss:  0.3068274230957031\t ACC train:  0.6333333333333333\t ACC test:  0.5977777777777777\n",
      "\tEpoch 289: \tAverage Loss:  0.30539862060546874\t ACC train:  0.6833333333333333\t ACC test:  0.5822222222222222\n",
      "\tEpoch 290: \tAverage Loss:  0.3064532470703125\t ACC train:  0.65\t ACC test:  0.5955555555555555\n",
      "\tEpoch 291: \tAverage Loss:  0.30551541137695315\t ACC train:  0.6666666666666666\t ACC test:  0.5866666666666667\n",
      "\tEpoch 292: \tAverage Loss:  0.30629095458984373\t ACC train:  0.6666666666666666\t ACC test:  0.5777777777777777\n",
      "\tEpoch 293: \tAverage Loss:  0.30626419067382815\t ACC train:  0.6333333333333333\t ACC test:  0.5888888888888889\n",
      "\tEpoch 294: \tAverage Loss:  0.3045650634765625\t ACC train:  0.6333333333333333\t ACC test:  0.5911111111111111\n",
      "\tEpoch 295: \tAverage Loss:  0.3051329650878906\t ACC train:  0.65\t ACC test:  0.5822222222222222\n",
      "\tEpoch 296: \tAverage Loss:  0.3047550354003906\t ACC train:  0.65\t ACC test:  0.58\n",
      "\tEpoch 297: \tAverage Loss:  0.3054820556640625\t ACC train:  0.6333333333333333\t ACC test:  0.5888888888888889\n",
      "\tEpoch 298: \tAverage Loss:  0.305134765625\t ACC train:  0.65\t ACC test:  0.5777777777777777\n",
      "\tEpoch 299: \tAverage Loss:  0.3044475708007813\t ACC train:  0.6666666666666666\t ACC test:  0.6044444444444445\n",
      "\tEpoch 300: \tAverage Loss:  0.30459222412109377\t ACC train:  0.6333333333333333\t ACC test:  0.5888888888888889\n",
      "\tEpoch 301: \tAverage Loss:  0.3041210021972656\t ACC train:  0.65\t ACC test:  0.6044444444444445\n",
      "\tEpoch 302: \tAverage Loss:  0.30340756225585935\t ACC train:  0.6666666666666666\t ACC test:  0.5977777777777777\n",
      "\tEpoch 303: \tAverage Loss:  0.30248431396484377\t ACC train:  0.6333333333333333\t ACC test:  0.5933333333333334\n",
      "\tEpoch 304: \tAverage Loss:  0.30377935791015626\t ACC train:  0.65\t ACC test:  0.5955555555555555\n",
      "\tEpoch 305: \tAverage Loss:  0.30343701171875\t ACC train:  0.6666666666666666\t ACC test:  0.6\n",
      "\tEpoch 306: \tAverage Loss:  0.3035032043457031\t ACC train:  0.6\t ACC test:  0.5955555555555555\n",
      "\tEpoch 307: \tAverage Loss:  0.3030499267578125\t ACC train:  0.6333333333333333\t ACC test:  0.5822222222222222\n",
      "\tEpoch 308: \tAverage Loss:  0.30310519409179687\t ACC train:  0.6166666666666667\t ACC test:  0.5977777777777777\n",
      "\tEpoch 309: \tAverage Loss:  0.30215374755859375\t ACC train:  0.65\t ACC test:  0.6088888888888889\n",
      "\tEpoch 310: \tAverage Loss:  0.3033764343261719\t ACC train:  0.6166666666666667\t ACC test:  0.5977777777777777\n",
      "\tEpoch 311: \tAverage Loss:  0.3025128479003906\t ACC train:  0.65\t ACC test:  0.5933333333333334\n",
      "\tEpoch 312: \tAverage Loss:  0.30290423583984377\t ACC train:  0.65\t ACC test:  0.5866666666666667\n",
      "\tEpoch 313: \tAverage Loss:  0.3031198120117187\t ACC train:  0.6166666666666667\t ACC test:  0.5822222222222222\n",
      "\tEpoch 314: \tAverage Loss:  0.30172393798828123\t ACC train:  0.65\t ACC test:  0.6\n",
      "\tEpoch 315: \tAverage Loss:  0.30149380493164063\t ACC train:  0.6333333333333333\t ACC test:  0.5933333333333334\n",
      "\tEpoch 316: \tAverage Loss:  0.301529296875\t ACC train:  0.6833333333333333\t ACC test:  0.5933333333333334\n",
      "\tEpoch 317: \tAverage Loss:  0.30098916625976563\t ACC train:  0.6333333333333333\t ACC test:  0.5911111111111111\n",
      "\tEpoch 318: \tAverage Loss:  0.3025434265136719\t ACC train:  0.6333333333333333\t ACC test:  0.5933333333333334\n",
      "\tEpoch 319: \tAverage Loss:  0.30076956176757813\t ACC train:  0.6666666666666666\t ACC test:  0.6\n",
      "\tEpoch 320: \tAverage Loss:  0.3014385681152344\t ACC train:  0.6166666666666667\t ACC test:  0.5866666666666667\n",
      "\tEpoch 321: \tAverage Loss:  0.2996596984863281\t ACC train:  0.6333333333333333\t ACC test:  0.5844444444444444\n",
      "\tEpoch 322: \tAverage Loss:  0.3004847412109375\t ACC train:  0.65\t ACC test:  0.5866666666666667\n",
      "\tEpoch 323: \tAverage Loss:  0.30152896118164063\t ACC train:  0.6166666666666667\t ACC test:  0.5866666666666667\n",
      "\tEpoch 324: \tAverage Loss:  0.30056683349609375\t ACC train:  0.6333333333333333\t ACC test:  0.5955555555555555\n",
      "\tEpoch 325: \tAverage Loss:  0.3006922607421875\t ACC train:  0.6166666666666667\t ACC test:  0.5977777777777777\n",
      "\tEpoch 326: \tAverage Loss:  0.30001995849609375\t ACC train:  0.6333333333333333\t ACC test:  0.5933333333333334\n",
      "\tEpoch 327: \tAverage Loss:  0.3007072448730469\t ACC train:  0.6333333333333333\t ACC test:  0.5955555555555555\n",
      "\tEpoch 328: \tAverage Loss:  0.3004837341308594\t ACC train:  0.6333333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 329: \tAverage Loss:  0.2993698425292969\t ACC train:  0.6333333333333333\t ACC test:  0.6\n",
      "\tEpoch 330: \tAverage Loss:  0.30058880615234373\t ACC train:  0.6666666666666666\t ACC test:  0.5933333333333334\n",
      "\tEpoch 331: \tAverage Loss:  0.2990715026855469\t ACC train:  0.65\t ACC test:  0.5977777777777777\n",
      "\tEpoch 332: \tAverage Loss:  0.30018307495117186\t ACC train:  0.6333333333333333\t ACC test:  0.5888888888888889\n",
      "\tEpoch 333: \tAverage Loss:  0.3000263671875\t ACC train:  0.6666666666666666\t ACC test:  0.5933333333333334\n",
      "\tEpoch 334: \tAverage Loss:  0.2989451904296875\t ACC train:  0.6333333333333333\t ACC test:  0.6022222222222222\n",
      "\tEpoch 335: \tAverage Loss:  0.29856625366210937\t ACC train:  0.65\t ACC test:  0.5866666666666667\n",
      "\tEpoch 336: \tAverage Loss:  0.2981051330566406\t ACC train:  0.6166666666666667\t ACC test:  0.5933333333333334\n",
      "\tEpoch 337: \tAverage Loss:  0.29798101806640626\t ACC train:  0.65\t ACC test:  0.5977777777777777\n",
      "\tEpoch 338: \tAverage Loss:  0.29847323608398435\t ACC train:  0.6333333333333333\t ACC test:  0.5866666666666667\n",
      "\tEpoch 339: \tAverage Loss:  0.29843692016601564\t ACC train:  0.6833333333333333\t ACC test:  0.5977777777777777\n",
      "\tEpoch 340: \tAverage Loss:  0.2979375\t ACC train:  0.6833333333333333\t ACC test:  0.6088888888888889\n",
      "\tEpoch 341: \tAverage Loss:  0.2986299133300781\t ACC train:  0.6833333333333333\t ACC test:  0.5911111111111111\n",
      "\tEpoch 342: \tAverage Loss:  0.29918585205078124\t ACC train:  0.6166666666666667\t ACC test:  0.5977777777777777\n",
      "\tEpoch 343: \tAverage Loss:  0.2981805114746094\t ACC train:  0.6333333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 344: \tAverage Loss:  0.29663900756835937\t ACC train:  0.6666666666666666\t ACC test:  0.6088888888888889\n",
      "\tEpoch 345: \tAverage Loss:  0.29869793701171876\t ACC train:  0.6333333333333333\t ACC test:  0.6022222222222222\n",
      "\tEpoch 346: \tAverage Loss:  0.29816268920898437\t ACC train:  0.65\t ACC test:  0.6088888888888889\n",
      "\tEpoch 347: \tAverage Loss:  0.2982652282714844\t ACC train:  0.6666666666666666\t ACC test:  0.6111111111111112\n",
      "\tEpoch 348: \tAverage Loss:  0.2964830627441406\t ACC train:  0.6666666666666666\t ACC test:  0.5888888888888889\n",
      "\tEpoch 349: \tAverage Loss:  0.29768484497070313\t ACC train:  0.6666666666666666\t ACC test:  0.5977777777777777\n",
      "\tEpoch 350: \tAverage Loss:  0.296495849609375\t ACC train:  0.65\t ACC test:  0.6044444444444445\n",
      "\tEpoch 351: \tAverage Loss:  0.2965748901367187\t ACC train:  0.6166666666666667\t ACC test:  0.6022222222222222\n",
      "\tEpoch 352: \tAverage Loss:  0.29598068237304687\t ACC train:  0.6333333333333333\t ACC test:  0.5933333333333334\n",
      "\tEpoch 353: \tAverage Loss:  0.2976183776855469\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 354: \tAverage Loss:  0.2968511962890625\t ACC train:  0.6666666666666666\t ACC test:  0.5955555555555555\n",
      "\tEpoch 355: \tAverage Loss:  0.2958673400878906\t ACC train:  0.6666666666666666\t ACC test:  0.6044444444444445\n",
      "\tEpoch 356: \tAverage Loss:  0.29643893432617185\t ACC train:  0.65\t ACC test:  0.6088888888888889\n",
      "\tEpoch 357: \tAverage Loss:  0.295366943359375\t ACC train:  0.6333333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 358: \tAverage Loss:  0.2959429931640625\t ACC train:  0.65\t ACC test:  0.6022222222222222\n",
      "\tEpoch 359: \tAverage Loss:  0.2959500732421875\t ACC train:  0.6333333333333333\t ACC test:  0.5977777777777777\n",
      "\tEpoch 360: \tAverage Loss:  0.2954039001464844\t ACC train:  0.6833333333333333\t ACC test:  0.6155555555555555\n",
      "\tEpoch 361: \tAverage Loss:  0.2960479736328125\t ACC train:  0.65\t ACC test:  0.6044444444444445\n",
      "\tEpoch 362: \tAverage Loss:  0.29543060302734375\t ACC train:  0.6833333333333333\t ACC test:  0.6066666666666667\n",
      "\tEpoch 363: \tAverage Loss:  0.29533029174804687\t ACC train:  0.6666666666666666\t ACC test:  0.6177777777777778\n",
      "\tEpoch 364: \tAverage Loss:  0.2955355224609375\t ACC train:  0.6333333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 365: \tAverage Loss:  0.2944317321777344\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 366: \tAverage Loss:  0.29409854125976564\t ACC train:  0.6666666666666666\t ACC test:  0.6066666666666667\n",
      "\tEpoch 367: \tAverage Loss:  0.2953470153808594\t ACC train:  0.6666666666666666\t ACC test:  0.6044444444444445\n",
      "\tEpoch 368: \tAverage Loss:  0.29381317138671875\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 369: \tAverage Loss:  0.29453219604492187\t ACC train:  0.6666666666666666\t ACC test:  0.6044444444444445\n",
      "\tEpoch 370: \tAverage Loss:  0.29525888061523436\t ACC train:  0.6666666666666666\t ACC test:  0.6\n",
      "\tEpoch 371: \tAverage Loss:  0.29470785522460935\t ACC train:  0.6333333333333333\t ACC test:  0.6022222222222222\n",
      "\tEpoch 372: \tAverage Loss:  0.2936665954589844\t ACC train:  0.6666666666666666\t ACC test:  0.6\n",
      "\tEpoch 373: \tAverage Loss:  0.29398934936523435\t ACC train:  0.6333333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 374: \tAverage Loss:  0.29380624389648435\t ACC train:  0.6833333333333333\t ACC test:  0.6111111111111112\n",
      "\tEpoch 375: \tAverage Loss:  0.2939462890625\t ACC train:  0.65\t ACC test:  0.6022222222222222\n",
      "\tEpoch 376: \tAverage Loss:  0.2946363220214844\t ACC train:  0.6666666666666666\t ACC test:  0.6044444444444445\n",
      "\tEpoch 377: \tAverage Loss:  0.29288397216796874\t ACC train:  0.6666666666666666\t ACC test:  0.6155555555555555\n",
      "\tEpoch 378: \tAverage Loss:  0.29272613525390623\t ACC train:  0.6666666666666666\t ACC test:  0.5933333333333334\n",
      "\tEpoch 379: \tAverage Loss:  0.2926597595214844\t ACC train:  0.65\t ACC test:  0.6\n",
      "\tEpoch 380: \tAverage Loss:  0.2938001708984375\t ACC train:  0.6666666666666666\t ACC test:  0.6022222222222222\n",
      "\tEpoch 381: \tAverage Loss:  0.2927420349121094\t ACC train:  0.6833333333333333\t ACC test:  0.6022222222222222\n",
      "\tEpoch 382: \tAverage Loss:  0.29271240234375\t ACC train:  0.6666666666666666\t ACC test:  0.6\n",
      "\tEpoch 383: \tAverage Loss:  0.2931022644042969\t ACC train:  0.6666666666666666\t ACC test:  0.5977777777777777\n",
      "\tEpoch 384: \tAverage Loss:  0.2927529296875\t ACC train:  0.65\t ACC test:  0.6\n",
      "\tEpoch 385: \tAverage Loss:  0.2911817626953125\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 386: \tAverage Loss:  0.29302178955078123\t ACC train:  0.65\t ACC test:  0.6044444444444445\n",
      "\tEpoch 387: \tAverage Loss:  0.293045166015625\t ACC train:  0.6166666666666667\t ACC test:  0.6088888888888889\n",
      "\tEpoch 388: \tAverage Loss:  0.2919759826660156\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 389: \tAverage Loss:  0.2921378173828125\t ACC train:  0.6833333333333333\t ACC test:  0.6066666666666667\n",
      "\tEpoch 390: \tAverage Loss:  0.29185394287109373\t ACC train:  0.6666666666666666\t ACC test:  0.6088888888888889\n",
      "\tEpoch 391: \tAverage Loss:  0.2920631713867187\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 392: \tAverage Loss:  0.2916980590820312\t ACC train:  0.6666666666666666\t ACC test:  0.6155555555555555\n",
      "\tEpoch 393: \tAverage Loss:  0.2916631469726563\t ACC train:  0.6833333333333333\t ACC test:  0.6133333333333333\n",
      "\tEpoch 394: \tAverage Loss:  0.2904462890625\t ACC train:  0.6666666666666666\t ACC test:  0.6111111111111112\n",
      "\tEpoch 395: \tAverage Loss:  0.2909622497558594\t ACC train:  0.6333333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 396: \tAverage Loss:  0.2904065246582031\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 397: \tAverage Loss:  0.2901048583984375\t ACC train:  0.6666666666666666\t ACC test:  0.6111111111111112\n",
      "\tEpoch 398: \tAverage Loss:  0.2898584899902344\t ACC train:  0.6666666666666666\t ACC test:  0.6088888888888889\n",
      "\tEpoch 399: \tAverage Loss:  0.29151593017578126\t ACC train:  0.7333333333333333\t ACC test:  0.6288888888888889\n",
      "\tEpoch 400: \tAverage Loss:  0.29087548828125\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 401: \tAverage Loss:  0.28995330810546877\t ACC train:  0.7666666666666667\t ACC test:  0.6622222222222223\n",
      "\tEpoch 402: \tAverage Loss:  0.289486328125\t ACC train:  0.7333333333333333\t ACC test:  0.6644444444444444\n",
      "\tEpoch 403: \tAverage Loss:  0.2903533630371094\t ACC train:  0.75\t ACC test:  0.6844444444444444\n",
      "\tEpoch 404: \tAverage Loss:  0.2897488098144531\t ACC train:  0.7666666666666667\t ACC test:  0.6844444444444444\n",
      "\tEpoch 405: \tAverage Loss:  0.28936502075195314\t ACC train:  0.7666666666666667\t ACC test:  0.6977777777777778\n",
      "\tEpoch 406: \tAverage Loss:  0.28934402465820314\t ACC train:  0.8166666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 407: \tAverage Loss:  0.28845074462890624\t ACC train:  0.7833333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 408: \tAverage Loss:  0.2893406066894531\t ACC train:  0.7833333333333333\t ACC test:  0.7222222222222222\n",
      "\tEpoch 409: \tAverage Loss:  0.2896034851074219\t ACC train:  0.7833333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 410: \tAverage Loss:  0.2890329895019531\t ACC train:  0.7666666666666667\t ACC test:  0.7244444444444444\n",
      "\tEpoch 411: \tAverage Loss:  0.2885220336914063\t ACC train:  0.8333333333333334\t ACC test:  0.7155555555555555\n",
      "\tEpoch 412: \tAverage Loss:  0.28921621704101563\t ACC train:  0.7666666666666667\t ACC test:  0.72\n",
      "\tEpoch 413: \tAverage Loss:  0.2884381408691406\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 414: \tAverage Loss:  0.2881800231933594\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 415: \tAverage Loss:  0.2891402282714844\t ACC train:  0.8\t ACC test:  0.7111111111111111\n",
      "\tEpoch 416: \tAverage Loss:  0.28888937377929685\t ACC train:  0.7666666666666667\t ACC test:  0.7288888888888889\n",
      "\tEpoch 417: \tAverage Loss:  0.28869699096679685\t ACC train:  0.8\t ACC test:  0.7266666666666667\n",
      "\tEpoch 418: \tAverage Loss:  0.28747824096679686\t ACC train:  0.7833333333333333\t ACC test:  0.7355555555555555\n",
      "\tEpoch 419: \tAverage Loss:  0.2874779052734375\t ACC train:  0.8166666666666667\t ACC test:  0.7533333333333333\n",
      "\tEpoch 420: \tAverage Loss:  0.28754425048828125\t ACC train:  0.7833333333333333\t ACC test:  0.7555555555555555\n",
      "\tEpoch 421: \tAverage Loss:  0.2884065246582031\t ACC train:  0.8666666666666667\t ACC test:  0.7644444444444445\n",
      "\tEpoch 422: \tAverage Loss:  0.2874626770019531\t ACC train:  0.8166666666666667\t ACC test:  0.74\n",
      "\tEpoch 423: \tAverage Loss:  0.2872288513183594\t ACC train:  0.85\t ACC test:  0.7688888888888888\n",
      "\tEpoch 424: \tAverage Loss:  0.2867933349609375\t ACC train:  0.8\t ACC test:  0.76\n",
      "\tEpoch 425: \tAverage Loss:  0.28701742553710935\t ACC train:  0.8666666666666667\t ACC test:  0.7666666666666667\n",
      "\tEpoch 426: \tAverage Loss:  0.28731747436523436\t ACC train:  0.8166666666666667\t ACC test:  0.7733333333333333\n",
      "\tEpoch 427: \tAverage Loss:  0.28670510864257814\t ACC train:  0.85\t ACC test:  0.7511111111111111\n",
      "\tEpoch 428: \tAverage Loss:  0.28685980224609375\t ACC train:  0.8333333333333334\t ACC test:  0.7755555555555556\n",
      "\tEpoch 429: \tAverage Loss:  0.2861320495605469\t ACC train:  0.8333333333333334\t ACC test:  0.78\n",
      "\tEpoch 430: \tAverage Loss:  0.28625888061523436\t ACC train:  0.8833333333333333\t ACC test:  0.7644444444444445\n",
      "\tEpoch 431: \tAverage Loss:  0.286515869140625\t ACC train:  0.85\t ACC test:  0.7577777777777778\n",
      "\tEpoch 432: \tAverage Loss:  0.28638250732421877\t ACC train:  0.8333333333333334\t ACC test:  0.76\n",
      "\tEpoch 433: \tAverage Loss:  0.2858750305175781\t ACC train:  0.85\t ACC test:  0.7666666666666667\n",
      "\tEpoch 434: \tAverage Loss:  0.2863103332519531\t ACC train:  0.85\t ACC test:  0.7733333333333333\n",
      "\tEpoch 435: \tAverage Loss:  0.2851717529296875\t ACC train:  0.9\t ACC test:  0.7533333333333333\n",
      "\tEpoch 436: \tAverage Loss:  0.28484857177734374\t ACC train:  0.85\t ACC test:  0.7688888888888888\n",
      "\tEpoch 437: \tAverage Loss:  0.28568157958984375\t ACC train:  0.8666666666666667\t ACC test:  0.7777777777777778\n",
      "\tEpoch 438: \tAverage Loss:  0.28523342895507814\t ACC train:  0.8666666666666667\t ACC test:  0.7844444444444445\n",
      "\tEpoch 439: \tAverage Loss:  0.2855527038574219\t ACC train:  0.85\t ACC test:  0.7644444444444445\n",
      "\tEpoch 440: \tAverage Loss:  0.2853297119140625\t ACC train:  0.9\t ACC test:  0.78\n",
      "\tEpoch 441: \tAverage Loss:  0.2846968994140625\t ACC train:  0.8833333333333333\t ACC test:  0.7755555555555556\n",
      "\tEpoch 442: \tAverage Loss:  0.2848448181152344\t ACC train:  0.8833333333333333\t ACC test:  0.78\n",
      "\tEpoch 443: \tAverage Loss:  0.28463006591796874\t ACC train:  0.8833333333333333\t ACC test:  0.7822222222222223\n",
      "\tEpoch 444: \tAverage Loss:  0.28471908569335935\t ACC train:  0.85\t ACC test:  0.7888888888888889\n",
      "\tEpoch 445: \tAverage Loss:  0.28547088623046873\t ACC train:  0.8666666666666667\t ACC test:  0.7822222222222223\n",
      "\tEpoch 446: \tAverage Loss:  0.28330746459960937\t ACC train:  0.8666666666666667\t ACC test:  0.7733333333333333\n",
      "\tEpoch 447: \tAverage Loss:  0.2836773986816406\t ACC train:  0.9\t ACC test:  0.7822222222222223\n",
      "\tEpoch 448: \tAverage Loss:  0.28334234619140625\t ACC train:  0.85\t ACC test:  0.7733333333333333\n",
      "\tEpoch 449: \tAverage Loss:  0.28408505249023436\t ACC train:  0.8666666666666667\t ACC test:  0.7844444444444445\n",
      "\tEpoch 450: \tAverage Loss:  0.28495809936523436\t ACC train:  0.8833333333333333\t ACC test:  0.7777777777777778\n",
      "\tEpoch 451: \tAverage Loss:  0.2839595031738281\t ACC train:  0.8833333333333333\t ACC test:  0.7755555555555556\n",
      "\tEpoch 452: \tAverage Loss:  0.2838519287109375\t ACC train:  0.8833333333333333\t ACC test:  0.7933333333333333\n",
      "\tEpoch 453: \tAverage Loss:  0.2823160095214844\t ACC train:  0.9\t ACC test:  0.7666666666666667\n",
      "\tEpoch 454: \tAverage Loss:  0.2826098022460938\t ACC train:  0.8666666666666667\t ACC test:  0.7933333333333333\n",
      "\tEpoch 455: \tAverage Loss:  0.2830550842285156\t ACC train:  0.8666666666666667\t ACC test:  0.7888888888888889\n",
      "\tEpoch 456: \tAverage Loss:  0.2827005920410156\t ACC train:  0.8833333333333333\t ACC test:  0.7955555555555556\n",
      "\tEpoch 457: \tAverage Loss:  0.28236587524414064\t ACC train:  0.85\t ACC test:  0.7822222222222223\n",
      "\tEpoch 458: \tAverage Loss:  0.2813582763671875\t ACC train:  0.8666666666666667\t ACC test:  0.7888888888888889\n",
      "\tEpoch 459: \tAverage Loss:  0.2822367553710938\t ACC train:  0.8833333333333333\t ACC test:  0.7955555555555556\n",
      "\tEpoch 460: \tAverage Loss:  0.282340576171875\t ACC train:  0.8833333333333333\t ACC test:  0.7844444444444445\n",
      "\tEpoch 461: \tAverage Loss:  0.2828850402832031\t ACC train:  0.8833333333333333\t ACC test:  0.7733333333333333\n",
      "\tEpoch 462: \tAverage Loss:  0.28152618408203123\t ACC train:  0.8666666666666667\t ACC test:  0.7844444444444445\n",
      "\tEpoch 463: \tAverage Loss:  0.2823270263671875\t ACC train:  0.8833333333333333\t ACC test:  0.7888888888888889\n",
      "\tEpoch 464: \tAverage Loss:  0.2821163330078125\t ACC train:  0.8666666666666667\t ACC test:  0.7888888888888889\n",
      "\tEpoch 465: \tAverage Loss:  0.28140032958984373\t ACC train:  0.8833333333333333\t ACC test:  0.7911111111111111\n",
      "\tEpoch 466: \tAverage Loss:  0.28039328002929687\t ACC train:  0.8666666666666667\t ACC test:  0.7711111111111111\n",
      "\tEpoch 467: \tAverage Loss:  0.2824263610839844\t ACC train:  0.8666666666666667\t ACC test:  0.7822222222222223\n",
      "\tEpoch 468: \tAverage Loss:  0.28166656494140624\t ACC train:  0.8833333333333333\t ACC test:  0.7844444444444445\n",
      "\tEpoch 469: \tAverage Loss:  0.280691162109375\t ACC train:  0.8833333333333333\t ACC test:  0.7888888888888889\n",
      "\tEpoch 470: \tAverage Loss:  0.280846435546875\t ACC train:  0.9\t ACC test:  0.7711111111111111\n",
      "\tEpoch 471: \tAverage Loss:  0.28078057861328126\t ACC train:  0.8833333333333333\t ACC test:  0.8044444444444444\n",
      "\tEpoch 472: \tAverage Loss:  0.28153567504882815\t ACC train:  0.9\t ACC test:  0.8\n",
      "\tEpoch 473: \tAverage Loss:  0.2795224609375\t ACC train:  0.8833333333333333\t ACC test:  0.7777777777777778\n",
      "\tEpoch 474: \tAverage Loss:  0.2802693786621094\t ACC train:  0.8666666666666667\t ACC test:  0.7911111111111111\n",
      "\tEpoch 475: \tAverage Loss:  0.2810054321289063\t ACC train:  0.9166666666666666\t ACC test:  0.7888888888888889\n",
      "\tEpoch 476: \tAverage Loss:  0.28034976196289063\t ACC train:  0.8833333333333333\t ACC test:  0.7888888888888889\n",
      "\tEpoch 477: \tAverage Loss:  0.2811148376464844\t ACC train:  0.8833333333333333\t ACC test:  0.8\n",
      "\tEpoch 478: \tAverage Loss:  0.27905520629882813\t ACC train:  0.8833333333333333\t ACC test:  0.7955555555555556\n",
      "\tEpoch 479: \tAverage Loss:  0.280111328125\t ACC train:  0.9\t ACC test:  0.7755555555555556\n",
      "\tEpoch 480: \tAverage Loss:  0.27881570434570313\t ACC train:  0.9166666666666666\t ACC test:  0.7866666666666666\n",
      "\tEpoch 481: \tAverage Loss:  0.27976412963867187\t ACC train:  0.9166666666666666\t ACC test:  0.7911111111111111\n",
      "\tEpoch 482: \tAverage Loss:  0.2802976379394531\t ACC train:  0.8833333333333333\t ACC test:  0.7955555555555556\n",
      "\tEpoch 483: \tAverage Loss:  0.278844970703125\t ACC train:  0.9\t ACC test:  0.78\n",
      "\tEpoch 484: \tAverage Loss:  0.2795713806152344\t ACC train:  0.9\t ACC test:  0.7866666666666666\n",
      "\tEpoch 485: \tAverage Loss:  0.27873867797851565\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 486: \tAverage Loss:  0.27858828735351565\t ACC train:  0.9166666666666666\t ACC test:  0.7911111111111111\n",
      "\tEpoch 487: \tAverage Loss:  0.2794460754394531\t ACC train:  0.9\t ACC test:  0.7933333333333333\n",
      "\tEpoch 488: \tAverage Loss:  0.27873797607421874\t ACC train:  0.9\t ACC test:  0.7866666666666666\n",
      "\tEpoch 489: \tAverage Loss:  0.27804266357421875\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 490: \tAverage Loss:  0.278576171875\t ACC train:  0.9166666666666666\t ACC test:  0.8\n",
      "\tEpoch 491: \tAverage Loss:  0.2794342956542969\t ACC train:  0.9\t ACC test:  0.7888888888888889\n",
      "\tEpoch 492: \tAverage Loss:  0.2785059814453125\t ACC train:  0.8833333333333333\t ACC test:  0.7933333333333333\n",
      "\tEpoch 493: \tAverage Loss:  0.2790904541015625\t ACC train:  0.9\t ACC test:  0.8\n",
      "\tEpoch 494: \tAverage Loss:  0.2778812255859375\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 495: \tAverage Loss:  0.2782242126464844\t ACC train:  0.8833333333333333\t ACC test:  0.7933333333333333\n",
      "\tEpoch 496: \tAverage Loss:  0.27786105346679685\t ACC train:  0.9166666666666666\t ACC test:  0.7955555555555556\n",
      "\tEpoch 497: \tAverage Loss:  0.27661688232421877\t ACC train:  0.9166666666666666\t ACC test:  0.7977777777777778\n",
      "\tEpoch 498: \tAverage Loss:  0.2777952575683594\t ACC train:  0.9\t ACC test:  0.7777777777777778\n",
      "\tEpoch 499: \tAverage Loss:  0.27691079711914063\t ACC train:  0.9\t ACC test:  0.7844444444444445\n",
      "\tEpoch 500: \tAverage Loss:  0.2768607177734375\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 501: \tAverage Loss:  0.2780767822265625\t ACC train:  0.9\t ACC test:  0.7933333333333333\n",
      "\tEpoch 502: \tAverage Loss:  0.2773602600097656\t ACC train:  0.9\t ACC test:  0.7888888888888889\n",
      "\tEpoch 503: \tAverage Loss:  0.2769245300292969\t ACC train:  0.9\t ACC test:  0.8022222222222222\n",
      "\tEpoch 504: \tAverage Loss:  0.276690673828125\t ACC train:  0.9\t ACC test:  0.78\n",
      "\tEpoch 505: \tAverage Loss:  0.2769190979003906\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 506: \tAverage Loss:  0.27608963012695314\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 507: \tAverage Loss:  0.27628924560546875\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 508: \tAverage Loss:  0.2764793701171875\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 509: \tAverage Loss:  0.275966064453125\t ACC train:  0.9166666666666666\t ACC test:  0.7844444444444445\n",
      "\tEpoch 510: \tAverage Loss:  0.2760340576171875\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 511: \tAverage Loss:  0.2753497619628906\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 512: \tAverage Loss:  0.2754871826171875\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 513: \tAverage Loss:  0.2759575500488281\t ACC train:  0.9\t ACC test:  0.7866666666666666\n",
      "\tEpoch 514: \tAverage Loss:  0.27599658203125\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 515: \tAverage Loss:  0.27529107666015623\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 516: \tAverage Loss:  0.27558880615234377\t ACC train:  0.9166666666666666\t ACC test:  0.7866666666666666\n",
      "\tEpoch 517: \tAverage Loss:  0.275947265625\t ACC train:  0.9166666666666666\t ACC test:  0.7866666666666666\n",
      "\tEpoch 518: \tAverage Loss:  0.27579507446289064\t ACC train:  0.9166666666666666\t ACC test:  0.8044444444444444\n",
      "\tEpoch 519: \tAverage Loss:  0.2742170715332031\t ACC train:  0.9\t ACC test:  0.7933333333333333\n",
      "\tEpoch 520: \tAverage Loss:  0.27583392333984375\t ACC train:  0.8833333333333333\t ACC test:  0.7955555555555556\n",
      "\tEpoch 521: \tAverage Loss:  0.27490283203125\t ACC train:  0.9166666666666666\t ACC test:  0.7977777777777778\n",
      "\tEpoch 522: \tAverage Loss:  0.27458740234375\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 523: \tAverage Loss:  0.2740154724121094\t ACC train:  0.9\t ACC test:  0.7933333333333333\n",
      "\tEpoch 524: \tAverage Loss:  0.2747572021484375\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 525: \tAverage Loss:  0.2746473388671875\t ACC train:  0.9166666666666666\t ACC test:  0.7888888888888889\n",
      "\tEpoch 526: \tAverage Loss:  0.2747256469726562\t ACC train:  0.9\t ACC test:  0.7844444444444445\n",
      "\tEpoch 527: \tAverage Loss:  0.27413946533203126\t ACC train:  0.9\t ACC test:  0.7822222222222223\n",
      "\tEpoch 528: \tAverage Loss:  0.27401190185546875\t ACC train:  0.9\t ACC test:  0.7822222222222223\n",
      "\tEpoch 529: \tAverage Loss:  0.27359423828125\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 530: \tAverage Loss:  0.27304022216796875\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 531: \tAverage Loss:  0.2734957275390625\t ACC train:  0.9166666666666666\t ACC test:  0.8\n",
      "\tEpoch 532: \tAverage Loss:  0.27454193115234377\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 533: \tAverage Loss:  0.2732419128417969\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 534: \tAverage Loss:  0.2731915283203125\t ACC train:  0.9166666666666666\t ACC test:  0.7911111111111111\n",
      "\tEpoch 535: \tAverage Loss:  0.2732818603515625\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 536: \tAverage Loss:  0.2719950866699219\t ACC train:  0.9\t ACC test:  0.7888888888888889\n",
      "\tEpoch 537: \tAverage Loss:  0.2726616516113281\t ACC train:  0.9166666666666666\t ACC test:  0.7755555555555556\n",
      "\tEpoch 538: \tAverage Loss:  0.27338470458984376\t ACC train:  0.9166666666666666\t ACC test:  0.8066666666666666\n",
      "\tEpoch 539: \tAverage Loss:  0.2719721374511719\t ACC train:  0.9\t ACC test:  0.8022222222222222\n",
      "\tEpoch 540: \tAverage Loss:  0.272336181640625\t ACC train:  0.9333333333333333\t ACC test:  0.7911111111111111\n",
      "\tEpoch 541: \tAverage Loss:  0.27207064819335935\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 542: \tAverage Loss:  0.27225234985351565\t ACC train:  0.9\t ACC test:  0.7933333333333333\n",
      "\tEpoch 543: \tAverage Loss:  0.2726781921386719\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 544: \tAverage Loss:  0.27164120483398435\t ACC train:  0.9166666666666666\t ACC test:  0.7844444444444445\n",
      "\tEpoch 545: \tAverage Loss:  0.27215252685546876\t ACC train:  0.9166666666666666\t ACC test:  0.7866666666666666\n",
      "\tEpoch 546: \tAverage Loss:  0.27218182373046873\t ACC train:  0.9\t ACC test:  0.7866666666666666\n",
      "\tEpoch 547: \tAverage Loss:  0.27196923828125\t ACC train:  0.9\t ACC test:  0.7933333333333333\n",
      "\tEpoch 548: \tAverage Loss:  0.27198602294921875\t ACC train:  0.9166666666666666\t ACC test:  0.7888888888888889\n",
      "\tEpoch 549: \tAverage Loss:  0.2715713806152344\t ACC train:  0.9166666666666666\t ACC test:  0.8022222222222222\n",
      "\tEpoch 550: \tAverage Loss:  0.2719010009765625\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 551: \tAverage Loss:  0.27211724853515623\t ACC train:  0.9166666666666666\t ACC test:  0.7955555555555556\n",
      "\tEpoch 552: \tAverage Loss:  0.27223275756835935\t ACC train:  0.9166666666666666\t ACC test:  0.8022222222222222\n",
      "\tEpoch 553: \tAverage Loss:  0.27132794189453124\t ACC train:  0.9333333333333333\t ACC test:  0.7933333333333333\n",
      "\tEpoch 554: \tAverage Loss:  0.27197085571289065\t ACC train:  0.9333333333333333\t ACC test:  0.7866666666666666\n",
      "\tEpoch 555: \tAverage Loss:  0.272002685546875\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 556: \tAverage Loss:  0.2719241638183594\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 557: \tAverage Loss:  0.27103280639648436\t ACC train:  0.9166666666666666\t ACC test:  0.8066666666666666\n",
      "\tEpoch 558: \tAverage Loss:  0.27094479370117186\t ACC train:  0.9166666666666666\t ACC test:  0.8066666666666666\n",
      "\tEpoch 559: \tAverage Loss:  0.27123184204101564\t ACC train:  0.9\t ACC test:  0.8022222222222222\n",
      "\tEpoch 560: \tAverage Loss:  0.27056222534179686\t ACC train:  0.9333333333333333\t ACC test:  0.8022222222222222\n",
      "\tEpoch 561: \tAverage Loss:  0.2708331298828125\t ACC train:  0.9166666666666666\t ACC test:  0.7911111111111111\n",
      "\tEpoch 562: \tAverage Loss:  0.27062881469726563\t ACC train:  0.9166666666666666\t ACC test:  0.7911111111111111\n",
      "\tEpoch 563: \tAverage Loss:  0.2704775695800781\t ACC train:  0.9\t ACC test:  0.7888888888888889\n",
      "\tEpoch 564: \tAverage Loss:  0.2702369384765625\t ACC train:  0.9\t ACC test:  0.8088888888888889\n",
      "\tEpoch 565: \tAverage Loss:  0.2693620300292969\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 566: \tAverage Loss:  0.2704930725097656\t ACC train:  0.9\t ACC test:  0.8\n",
      "\tEpoch 567: \tAverage Loss:  0.27068408203125\t ACC train:  0.9\t ACC test:  0.7888888888888889\n",
      "\tEpoch 568: \tAverage Loss:  0.2696627502441406\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 569: \tAverage Loss:  0.2701445617675781\t ACC train:  0.9166666666666666\t ACC test:  0.7844444444444445\n",
      "\tEpoch 570: \tAverage Loss:  0.2698115234375\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 571: \tAverage Loss:  0.2697430419921875\t ACC train:  0.9333333333333333\t ACC test:  0.7977777777777778\n",
      "\tEpoch 572: \tAverage Loss:  0.2701082153320313\t ACC train:  0.9\t ACC test:  0.7777777777777778\n",
      "\tEpoch 573: \tAverage Loss:  0.268624755859375\t ACC train:  0.9\t ACC test:  0.7933333333333333\n",
      "\tEpoch 574: \tAverage Loss:  0.2691444702148437\t ACC train:  0.9333333333333333\t ACC test:  0.8\n",
      "\tEpoch 575: \tAverage Loss:  0.26916094970703125\t ACC train:  0.9166666666666666\t ACC test:  0.7911111111111111\n",
      "\tEpoch 576: \tAverage Loss:  0.2688358154296875\t ACC train:  0.9\t ACC test:  0.7866666666666666\n",
      "\tEpoch 577: \tAverage Loss:  0.26854425048828123\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 578: \tAverage Loss:  0.2693001708984375\t ACC train:  0.9333333333333333\t ACC test:  0.7933333333333333\n",
      "\tEpoch 579: \tAverage Loss:  0.26874465942382814\t ACC train:  0.9333333333333333\t ACC test:  0.8\n",
      "\tEpoch 580: \tAverage Loss:  0.26903729248046876\t ACC train:  0.9333333333333333\t ACC test:  0.7933333333333333\n",
      "\tEpoch 581: \tAverage Loss:  0.26896841430664065\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 582: \tAverage Loss:  0.26803628540039065\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 583: \tAverage Loss:  0.2685950012207031\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 584: \tAverage Loss:  0.268658203125\t ACC train:  0.9\t ACC test:  0.8\n",
      "\tEpoch 585: \tAverage Loss:  0.268631103515625\t ACC train:  0.9333333333333333\t ACC test:  0.7911111111111111\n",
      "\tEpoch 586: \tAverage Loss:  0.2692161254882813\t ACC train:  0.9166666666666666\t ACC test:  0.7955555555555556\n",
      "\tEpoch 587: \tAverage Loss:  0.26794149780273435\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 588: \tAverage Loss:  0.2688028869628906\t ACC train:  0.9166666666666666\t ACC test:  0.8044444444444444\n",
      "\tEpoch 589: \tAverage Loss:  0.26757064819335935\t ACC train:  0.9\t ACC test:  0.8022222222222222\n",
      "\tEpoch 590: \tAverage Loss:  0.26776007080078124\t ACC train:  0.9166666666666666\t ACC test:  0.8022222222222222\n",
      "\tEpoch 591: \tAverage Loss:  0.26833645629882813\t ACC train:  0.9166666666666666\t ACC test:  0.8\n",
      "\tEpoch 592: \tAverage Loss:  0.26756396484375\t ACC train:  0.9166666666666666\t ACC test:  0.7977777777777778\n",
      "\tEpoch 593: \tAverage Loss:  0.26717724609375\t ACC train:  0.9166666666666666\t ACC test:  0.7822222222222223\n",
      "\tEpoch 594: \tAverage Loss:  0.26755892944335935\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 595: \tAverage Loss:  0.2673033142089844\t ACC train:  0.9166666666666666\t ACC test:  0.7955555555555556\n",
      "\tEpoch 596: \tAverage Loss:  0.267087646484375\t ACC train:  0.9333333333333333\t ACC test:  0.7911111111111111\n",
      "\tEpoch 597: \tAverage Loss:  0.26724240112304687\t ACC train:  0.9\t ACC test:  0.8\n",
      "\tEpoch 598: \tAverage Loss:  0.2668495788574219\t ACC train:  0.9166666666666666\t ACC test:  0.8022222222222222\n",
      "\tEpoch 599: \tAverage Loss:  0.2672031555175781\t ACC train:  0.9166666666666666\t ACC test:  0.8088888888888889\n",
      "\tEpoch 600: \tAverage Loss:  0.26736669921875\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 601: \tAverage Loss:  0.2667644958496094\t ACC train:  0.9166666666666666\t ACC test:  0.7977777777777778\n",
      "\tEpoch 602: \tAverage Loss:  0.2672030029296875\t ACC train:  0.9166666666666666\t ACC test:  0.8022222222222222\n",
      "\tEpoch 603: \tAverage Loss:  0.26736605834960936\t ACC train:  0.9166666666666666\t ACC test:  0.7866666666666666\n",
      "\tEpoch 604: \tAverage Loss:  0.2670823364257813\t ACC train:  0.9333333333333333\t ACC test:  0.7866666666666666\n",
      "\tEpoch 605: \tAverage Loss:  0.26774801635742185\t ACC train:  0.9\t ACC test:  0.7933333333333333\n",
      "\tEpoch 606: \tAverage Loss:  0.26740814208984376\t ACC train:  0.9\t ACC test:  0.7866666666666666\n",
      "\tEpoch 607: \tAverage Loss:  0.2672535705566406\t ACC train:  0.9166666666666666\t ACC test:  0.7977777777777778\n",
      "\tEpoch 608: \tAverage Loss:  0.2667829895019531\t ACC train:  0.9333333333333333\t ACC test:  0.8066666666666666\n",
      "\tEpoch 609: \tAverage Loss:  0.26588369750976565\t ACC train:  0.9\t ACC test:  0.7933333333333333\n",
      "\tEpoch 610: \tAverage Loss:  0.26657656860351564\t ACC train:  0.9333333333333333\t ACC test:  0.7955555555555556\n",
      "\tEpoch 611: \tAverage Loss:  0.2661277160644531\t ACC train:  0.9166666666666666\t ACC test:  0.7888888888888889\n",
      "\tEpoch 612: \tAverage Loss:  0.26682644653320314\t ACC train:  0.9\t ACC test:  0.8022222222222222\n",
      "\tEpoch 613: \tAverage Loss:  0.2668453369140625\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 614: \tAverage Loss:  0.2663287658691406\t ACC train:  0.9166666666666666\t ACC test:  0.78\n",
      "\tEpoch 615: \tAverage Loss:  0.2656513671875\t ACC train:  0.9166666666666666\t ACC test:  0.7977777777777778\n",
      "\tEpoch 616: \tAverage Loss:  0.26558541870117186\t ACC train:  0.9166666666666666\t ACC test:  0.8\n",
      "\tEpoch 617: \tAverage Loss:  0.26714736938476563\t ACC train:  0.9166666666666666\t ACC test:  0.8\n",
      "\tEpoch 618: \tAverage Loss:  0.2660625305175781\t ACC train:  0.9333333333333333\t ACC test:  0.7933333333333333\n",
      "\tEpoch 619: \tAverage Loss:  0.26577191162109376\t ACC train:  0.9166666666666666\t ACC test:  0.7866666666666666\n",
      "\tEpoch 620: \tAverage Loss:  0.2657855224609375\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 621: \tAverage Loss:  0.2653301086425781\t ACC train:  0.9166666666666666\t ACC test:  0.7911111111111111\n",
      "\tEpoch 622: \tAverage Loss:  0.26456005859375\t ACC train:  0.9166666666666666\t ACC test:  0.8022222222222222\n",
      "\tEpoch 623: \tAverage Loss:  0.26527166748046876\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 624: \tAverage Loss:  0.2657152099609375\t ACC train:  0.9166666666666666\t ACC test:  0.8\n",
      "\tEpoch 625: \tAverage Loss:  0.2652271728515625\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 626: \tAverage Loss:  0.2644722595214844\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "\tEpoch 627: \tAverage Loss:  0.264992919921875\t ACC train:  0.9\t ACC test:  0.7911111111111111\n",
      "\tEpoch 628: \tAverage Loss:  0.26555389404296875\t ACC train:  0.9166666666666666\t ACC test:  0.8066666666666666\n",
      "\tEpoch 629: \tAverage Loss:  0.2658301086425781\t ACC train:  0.9166666666666666\t ACC test:  0.7844444444444445\n",
      "\tEpoch 630: \tAverage Loss:  0.2657051696777344\t ACC train:  0.9333333333333333\t ACC test:  0.7844444444444445\n",
      "\tEpoch 631: \tAverage Loss:  0.26488214111328123\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 632: \tAverage Loss:  0.2644194030761719\t ACC train:  0.9166666666666666\t ACC test:  0.7866666666666666\n",
      "\tEpoch 633: \tAverage Loss:  0.26446435546875\t ACC train:  0.9166666666666666\t ACC test:  0.8022222222222222\n",
      "\tEpoch 634: \tAverage Loss:  0.26434796142578126\t ACC train:  0.9166666666666666\t ACC test:  0.7911111111111111\n",
      "\tEpoch 635: \tAverage Loss:  0.26464007568359377\t ACC train:  0.9166666666666666\t ACC test:  0.7888888888888889\n",
      "\tEpoch 636: \tAverage Loss:  0.2645331115722656\t ACC train:  0.9333333333333333\t ACC test:  0.7844444444444445\n",
      "\tEpoch 637: \tAverage Loss:  0.26434988403320314\t ACC train:  0.9\t ACC test:  0.8044444444444444\n",
      "\tEpoch 638: \tAverage Loss:  0.2646031494140625\t ACC train:  0.9166666666666666\t ACC test:  0.8022222222222222\n",
      "\tEpoch 639: \tAverage Loss:  0.2638707580566406\t ACC train:  0.95\t ACC test:  0.8\n",
      "\tEpoch 640: \tAverage Loss:  0.26517031860351564\t ACC train:  0.9\t ACC test:  0.7888888888888889\n",
      "\tEpoch 641: \tAverage Loss:  0.2638319091796875\t ACC train:  0.9166666666666666\t ACC test:  0.7977777777777778\n",
      "\tEpoch 642: \tAverage Loss:  0.26359487915039065\t ACC train:  0.9166666666666666\t ACC test:  0.7933333333333333\n",
      "Stopping early at epoch 642. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 70\n",
      "\tEpoch 1: \tAverage Loss:  0.6863866577148438\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 2: \tAverage Loss:  0.6820177001953125\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 3: \tAverage Loss:  0.678081298828125\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 4: \tAverage Loss:  0.6744014282226563\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 5: \tAverage Loss:  0.6708443603515625\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 6: \tAverage Loss:  0.6678041381835937\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 7: \tAverage Loss:  0.6649816284179687\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 8: \tAverage Loss:  0.6625485229492187\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 9: \tAverage Loss:  0.660267333984375\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 10: \tAverage Loss:  0.6581859130859375\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 11: \tAverage Loss:  0.655995849609375\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 12: \tAverage Loss:  0.6539763793945312\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 13: \tAverage Loss:  0.6522642822265625\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 14: \tAverage Loss:  0.6505582275390625\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 15: \tAverage Loss:  0.6487699584960938\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 16: \tAverage Loss:  0.6471131591796875\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 17: \tAverage Loss:  0.6455399780273438\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 18: \tAverage Loss:  0.6441179809570312\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 19: \tAverage Loss:  0.6427269897460938\t ACC train:  0.44285714285714284\t ACC test:  0.5133333333333333\n",
      "\tEpoch 20: \tAverage Loss:  0.641441162109375\t ACC train:  0.4714285714285714\t ACC test:  0.5222222222222223\n",
      "\tEpoch 21: \tAverage Loss:  0.639916259765625\t ACC train:  0.5571428571428572\t ACC test:  0.5288888888888889\n",
      "\tEpoch 22: \tAverage Loss:  0.6385994873046875\t ACC train:  0.5571428571428572\t ACC test:  0.4822222222222222\n",
      "\tEpoch 23: \tAverage Loss:  0.63731298828125\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  0.6360828857421875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  0.6348972778320312\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  0.633877197265625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  0.6326876831054687\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  0.6315792846679688\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  0.630736572265625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  0.629777587890625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  0.6286263427734375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  0.6277476196289062\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  0.6268444213867187\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  0.6259616088867187\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  0.6250883178710938\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  0.6243240356445312\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  0.6235250854492187\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  0.6227548828125\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  0.6221027221679688\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  0.6212985229492187\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  0.6206369018554687\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  0.6199529418945312\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  0.6193126220703125\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  0.618734619140625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  0.6181729736328125\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  0.6175875244140625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  0.61700244140625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  0.6164777221679687\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  0.6159656372070312\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  0.615397705078125\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  0.6149750366210938\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  0.61442041015625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.61402099609375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  0.613580078125\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  0.6130900268554688\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  0.6127672729492187\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  0.6123357543945313\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  0.6118848266601562\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  0.6115962524414063\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  0.6111078491210937\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  0.6109554443359375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  0.6104178466796875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  0.6102938842773438\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  0.6097199096679687\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  0.609494140625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.60938525390625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  0.608781982421875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  0.6085966796875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  0.608310791015625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  0.6082306518554688\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  0.6079365234375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  0.607525634765625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  0.6071799926757813\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  0.6070667724609375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  0.6068011474609375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  0.6064605102539062\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  0.6065062255859375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  0.6062967529296875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  0.6060465087890625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.6059456176757813\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  0.6055654907226562\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  0.60544482421875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  0.6047384643554687\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 84: \tAverage Loss:  0.604889892578125\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 85: \tAverage Loss:  0.6047249755859375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 86: \tAverage Loss:  0.6047665405273438\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 87: \tAverage Loss:  0.6047774658203126\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 88: \tAverage Loss:  0.6041082153320313\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 89: \tAverage Loss:  0.604365966796875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 90: \tAverage Loss:  0.6038368530273438\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 91: \tAverage Loss:  0.6040189208984375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 92: \tAverage Loss:  0.6036482543945313\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 93: \tAverage Loss:  0.6034495239257812\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 94: \tAverage Loss:  0.6032996215820312\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 95: \tAverage Loss:  0.603258544921875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 96: \tAverage Loss:  0.6029017944335937\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 97: \tAverage Loss:  0.6028416748046875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 98: \tAverage Loss:  0.6022584838867188\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 99: \tAverage Loss:  0.6029854125976563\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 100: \tAverage Loss:  0.6020946655273437\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  0.60229931640625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 102: \tAverage Loss:  0.6017528686523438\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 103: \tAverage Loss:  0.6017207641601563\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 104: \tAverage Loss:  0.6016825561523438\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 105: \tAverage Loss:  0.6017825317382812\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 106: \tAverage Loss:  0.6013372192382812\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 107: \tAverage Loss:  0.601058837890625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 108: \tAverage Loss:  0.6005372314453125\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 109: \tAverage Loss:  0.600996826171875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 110: \tAverage Loss:  0.6007077026367188\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 111: \tAverage Loss:  0.6001171875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 112: \tAverage Loss:  0.5996468505859375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 113: \tAverage Loss:  0.6003096313476562\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 114: \tAverage Loss:  0.6003411254882812\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 115: \tAverage Loss:  0.5986332397460937\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 116: \tAverage Loss:  0.599092041015625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 117: \tAverage Loss:  0.59815673828125\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 118: \tAverage Loss:  0.5979537353515625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 119: \tAverage Loss:  0.5972581787109374\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 120: \tAverage Loss:  0.598156005859375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 121: \tAverage Loss:  0.5998134155273438\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 122: \tAverage Loss:  0.5965845336914063\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 123: \tAverage Loss:  0.5978759765625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 124: \tAverage Loss:  0.596423583984375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 125: \tAverage Loss:  0.596177490234375\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 126: \tAverage Loss:  0.596259521484375\t ACC train:  0.5571428571428572\t ACC test:  0.4888888888888889\n",
      "\tEpoch 127: \tAverage Loss:  0.5950213623046875\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 128: \tAverage Loss:  0.5957996215820313\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 129: \tAverage Loss:  0.596213134765625\t ACC train:  0.5571428571428572\t ACC test:  0.4888888888888889\n",
      "\tEpoch 130: \tAverage Loss:  0.5929112548828125\t ACC train:  0.5571428571428572\t ACC test:  0.49333333333333335\n",
      "\tEpoch 131: \tAverage Loss:  0.5919957275390625\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 132: \tAverage Loss:  0.5925401611328125\t ACC train:  0.5571428571428572\t ACC test:  0.4911111111111111\n",
      "\tEpoch 133: \tAverage Loss:  0.5944940795898438\t ACC train:  0.5571428571428572\t ACC test:  0.4866666666666667\n",
      "\tEpoch 134: \tAverage Loss:  0.5918775024414062\t ACC train:  0.5571428571428572\t ACC test:  0.4955555555555556\n",
      "\tEpoch 135: \tAverage Loss:  0.5921134643554687\t ACC train:  0.5571428571428572\t ACC test:  0.5\n",
      "\tEpoch 136: \tAverage Loss:  0.5885939331054687\t ACC train:  0.5857142857142857\t ACC test:  0.5022222222222222\n",
      "\tEpoch 137: \tAverage Loss:  0.5888214111328125\t ACC train:  0.6\t ACC test:  0.5177777777777778\n",
      "\tEpoch 138: \tAverage Loss:  0.5897828979492188\t ACC train:  0.5857142857142857\t ACC test:  0.5088888888888888\n",
      "\tEpoch 139: \tAverage Loss:  0.589115478515625\t ACC train:  0.6\t ACC test:  0.5222222222222223\n",
      "\tEpoch 140: \tAverage Loss:  0.5869271240234375\t ACC train:  0.6142857142857143\t ACC test:  0.5266666666666666\n",
      "\tEpoch 141: \tAverage Loss:  0.58680126953125\t ACC train:  0.6142857142857143\t ACC test:  0.5422222222222223\n",
      "\tEpoch 142: \tAverage Loss:  0.5861544799804688\t ACC train:  0.6285714285714286\t ACC test:  0.5377777777777778\n",
      "\tEpoch 143: \tAverage Loss:  0.5896685180664063\t ACC train:  0.6285714285714286\t ACC test:  0.5488888888888889\n",
      "\tEpoch 144: \tAverage Loss:  0.5804974975585937\t ACC train:  0.6428571428571429\t ACC test:  0.5755555555555556\n",
      "\tEpoch 145: \tAverage Loss:  0.5819667358398437\t ACC train:  0.6857142857142857\t ACC test:  0.5622222222222222\n",
      "\tEpoch 146: \tAverage Loss:  0.58021044921875\t ACC train:  0.6857142857142857\t ACC test:  0.5711111111111111\n",
      "\tEpoch 147: \tAverage Loss:  0.5776136474609375\t ACC train:  0.6714285714285714\t ACC test:  0.5844444444444444\n",
      "\tEpoch 148: \tAverage Loss:  0.5797747192382813\t ACC train:  0.6714285714285714\t ACC test:  0.5911111111111111\n",
      "\tEpoch 149: \tAverage Loss:  0.5805146484375\t ACC train:  0.7\t ACC test:  0.58\n",
      "\tEpoch 150: \tAverage Loss:  0.576173828125\t ACC train:  0.6857142857142857\t ACC test:  0.5955555555555555\n",
      "\tEpoch 151: \tAverage Loss:  0.570699462890625\t ACC train:  0.6714285714285714\t ACC test:  0.5888888888888889\n",
      "\tEpoch 152: \tAverage Loss:  0.5731898193359375\t ACC train:  0.6571428571428571\t ACC test:  0.6022222222222222\n",
      "\tEpoch 153: \tAverage Loss:  0.5660288696289062\t ACC train:  0.6857142857142857\t ACC test:  0.6044444444444445\n",
      "\tEpoch 154: \tAverage Loss:  0.5668394165039062\t ACC train:  0.6714285714285714\t ACC test:  0.6066666666666667\n",
      "\tEpoch 155: \tAverage Loss:  0.56977734375\t ACC train:  0.6571428571428571\t ACC test:  0.6222222222222222\n",
      "\tEpoch 156: \tAverage Loss:  0.562673095703125\t ACC train:  0.6857142857142857\t ACC test:  0.6088888888888889\n",
      "\tEpoch 157: \tAverage Loss:  0.5654906616210937\t ACC train:  0.6857142857142857\t ACC test:  0.6155555555555555\n",
      "\tEpoch 158: \tAverage Loss:  0.5554575805664063\t ACC train:  0.7\t ACC test:  0.5933333333333334\n",
      "\tEpoch 159: \tAverage Loss:  0.5546337280273438\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 160: \tAverage Loss:  0.5539061279296875\t ACC train:  0.7142857142857143\t ACC test:  0.6111111111111112\n",
      "\tEpoch 161: \tAverage Loss:  0.5523500366210937\t ACC train:  0.7428571428571429\t ACC test:  0.6066666666666667\n",
      "\tEpoch 162: \tAverage Loss:  0.5543101806640625\t ACC train:  0.7142857142857143\t ACC test:  0.6177777777777778\n",
      "\tEpoch 163: \tAverage Loss:  0.543505859375\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 164: \tAverage Loss:  0.5443363647460937\t ACC train:  0.6857142857142857\t ACC test:  0.6288888888888889\n",
      "\tEpoch 165: \tAverage Loss:  0.5475654296875\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 166: \tAverage Loss:  0.540193603515625\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 167: \tAverage Loss:  0.5362717895507813\t ACC train:  0.7142857142857143\t ACC test:  0.6111111111111112\n",
      "\tEpoch 168: \tAverage Loss:  0.5256272583007813\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 169: \tAverage Loss:  0.52752294921875\t ACC train:  0.7142857142857143\t ACC test:  0.6155555555555555\n",
      "\tEpoch 170: \tAverage Loss:  0.5269340209960938\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 171: \tAverage Loss:  0.5238825073242187\t ACC train:  0.7142857142857143\t ACC test:  0.62\n",
      "\tEpoch 172: \tAverage Loss:  0.5206231689453125\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 173: \tAverage Loss:  0.5167413940429687\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 174: \tAverage Loss:  0.5138667602539062\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 175: \tAverage Loss:  0.5134000244140625\t ACC train:  0.7142857142857143\t ACC test:  0.6133333333333333\n",
      "\tEpoch 176: \tAverage Loss:  0.5082367553710937\t ACC train:  0.7142857142857143\t ACC test:  0.6022222222222222\n",
      "\tEpoch 177: \tAverage Loss:  0.5081317749023437\t ACC train:  0.7285714285714285\t ACC test:  0.6155555555555555\n",
      "\tEpoch 178: \tAverage Loss:  0.5078876342773437\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 179: \tAverage Loss:  0.5037590637207031\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 180: \tAverage Loss:  0.5017799682617188\t ACC train:  0.7142857142857143\t ACC test:  0.6022222222222222\n",
      "\tEpoch 181: \tAverage Loss:  0.4981181640625\t ACC train:  0.6857142857142857\t ACC test:  0.6066666666666667\n",
      "\tEpoch 182: \tAverage Loss:  0.49446820068359376\t ACC train:  0.7285714285714285\t ACC test:  0.6066666666666667\n",
      "\tEpoch 183: \tAverage Loss:  0.4958369140625\t ACC train:  0.7285714285714285\t ACC test:  0.6244444444444445\n",
      "\tEpoch 184: \tAverage Loss:  0.48960205078125\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 185: \tAverage Loss:  0.48932403564453125\t ACC train:  0.7142857142857143\t ACC test:  0.6111111111111112\n",
      "\tEpoch 186: \tAverage Loss:  0.4863663330078125\t ACC train:  0.7285714285714285\t ACC test:  0.6222222222222222\n",
      "\tEpoch 187: \tAverage Loss:  0.48323779296875\t ACC train:  0.7428571428571429\t ACC test:  0.6222222222222222\n",
      "\tEpoch 188: \tAverage Loss:  0.48210610961914063\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 189: \tAverage Loss:  0.4776672668457031\t ACC train:  0.7428571428571429\t ACC test:  0.6244444444444445\n",
      "\tEpoch 190: \tAverage Loss:  0.475293212890625\t ACC train:  0.7285714285714285\t ACC test:  0.6222222222222222\n",
      "\tEpoch 191: \tAverage Loss:  0.4750571899414063\t ACC train:  0.7142857142857143\t ACC test:  0.6244444444444445\n",
      "\tEpoch 192: \tAverage Loss:  0.4695940246582031\t ACC train:  0.7285714285714285\t ACC test:  0.6244444444444445\n",
      "\tEpoch 193: \tAverage Loss:  0.4708912963867187\t ACC train:  0.7142857142857143\t ACC test:  0.6244444444444445\n",
      "\tEpoch 194: \tAverage Loss:  0.4655338134765625\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 195: \tAverage Loss:  0.46350515747070314\t ACC train:  0.7285714285714285\t ACC test:  0.6177777777777778\n",
      "\tEpoch 196: \tAverage Loss:  0.4599971008300781\t ACC train:  0.7142857142857143\t ACC test:  0.6266666666666667\n",
      "\tEpoch 197: \tAverage Loss:  0.4611664733886719\t ACC train:  0.7285714285714285\t ACC test:  0.6288888888888889\n",
      "\tEpoch 198: \tAverage Loss:  0.4585223083496094\t ACC train:  0.6857142857142857\t ACC test:  0.6266666666666667\n",
      "\tEpoch 199: \tAverage Loss:  0.45480914306640624\t ACC train:  0.7285714285714285\t ACC test:  0.6266666666666667\n",
      "\tEpoch 200: \tAverage Loss:  0.4555662841796875\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 201: \tAverage Loss:  0.4515169677734375\t ACC train:  0.7142857142857143\t ACC test:  0.6266666666666667\n",
      "\tEpoch 202: \tAverage Loss:  0.44883395385742186\t ACC train:  0.7428571428571429\t ACC test:  0.62\n",
      "\tEpoch 203: \tAverage Loss:  0.4487064514160156\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 204: \tAverage Loss:  0.4454924011230469\t ACC train:  0.7285714285714285\t ACC test:  0.6222222222222222\n",
      "\tEpoch 205: \tAverage Loss:  0.4451898498535156\t ACC train:  0.6857142857142857\t ACC test:  0.6311111111111111\n",
      "\tEpoch 206: \tAverage Loss:  0.43948358154296874\t ACC train:  0.7142857142857143\t ACC test:  0.62\n",
      "\tEpoch 207: \tAverage Loss:  0.44147332763671876\t ACC train:  0.7142857142857143\t ACC test:  0.6311111111111111\n",
      "\tEpoch 208: \tAverage Loss:  0.439090087890625\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 209: \tAverage Loss:  0.43791351318359373\t ACC train:  0.7428571428571429\t ACC test:  0.6155555555555555\n",
      "\tEpoch 210: \tAverage Loss:  0.4343180847167969\t ACC train:  0.7142857142857143\t ACC test:  0.6311111111111111\n",
      "\tEpoch 211: \tAverage Loss:  0.4325762939453125\t ACC train:  0.7142857142857143\t ACC test:  0.6288888888888889\n",
      "\tEpoch 212: \tAverage Loss:  0.43055316162109375\t ACC train:  0.7285714285714285\t ACC test:  0.6177777777777778\n",
      "\tEpoch 213: \tAverage Loss:  0.43170120239257814\t ACC train:  0.7142857142857143\t ACC test:  0.6155555555555555\n",
      "\tEpoch 214: \tAverage Loss:  0.42846438598632813\t ACC train:  0.7428571428571429\t ACC test:  0.6266666666666667\n",
      "\tEpoch 215: \tAverage Loss:  0.4256501770019531\t ACC train:  0.7142857142857143\t ACC test:  0.6244444444444445\n",
      "\tEpoch 216: \tAverage Loss:  0.4244945373535156\t ACC train:  0.7142857142857143\t ACC test:  0.6222222222222222\n",
      "\tEpoch 217: \tAverage Loss:  0.4227314453125\t ACC train:  0.7142857142857143\t ACC test:  0.6288888888888889\n",
      "\tEpoch 218: \tAverage Loss:  0.42126116943359376\t ACC train:  0.7285714285714285\t ACC test:  0.6288888888888889\n",
      "\tEpoch 219: \tAverage Loss:  0.4212455139160156\t ACC train:  0.7285714285714285\t ACC test:  0.6266666666666667\n",
      "\tEpoch 220: \tAverage Loss:  0.4176873474121094\t ACC train:  0.7428571428571429\t ACC test:  0.6222222222222222\n",
      "\tEpoch 221: \tAverage Loss:  0.41794293212890626\t ACC train:  0.7142857142857143\t ACC test:  0.6288888888888889\n",
      "\tEpoch 222: \tAverage Loss:  0.41479681396484375\t ACC train:  0.7285714285714285\t ACC test:  0.6222222222222222\n",
      "\tEpoch 223: \tAverage Loss:  0.413414794921875\t ACC train:  0.7571428571428571\t ACC test:  0.6377777777777778\n",
      "\tEpoch 224: \tAverage Loss:  0.41379244995117187\t ACC train:  0.7285714285714285\t ACC test:  0.6244444444444445\n",
      "\tEpoch 225: \tAverage Loss:  0.41301544189453127\t ACC train:  0.7285714285714285\t ACC test:  0.6222222222222222\n",
      "\tEpoch 226: \tAverage Loss:  0.412935791015625\t ACC train:  0.7428571428571429\t ACC test:  0.6288888888888889\n",
      "\tEpoch 227: \tAverage Loss:  0.40912973022460936\t ACC train:  0.7285714285714285\t ACC test:  0.6355555555555555\n",
      "\tEpoch 228: \tAverage Loss:  0.409477294921875\t ACC train:  0.7428571428571429\t ACC test:  0.62\n",
      "\tEpoch 229: \tAverage Loss:  0.405913330078125\t ACC train:  0.7428571428571429\t ACC test:  0.6333333333333333\n",
      "\tEpoch 230: \tAverage Loss:  0.40475433349609374\t ACC train:  0.7571428571428571\t ACC test:  0.6222222222222222\n",
      "\tEpoch 231: \tAverage Loss:  0.40410494995117185\t ACC train:  0.7285714285714285\t ACC test:  0.6244444444444445\n",
      "\tEpoch 232: \tAverage Loss:  0.4037244873046875\t ACC train:  0.7428571428571429\t ACC test:  0.6311111111111111\n",
      "\tEpoch 233: \tAverage Loss:  0.40152630615234375\t ACC train:  0.7428571428571429\t ACC test:  0.6222222222222222\n",
      "\tEpoch 234: \tAverage Loss:  0.401364013671875\t ACC train:  0.7285714285714285\t ACC test:  0.6333333333333333\n",
      "\tEpoch 235: \tAverage Loss:  0.3989840393066406\t ACC train:  0.7428571428571429\t ACC test:  0.6333333333333333\n",
      "\tEpoch 236: \tAverage Loss:  0.40272915649414065\t ACC train:  0.7428571428571429\t ACC test:  0.6377777777777778\n",
      "\tEpoch 237: \tAverage Loss:  0.3984400634765625\t ACC train:  0.7285714285714285\t ACC test:  0.6177777777777778\n",
      "\tEpoch 238: \tAverage Loss:  0.39654537963867187\t ACC train:  0.7285714285714285\t ACC test:  0.6266666666666667\n",
      "\tEpoch 239: \tAverage Loss:  0.3972711791992187\t ACC train:  0.7571428571428571\t ACC test:  0.6266666666666667\n",
      "\tEpoch 240: \tAverage Loss:  0.3952958984375\t ACC train:  0.7571428571428571\t ACC test:  0.6333333333333333\n",
      "\tEpoch 241: \tAverage Loss:  0.3950052490234375\t ACC train:  0.7428571428571429\t ACC test:  0.6355555555555555\n",
      "\tEpoch 242: \tAverage Loss:  0.3926848449707031\t ACC train:  0.7428571428571429\t ACC test:  0.6222222222222222\n",
      "\tEpoch 243: \tAverage Loss:  0.3914458618164062\t ACC train:  0.7428571428571429\t ACC test:  0.6333333333333333\n",
      "\tEpoch 244: \tAverage Loss:  0.3910306396484375\t ACC train:  0.7428571428571429\t ACC test:  0.62\n",
      "\tEpoch 245: \tAverage Loss:  0.38908148193359376\t ACC train:  0.7142857142857143\t ACC test:  0.6288888888888889\n",
      "\tEpoch 246: \tAverage Loss:  0.388688232421875\t ACC train:  0.7428571428571429\t ACC test:  0.6266666666666667\n",
      "\tEpoch 247: \tAverage Loss:  0.388217529296875\t ACC train:  0.7428571428571429\t ACC test:  0.6311111111111111\n",
      "\tEpoch 248: \tAverage Loss:  0.3875911865234375\t ACC train:  0.7571428571428571\t ACC test:  0.6333333333333333\n",
      "\tEpoch 249: \tAverage Loss:  0.38630804443359373\t ACC train:  0.7285714285714285\t ACC test:  0.6333333333333333\n",
      "\tEpoch 250: \tAverage Loss:  0.3840048522949219\t ACC train:  0.7428571428571429\t ACC test:  0.6333333333333333\n",
      "\tEpoch 251: \tAverage Loss:  0.38472613525390625\t ACC train:  0.7428571428571429\t ACC test:  0.6222222222222222\n",
      "\tEpoch 252: \tAverage Loss:  0.3837616577148438\t ACC train:  0.7428571428571429\t ACC test:  0.6222222222222222\n",
      "\tEpoch 253: \tAverage Loss:  0.38355804443359376\t ACC train:  0.7428571428571429\t ACC test:  0.6244444444444445\n",
      "\tEpoch 254: \tAverage Loss:  0.3812330017089844\t ACC train:  0.7714285714285715\t ACC test:  0.6244444444444445\n",
      "\tEpoch 255: \tAverage Loss:  0.38103594970703125\t ACC train:  0.7428571428571429\t ACC test:  0.6266666666666667\n",
      "\tEpoch 256: \tAverage Loss:  0.3801563720703125\t ACC train:  0.7714285714285715\t ACC test:  0.6311111111111111\n",
      "\tEpoch 257: \tAverage Loss:  0.3798343200683594\t ACC train:  0.7428571428571429\t ACC test:  0.6288888888888889\n",
      "\tEpoch 258: \tAverage Loss:  0.3791994323730469\t ACC train:  0.7714285714285715\t ACC test:  0.6244444444444445\n",
      "\tEpoch 259: \tAverage Loss:  0.3776522521972656\t ACC train:  0.7714285714285715\t ACC test:  0.6311111111111111\n",
      "\tEpoch 260: \tAverage Loss:  0.3774605712890625\t ACC train:  0.7714285714285715\t ACC test:  0.6266666666666667\n",
      "\tEpoch 261: \tAverage Loss:  0.3768050231933594\t ACC train:  0.7571428571428571\t ACC test:  0.6244444444444445\n",
      "\tEpoch 262: \tAverage Loss:  0.3763249206542969\t ACC train:  0.7714285714285715\t ACC test:  0.6266666666666667\n",
      "\tEpoch 263: \tAverage Loss:  0.37482687377929685\t ACC train:  0.7714285714285715\t ACC test:  0.6266666666666667\n",
      "\tEpoch 264: \tAverage Loss:  0.3752843017578125\t ACC train:  0.7571428571428571\t ACC test:  0.6355555555555555\n",
      "\tEpoch 265: \tAverage Loss:  0.3738433837890625\t ACC train:  0.7571428571428571\t ACC test:  0.6311111111111111\n",
      "\tEpoch 266: \tAverage Loss:  0.37313528442382815\t ACC train:  0.7571428571428571\t ACC test:  0.6333333333333333\n",
      "\tEpoch 267: \tAverage Loss:  0.3729651184082031\t ACC train:  0.7714285714285715\t ACC test:  0.6244444444444445\n",
      "\tEpoch 268: \tAverage Loss:  0.3728125305175781\t ACC train:  0.7714285714285715\t ACC test:  0.6311111111111111\n",
      "\tEpoch 269: \tAverage Loss:  0.37347366333007814\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 270: \tAverage Loss:  0.37118231201171875\t ACC train:  0.7714285714285715\t ACC test:  0.6333333333333333\n",
      "\tEpoch 271: \tAverage Loss:  0.3699483947753906\t ACC train:  0.7714285714285715\t ACC test:  0.6333333333333333\n",
      "\tEpoch 272: \tAverage Loss:  0.371210205078125\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 273: \tAverage Loss:  0.36857000732421874\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 274: \tAverage Loss:  0.369\t ACC train:  0.7714285714285715\t ACC test:  0.6377777777777778\n",
      "\tEpoch 275: \tAverage Loss:  0.3682035827636719\t ACC train:  0.7714285714285715\t ACC test:  0.6333333333333333\n",
      "\tEpoch 276: \tAverage Loss:  0.3672679138183594\t ACC train:  0.7714285714285715\t ACC test:  0.6333333333333333\n",
      "\tEpoch 277: \tAverage Loss:  0.36711529541015625\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 278: \tAverage Loss:  0.3657703857421875\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 279: \tAverage Loss:  0.3658056030273438\t ACC train:  0.7714285714285715\t ACC test:  0.6333333333333333\n",
      "\tEpoch 280: \tAverage Loss:  0.36546322631835937\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 281: \tAverage Loss:  0.36417532348632814\t ACC train:  0.7714285714285715\t ACC test:  0.6311111111111111\n",
      "\tEpoch 282: \tAverage Loss:  0.364677734375\t ACC train:  0.7714285714285715\t ACC test:  0.6311111111111111\n",
      "\tEpoch 283: \tAverage Loss:  0.36433761596679687\t ACC train:  0.7714285714285715\t ACC test:  0.6333333333333333\n",
      "\tEpoch 284: \tAverage Loss:  0.36347930908203124\t ACC train:  0.7714285714285715\t ACC test:  0.6288888888888889\n",
      "\tEpoch 285: \tAverage Loss:  0.3632520751953125\t ACC train:  0.7714285714285715\t ACC test:  0.6377777777777778\n",
      "\tEpoch 286: \tAverage Loss:  0.36243194580078125\t ACC train:  0.7714285714285715\t ACC test:  0.6333333333333333\n",
      "\tEpoch 287: \tAverage Loss:  0.362561767578125\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 288: \tAverage Loss:  0.36256655883789063\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 289: \tAverage Loss:  0.3608624572753906\t ACC train:  0.7714285714285715\t ACC test:  0.6377777777777778\n",
      "\tEpoch 290: \tAverage Loss:  0.36090597534179686\t ACC train:  0.7571428571428571\t ACC test:  0.6355555555555555\n",
      "\tEpoch 291: \tAverage Loss:  0.360233642578125\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 292: \tAverage Loss:  0.36109759521484375\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 293: \tAverage Loss:  0.3603955688476562\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 294: \tAverage Loss:  0.35884967041015625\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 295: \tAverage Loss:  0.3594302062988281\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 296: \tAverage Loss:  0.358759521484375\t ACC train:  0.7571428571428571\t ACC test:  0.6377777777777778\n",
      "\tEpoch 297: \tAverage Loss:  0.3592404479980469\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 298: \tAverage Loss:  0.356927978515625\t ACC train:  0.7714285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 299: \tAverage Loss:  0.357437744140625\t ACC train:  0.7714285714285715\t ACC test:  0.6377777777777778\n",
      "\tEpoch 300: \tAverage Loss:  0.3560152587890625\t ACC train:  0.7571428571428571\t ACC test:  0.64\n",
      "\tEpoch 301: \tAverage Loss:  0.35741329956054685\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 302: \tAverage Loss:  0.3562467041015625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 303: \tAverage Loss:  0.35505108642578126\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 304: \tAverage Loss:  0.355410888671875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 305: \tAverage Loss:  0.35525518798828126\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 306: \tAverage Loss:  0.35527093505859375\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 307: \tAverage Loss:  0.35429010009765627\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 308: \tAverage Loss:  0.35414813232421877\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 309: \tAverage Loss:  0.35422833251953123\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 310: \tAverage Loss:  0.35376528930664064\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 311: \tAverage Loss:  0.35280050659179685\t ACC train:  0.7714285714285715\t ACC test:  0.6377777777777778\n",
      "\tEpoch 312: \tAverage Loss:  0.3533331909179688\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 313: \tAverage Loss:  0.35291653442382814\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 314: \tAverage Loss:  0.35264959716796873\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 315: \tAverage Loss:  0.3521732177734375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 316: \tAverage Loss:  0.351449462890625\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 317: \tAverage Loss:  0.352646728515625\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 318: \tAverage Loss:  0.35087713623046873\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 319: \tAverage Loss:  0.35080087280273436\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 320: \tAverage Loss:  0.3510556945800781\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 321: \tAverage Loss:  0.3506004333496094\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 322: \tAverage Loss:  0.3502620849609375\t ACC train:  0.7714285714285715\t ACC test:  0.6377777777777778\n",
      "\tEpoch 323: \tAverage Loss:  0.34976806640625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 324: \tAverage Loss:  0.3498388671875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 325: \tAverage Loss:  0.35002713012695313\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 326: \tAverage Loss:  0.34865158081054687\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 327: \tAverage Loss:  0.34929977416992186\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 328: \tAverage Loss:  0.3484690856933594\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 329: \tAverage Loss:  0.34896804809570314\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 330: \tAverage Loss:  0.3482333984375\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 331: \tAverage Loss:  0.34777447509765624\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 332: \tAverage Loss:  0.34759722900390627\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 333: \tAverage Loss:  0.3473609313964844\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 334: \tAverage Loss:  0.3470452880859375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 335: \tAverage Loss:  0.34782171630859376\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 336: \tAverage Loss:  0.3465609130859375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 337: \tAverage Loss:  0.34656195068359374\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 338: \tAverage Loss:  0.3462439270019531\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 339: \tAverage Loss:  0.34592352294921874\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 340: \tAverage Loss:  0.3458072204589844\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 341: \tAverage Loss:  0.34625070190429685\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 342: \tAverage Loss:  0.34613336181640625\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 343: \tAverage Loss:  0.3453133239746094\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 344: \tAverage Loss:  0.34537713623046873\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 345: \tAverage Loss:  0.3453786315917969\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 346: \tAverage Loss:  0.3449395141601562\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 347: \tAverage Loss:  0.34441552734375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 348: \tAverage Loss:  0.34431207275390624\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 349: \tAverage Loss:  0.3435713806152344\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 350: \tAverage Loss:  0.3442275085449219\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 351: \tAverage Loss:  0.34383746337890625\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 352: \tAverage Loss:  0.3436132507324219\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 353: \tAverage Loss:  0.34366583251953126\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 354: \tAverage Loss:  0.3433314208984375\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 355: \tAverage Loss:  0.3430966491699219\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 356: \tAverage Loss:  0.3427419738769531\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 357: \tAverage Loss:  0.34306744384765625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 358: \tAverage Loss:  0.343333984375\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 359: \tAverage Loss:  0.3426499938964844\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 360: \tAverage Loss:  0.3425433044433594\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 361: \tAverage Loss:  0.34300341796875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 362: \tAverage Loss:  0.3418492126464844\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 363: \tAverage Loss:  0.3422334899902344\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 364: \tAverage Loss:  0.3423299255371094\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 365: \tAverage Loss:  0.34184329223632814\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 366: \tAverage Loss:  0.34173226928710937\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 367: \tAverage Loss:  0.34140008544921874\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 368: \tAverage Loss:  0.3409020080566406\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 369: \tAverage Loss:  0.3412095336914063\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 370: \tAverage Loss:  0.3418517761230469\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 371: \tAverage Loss:  0.3410524597167969\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 372: \tAverage Loss:  0.3419000549316406\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 373: \tAverage Loss:  0.34078713989257814\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 374: \tAverage Loss:  0.3409427490234375\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 375: \tAverage Loss:  0.3403314514160156\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 376: \tAverage Loss:  0.33982229614257814\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 377: \tAverage Loss:  0.34052484130859373\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 378: \tAverage Loss:  0.34010931396484373\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 379: \tAverage Loss:  0.3400085754394531\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 380: \tAverage Loss:  0.3404720764160156\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 381: \tAverage Loss:  0.34028585815429685\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 382: \tAverage Loss:  0.3394715576171875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 383: \tAverage Loss:  0.339392822265625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 384: \tAverage Loss:  0.33950311279296874\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 385: \tAverage Loss:  0.33947952270507814\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 386: \tAverage Loss:  0.3388752746582031\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 387: \tAverage Loss:  0.33892782592773435\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 388: \tAverage Loss:  0.33836294555664065\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 389: \tAverage Loss:  0.3390559387207031\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 390: \tAverage Loss:  0.338828369140625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 391: \tAverage Loss:  0.3389750061035156\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 392: \tAverage Loss:  0.3382764892578125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 393: \tAverage Loss:  0.33856155395507814\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 394: \tAverage Loss:  0.33856307983398437\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 395: \tAverage Loss:  0.33812103271484373\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 396: \tAverage Loss:  0.3381744384765625\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 397: \tAverage Loss:  0.3382529602050781\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 398: \tAverage Loss:  0.3380185241699219\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 399: \tAverage Loss:  0.33858126831054686\t ACC train:  0.7714285714285715\t ACC test:  0.6511111111111111\n",
      "\tEpoch 400: \tAverage Loss:  0.3376828308105469\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 401: \tAverage Loss:  0.337909912109375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 402: \tAverage Loss:  0.33763531494140625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 403: \tAverage Loss:  0.3373683776855469\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 404: \tAverage Loss:  0.33717474365234373\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 405: \tAverage Loss:  0.33701251220703127\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 406: \tAverage Loss:  0.33759478759765627\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 407: \tAverage Loss:  0.33729904174804687\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 408: \tAverage Loss:  0.337636474609375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 409: \tAverage Loss:  0.3366392517089844\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 410: \tAverage Loss:  0.33718051147460937\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 411: \tAverage Loss:  0.3373896484375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 412: \tAverage Loss:  0.3368553466796875\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 413: \tAverage Loss:  0.33670703125\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 414: \tAverage Loss:  0.3366809692382812\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 415: \tAverage Loss:  0.33623333740234373\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 416: \tAverage Loss:  0.3363793334960937\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 417: \tAverage Loss:  0.33627215576171876\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 418: \tAverage Loss:  0.3359073486328125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 419: \tAverage Loss:  0.33563006591796873\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 420: \tAverage Loss:  0.33659814453125\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 421: \tAverage Loss:  0.33582565307617185\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 422: \tAverage Loss:  0.3354378662109375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 423: \tAverage Loss:  0.3357770690917969\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 424: \tAverage Loss:  0.33580148315429686\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 425: \tAverage Loss:  0.33506179809570313\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 426: \tAverage Loss:  0.3354761047363281\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 427: \tAverage Loss:  0.33520733642578127\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 428: \tAverage Loss:  0.3348357543945312\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 429: \tAverage Loss:  0.3349307861328125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 430: \tAverage Loss:  0.334739501953125\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 431: \tAverage Loss:  0.33471051025390625\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 432: \tAverage Loss:  0.3346708984375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 433: \tAverage Loss:  0.33448028564453125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 434: \tAverage Loss:  0.33522052001953123\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 435: \tAverage Loss:  0.3351703491210937\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 436: \tAverage Loss:  0.3351602478027344\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 437: \tAverage Loss:  0.33453668212890625\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 438: \tAverage Loss:  0.334314208984375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 439: \tAverage Loss:  0.33405975341796873\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 440: \tAverage Loss:  0.3341245727539062\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 441: \tAverage Loss:  0.33406399536132814\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 442: \tAverage Loss:  0.33472686767578125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 443: \tAverage Loss:  0.33438711547851563\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 444: \tAverage Loss:  0.33447418212890623\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 445: \tAverage Loss:  0.3341886291503906\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 446: \tAverage Loss:  0.333368408203125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 447: \tAverage Loss:  0.334015869140625\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 448: \tAverage Loss:  0.333568359375\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 449: \tAverage Loss:  0.33419161987304685\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 450: \tAverage Loss:  0.33370193481445315\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 451: \tAverage Loss:  0.3333509521484375\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 452: \tAverage Loss:  0.33314224243164064\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 453: \tAverage Loss:  0.3337537841796875\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 454: \tAverage Loss:  0.3334320373535156\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 455: \tAverage Loss:  0.3342827453613281\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 456: \tAverage Loss:  0.3336809692382813\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 457: \tAverage Loss:  0.33318634033203126\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 458: \tAverage Loss:  0.3328970947265625\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 459: \tAverage Loss:  0.3325503234863281\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 460: \tAverage Loss:  0.3326096496582031\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 461: \tAverage Loss:  0.3330982666015625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 462: \tAverage Loss:  0.3329777221679687\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 463: \tAverage Loss:  0.33264837646484374\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 464: \tAverage Loss:  0.33288104248046874\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 465: \tAverage Loss:  0.3324033203125\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 466: \tAverage Loss:  0.33258480834960935\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 467: \tAverage Loss:  0.3321056213378906\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 468: \tAverage Loss:  0.3322996826171875\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 469: \tAverage Loss:  0.3323170471191406\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 470: \tAverage Loss:  0.33206332397460936\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 471: \tAverage Loss:  0.3319033508300781\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 472: \tAverage Loss:  0.33213674926757814\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 473: \tAverage Loss:  0.33177206420898436\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 474: \tAverage Loss:  0.3321163940429688\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 475: \tAverage Loss:  0.3314909362792969\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 476: \tAverage Loss:  0.33188595581054686\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 477: \tAverage Loss:  0.33209939575195313\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 478: \tAverage Loss:  0.33195535278320315\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 479: \tAverage Loss:  0.33155111694335937\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 480: \tAverage Loss:  0.3313965148925781\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 481: \tAverage Loss:  0.33119515991210935\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 482: \tAverage Loss:  0.33139926147460935\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 483: \tAverage Loss:  0.33149276733398436\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 484: \tAverage Loss:  0.33093212890625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 485: \tAverage Loss:  0.3318567504882812\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 486: \tAverage Loss:  0.33187490844726564\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 487: \tAverage Loss:  0.33122500610351563\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 488: \tAverage Loss:  0.33166668701171875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 489: \tAverage Loss:  0.3312133483886719\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 490: \tAverage Loss:  0.3313779907226562\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 491: \tAverage Loss:  0.3310766906738281\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 492: \tAverage Loss:  0.33103076171875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 493: \tAverage Loss:  0.33096951293945315\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 494: \tAverage Loss:  0.3304199523925781\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 495: \tAverage Loss:  0.3303260803222656\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 496: \tAverage Loss:  0.3307117614746094\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 497: \tAverage Loss:  0.330779052734375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 498: \tAverage Loss:  0.3308299560546875\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 499: \tAverage Loss:  0.33067300415039064\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 500: \tAverage Loss:  0.3304634704589844\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 501: \tAverage Loss:  0.3302254943847656\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 502: \tAverage Loss:  0.3300589904785156\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 503: \tAverage Loss:  0.33062789916992186\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 504: \tAverage Loss:  0.3303920593261719\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 505: \tAverage Loss:  0.33090676879882813\t ACC train:  0.7714285714285715\t ACC test:  0.6511111111111111\n",
      "\tEpoch 506: \tAverage Loss:  0.33000750732421874\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 507: \tAverage Loss:  0.3300428161621094\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 508: \tAverage Loss:  0.3302653503417969\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 509: \tAverage Loss:  0.329662353515625\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 510: \tAverage Loss:  0.3300679321289062\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 511: \tAverage Loss:  0.33014892578125\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 512: \tAverage Loss:  0.3300457763671875\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 513: \tAverage Loss:  0.3297580261230469\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 514: \tAverage Loss:  0.33001507568359373\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 515: \tAverage Loss:  0.3300758361816406\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 516: \tAverage Loss:  0.33011309814453127\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 517: \tAverage Loss:  0.32977114868164065\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 518: \tAverage Loss:  0.32961788940429687\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 519: \tAverage Loss:  0.32932376098632815\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 520: \tAverage Loss:  0.32919451904296876\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 521: \tAverage Loss:  0.3289598693847656\t ACC train:  0.7714285714285715\t ACC test:  0.6511111111111111\n",
      "\tEpoch 522: \tAverage Loss:  0.3292353515625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 523: \tAverage Loss:  0.3292136840820313\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 524: \tAverage Loss:  0.3295757751464844\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 525: \tAverage Loss:  0.328897216796875\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 526: \tAverage Loss:  0.32927618408203124\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 527: \tAverage Loss:  0.32884127807617186\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 528: \tAverage Loss:  0.329291259765625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 529: \tAverage Loss:  0.32883135986328127\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 530: \tAverage Loss:  0.3290926513671875\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 531: \tAverage Loss:  0.32895123291015627\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 532: \tAverage Loss:  0.32878335571289063\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 533: \tAverage Loss:  0.3283377990722656\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 534: \tAverage Loss:  0.328284912109375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 535: \tAverage Loss:  0.3281533203125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 536: \tAverage Loss:  0.3290621032714844\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 537: \tAverage Loss:  0.3287189025878906\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 538: \tAverage Loss:  0.32820245361328126\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 539: \tAverage Loss:  0.3286527099609375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 540: \tAverage Loss:  0.328908935546875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 541: \tAverage Loss:  0.3285040283203125\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 542: \tAverage Loss:  0.32826034545898436\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 543: \tAverage Loss:  0.32792181396484377\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 544: \tAverage Loss:  0.3284338073730469\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 545: \tAverage Loss:  0.3284882507324219\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 546: \tAverage Loss:  0.3281199340820313\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 547: \tAverage Loss:  0.32775674438476565\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 548: \tAverage Loss:  0.3279682006835937\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 549: \tAverage Loss:  0.3279798583984375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 550: \tAverage Loss:  0.32759368896484375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 551: \tAverage Loss:  0.32778359985351563\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 552: \tAverage Loss:  0.32738796997070313\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 553: \tAverage Loss:  0.3277093200683594\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 554: \tAverage Loss:  0.3278255615234375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 555: \tAverage Loss:  0.32723419189453123\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 556: \tAverage Loss:  0.3276299743652344\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 557: \tAverage Loss:  0.32766476440429687\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 558: \tAverage Loss:  0.3276010437011719\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 559: \tAverage Loss:  0.3272294921875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 560: \tAverage Loss:  0.327603271484375\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 561: \tAverage Loss:  0.3278966369628906\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 562: \tAverage Loss:  0.32743646240234375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 563: \tAverage Loss:  0.32724642944335935\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 564: \tAverage Loss:  0.3272664489746094\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 565: \tAverage Loss:  0.3272360229492188\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 566: \tAverage Loss:  0.3274517822265625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 567: \tAverage Loss:  0.3276087341308594\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 568: \tAverage Loss:  0.3275838623046875\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 569: \tAverage Loss:  0.3273968811035156\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 570: \tAverage Loss:  0.3272821350097656\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 571: \tAverage Loss:  0.327057373046875\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 572: \tAverage Loss:  0.32775091552734376\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 573: \tAverage Loss:  0.32698922729492186\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 574: \tAverage Loss:  0.3269468688964844\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 575: \tAverage Loss:  0.3267801208496094\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 576: \tAverage Loss:  0.32674383544921876\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 577: \tAverage Loss:  0.3264820556640625\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 578: \tAverage Loss:  0.32710885620117186\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 579: \tAverage Loss:  0.32664865112304686\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 580: \tAverage Loss:  0.32703701782226563\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 581: \tAverage Loss:  0.32642437744140623\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 582: \tAverage Loss:  0.3267232971191406\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 583: \tAverage Loss:  0.32675390625\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 584: \tAverage Loss:  0.3263955383300781\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 585: \tAverage Loss:  0.32650262451171874\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 586: \tAverage Loss:  0.32654296875\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 587: \tAverage Loss:  0.32668002319335937\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 588: \tAverage Loss:  0.3257835693359375\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 589: \tAverage Loss:  0.32659912109375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 590: \tAverage Loss:  0.32571044921875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 591: \tAverage Loss:  0.3264025268554688\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 592: \tAverage Loss:  0.3259501953125\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 593: \tAverage Loss:  0.3262872924804687\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 594: \tAverage Loss:  0.32589321899414064\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 595: \tAverage Loss:  0.32608282470703126\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 596: \tAverage Loss:  0.32607769775390627\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 597: \tAverage Loss:  0.32655465698242186\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 598: \tAverage Loss:  0.32623751831054687\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 599: \tAverage Loss:  0.3256901550292969\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 600: \tAverage Loss:  0.3263864440917969\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 601: \tAverage Loss:  0.32598208618164065\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 602: \tAverage Loss:  0.3257265625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 603: \tAverage Loss:  0.3260191955566406\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 604: \tAverage Loss:  0.3258011474609375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 605: \tAverage Loss:  0.3258984375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 606: \tAverage Loss:  0.3258978271484375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 607: \tAverage Loss:  0.32545611572265626\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 608: \tAverage Loss:  0.32595223999023437\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 609: \tAverage Loss:  0.325793212890625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 610: \tAverage Loss:  0.3255130310058594\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 611: \tAverage Loss:  0.3251456298828125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 612: \tAverage Loss:  0.32558013916015627\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 613: \tAverage Loss:  0.32565631103515624\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 614: \tAverage Loss:  0.3258040466308594\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 615: \tAverage Loss:  0.3253131713867187\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 616: \tAverage Loss:  0.32522723388671876\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 617: \tAverage Loss:  0.32543890380859375\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 618: \tAverage Loss:  0.32509799194335937\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 619: \tAverage Loss:  0.3248519287109375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 620: \tAverage Loss:  0.32548773193359376\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 621: \tAverage Loss:  0.3253868408203125\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 622: \tAverage Loss:  0.3253869323730469\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 623: \tAverage Loss:  0.32479855346679687\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 624: \tAverage Loss:  0.32504843139648437\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 625: \tAverage Loss:  0.32504486083984374\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 626: \tAverage Loss:  0.32512832641601563\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 627: \tAverage Loss:  0.32496603393554685\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 628: \tAverage Loss:  0.3248761291503906\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 629: \tAverage Loss:  0.3251314697265625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 630: \tAverage Loss:  0.32489813232421877\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 631: \tAverage Loss:  0.32484454345703123\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 632: \tAverage Loss:  0.32507244873046875\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 633: \tAverage Loss:  0.3247979736328125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 634: \tAverage Loss:  0.3251406860351562\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 635: \tAverage Loss:  0.32451528930664064\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 636: \tAverage Loss:  0.3246728515625\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 637: \tAverage Loss:  0.32493991088867186\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 638: \tAverage Loss:  0.32466195678710935\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 639: \tAverage Loss:  0.32458001708984374\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 640: \tAverage Loss:  0.3245256042480469\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 641: \tAverage Loss:  0.3244654235839844\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 642: \tAverage Loss:  0.3246300048828125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 643: \tAverage Loss:  0.3241932373046875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 644: \tAverage Loss:  0.3242882995605469\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 645: \tAverage Loss:  0.32465472412109375\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 646: \tAverage Loss:  0.32463363647460936\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 647: \tAverage Loss:  0.3244014892578125\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 648: \tAverage Loss:  0.3240912780761719\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 649: \tAverage Loss:  0.3243231201171875\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 650: \tAverage Loss:  0.3234749755859375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 651: \tAverage Loss:  0.3243138427734375\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 652: \tAverage Loss:  0.3241845703125\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 653: \tAverage Loss:  0.3237608642578125\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 654: \tAverage Loss:  0.32414105224609374\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 655: \tAverage Loss:  0.32368228149414063\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 656: \tAverage Loss:  0.3237803955078125\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 657: \tAverage Loss:  0.3240903625488281\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 658: \tAverage Loss:  0.323891845703125\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 659: \tAverage Loss:  0.3239554443359375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 660: \tAverage Loss:  0.3241784362792969\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 661: \tAverage Loss:  0.3243148193359375\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 662: \tAverage Loss:  0.3237805480957031\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 663: \tAverage Loss:  0.3238541259765625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 664: \tAverage Loss:  0.32404562377929685\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 665: \tAverage Loss:  0.32374771118164064\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 666: \tAverage Loss:  0.3233650207519531\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 667: \tAverage Loss:  0.3237156372070312\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 668: \tAverage Loss:  0.323635009765625\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 669: \tAverage Loss:  0.3237699890136719\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 670: \tAverage Loss:  0.32392730712890627\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 671: \tAverage Loss:  0.3231620178222656\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 672: \tAverage Loss:  0.32318801879882814\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 673: \tAverage Loss:  0.323534912109375\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 674: \tAverage Loss:  0.3229205322265625\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 675: \tAverage Loss:  0.3235490417480469\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 676: \tAverage Loss:  0.32311395263671877\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 677: \tAverage Loss:  0.3236717834472656\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 678: \tAverage Loss:  0.3233258056640625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 679: \tAverage Loss:  0.3233091125488281\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 680: \tAverage Loss:  0.32360833740234374\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 681: \tAverage Loss:  0.3233049011230469\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 682: \tAverage Loss:  0.32364688110351564\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 683: \tAverage Loss:  0.32310617065429686\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 684: \tAverage Loss:  0.32358135986328124\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 685: \tAverage Loss:  0.3228722839355469\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 686: \tAverage Loss:  0.3232061767578125\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 687: \tAverage Loss:  0.3230870056152344\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 688: \tAverage Loss:  0.3235968322753906\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 689: \tAverage Loss:  0.322928955078125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 690: \tAverage Loss:  0.32284347534179686\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 691: \tAverage Loss:  0.3226810607910156\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 692: \tAverage Loss:  0.3225461730957031\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 693: \tAverage Loss:  0.32303424072265624\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 694: \tAverage Loss:  0.32268270874023436\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 695: \tAverage Loss:  0.32218600463867186\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 696: \tAverage Loss:  0.32260150146484373\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 697: \tAverage Loss:  0.3226767578125\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 698: \tAverage Loss:  0.32238522338867187\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 699: \tAverage Loss:  0.32282485961914065\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 700: \tAverage Loss:  0.32202276611328123\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 701: \tAverage Loss:  0.32225234985351564\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 702: \tAverage Loss:  0.32268701171875\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 703: \tAverage Loss:  0.3229530029296875\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 704: \tAverage Loss:  0.322656494140625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 705: \tAverage Loss:  0.322348388671875\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 706: \tAverage Loss:  0.32195004272460936\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 707: \tAverage Loss:  0.3220433959960938\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 708: \tAverage Loss:  0.3226317443847656\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 709: \tAverage Loss:  0.32236541748046876\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 710: \tAverage Loss:  0.32261334228515626\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 711: \tAverage Loss:  0.32195953369140623\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 712: \tAverage Loss:  0.32241616821289065\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 713: \tAverage Loss:  0.32254318237304686\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 714: \tAverage Loss:  0.32202349853515627\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 715: \tAverage Loss:  0.3217816162109375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 716: \tAverage Loss:  0.3219696350097656\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 717: \tAverage Loss:  0.32210650634765625\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 718: \tAverage Loss:  0.3217371520996094\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 719: \tAverage Loss:  0.32139886474609375\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 720: \tAverage Loss:  0.32220379638671875\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 721: \tAverage Loss:  0.3223154296875\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 722: \tAverage Loss:  0.32173834228515624\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 723: \tAverage Loss:  0.32186911010742186\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 724: \tAverage Loss:  0.32237054443359375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 725: \tAverage Loss:  0.3211839599609375\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 726: \tAverage Loss:  0.32111334228515626\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 727: \tAverage Loss:  0.322234375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 728: \tAverage Loss:  0.32160000610351563\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 729: \tAverage Loss:  0.3217126159667969\t ACC train:  0.7714285714285715\t ACC test:  0.6511111111111111\n",
      "\tEpoch 730: \tAverage Loss:  0.3212976684570312\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 731: \tAverage Loss:  0.3218648376464844\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 732: \tAverage Loss:  0.32148983764648437\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 733: \tAverage Loss:  0.32128961181640625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 734: \tAverage Loss:  0.3211319885253906\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 735: \tAverage Loss:  0.3218341674804687\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 736: \tAverage Loss:  0.32111090087890626\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 737: \tAverage Loss:  0.3212796325683594\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 738: \tAverage Loss:  0.3212318115234375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 739: \tAverage Loss:  0.3214222412109375\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 740: \tAverage Loss:  0.3208366088867188\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 741: \tAverage Loss:  0.32200973510742187\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 742: \tAverage Loss:  0.3212839965820313\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 743: \tAverage Loss:  0.3208048095703125\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 744: \tAverage Loss:  0.3208016357421875\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 745: \tAverage Loss:  0.3208495788574219\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 746: \tAverage Loss:  0.3211558532714844\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 747: \tAverage Loss:  0.32087173461914065\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 748: \tAverage Loss:  0.32086117553710936\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 749: \tAverage Loss:  0.3214433288574219\t ACC train:  0.7714285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 750: \tAverage Loss:  0.3208841552734375\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 751: \tAverage Loss:  0.3207196044921875\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 752: \tAverage Loss:  0.3213132629394531\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 753: \tAverage Loss:  0.3214443359375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 754: \tAverage Loss:  0.321409423828125\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 755: \tAverage Loss:  0.32146823120117185\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 756: \tAverage Loss:  0.3209134521484375\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 757: \tAverage Loss:  0.32131289672851565\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 758: \tAverage Loss:  0.32031851196289063\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 759: \tAverage Loss:  0.3205536193847656\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 760: \tAverage Loss:  0.32046884155273436\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 761: \tAverage Loss:  0.32042132568359377\t ACC train:  0.7714285714285715\t ACC test:  0.64\n",
      "\tEpoch 762: \tAverage Loss:  0.3212476501464844\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 763: \tAverage Loss:  0.3203225402832031\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 764: \tAverage Loss:  0.3207606506347656\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 765: \tAverage Loss:  0.3204684753417969\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 766: \tAverage Loss:  0.32029583740234374\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 767: \tAverage Loss:  0.32028369140625\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 768: \tAverage Loss:  0.32038604736328125\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 769: \tAverage Loss:  0.32065631103515624\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 770: \tAverage Loss:  0.31989566040039064\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 771: \tAverage Loss:  0.3204450988769531\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 772: \tAverage Loss:  0.3205626220703125\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 773: \tAverage Loss:  0.3198287658691406\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 774: \tAverage Loss:  0.32066720581054686\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 775: \tAverage Loss:  0.3200888671875\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 776: \tAverage Loss:  0.320055419921875\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 777: \tAverage Loss:  0.32062515258789065\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 778: \tAverage Loss:  0.32069866943359376\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 779: \tAverage Loss:  0.3204082641601563\t ACC train:  0.7714285714285715\t ACC test:  0.6444444444444445\n",
      "\tEpoch 780: \tAverage Loss:  0.32025302124023436\t ACC train:  0.7714285714285715\t ACC test:  0.6488888888888888\n",
      "\tEpoch 781: \tAverage Loss:  0.3202002868652344\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 782: \tAverage Loss:  0.3200702209472656\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 783: \tAverage Loss:  0.31980325317382813\t ACC train:  0.7714285714285715\t ACC test:  0.6466666666666666\n",
      "Stopping early at epoch 783. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 80\n",
      "\tEpoch 1: \tAverage Loss:  0.8156689453125\t ACC train:  0.3875\t ACC test:  0.4822222222222222\n",
      "\tEpoch 2: \tAverage Loss:  0.8128115234375\t ACC train:  0.5625\t ACC test:  0.5266666666666666\n",
      "\tEpoch 3: \tAverage Loss:  0.8102301635742187\t ACC train:  0.45\t ACC test:  0.4866666666666667\n",
      "\tEpoch 4: \tAverage Loss:  0.806939208984375\t ACC train:  0.6\t ACC test:  0.48\n",
      "\tEpoch 5: \tAverage Loss:  0.803627685546875\t ACC train:  0.5125\t ACC test:  0.5044444444444445\n",
      "\tEpoch 6: \tAverage Loss:  0.8016819458007812\t ACC train:  0.4\t ACC test:  0.4911111111111111\n",
      "\tEpoch 7: \tAverage Loss:  0.7975506591796875\t ACC train:  0.575\t ACC test:  0.5355555555555556\n",
      "\tEpoch 8: \tAverage Loss:  0.794583984375\t ACC train:  0.55\t ACC test:  0.44666666666666666\n",
      "\tEpoch 9: \tAverage Loss:  0.7924818725585937\t ACC train:  0.5375\t ACC test:  0.4888888888888889\n",
      "\tEpoch 10: \tAverage Loss:  0.7887140502929687\t ACC train:  0.575\t ACC test:  0.4688888888888889\n",
      "\tEpoch 11: \tAverage Loss:  0.7868139038085937\t ACC train:  0.55\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  0.7842464599609374\t ACC train:  0.5625\t ACC test:  0.4822222222222222\n",
      "\tEpoch 13: \tAverage Loss:  0.7806136474609375\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  0.7780553588867187\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  0.77359423828125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  0.7722028198242188\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  0.7679105834960938\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  0.7671956787109375\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  0.7633048706054687\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  0.7611970825195312\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  0.7587023315429687\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  0.7563930053710938\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  0.75428076171875\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  0.7522119750976562\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  0.7496538696289062\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  0.7476600341796875\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  0.7450132446289063\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  0.74330712890625\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  0.7403352661132813\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  0.7389252319335937\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  0.7362329711914063\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  0.7341334838867187\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  0.7324013061523438\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  0.7310265502929687\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  0.7286466064453125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  0.7275845336914063\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  0.7249266357421875\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  0.722697509765625\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  0.7218432006835938\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  0.7203494262695312\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  0.7180358276367188\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  0.7175249633789063\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  0.7150367431640625\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  0.714455322265625\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  0.7121464233398438\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  0.7110745849609375\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  0.7101788330078125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  0.7081384887695312\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  0.7094931030273437\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  0.7075175170898438\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  0.7059968872070312\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  0.7027922973632813\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.701233642578125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  0.7020839233398437\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  0.70001171875\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  0.6998911743164062\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  0.6973173828125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  0.6983575439453125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  0.6945665893554688\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  0.6917492065429688\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  0.6939556884765625\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  0.6903876342773437\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  0.69050732421875\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  0.6921934814453125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  0.6886239624023438\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.6890697021484375\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  0.6862158813476562\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  0.6870213012695312\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  0.6832147216796876\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  0.6846318969726563\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  0.6796036376953125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  0.6817685546875\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  0.6825698852539063\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  0.67681396484375\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  0.675620849609375\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  0.6741254272460937\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  0.674162109375\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  0.6705750732421875\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  0.6682266235351563\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.6697755126953125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  0.671259765625\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  0.6610222778320313\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  0.6687813720703125\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 84: \tAverage Loss:  0.6610392456054688\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 85: \tAverage Loss:  0.6613336791992187\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 86: \tAverage Loss:  0.6599459228515625\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 87: \tAverage Loss:  0.6551165161132813\t ACC train:  0.5625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 88: \tAverage Loss:  0.6607361450195313\t ACC train:  0.5625\t ACC test:  0.5\n",
      "\tEpoch 89: \tAverage Loss:  0.6544432373046875\t ACC train:  0.5625\t ACC test:  0.49777777777777776\n",
      "\tEpoch 90: \tAverage Loss:  0.65280859375\t ACC train:  0.5625\t ACC test:  0.4955555555555556\n",
      "\tEpoch 91: \tAverage Loss:  0.6501184692382812\t ACC train:  0.5875\t ACC test:  0.5088888888888888\n",
      "\tEpoch 92: \tAverage Loss:  0.6379918212890625\t ACC train:  0.5875\t ACC test:  0.5044444444444445\n",
      "\tEpoch 93: \tAverage Loss:  0.6434126586914063\t ACC train:  0.6125\t ACC test:  0.5244444444444445\n",
      "\tEpoch 94: \tAverage Loss:  0.6374262084960938\t ACC train:  0.5875\t ACC test:  0.5222222222222223\n",
      "\tEpoch 95: \tAverage Loss:  0.6344855346679688\t ACC train:  0.625\t ACC test:  0.5444444444444444\n",
      "\tEpoch 96: \tAverage Loss:  0.6372144165039062\t ACC train:  0.625\t ACC test:  0.5577777777777778\n",
      "\tEpoch 97: \tAverage Loss:  0.6297139892578125\t ACC train:  0.6375\t ACC test:  0.5555555555555556\n",
      "\tEpoch 98: \tAverage Loss:  0.6248236694335938\t ACC train:  0.65\t ACC test:  0.5733333333333334\n",
      "\tEpoch 99: \tAverage Loss:  0.6277073974609375\t ACC train:  0.675\t ACC test:  0.5688888888888889\n",
      "\tEpoch 100: \tAverage Loss:  0.6098766479492187\t ACC train:  0.675\t ACC test:  0.5755555555555556\n",
      "\tEpoch 101: \tAverage Loss:  0.6098397216796875\t ACC train:  0.675\t ACC test:  0.5844444444444444\n",
      "\tEpoch 102: \tAverage Loss:  0.619577880859375\t ACC train:  0.675\t ACC test:  0.5911111111111111\n",
      "\tEpoch 103: \tAverage Loss:  0.60355419921875\t ACC train:  0.7\t ACC test:  0.5866666666666667\n",
      "\tEpoch 104: \tAverage Loss:  0.6062826538085937\t ACC train:  0.7125\t ACC test:  0.5955555555555555\n",
      "\tEpoch 105: \tAverage Loss:  0.6134912109375\t ACC train:  0.7375\t ACC test:  0.6155555555555555\n",
      "\tEpoch 106: \tAverage Loss:  0.6026243286132813\t ACC train:  0.7125\t ACC test:  0.6\n",
      "\tEpoch 107: \tAverage Loss:  0.5970595703125\t ACC train:  0.6625\t ACC test:  0.6111111111111112\n",
      "\tEpoch 108: \tAverage Loss:  0.5950827026367187\t ACC train:  0.7\t ACC test:  0.6022222222222222\n",
      "\tEpoch 109: \tAverage Loss:  0.5954174194335937\t ACC train:  0.7125\t ACC test:  0.6066666666666667\n",
      "\tEpoch 110: \tAverage Loss:  0.5905279541015624\t ACC train:  0.675\t ACC test:  0.6133333333333333\n",
      "\tEpoch 111: \tAverage Loss:  0.587399658203125\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 112: \tAverage Loss:  0.5807604370117188\t ACC train:  0.6875\t ACC test:  0.6177777777777778\n",
      "\tEpoch 113: \tAverage Loss:  0.5830684814453125\t ACC train:  0.7125\t ACC test:  0.5977777777777777\n",
      "\tEpoch 114: \tAverage Loss:  0.5692320556640625\t ACC train:  0.6875\t ACC test:  0.6244444444444445\n",
      "\tEpoch 115: \tAverage Loss:  0.5646944580078125\t ACC train:  0.6375\t ACC test:  0.6044444444444445\n",
      "\tEpoch 116: \tAverage Loss:  0.568159912109375\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 117: \tAverage Loss:  0.5604902954101563\t ACC train:  0.7\t ACC test:  0.5866666666666667\n",
      "\tEpoch 118: \tAverage Loss:  0.5609469604492188\t ACC train:  0.6625\t ACC test:  0.6066666666666667\n",
      "\tEpoch 119: \tAverage Loss:  0.556043701171875\t ACC train:  0.7\t ACC test:  0.5777777777777777\n",
      "\tEpoch 120: \tAverage Loss:  0.552223388671875\t ACC train:  0.6625\t ACC test:  0.5933333333333334\n",
      "\tEpoch 121: \tAverage Loss:  0.5494098510742188\t ACC train:  0.675\t ACC test:  0.5822222222222222\n",
      "\tEpoch 122: \tAverage Loss:  0.5471446533203125\t ACC train:  0.7\t ACC test:  0.5844444444444444\n",
      "\tEpoch 123: \tAverage Loss:  0.5430859375\t ACC train:  0.6375\t ACC test:  0.5822222222222222\n",
      "\tEpoch 124: \tAverage Loss:  0.5399345703125\t ACC train:  0.675\t ACC test:  0.5666666666666667\n",
      "\tEpoch 125: \tAverage Loss:  0.5356072998046875\t ACC train:  0.6375\t ACC test:  0.5733333333333334\n",
      "\tEpoch 126: \tAverage Loss:  0.5329378051757813\t ACC train:  0.6375\t ACC test:  0.5688888888888889\n",
      "\tEpoch 127: \tAverage Loss:  0.5308052978515625\t ACC train:  0.6625\t ACC test:  0.5533333333333333\n",
      "\tEpoch 128: \tAverage Loss:  0.526878173828125\t ACC train:  0.625\t ACC test:  0.5844444444444444\n",
      "\tEpoch 129: \tAverage Loss:  0.5266280517578125\t ACC train:  0.65\t ACC test:  0.5733333333333334\n",
      "\tEpoch 130: \tAverage Loss:  0.5228209228515625\t ACC train:  0.625\t ACC test:  0.5622222222222222\n",
      "\tEpoch 131: \tAverage Loss:  0.5168298950195312\t ACC train:  0.6625\t ACC test:  0.5755555555555556\n",
      "\tEpoch 132: \tAverage Loss:  0.5176259155273437\t ACC train:  0.6125\t ACC test:  0.5666666666666667\n",
      "\tEpoch 133: \tAverage Loss:  0.513904296875\t ACC train:  0.65\t ACC test:  0.5377777777777778\n",
      "\tEpoch 134: \tAverage Loss:  0.5086230773925782\t ACC train:  0.65\t ACC test:  0.5666666666666667\n",
      "\tEpoch 135: \tAverage Loss:  0.5082890625\t ACC train:  0.6375\t ACC test:  0.5511111111111111\n",
      "\tEpoch 136: \tAverage Loss:  0.5074833374023437\t ACC train:  0.6625\t ACC test:  0.5555555555555556\n",
      "\tEpoch 137: \tAverage Loss:  0.5054027709960938\t ACC train:  0.6625\t ACC test:  0.5533333333333333\n",
      "\tEpoch 138: \tAverage Loss:  0.5020201110839844\t ACC train:  0.6375\t ACC test:  0.5488888888888889\n",
      "\tEpoch 139: \tAverage Loss:  0.49950634765625\t ACC train:  0.6\t ACC test:  0.5688888888888889\n",
      "\tEpoch 140: \tAverage Loss:  0.49869342041015624\t ACC train:  0.625\t ACC test:  0.5555555555555556\n",
      "\tEpoch 141: \tAverage Loss:  0.49645745849609374\t ACC train:  0.6125\t ACC test:  0.5511111111111111\n",
      "\tEpoch 142: \tAverage Loss:  0.49054931640625\t ACC train:  0.6625\t ACC test:  0.5488888888888889\n",
      "\tEpoch 143: \tAverage Loss:  0.48949383544921876\t ACC train:  0.5875\t ACC test:  0.5511111111111111\n",
      "\tEpoch 144: \tAverage Loss:  0.4910326232910156\t ACC train:  0.65\t ACC test:  0.56\n",
      "\tEpoch 145: \tAverage Loss:  0.4895670166015625\t ACC train:  0.6375\t ACC test:  0.5577777777777778\n",
      "\tEpoch 146: \tAverage Loss:  0.48324993896484375\t ACC train:  0.65\t ACC test:  0.5711111111111111\n",
      "\tEpoch 147: \tAverage Loss:  0.481438232421875\t ACC train:  0.65\t ACC test:  0.5555555555555556\n",
      "\tEpoch 148: \tAverage Loss:  0.4808697814941406\t ACC train:  0.6375\t ACC test:  0.5488888888888889\n",
      "\tEpoch 149: \tAverage Loss:  0.4779583740234375\t ACC train:  0.65\t ACC test:  0.5511111111111111\n",
      "\tEpoch 150: \tAverage Loss:  0.47886453247070315\t ACC train:  0.65\t ACC test:  0.5511111111111111\n",
      "\tEpoch 151: \tAverage Loss:  0.48170068359375\t ACC train:  0.6625\t ACC test:  0.5555555555555556\n",
      "\tEpoch 152: \tAverage Loss:  0.4750870361328125\t ACC train:  0.7\t ACC test:  0.5644444444444444\n",
      "\tEpoch 153: \tAverage Loss:  0.47587103271484377\t ACC train:  0.6125\t ACC test:  0.56\n",
      "\tEpoch 154: \tAverage Loss:  0.473660400390625\t ACC train:  0.65\t ACC test:  0.5555555555555556\n",
      "\tEpoch 155: \tAverage Loss:  0.4704385681152344\t ACC train:  0.625\t ACC test:  0.5555555555555556\n",
      "\tEpoch 156: \tAverage Loss:  0.4687976379394531\t ACC train:  0.65\t ACC test:  0.5533333333333333\n",
      "\tEpoch 157: \tAverage Loss:  0.46873471069335937\t ACC train:  0.65\t ACC test:  0.5644444444444444\n",
      "\tEpoch 158: \tAverage Loss:  0.465158203125\t ACC train:  0.6125\t ACC test:  0.5555555555555556\n",
      "\tEpoch 159: \tAverage Loss:  0.4660328369140625\t ACC train:  0.675\t ACC test:  0.5577777777777778\n",
      "\tEpoch 160: \tAverage Loss:  0.46252590942382815\t ACC train:  0.675\t ACC test:  0.5555555555555556\n",
      "\tEpoch 161: \tAverage Loss:  0.4635755615234375\t ACC train:  0.65\t ACC test:  0.5422222222222223\n",
      "\tEpoch 162: \tAverage Loss:  0.46077532958984374\t ACC train:  0.625\t ACC test:  0.5511111111111111\n",
      "\tEpoch 163: \tAverage Loss:  0.45867724609375\t ACC train:  0.675\t ACC test:  0.5622222222222222\n",
      "\tEpoch 164: \tAverage Loss:  0.4599802551269531\t ACC train:  0.6375\t ACC test:  0.5466666666666666\n",
      "\tEpoch 165: \tAverage Loss:  0.45699395751953126\t ACC train:  0.6125\t ACC test:  0.5577777777777778\n",
      "\tEpoch 166: \tAverage Loss:  0.45726605224609373\t ACC train:  0.625\t ACC test:  0.5444444444444444\n",
      "\tEpoch 167: \tAverage Loss:  0.45527972412109374\t ACC train:  0.6625\t ACC test:  0.5444444444444444\n",
      "\tEpoch 168: \tAverage Loss:  0.4532803955078125\t ACC train:  0.6625\t ACC test:  0.5577777777777778\n",
      "\tEpoch 169: \tAverage Loss:  0.45238983154296875\t ACC train:  0.6625\t ACC test:  0.5555555555555556\n",
      "\tEpoch 170: \tAverage Loss:  0.45096484375\t ACC train:  0.6375\t ACC test:  0.5577777777777778\n",
      "\tEpoch 171: \tAverage Loss:  0.45045367431640626\t ACC train:  0.6875\t ACC test:  0.5644444444444444\n",
      "\tEpoch 172: \tAverage Loss:  0.45205996704101564\t ACC train:  0.6625\t ACC test:  0.5688888888888889\n",
      "\tEpoch 173: \tAverage Loss:  0.449836181640625\t ACC train:  0.65\t ACC test:  0.5688888888888889\n",
      "\tEpoch 174: \tAverage Loss:  0.4494398193359375\t ACC train:  0.675\t ACC test:  0.5488888888888889\n",
      "\tEpoch 175: \tAverage Loss:  0.44648434448242186\t ACC train:  0.6375\t ACC test:  0.5711111111111111\n",
      "\tEpoch 176: \tAverage Loss:  0.4458592834472656\t ACC train:  0.6625\t ACC test:  0.5644444444444444\n",
      "\tEpoch 177: \tAverage Loss:  0.445131103515625\t ACC train:  0.65\t ACC test:  0.5511111111111111\n",
      "\tEpoch 178: \tAverage Loss:  0.44429736328125\t ACC train:  0.65\t ACC test:  0.5688888888888889\n",
      "\tEpoch 179: \tAverage Loss:  0.4422311706542969\t ACC train:  0.6375\t ACC test:  0.56\n",
      "\tEpoch 180: \tAverage Loss:  0.4424213562011719\t ACC train:  0.6875\t ACC test:  0.56\n",
      "\tEpoch 181: \tAverage Loss:  0.44265948486328127\t ACC train:  0.65\t ACC test:  0.5644444444444444\n",
      "\tEpoch 182: \tAverage Loss:  0.44088592529296877\t ACC train:  0.675\t ACC test:  0.5711111111111111\n",
      "\tEpoch 183: \tAverage Loss:  0.44065481567382814\t ACC train:  0.675\t ACC test:  0.5622222222222222\n",
      "\tEpoch 184: \tAverage Loss:  0.43910101318359374\t ACC train:  0.675\t ACC test:  0.5733333333333334\n",
      "\tEpoch 185: \tAverage Loss:  0.4395745239257812\t ACC train:  0.6375\t ACC test:  0.5755555555555556\n",
      "\tEpoch 186: \tAverage Loss:  0.4376169128417969\t ACC train:  0.6625\t ACC test:  0.58\n",
      "\tEpoch 187: \tAverage Loss:  0.43796835327148437\t ACC train:  0.6375\t ACC test:  0.5644444444444444\n",
      "\tEpoch 188: \tAverage Loss:  0.43769622802734376\t ACC train:  0.675\t ACC test:  0.56\n",
      "\tEpoch 189: \tAverage Loss:  0.4362332458496094\t ACC train:  0.65\t ACC test:  0.5711111111111111\n",
      "\tEpoch 190: \tAverage Loss:  0.43647332763671876\t ACC train:  0.6875\t ACC test:  0.5777777777777777\n",
      "\tEpoch 191: \tAverage Loss:  0.4345087585449219\t ACC train:  0.6625\t ACC test:  0.5688888888888889\n",
      "\tEpoch 192: \tAverage Loss:  0.434306396484375\t ACC train:  0.65\t ACC test:  0.58\n",
      "\tEpoch 193: \tAverage Loss:  0.432778076171875\t ACC train:  0.6375\t ACC test:  0.58\n",
      "\tEpoch 194: \tAverage Loss:  0.4332431640625\t ACC train:  0.675\t ACC test:  0.5866666666666667\n",
      "\tEpoch 195: \tAverage Loss:  0.43185073852539063\t ACC train:  0.6625\t ACC test:  0.5777777777777777\n",
      "\tEpoch 196: \tAverage Loss:  0.432190185546875\t ACC train:  0.6625\t ACC test:  0.5711111111111111\n",
      "\tEpoch 197: \tAverage Loss:  0.43112844848632814\t ACC train:  0.65\t ACC test:  0.58\n",
      "\tEpoch 198: \tAverage Loss:  0.4295027770996094\t ACC train:  0.65\t ACC test:  0.5733333333333334\n",
      "\tEpoch 199: \tAverage Loss:  0.4297951354980469\t ACC train:  0.675\t ACC test:  0.5622222222222222\n",
      "\tEpoch 200: \tAverage Loss:  0.4291939697265625\t ACC train:  0.6875\t ACC test:  0.58\n",
      "\tEpoch 201: \tAverage Loss:  0.4288653869628906\t ACC train:  0.675\t ACC test:  0.5688888888888889\n",
      "\tEpoch 202: \tAverage Loss:  0.4287890014648438\t ACC train:  0.6625\t ACC test:  0.5777777777777777\n",
      "\tEpoch 203: \tAverage Loss:  0.42828863525390626\t ACC train:  0.65\t ACC test:  0.5866666666666667\n",
      "\tEpoch 204: \tAverage Loss:  0.42742385864257815\t ACC train:  0.6625\t ACC test:  0.5844444444444444\n",
      "\tEpoch 205: \tAverage Loss:  0.42566070556640623\t ACC train:  0.6625\t ACC test:  0.5777777777777777\n",
      "\tEpoch 206: \tAverage Loss:  0.4270361633300781\t ACC train:  0.675\t ACC test:  0.5711111111111111\n",
      "\tEpoch 207: \tAverage Loss:  0.4264964599609375\t ACC train:  0.6875\t ACC test:  0.5911111111111111\n",
      "\tEpoch 208: \tAverage Loss:  0.4248785400390625\t ACC train:  0.6875\t ACC test:  0.58\n",
      "\tEpoch 209: \tAverage Loss:  0.4252465209960937\t ACC train:  0.6375\t ACC test:  0.5888888888888889\n",
      "\tEpoch 210: \tAverage Loss:  0.42430682373046874\t ACC train:  0.675\t ACC test:  0.5866666666666667\n",
      "\tEpoch 211: \tAverage Loss:  0.4245199890136719\t ACC train:  0.675\t ACC test:  0.5866666666666667\n",
      "\tEpoch 212: \tAverage Loss:  0.423436279296875\t ACC train:  0.675\t ACC test:  0.5822222222222222\n",
      "\tEpoch 213: \tAverage Loss:  0.4225193176269531\t ACC train:  0.6625\t ACC test:  0.5755555555555556\n",
      "\tEpoch 214: \tAverage Loss:  0.42282159423828125\t ACC train:  0.6625\t ACC test:  0.5688888888888889\n",
      "\tEpoch 215: \tAverage Loss:  0.42228704833984376\t ACC train:  0.6625\t ACC test:  0.5733333333333334\n",
      "\tEpoch 216: \tAverage Loss:  0.4239881286621094\t ACC train:  0.6625\t ACC test:  0.5777777777777777\n",
      "\tEpoch 217: \tAverage Loss:  0.4207333984375\t ACC train:  0.65\t ACC test:  0.5866666666666667\n",
      "\tEpoch 218: \tAverage Loss:  0.4207966003417969\t ACC train:  0.65\t ACC test:  0.5688888888888889\n",
      "\tEpoch 219: \tAverage Loss:  0.4211641845703125\t ACC train:  0.6625\t ACC test:  0.5866666666666667\n",
      "\tEpoch 220: \tAverage Loss:  0.4206263732910156\t ACC train:  0.65\t ACC test:  0.5977777777777777\n",
      "\tEpoch 221: \tAverage Loss:  0.420549072265625\t ACC train:  0.7\t ACC test:  0.5888888888888889\n",
      "\tEpoch 222: \tAverage Loss:  0.41910714721679687\t ACC train:  0.6875\t ACC test:  0.58\n",
      "\tEpoch 223: \tAverage Loss:  0.4196979064941406\t ACC train:  0.675\t ACC test:  0.5866666666666667\n",
      "\tEpoch 224: \tAverage Loss:  0.41866015625\t ACC train:  0.7125\t ACC test:  0.5888888888888889\n",
      "\tEpoch 225: \tAverage Loss:  0.4190408935546875\t ACC train:  0.65\t ACC test:  0.5955555555555555\n",
      "\tEpoch 226: \tAverage Loss:  0.41834024047851565\t ACC train:  0.7\t ACC test:  0.5911111111111111\n",
      "\tEpoch 227: \tAverage Loss:  0.4175432739257813\t ACC train:  0.675\t ACC test:  0.5911111111111111\n",
      "\tEpoch 228: \tAverage Loss:  0.41721307373046873\t ACC train:  0.6625\t ACC test:  0.5911111111111111\n",
      "\tEpoch 229: \tAverage Loss:  0.41721218872070315\t ACC train:  0.6625\t ACC test:  0.5844444444444444\n",
      "\tEpoch 230: \tAverage Loss:  0.4160914306640625\t ACC train:  0.6875\t ACC test:  0.5866666666666667\n",
      "\tEpoch 231: \tAverage Loss:  0.4165127563476563\t ACC train:  0.65\t ACC test:  0.5755555555555556\n",
      "\tEpoch 232: \tAverage Loss:  0.41596524047851563\t ACC train:  0.6625\t ACC test:  0.5888888888888889\n",
      "\tEpoch 233: \tAverage Loss:  0.4153948974609375\t ACC train:  0.65\t ACC test:  0.5866666666666667\n",
      "\tEpoch 234: \tAverage Loss:  0.4156491394042969\t ACC train:  0.65\t ACC test:  0.5911111111111111\n",
      "\tEpoch 235: \tAverage Loss:  0.4152756042480469\t ACC train:  0.675\t ACC test:  0.6\n",
      "\tEpoch 236: \tAverage Loss:  0.41530096435546876\t ACC train:  0.675\t ACC test:  0.5977777777777777\n",
      "\tEpoch 237: \tAverage Loss:  0.4150168151855469\t ACC train:  0.6875\t ACC test:  0.5977777777777777\n",
      "\tEpoch 238: \tAverage Loss:  0.41443466186523437\t ACC train:  0.7\t ACC test:  0.5955555555555555\n",
      "\tEpoch 239: \tAverage Loss:  0.4138206481933594\t ACC train:  0.6875\t ACC test:  0.5977777777777777\n",
      "\tEpoch 240: \tAverage Loss:  0.41390902709960936\t ACC train:  0.675\t ACC test:  0.5955555555555555\n",
      "\tEpoch 241: \tAverage Loss:  0.4137571716308594\t ACC train:  0.6625\t ACC test:  0.6\n",
      "\tEpoch 242: \tAverage Loss:  0.4127810363769531\t ACC train:  0.6875\t ACC test:  0.5911111111111111\n",
      "\tEpoch 243: \tAverage Loss:  0.4122231140136719\t ACC train:  0.675\t ACC test:  0.6\n",
      "\tEpoch 244: \tAverage Loss:  0.413557373046875\t ACC train:  0.675\t ACC test:  0.6022222222222222\n",
      "\tEpoch 245: \tAverage Loss:  0.4123435668945313\t ACC train:  0.6375\t ACC test:  0.5933333333333334\n",
      "\tEpoch 246: \tAverage Loss:  0.4119197998046875\t ACC train:  0.675\t ACC test:  0.5933333333333334\n",
      "\tEpoch 247: \tAverage Loss:  0.41208935546875\t ACC train:  0.6875\t ACC test:  0.5955555555555555\n",
      "\tEpoch 248: \tAverage Loss:  0.4123162536621094\t ACC train:  0.6875\t ACC test:  0.5888888888888889\n",
      "\tEpoch 249: \tAverage Loss:  0.41179571533203124\t ACC train:  0.6625\t ACC test:  0.6022222222222222\n",
      "\tEpoch 250: \tAverage Loss:  0.41001190185546876\t ACC train:  0.6625\t ACC test:  0.5933333333333334\n",
      "\tEpoch 251: \tAverage Loss:  0.4109656982421875\t ACC train:  0.6625\t ACC test:  0.5888888888888889\n",
      "\tEpoch 252: \tAverage Loss:  0.409863037109375\t ACC train:  0.6625\t ACC test:  0.5866666666666667\n",
      "\tEpoch 253: \tAverage Loss:  0.41078805541992186\t ACC train:  0.65\t ACC test:  0.5822222222222222\n",
      "\tEpoch 254: \tAverage Loss:  0.4097213439941406\t ACC train:  0.6625\t ACC test:  0.5822222222222222\n",
      "\tEpoch 255: \tAverage Loss:  0.40986569213867186\t ACC train:  0.675\t ACC test:  0.6022222222222222\n",
      "\tEpoch 256: \tAverage Loss:  0.4097326354980469\t ACC train:  0.6625\t ACC test:  0.5866666666666667\n",
      "\tEpoch 257: \tAverage Loss:  0.4100847473144531\t ACC train:  0.6625\t ACC test:  0.5888888888888889\n",
      "\tEpoch 258: \tAverage Loss:  0.40878411865234376\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 259: \tAverage Loss:  0.40889434814453124\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 260: \tAverage Loss:  0.40924993896484374\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 261: \tAverage Loss:  0.408939697265625\t ACC train:  0.65\t ACC test:  0.6044444444444445\n",
      "\tEpoch 262: \tAverage Loss:  0.40873672485351564\t ACC train:  0.675\t ACC test:  0.5977777777777777\n",
      "\tEpoch 263: \tAverage Loss:  0.40901763916015627\t ACC train:  0.675\t ACC test:  0.6044444444444445\n",
      "\tEpoch 264: \tAverage Loss:  0.4073371887207031\t ACC train:  0.675\t ACC test:  0.6\n",
      "\tEpoch 265: \tAverage Loss:  0.40817080688476565\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 266: \tAverage Loss:  0.4076817932128906\t ACC train:  0.7125\t ACC test:  0.6088888888888889\n",
      "\tEpoch 267: \tAverage Loss:  0.4075169067382812\t ACC train:  0.7125\t ACC test:  0.6066666666666667\n",
      "\tEpoch 268: \tAverage Loss:  0.4072343139648438\t ACC train:  0.6875\t ACC test:  0.6\n",
      "\tEpoch 269: \tAverage Loss:  0.40696221923828124\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 270: \tAverage Loss:  0.4063775329589844\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 271: \tAverage Loss:  0.4069775085449219\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 272: \tAverage Loss:  0.40553173828125\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 273: \tAverage Loss:  0.40626528930664063\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 274: \tAverage Loss:  0.40596026611328123\t ACC train:  0.7125\t ACC test:  0.6\n",
      "\tEpoch 275: \tAverage Loss:  0.40590869140625\t ACC train:  0.6875\t ACC test:  0.6066666666666667\n",
      "\tEpoch 276: \tAverage Loss:  0.40595111083984375\t ACC train:  0.6875\t ACC test:  0.6044444444444445\n",
      "\tEpoch 277: \tAverage Loss:  0.40646047973632815\t ACC train:  0.6875\t ACC test:  0.6022222222222222\n",
      "\tEpoch 278: \tAverage Loss:  0.40455078125\t ACC train:  0.7125\t ACC test:  0.6155555555555555\n",
      "\tEpoch 279: \tAverage Loss:  0.40470993041992187\t ACC train:  0.725\t ACC test:  0.6133333333333333\n",
      "\tEpoch 280: \tAverage Loss:  0.4046234130859375\t ACC train:  0.7125\t ACC test:  0.6044444444444445\n",
      "\tEpoch 281: \tAverage Loss:  0.40456930541992187\t ACC train:  0.7125\t ACC test:  0.6111111111111112\n",
      "\tEpoch 282: \tAverage Loss:  0.403949462890625\t ACC train:  0.7125\t ACC test:  0.6133333333333333\n",
      "\tEpoch 283: \tAverage Loss:  0.40424642944335937\t ACC train:  0.7\t ACC test:  0.6\n",
      "\tEpoch 284: \tAverage Loss:  0.404729248046875\t ACC train:  0.6875\t ACC test:  0.6\n",
      "\tEpoch 285: \tAverage Loss:  0.4042578430175781\t ACC train:  0.7\t ACC test:  0.5933333333333334\n",
      "\tEpoch 286: \tAverage Loss:  0.4045279541015625\t ACC train:  0.7125\t ACC test:  0.6066666666666667\n",
      "\tEpoch 287: \tAverage Loss:  0.4039349670410156\t ACC train:  0.7125\t ACC test:  0.6088888888888889\n",
      "\tEpoch 288: \tAverage Loss:  0.4036531372070313\t ACC train:  0.7375\t ACC test:  0.6177777777777778\n",
      "\tEpoch 289: \tAverage Loss:  0.4046773986816406\t ACC train:  0.675\t ACC test:  0.6266666666666667\n",
      "\tEpoch 290: \tAverage Loss:  0.404493896484375\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 291: \tAverage Loss:  0.40261239624023437\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 292: \tAverage Loss:  0.40323031616210936\t ACC train:  0.7\t ACC test:  0.6022222222222222\n",
      "\tEpoch 293: \tAverage Loss:  0.4032468872070312\t ACC train:  0.6875\t ACC test:  0.6044444444444445\n",
      "\tEpoch 294: \tAverage Loss:  0.4022447509765625\t ACC train:  0.7\t ACC test:  0.6044444444444445\n",
      "\tEpoch 295: \tAverage Loss:  0.4027515258789062\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 296: \tAverage Loss:  0.402295654296875\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 297: \tAverage Loss:  0.401361572265625\t ACC train:  0.7125\t ACC test:  0.6133333333333333\n",
      "\tEpoch 298: \tAverage Loss:  0.40190045166015625\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 299: \tAverage Loss:  0.4013071594238281\t ACC train:  0.7125\t ACC test:  0.6222222222222222\n",
      "\tEpoch 300: \tAverage Loss:  0.40214291381835937\t ACC train:  0.725\t ACC test:  0.6155555555555555\n",
      "\tEpoch 301: \tAverage Loss:  0.40157025146484376\t ACC train:  0.7125\t ACC test:  0.6111111111111112\n",
      "\tEpoch 302: \tAverage Loss:  0.4007876281738281\t ACC train:  0.7125\t ACC test:  0.6155555555555555\n",
      "\tEpoch 303: \tAverage Loss:  0.4013099670410156\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 304: \tAverage Loss:  0.40083404541015627\t ACC train:  0.7125\t ACC test:  0.6088888888888889\n",
      "\tEpoch 305: \tAverage Loss:  0.4002752685546875\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 306: \tAverage Loss:  0.4000545043945313\t ACC train:  0.725\t ACC test:  0.6155555555555555\n",
      "\tEpoch 307: \tAverage Loss:  0.40048965454101565\t ACC train:  0.725\t ACC test:  0.6244444444444445\n",
      "\tEpoch 308: \tAverage Loss:  0.40071002197265626\t ACC train:  0.7375\t ACC test:  0.62\n",
      "\tEpoch 309: \tAverage Loss:  0.4002096252441406\t ACC train:  0.7375\t ACC test:  0.6222222222222222\n",
      "\tEpoch 310: \tAverage Loss:  0.4001203308105469\t ACC train:  0.725\t ACC test:  0.62\n",
      "\tEpoch 311: \tAverage Loss:  0.4003533935546875\t ACC train:  0.725\t ACC test:  0.6266666666666667\n",
      "\tEpoch 312: \tAverage Loss:  0.39999755859375\t ACC train:  0.675\t ACC test:  0.6133333333333333\n",
      "\tEpoch 313: \tAverage Loss:  0.3998183898925781\t ACC train:  0.725\t ACC test:  0.6155555555555555\n",
      "\tEpoch 314: \tAverage Loss:  0.4002551574707031\t ACC train:  0.7125\t ACC test:  0.6155555555555555\n",
      "\tEpoch 315: \tAverage Loss:  0.39929278564453125\t ACC train:  0.7125\t ACC test:  0.6088888888888889\n",
      "\tEpoch 316: \tAverage Loss:  0.3995744934082031\t ACC train:  0.7125\t ACC test:  0.6155555555555555\n",
      "\tEpoch 317: \tAverage Loss:  0.39917611694335936\t ACC train:  0.725\t ACC test:  0.6288888888888889\n",
      "\tEpoch 318: \tAverage Loss:  0.3990045166015625\t ACC train:  0.725\t ACC test:  0.6155555555555555\n",
      "\tEpoch 319: \tAverage Loss:  0.39886740112304686\t ACC train:  0.725\t ACC test:  0.6288888888888889\n",
      "\tEpoch 320: \tAverage Loss:  0.3988197021484375\t ACC train:  0.7125\t ACC test:  0.6222222222222222\n",
      "\tEpoch 321: \tAverage Loss:  0.39857177734375\t ACC train:  0.7125\t ACC test:  0.6244444444444445\n",
      "\tEpoch 322: \tAverage Loss:  0.39833917236328126\t ACC train:  0.725\t ACC test:  0.62\n",
      "\tEpoch 323: \tAverage Loss:  0.398637451171875\t ACC train:  0.725\t ACC test:  0.6311111111111111\n",
      "\tEpoch 324: \tAverage Loss:  0.39862908935546876\t ACC train:  0.725\t ACC test:  0.6244444444444445\n",
      "\tEpoch 325: \tAverage Loss:  0.39801089477539064\t ACC train:  0.7125\t ACC test:  0.6222222222222222\n",
      "\tEpoch 326: \tAverage Loss:  0.3981751403808594\t ACC train:  0.7125\t ACC test:  0.62\n",
      "\tEpoch 327: \tAverage Loss:  0.397464599609375\t ACC train:  0.7125\t ACC test:  0.6133333333333333\n",
      "\tEpoch 328: \tAverage Loss:  0.397022216796875\t ACC train:  0.7125\t ACC test:  0.6133333333333333\n",
      "\tEpoch 329: \tAverage Loss:  0.3971009826660156\t ACC train:  0.725\t ACC test:  0.62\n",
      "\tEpoch 330: \tAverage Loss:  0.3967353515625\t ACC train:  0.725\t ACC test:  0.62\n",
      "\tEpoch 331: \tAverage Loss:  0.39704571533203126\t ACC train:  0.7375\t ACC test:  0.6244444444444445\n",
      "\tEpoch 332: \tAverage Loss:  0.3969236145019531\t ACC train:  0.7125\t ACC test:  0.6333333333333333\n",
      "\tEpoch 333: \tAverage Loss:  0.3968356018066406\t ACC train:  0.7125\t ACC test:  0.6288888888888889\n",
      "\tEpoch 334: \tAverage Loss:  0.3971339416503906\t ACC train:  0.725\t ACC test:  0.6222222222222222\n",
      "\tEpoch 335: \tAverage Loss:  0.396395263671875\t ACC train:  0.7375\t ACC test:  0.62\n",
      "\tEpoch 336: \tAverage Loss:  0.396868896484375\t ACC train:  0.725\t ACC test:  0.6177777777777778\n",
      "\tEpoch 337: \tAverage Loss:  0.39700094604492187\t ACC train:  0.7125\t ACC test:  0.6222222222222222\n",
      "\tEpoch 338: \tAverage Loss:  0.39658197021484376\t ACC train:  0.725\t ACC test:  0.6222222222222222\n",
      "\tEpoch 339: \tAverage Loss:  0.3962774658203125\t ACC train:  0.725\t ACC test:  0.6266666666666667\n",
      "\tEpoch 340: \tAverage Loss:  0.39585415649414063\t ACC train:  0.725\t ACC test:  0.62\n",
      "\tEpoch 341: \tAverage Loss:  0.39539227294921875\t ACC train:  0.7375\t ACC test:  0.6244444444444445\n",
      "\tEpoch 342: \tAverage Loss:  0.395612548828125\t ACC train:  0.7375\t ACC test:  0.6288888888888889\n",
      "\tEpoch 343: \tAverage Loss:  0.395486572265625\t ACC train:  0.725\t ACC test:  0.6266666666666667\n",
      "\tEpoch 344: \tAverage Loss:  0.39558489990234375\t ACC train:  0.725\t ACC test:  0.6311111111111111\n",
      "\tEpoch 345: \tAverage Loss:  0.39510345458984375\t ACC train:  0.725\t ACC test:  0.6266666666666667\n",
      "\tEpoch 346: \tAverage Loss:  0.3952839965820312\t ACC train:  0.7375\t ACC test:  0.6288888888888889\n",
      "\tEpoch 347: \tAverage Loss:  0.39560052490234376\t ACC train:  0.7375\t ACC test:  0.6222222222222222\n",
      "\tEpoch 348: \tAverage Loss:  0.3952308654785156\t ACC train:  0.7125\t ACC test:  0.6244444444444445\n",
      "\tEpoch 349: \tAverage Loss:  0.3947605590820312\t ACC train:  0.7375\t ACC test:  0.6288888888888889\n",
      "\tEpoch 350: \tAverage Loss:  0.39499285888671876\t ACC train:  0.7375\t ACC test:  0.6222222222222222\n",
      "\tEpoch 351: \tAverage Loss:  0.3947038269042969\t ACC train:  0.725\t ACC test:  0.6266666666666667\n",
      "\tEpoch 352: \tAverage Loss:  0.3941917724609375\t ACC train:  0.75\t ACC test:  0.6266666666666667\n",
      "\tEpoch 353: \tAverage Loss:  0.39425234985351565\t ACC train:  0.725\t ACC test:  0.6311111111111111\n",
      "\tEpoch 354: \tAverage Loss:  0.3947174682617188\t ACC train:  0.75\t ACC test:  0.6266666666666667\n",
      "\tEpoch 355: \tAverage Loss:  0.3940231628417969\t ACC train:  0.75\t ACC test:  0.6266666666666667\n",
      "\tEpoch 356: \tAverage Loss:  0.3940245056152344\t ACC train:  0.7375\t ACC test:  0.6311111111111111\n",
      "\tEpoch 357: \tAverage Loss:  0.3939194641113281\t ACC train:  0.75\t ACC test:  0.6266666666666667\n",
      "\tEpoch 358: \tAverage Loss:  0.3938228759765625\t ACC train:  0.7125\t ACC test:  0.6288888888888889\n",
      "\tEpoch 359: \tAverage Loss:  0.3935987548828125\t ACC train:  0.7375\t ACC test:  0.62\n",
      "\tEpoch 360: \tAverage Loss:  0.39372720336914063\t ACC train:  0.7375\t ACC test:  0.62\n",
      "\tEpoch 361: \tAverage Loss:  0.3931722412109375\t ACC train:  0.7375\t ACC test:  0.6266666666666667\n",
      "\tEpoch 362: \tAverage Loss:  0.39331268310546874\t ACC train:  0.7375\t ACC test:  0.6244444444444445\n",
      "\tEpoch 363: \tAverage Loss:  0.3936162414550781\t ACC train:  0.725\t ACC test:  0.6244444444444445\n",
      "\tEpoch 364: \tAverage Loss:  0.3930381774902344\t ACC train:  0.75\t ACC test:  0.6244444444444445\n",
      "\tEpoch 365: \tAverage Loss:  0.392971923828125\t ACC train:  0.75\t ACC test:  0.6266666666666667\n",
      "\tEpoch 366: \tAverage Loss:  0.393072509765625\t ACC train:  0.75\t ACC test:  0.6311111111111111\n",
      "\tEpoch 367: \tAverage Loss:  0.3926737365722656\t ACC train:  0.725\t ACC test:  0.6333333333333333\n",
      "\tEpoch 368: \tAverage Loss:  0.39242050170898435\t ACC train:  0.725\t ACC test:  0.6311111111111111\n",
      "\tEpoch 369: \tAverage Loss:  0.39281024169921874\t ACC train:  0.75\t ACC test:  0.6288888888888889\n",
      "\tEpoch 370: \tAverage Loss:  0.39277435302734376\t ACC train:  0.75\t ACC test:  0.6244444444444445\n",
      "\tEpoch 371: \tAverage Loss:  0.3921089172363281\t ACC train:  0.7375\t ACC test:  0.6355555555555555\n",
      "\tEpoch 372: \tAverage Loss:  0.39240020751953125\t ACC train:  0.7375\t ACC test:  0.6288888888888889\n",
      "\tEpoch 373: \tAverage Loss:  0.3924946594238281\t ACC train:  0.75\t ACC test:  0.6333333333333333\n",
      "\tEpoch 374: \tAverage Loss:  0.39211199951171877\t ACC train:  0.75\t ACC test:  0.6333333333333333\n",
      "\tEpoch 375: \tAverage Loss:  0.3923956298828125\t ACC train:  0.75\t ACC test:  0.6266666666666667\n",
      "\tEpoch 376: \tAverage Loss:  0.3919088439941406\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 377: \tAverage Loss:  0.3921849365234375\t ACC train:  0.7375\t ACC test:  0.6222222222222222\n",
      "\tEpoch 378: \tAverage Loss:  0.39169973754882814\t ACC train:  0.75\t ACC test:  0.6266666666666667\n",
      "\tEpoch 379: \tAverage Loss:  0.39178317260742185\t ACC train:  0.75\t ACC test:  0.6266666666666667\n",
      "\tEpoch 380: \tAverage Loss:  0.39160488891601564\t ACC train:  0.7625\t ACC test:  0.6333333333333333\n",
      "\tEpoch 381: \tAverage Loss:  0.3913785400390625\t ACC train:  0.75\t ACC test:  0.6311111111111111\n",
      "\tEpoch 382: \tAverage Loss:  0.3911949462890625\t ACC train:  0.75\t ACC test:  0.6333333333333333\n",
      "\tEpoch 383: \tAverage Loss:  0.39139059448242186\t ACC train:  0.75\t ACC test:  0.6288888888888889\n",
      "\tEpoch 384: \tAverage Loss:  0.3910386657714844\t ACC train:  0.75\t ACC test:  0.64\n",
      "\tEpoch 385: \tAverage Loss:  0.3909995422363281\t ACC train:  0.75\t ACC test:  0.6288888888888889\n",
      "\tEpoch 386: \tAverage Loss:  0.3914063110351563\t ACC train:  0.75\t ACC test:  0.6311111111111111\n",
      "\tEpoch 387: \tAverage Loss:  0.39053021240234376\t ACC train:  0.7625\t ACC test:  0.6311111111111111\n",
      "\tEpoch 388: \tAverage Loss:  0.39062139892578124\t ACC train:  0.75\t ACC test:  0.6311111111111111\n",
      "\tEpoch 389: \tAverage Loss:  0.39105560302734377\t ACC train:  0.7625\t ACC test:  0.6311111111111111\n",
      "\tEpoch 390: \tAverage Loss:  0.39055972290039065\t ACC train:  0.7625\t ACC test:  0.6333333333333333\n",
      "\tEpoch 391: \tAverage Loss:  0.390134521484375\t ACC train:  0.7625\t ACC test:  0.6288888888888889\n",
      "\tEpoch 392: \tAverage Loss:  0.39035983276367187\t ACC train:  0.75\t ACC test:  0.64\n",
      "\tEpoch 393: \tAverage Loss:  0.3899214782714844\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 394: \tAverage Loss:  0.3901390686035156\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 395: \tAverage Loss:  0.39022015380859376\t ACC train:  0.7625\t ACC test:  0.6333333333333333\n",
      "\tEpoch 396: \tAverage Loss:  0.389622314453125\t ACC train:  0.7625\t ACC test:  0.6266666666666667\n",
      "\tEpoch 397: \tAverage Loss:  0.3901041259765625\t ACC train:  0.75\t ACC test:  0.6311111111111111\n",
      "\tEpoch 398: \tAverage Loss:  0.38976483154296876\t ACC train:  0.75\t ACC test:  0.64\n",
      "\tEpoch 399: \tAverage Loss:  0.38963607788085936\t ACC train:  0.75\t ACC test:  0.6311111111111111\n",
      "\tEpoch 400: \tAverage Loss:  0.3894737548828125\t ACC train:  0.75\t ACC test:  0.6333333333333333\n",
      "\tEpoch 401: \tAverage Loss:  0.3891775817871094\t ACC train:  0.7625\t ACC test:  0.6288888888888889\n",
      "\tEpoch 402: \tAverage Loss:  0.3892290344238281\t ACC train:  0.75\t ACC test:  0.6377777777777778\n",
      "\tEpoch 403: \tAverage Loss:  0.38919757080078127\t ACC train:  0.75\t ACC test:  0.6355555555555555\n",
      "\tEpoch 404: \tAverage Loss:  0.3897489318847656\t ACC train:  0.7625\t ACC test:  0.6311111111111111\n",
      "\tEpoch 405: \tAverage Loss:  0.3890371398925781\t ACC train:  0.7375\t ACC test:  0.64\n",
      "\tEpoch 406: \tAverage Loss:  0.3891231689453125\t ACC train:  0.7625\t ACC test:  0.6355555555555555\n",
      "\tEpoch 407: \tAverage Loss:  0.38920404052734375\t ACC train:  0.7625\t ACC test:  0.6311111111111111\n",
      "\tEpoch 408: \tAverage Loss:  0.38881210327148436\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 409: \tAverage Loss:  0.3884340515136719\t ACC train:  0.7625\t ACC test:  0.6355555555555555\n",
      "\tEpoch 410: \tAverage Loss:  0.3886141357421875\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 411: \tAverage Loss:  0.3884664306640625\t ACC train:  0.7625\t ACC test:  0.6333333333333333\n",
      "\tEpoch 412: \tAverage Loss:  0.388324462890625\t ACC train:  0.75\t ACC test:  0.6355555555555555\n",
      "\tEpoch 413: \tAverage Loss:  0.388400634765625\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 414: \tAverage Loss:  0.3877674560546875\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 415: \tAverage Loss:  0.38784829711914065\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 416: \tAverage Loss:  0.38770855712890623\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 417: \tAverage Loss:  0.38768893432617185\t ACC train:  0.7625\t ACC test:  0.6288888888888889\n",
      "\tEpoch 418: \tAverage Loss:  0.38789297485351565\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 419: \tAverage Loss:  0.388080078125\t ACC train:  0.7625\t ACC test:  0.6333333333333333\n",
      "\tEpoch 420: \tAverage Loss:  0.3874892883300781\t ACC train:  0.75\t ACC test:  0.6422222222222222\n",
      "\tEpoch 421: \tAverage Loss:  0.38765902709960937\t ACC train:  0.75\t ACC test:  0.64\n",
      "\tEpoch 422: \tAverage Loss:  0.38725006103515625\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 423: \tAverage Loss:  0.387605224609375\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 424: \tAverage Loss:  0.38745068359375\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 425: \tAverage Loss:  0.38684591674804686\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 426: \tAverage Loss:  0.3869240417480469\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 427: \tAverage Loss:  0.38750238037109375\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 428: \tAverage Loss:  0.38658206176757814\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 429: \tAverage Loss:  0.38663458251953126\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 430: \tAverage Loss:  0.38675555419921875\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 431: \tAverage Loss:  0.38662368774414063\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 432: \tAverage Loss:  0.3865197143554687\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 433: \tAverage Loss:  0.3862971496582031\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 434: \tAverage Loss:  0.3865350646972656\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 435: \tAverage Loss:  0.3862619934082031\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 436: \tAverage Loss:  0.3860087585449219\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 437: \tAverage Loss:  0.38632958984375\t ACC train:  0.725\t ACC test:  0.6422222222222222\n",
      "\tEpoch 438: \tAverage Loss:  0.38594656372070313\t ACC train:  0.75\t ACC test:  0.6355555555555555\n",
      "\tEpoch 439: \tAverage Loss:  0.38578204345703127\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 440: \tAverage Loss:  0.3857545776367188\t ACC train:  0.7625\t ACC test:  0.6355555555555555\n",
      "\tEpoch 441: \tAverage Loss:  0.3862611083984375\t ACC train:  0.7625\t ACC test:  0.6355555555555555\n",
      "\tEpoch 442: \tAverage Loss:  0.38550616455078124\t ACC train:  0.75\t ACC test:  0.6377777777777778\n",
      "\tEpoch 443: \tAverage Loss:  0.385324951171875\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 444: \tAverage Loss:  0.38595779418945314\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 445: \tAverage Loss:  0.38555523681640624\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 446: \tAverage Loss:  0.38555450439453126\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 447: \tAverage Loss:  0.38489910888671874\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 448: \tAverage Loss:  0.38509597778320315\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 449: \tAverage Loss:  0.3851329345703125\t ACC train:  0.7625\t ACC test:  0.6355555555555555\n",
      "\tEpoch 450: \tAverage Loss:  0.3853379516601563\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 451: \tAverage Loss:  0.3852126770019531\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 452: \tAverage Loss:  0.3853029479980469\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 453: \tAverage Loss:  0.38480935668945315\t ACC train:  0.7625\t ACC test:  0.6355555555555555\n",
      "\tEpoch 454: \tAverage Loss:  0.3846248474121094\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 455: \tAverage Loss:  0.38478439331054687\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 456: \tAverage Loss:  0.3842854309082031\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 457: \tAverage Loss:  0.3848086242675781\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 458: \tAverage Loss:  0.3847027282714844\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 459: \tAverage Loss:  0.384247802734375\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 460: \tAverage Loss:  0.38407119750976565\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 461: \tAverage Loss:  0.38389938354492187\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 462: \tAverage Loss:  0.38384716796875\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 463: \tAverage Loss:  0.38432159423828127\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 464: \tAverage Loss:  0.383903564453125\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 465: \tAverage Loss:  0.38374923706054687\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 466: \tAverage Loss:  0.38384820556640625\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 467: \tAverage Loss:  0.38384432983398437\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 468: \tAverage Loss:  0.3837923278808594\t ACC train:  0.75\t ACC test:  0.64\n",
      "\tEpoch 469: \tAverage Loss:  0.383666748046875\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 470: \tAverage Loss:  0.38340957641601564\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 471: \tAverage Loss:  0.38348391723632813\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 472: \tAverage Loss:  0.3829365234375\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 473: \tAverage Loss:  0.38318801879882813\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 474: \tAverage Loss:  0.3829447021484375\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 475: \tAverage Loss:  0.38342373657226564\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 476: \tAverage Loss:  0.3830036315917969\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 477: \tAverage Loss:  0.38274569702148437\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 478: \tAverage Loss:  0.38343502807617186\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 479: \tAverage Loss:  0.3827672119140625\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 480: \tAverage Loss:  0.3829450378417969\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 481: \tAverage Loss:  0.3826953430175781\t ACC train:  0.75\t ACC test:  0.6422222222222222\n",
      "\tEpoch 482: \tAverage Loss:  0.38234805297851565\t ACC train:  0.7625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 483: \tAverage Loss:  0.382414794921875\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 484: \tAverage Loss:  0.3824216613769531\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 485: \tAverage Loss:  0.38226617431640625\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 486: \tAverage Loss:  0.38242669677734376\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 487: \tAverage Loss:  0.3822076416015625\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 488: \tAverage Loss:  0.38197491455078125\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 489: \tAverage Loss:  0.3822735595703125\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 490: \tAverage Loss:  0.38201943969726565\t ACC train:  0.7625\t ACC test:  0.6333333333333333\n",
      "\tEpoch 491: \tAverage Loss:  0.3822543334960937\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 492: \tAverage Loss:  0.3816791381835937\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 493: \tAverage Loss:  0.3816799011230469\t ACC train:  0.7625\t ACC test:  0.64\n",
      "\tEpoch 494: \tAverage Loss:  0.3815892028808594\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 495: \tAverage Loss:  0.38166229248046873\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 496: \tAverage Loss:  0.3815628967285156\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 497: \tAverage Loss:  0.38158953857421873\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 498: \tAverage Loss:  0.3811350402832031\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 499: \tAverage Loss:  0.3814238586425781\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 500: \tAverage Loss:  0.3813110046386719\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 501: \tAverage Loss:  0.3806009521484375\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 502: \tAverage Loss:  0.3811497192382812\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 503: \tAverage Loss:  0.38108364868164063\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 504: \tAverage Loss:  0.3807807922363281\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 505: \tAverage Loss:  0.38096707153320314\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 506: \tAverage Loss:  0.38072039794921875\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 507: \tAverage Loss:  0.38087991333007815\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 508: \tAverage Loss:  0.380707763671875\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 509: \tAverage Loss:  0.38088656616210936\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 510: \tAverage Loss:  0.3804820251464844\t ACC train:  0.7625\t ACC test:  0.6533333333333333\n",
      "\tEpoch 511: \tAverage Loss:  0.3807911376953125\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 512: \tAverage Loss:  0.3802715148925781\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 513: \tAverage Loss:  0.38012631225585936\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 514: \tAverage Loss:  0.3804772338867187\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 515: \tAverage Loss:  0.3801566162109375\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 516: \tAverage Loss:  0.380164306640625\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 517: \tAverage Loss:  0.3801453247070313\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 518: \tAverage Loss:  0.3796623840332031\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 519: \tAverage Loss:  0.37991845703125\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 520: \tAverage Loss:  0.3798287353515625\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 521: \tAverage Loss:  0.3795484619140625\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 522: \tAverage Loss:  0.3792688293457031\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 523: \tAverage Loss:  0.3796131286621094\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 524: \tAverage Loss:  0.3798255920410156\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 525: \tAverage Loss:  0.3792558288574219\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 526: \tAverage Loss:  0.37944540405273436\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 527: \tAverage Loss:  0.37922781372070313\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 528: \tAverage Loss:  0.37927975463867186\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 529: \tAverage Loss:  0.37924755859375\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 530: \tAverage Loss:  0.37892147827148437\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 531: \tAverage Loss:  0.37939566040039063\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 532: \tAverage Loss:  0.37897042846679685\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 533: \tAverage Loss:  0.37867276000976563\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 534: \tAverage Loss:  0.37875396728515626\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 535: \tAverage Loss:  0.37843258666992186\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 536: \tAverage Loss:  0.3786629638671875\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 537: \tAverage Loss:  0.37839654541015627\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 538: \tAverage Loss:  0.3784382019042969\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 539: \tAverage Loss:  0.3782723693847656\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 540: \tAverage Loss:  0.3782531433105469\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 541: \tAverage Loss:  0.3783934326171875\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 542: \tAverage Loss:  0.3784582824707031\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 543: \tAverage Loss:  0.378150390625\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 544: \tAverage Loss:  0.37780902099609376\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 545: \tAverage Loss:  0.37792080688476565\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 546: \tAverage Loss:  0.37795916748046876\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 547: \tAverage Loss:  0.37815505981445313\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 548: \tAverage Loss:  0.37764422607421877\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 549: \tAverage Loss:  0.3777325134277344\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 550: \tAverage Loss:  0.37760601806640626\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 551: \tAverage Loss:  0.3774560546875\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 552: \tAverage Loss:  0.3774154357910156\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 553: \tAverage Loss:  0.3772217102050781\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 554: \tAverage Loss:  0.37721636962890626\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 555: \tAverage Loss:  0.37687005615234376\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 556: \tAverage Loss:  0.37740670776367186\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 557: \tAverage Loss:  0.37702902221679685\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 558: \tAverage Loss:  0.37737576293945313\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 559: \tAverage Loss:  0.37703045654296874\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 560: \tAverage Loss:  0.3770783996582031\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 561: \tAverage Loss:  0.3769601135253906\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 562: \tAverage Loss:  0.3766695251464844\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 563: \tAverage Loss:  0.3768975830078125\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 564: \tAverage Loss:  0.37684857177734377\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 565: \tAverage Loss:  0.37627267456054686\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 566: \tAverage Loss:  0.3765310363769531\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 567: \tAverage Loss:  0.37648236083984377\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 568: \tAverage Loss:  0.3763846740722656\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 569: \tAverage Loss:  0.3764271545410156\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 570: \tAverage Loss:  0.3761440734863281\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 571: \tAverage Loss:  0.37611865234375\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 572: \tAverage Loss:  0.3762179870605469\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 573: \tAverage Loss:  0.37592822265625\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 574: \tAverage Loss:  0.3760246887207031\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 575: \tAverage Loss:  0.3760593566894531\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 576: \tAverage Loss:  0.37577023315429686\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 577: \tAverage Loss:  0.37558157348632815\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 578: \tAverage Loss:  0.37566030883789064\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 579: \tAverage Loss:  0.375610595703125\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 580: \tAverage Loss:  0.37543280029296877\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 581: \tAverage Loss:  0.37522174072265624\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 582: \tAverage Loss:  0.37517108154296874\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 583: \tAverage Loss:  0.3754434509277344\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 584: \tAverage Loss:  0.3757680053710937\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 585: \tAverage Loss:  0.37510418701171877\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 586: \tAverage Loss:  0.3752666015625\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 587: \tAverage Loss:  0.37498715209960937\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 588: \tAverage Loss:  0.375029541015625\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 589: \tAverage Loss:  0.3750487365722656\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 590: \tAverage Loss:  0.37478009033203125\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 591: \tAverage Loss:  0.37470269775390624\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 592: \tAverage Loss:  0.37475497436523436\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 593: \tAverage Loss:  0.374567626953125\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 594: \tAverage Loss:  0.37499981689453127\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 595: \tAverage Loss:  0.3747194519042969\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 596: \tAverage Loss:  0.3742734069824219\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 597: \tAverage Loss:  0.37430892944335936\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 598: \tAverage Loss:  0.37419110107421877\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 599: \tAverage Loss:  0.37393157958984374\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 600: \tAverage Loss:  0.3741579895019531\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 601: \tAverage Loss:  0.37424063110351563\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 602: \tAverage Loss:  0.37379547119140627\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 603: \tAverage Loss:  0.3736795654296875\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 604: \tAverage Loss:  0.37388043212890626\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 605: \tAverage Loss:  0.37405413818359373\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 606: \tAverage Loss:  0.37359210205078125\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 607: \tAverage Loss:  0.37377047729492185\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 608: \tAverage Loss:  0.3739494323730469\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 609: \tAverage Loss:  0.37352398681640625\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 610: \tAverage Loss:  0.3740672912597656\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 611: \tAverage Loss:  0.3738826599121094\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 612: \tAverage Loss:  0.37321249389648437\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 613: \tAverage Loss:  0.3734637451171875\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 614: \tAverage Loss:  0.37327789306640624\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 615: \tAverage Loss:  0.37305111694335935\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 616: \tAverage Loss:  0.37297299194335937\t ACC train:  0.7625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 617: \tAverage Loss:  0.3728251953125\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 618: \tAverage Loss:  0.3726856384277344\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 619: \tAverage Loss:  0.37283474731445315\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 620: \tAverage Loss:  0.3726250305175781\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 621: \tAverage Loss:  0.3724275817871094\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 622: \tAverage Loss:  0.3723255004882812\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 623: \tAverage Loss:  0.3723114318847656\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 624: \tAverage Loss:  0.37219012451171873\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 625: \tAverage Loss:  0.3723829040527344\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 626: \tAverage Loss:  0.37205078125\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 627: \tAverage Loss:  0.371898681640625\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 628: \tAverage Loss:  0.37177536010742185\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 629: \tAverage Loss:  0.37182443237304685\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 630: \tAverage Loss:  0.3717803955078125\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 631: \tAverage Loss:  0.371673828125\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 632: \tAverage Loss:  0.371356689453125\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 633: \tAverage Loss:  0.3714372863769531\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 634: \tAverage Loss:  0.37135140991210935\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 635: \tAverage Loss:  0.3712391357421875\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 636: \tAverage Loss:  0.37120245361328125\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 637: \tAverage Loss:  0.370985107421875\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 638: \tAverage Loss:  0.37084332275390625\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 639: \tAverage Loss:  0.37101495361328124\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 640: \tAverage Loss:  0.3709219970703125\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 641: \tAverage Loss:  0.37051971435546877\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 642: \tAverage Loss:  0.37099127197265624\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 643: \tAverage Loss:  0.3704828186035156\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 644: \tAverage Loss:  0.3702913513183594\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 645: \tAverage Loss:  0.3703387451171875\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 646: \tAverage Loss:  0.37063247680664063\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 647: \tAverage Loss:  0.3699017944335937\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 648: \tAverage Loss:  0.37021182250976564\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 649: \tAverage Loss:  0.3701118774414062\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 650: \tAverage Loss:  0.3698878784179688\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 651: \tAverage Loss:  0.3700043029785156\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 652: \tAverage Loss:  0.3696214599609375\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 653: \tAverage Loss:  0.36952789306640627\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 654: \tAverage Loss:  0.36927261352539065\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 655: \tAverage Loss:  0.36987579345703125\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 656: \tAverage Loss:  0.3690840759277344\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 657: \tAverage Loss:  0.36914968872070314\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 658: \tAverage Loss:  0.3691058044433594\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 659: \tAverage Loss:  0.369048583984375\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 660: \tAverage Loss:  0.3688898315429687\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 661: \tAverage Loss:  0.3685465087890625\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 662: \tAverage Loss:  0.3687471008300781\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 663: \tAverage Loss:  0.3689304504394531\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 664: \tAverage Loss:  0.36850082397460937\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 665: \tAverage Loss:  0.3681568298339844\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 666: \tAverage Loss:  0.36806396484375\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 667: \tAverage Loss:  0.36858294677734377\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 668: \tAverage Loss:  0.3680175476074219\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 669: \tAverage Loss:  0.36820669555664065\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 670: \tAverage Loss:  0.3681296691894531\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 671: \tAverage Loss:  0.3678396606445313\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 672: \tAverage Loss:  0.3676466369628906\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 673: \tAverage Loss:  0.36758316040039063\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 674: \tAverage Loss:  0.36775469970703123\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 675: \tAverage Loss:  0.36763372802734373\t ACC train:  0.7625\t ACC test:  0.6533333333333333\n",
      "\tEpoch 676: \tAverage Loss:  0.36703067016601565\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 677: \tAverage Loss:  0.36783984375\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 678: \tAverage Loss:  0.36789764404296876\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 679: \tAverage Loss:  0.36739300537109376\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 680: \tAverage Loss:  0.3666595764160156\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 681: \tAverage Loss:  0.3668039245605469\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 682: \tAverage Loss:  0.367228515625\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 683: \tAverage Loss:  0.3662681884765625\t ACC train:  0.7625\t ACC test:  0.6533333333333333\n",
      "\tEpoch 684: \tAverage Loss:  0.3662740478515625\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 685: \tAverage Loss:  0.366403564453125\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 686: \tAverage Loss:  0.36674530029296876\t ACC train:  0.7625\t ACC test:  0.6511111111111111\n",
      "\tEpoch 687: \tAverage Loss:  0.3659938659667969\t ACC train:  0.7625\t ACC test:  0.6533333333333333\n",
      "\tEpoch 688: \tAverage Loss:  0.36618441772460936\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 689: \tAverage Loss:  0.3660777282714844\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 690: \tAverage Loss:  0.3653365478515625\t ACC train:  0.7625\t ACC test:  0.6444444444444445\n",
      "\tEpoch 691: \tAverage Loss:  0.3654190673828125\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 692: \tAverage Loss:  0.36540228271484376\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 693: \tAverage Loss:  0.3658392333984375\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 694: \tAverage Loss:  0.365396728515625\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 695: \tAverage Loss:  0.36512686157226565\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 696: \tAverage Loss:  0.3650578308105469\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 697: \tAverage Loss:  0.3649957275390625\t ACC train:  0.7625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 698: \tAverage Loss:  0.36468002319335935\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 699: \tAverage Loss:  0.3648583679199219\t ACC train:  0.7625\t ACC test:  0.6466666666666666\n",
      "\tEpoch 700: \tAverage Loss:  0.3647729797363281\t ACC train:  0.775\t ACC test:  0.6622222222222223\n",
      "\tEpoch 701: \tAverage Loss:  0.3646419677734375\t ACC train:  0.8375\t ACC test:  0.6666666666666666\n",
      "\tEpoch 702: \tAverage Loss:  0.3649663696289063\t ACC train:  0.8\t ACC test:  0.6711111111111111\n",
      "\tEpoch 703: \tAverage Loss:  0.36437890625\t ACC train:  0.7875\t ACC test:  0.6755555555555556\n",
      "\tEpoch 704: \tAverage Loss:  0.36451177978515625\t ACC train:  0.7875\t ACC test:  0.6688888888888889\n",
      "\tEpoch 705: \tAverage Loss:  0.3638054504394531\t ACC train:  0.825\t ACC test:  0.6866666666666666\n",
      "\tEpoch 706: \tAverage Loss:  0.3640869445800781\t ACC train:  0.825\t ACC test:  0.68\n",
      "\tEpoch 707: \tAverage Loss:  0.3638746643066406\t ACC train:  0.825\t ACC test:  0.6911111111111111\n",
      "\tEpoch 708: \tAverage Loss:  0.36396697998046873\t ACC train:  0.8125\t ACC test:  0.6844444444444444\n",
      "\tEpoch 709: \tAverage Loss:  0.3636602783203125\t ACC train:  0.8125\t ACC test:  0.6977777777777778\n",
      "\tEpoch 710: \tAverage Loss:  0.36387274169921874\t ACC train:  0.8125\t ACC test:  0.6955555555555556\n",
      "\tEpoch 711: \tAverage Loss:  0.363429443359375\t ACC train:  0.8375\t ACC test:  0.7\n",
      "\tEpoch 712: \tAverage Loss:  0.36339208984375\t ACC train:  0.8375\t ACC test:  0.6888888888888889\n",
      "\tEpoch 713: \tAverage Loss:  0.3634637451171875\t ACC train:  0.85\t ACC test:  0.7111111111111111\n",
      "\tEpoch 714: \tAverage Loss:  0.3632978515625\t ACC train:  0.8375\t ACC test:  0.7022222222222222\n",
      "\tEpoch 715: \tAverage Loss:  0.3628979187011719\t ACC train:  0.85\t ACC test:  0.7133333333333334\n",
      "\tEpoch 716: \tAverage Loss:  0.3628978576660156\t ACC train:  0.8625\t ACC test:  0.7311111111111112\n",
      "\tEpoch 717: \tAverage Loss:  0.3628215637207031\t ACC train:  0.8625\t ACC test:  0.72\n",
      "\tEpoch 718: \tAverage Loss:  0.36275018310546875\t ACC train:  0.8625\t ACC test:  0.7244444444444444\n",
      "\tEpoch 719: \tAverage Loss:  0.3625094604492187\t ACC train:  0.85\t ACC test:  0.7266666666666667\n",
      "\tEpoch 720: \tAverage Loss:  0.3625038146972656\t ACC train:  0.8875\t ACC test:  0.7288888888888889\n",
      "\tEpoch 721: \tAverage Loss:  0.36211489868164065\t ACC train:  0.875\t ACC test:  0.7444444444444445\n",
      "\tEpoch 722: \tAverage Loss:  0.36179351806640625\t ACC train:  0.8625\t ACC test:  0.7422222222222222\n",
      "\tEpoch 723: \tAverage Loss:  0.36183404541015624\t ACC train:  0.9\t ACC test:  0.7422222222222222\n",
      "\tEpoch 724: \tAverage Loss:  0.3617392578125\t ACC train:  0.8875\t ACC test:  0.7555555555555555\n",
      "\tEpoch 725: \tAverage Loss:  0.3617156677246094\t ACC train:  0.8875\t ACC test:  0.7533333333333333\n",
      "\tEpoch 726: \tAverage Loss:  0.3613525695800781\t ACC train:  0.875\t ACC test:  0.7577777777777778\n",
      "\tEpoch 727: \tAverage Loss:  0.3619215087890625\t ACC train:  0.8875\t ACC test:  0.76\n",
      "\tEpoch 728: \tAverage Loss:  0.3610581970214844\t ACC train:  0.8875\t ACC test:  0.7577777777777778\n",
      "\tEpoch 729: \tAverage Loss:  0.3612824401855469\t ACC train:  0.8875\t ACC test:  0.7644444444444445\n",
      "\tEpoch 730: \tAverage Loss:  0.3614023132324219\t ACC train:  0.9\t ACC test:  0.7711111111111111\n",
      "\tEpoch 731: \tAverage Loss:  0.3609846801757812\t ACC train:  0.9125\t ACC test:  0.7644444444444445\n",
      "\tEpoch 732: \tAverage Loss:  0.3606546630859375\t ACC train:  0.9\t ACC test:  0.76\n",
      "\tEpoch 733: \tAverage Loss:  0.360912353515625\t ACC train:  0.9\t ACC test:  0.7688888888888888\n",
      "\tEpoch 734: \tAverage Loss:  0.3607451782226562\t ACC train:  0.9\t ACC test:  0.7688888888888888\n",
      "\tEpoch 735: \tAverage Loss:  0.3608450622558594\t ACC train:  0.9125\t ACC test:  0.7733333333333333\n",
      "\tEpoch 736: \tAverage Loss:  0.36089755249023436\t ACC train:  0.925\t ACC test:  0.7822222222222223\n",
      "\tEpoch 737: \tAverage Loss:  0.3601419067382812\t ACC train:  0.9125\t ACC test:  0.7822222222222223\n",
      "\tEpoch 738: \tAverage Loss:  0.3609320068359375\t ACC train:  0.9125\t ACC test:  0.7844444444444445\n",
      "\tEpoch 739: \tAverage Loss:  0.360552734375\t ACC train:  0.925\t ACC test:  0.7822222222222223\n",
      "\tEpoch 740: \tAverage Loss:  0.3601920166015625\t ACC train:  0.9125\t ACC test:  0.78\n",
      "\tEpoch 741: \tAverage Loss:  0.3602567443847656\t ACC train:  0.9125\t ACC test:  0.7866666666666666\n",
      "\tEpoch 742: \tAverage Loss:  0.3601357421875\t ACC train:  0.925\t ACC test:  0.7844444444444445\n",
      "\tEpoch 743: \tAverage Loss:  0.35983584594726564\t ACC train:  0.925\t ACC test:  0.7888888888888889\n",
      "\tEpoch 744: \tAverage Loss:  0.3594733581542969\t ACC train:  0.925\t ACC test:  0.7866666666666666\n",
      "\tEpoch 745: \tAverage Loss:  0.36024588012695313\t ACC train:  0.925\t ACC test:  0.7933333333333333\n",
      "\tEpoch 746: \tAverage Loss:  0.35950830078125\t ACC train:  0.9125\t ACC test:  0.7977777777777778\n",
      "\tEpoch 747: \tAverage Loss:  0.359710205078125\t ACC train:  0.9125\t ACC test:  0.7844444444444445\n",
      "\tEpoch 748: \tAverage Loss:  0.35941424560546875\t ACC train:  0.9125\t ACC test:  0.7866666666666666\n",
      "\tEpoch 749: \tAverage Loss:  0.35941595458984377\t ACC train:  0.925\t ACC test:  0.7955555555555556\n",
      "\tEpoch 750: \tAverage Loss:  0.3595316162109375\t ACC train:  0.9125\t ACC test:  0.7844444444444445\n",
      "\tEpoch 751: \tAverage Loss:  0.35981292724609376\t ACC train:  0.925\t ACC test:  0.7955555555555556\n",
      "\tEpoch 752: \tAverage Loss:  0.3589319152832031\t ACC train:  0.9\t ACC test:  0.7844444444444445\n",
      "\tEpoch 753: \tAverage Loss:  0.3598105163574219\t ACC train:  0.925\t ACC test:  0.78\n",
      "\tEpoch 754: \tAverage Loss:  0.35891964721679687\t ACC train:  0.925\t ACC test:  0.8\n",
      "\tEpoch 755: \tAverage Loss:  0.35847613525390626\t ACC train:  0.925\t ACC test:  0.7955555555555556\n",
      "\tEpoch 756: \tAverage Loss:  0.35914743041992186\t ACC train:  0.925\t ACC test:  0.7977777777777778\n",
      "\tEpoch 757: \tAverage Loss:  0.3586077880859375\t ACC train:  0.9125\t ACC test:  0.8\n",
      "\tEpoch 758: \tAverage Loss:  0.35865594482421875\t ACC train:  0.925\t ACC test:  0.7933333333333333\n",
      "\tEpoch 759: \tAverage Loss:  0.358075439453125\t ACC train:  0.9\t ACC test:  0.8022222222222222\n",
      "\tEpoch 760: \tAverage Loss:  0.35782528686523435\t ACC train:  0.925\t ACC test:  0.8022222222222222\n",
      "\tEpoch 761: \tAverage Loss:  0.3581685485839844\t ACC train:  0.9125\t ACC test:  0.8\n",
      "\tEpoch 762: \tAverage Loss:  0.3577975158691406\t ACC train:  0.925\t ACC test:  0.8044444444444444\n",
      "\tEpoch 763: \tAverage Loss:  0.35792587280273436\t ACC train:  0.9\t ACC test:  0.8022222222222222\n",
      "\tEpoch 764: \tAverage Loss:  0.35749569702148437\t ACC train:  0.8875\t ACC test:  0.7955555555555556\n",
      "\tEpoch 765: \tAverage Loss:  0.35912130737304687\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 766: \tAverage Loss:  0.35745925903320314\t ACC train:  0.9\t ACC test:  0.8022222222222222\n",
      "\tEpoch 767: \tAverage Loss:  0.35738751220703124\t ACC train:  0.9125\t ACC test:  0.8044444444444444\n",
      "\tEpoch 768: \tAverage Loss:  0.3585009765625\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 769: \tAverage Loss:  0.35724893188476564\t ACC train:  0.8875\t ACC test:  0.8044444444444444\n",
      "\tEpoch 770: \tAverage Loss:  0.35684469604492186\t ACC train:  0.8875\t ACC test:  0.7933333333333333\n",
      "\tEpoch 771: \tAverage Loss:  0.35902972412109374\t ACC train:  0.925\t ACC test:  0.7955555555555556\n",
      "\tEpoch 772: \tAverage Loss:  0.35810433959960936\t ACC train:  0.925\t ACC test:  0.8044444444444444\n",
      "\tEpoch 773: \tAverage Loss:  0.3570992736816406\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 774: \tAverage Loss:  0.35815631103515627\t ACC train:  0.9\t ACC test:  0.7977777777777778\n",
      "\tEpoch 775: \tAverage Loss:  0.3570666198730469\t ACC train:  0.9\t ACC test:  0.8088888888888889\n",
      "\tEpoch 776: \tAverage Loss:  0.35627481079101564\t ACC train:  0.925\t ACC test:  0.8044444444444444\n",
      "\tEpoch 777: \tAverage Loss:  0.3565914916992188\t ACC train:  0.925\t ACC test:  0.8022222222222222\n",
      "\tEpoch 778: \tAverage Loss:  0.35610568237304685\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 779: \tAverage Loss:  0.3566795654296875\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 780: \tAverage Loss:  0.35620635986328125\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 781: \tAverage Loss:  0.35587286376953126\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 782: \tAverage Loss:  0.35555181884765624\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 783: \tAverage Loss:  0.35602886962890623\t ACC train:  0.8875\t ACC test:  0.8066666666666666\n",
      "\tEpoch 784: \tAverage Loss:  0.3560231323242187\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 785: \tAverage Loss:  0.3552789001464844\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 786: \tAverage Loss:  0.35544525146484374\t ACC train:  0.925\t ACC test:  0.8044444444444444\n",
      "\tEpoch 787: \tAverage Loss:  0.35564498901367186\t ACC train:  0.9125\t ACC test:  0.8066666666666666\n",
      "\tEpoch 788: \tAverage Loss:  0.35571417236328123\t ACC train:  0.9\t ACC test:  0.8\n",
      "\tEpoch 789: \tAverage Loss:  0.3550301513671875\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 790: \tAverage Loss:  0.3554604797363281\t ACC train:  0.9\t ACC test:  0.8044444444444444\n",
      "\tEpoch 791: \tAverage Loss:  0.35549819946289063\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 792: \tAverage Loss:  0.3550457153320313\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 793: \tAverage Loss:  0.35541424560546875\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 794: \tAverage Loss:  0.3554900817871094\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 795: \tAverage Loss:  0.35476083374023437\t ACC train:  0.9\t ACC test:  0.8088888888888889\n",
      "\tEpoch 796: \tAverage Loss:  0.35497442626953124\t ACC train:  0.9125\t ACC test:  0.8066666666666666\n",
      "\tEpoch 797: \tAverage Loss:  0.35453857421875\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 798: \tAverage Loss:  0.35533441162109375\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 799: \tAverage Loss:  0.35476849365234375\t ACC train:  0.9\t ACC test:  0.82\n",
      "\tEpoch 800: \tAverage Loss:  0.3544544982910156\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 801: \tAverage Loss:  0.35454779052734375\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 802: \tAverage Loss:  0.35480859375\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 803: \tAverage Loss:  0.3544889831542969\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 804: \tAverage Loss:  0.353912841796875\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 805: \tAverage Loss:  0.354543212890625\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 806: \tAverage Loss:  0.3536932678222656\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 807: \tAverage Loss:  0.35399502563476565\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 808: \tAverage Loss:  0.3540330810546875\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 809: \tAverage Loss:  0.35368157958984375\t ACC train:  0.8875\t ACC test:  0.8222222222222222\n",
      "\tEpoch 810: \tAverage Loss:  0.3535115966796875\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 811: \tAverage Loss:  0.3540989990234375\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 812: \tAverage Loss:  0.35350665283203125\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 813: \tAverage Loss:  0.3534872131347656\t ACC train:  0.9\t ACC test:  0.82\n",
      "\tEpoch 814: \tAverage Loss:  0.353591796875\t ACC train:  0.9\t ACC test:  0.82\n",
      "\tEpoch 815: \tAverage Loss:  0.3534162292480469\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 816: \tAverage Loss:  0.3533691101074219\t ACC train:  0.9\t ACC test:  0.8044444444444444\n",
      "\tEpoch 817: \tAverage Loss:  0.3531269226074219\t ACC train:  0.8875\t ACC test:  0.8133333333333334\n",
      "\tEpoch 818: \tAverage Loss:  0.35317929077148436\t ACC train:  0.8875\t ACC test:  0.8133333333333334\n",
      "\tEpoch 819: \tAverage Loss:  0.3535334167480469\t ACC train:  0.9\t ACC test:  0.8088888888888889\n",
      "\tEpoch 820: \tAverage Loss:  0.35311032104492185\t ACC train:  0.875\t ACC test:  0.8133333333333334\n",
      "\tEpoch 821: \tAverage Loss:  0.35260009765625\t ACC train:  0.8875\t ACC test:  0.8155555555555556\n",
      "\tEpoch 822: \tAverage Loss:  0.3532501525878906\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 823: \tAverage Loss:  0.3526795654296875\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 824: \tAverage Loss:  0.3529057006835937\t ACC train:  0.8875\t ACC test:  0.8111111111111111\n",
      "\tEpoch 825: \tAverage Loss:  0.35281192016601565\t ACC train:  0.8875\t ACC test:  0.8177777777777778\n",
      "\tEpoch 826: \tAverage Loss:  0.3527930603027344\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 827: \tAverage Loss:  0.35224554443359374\t ACC train:  0.8875\t ACC test:  0.8133333333333334\n",
      "\tEpoch 828: \tAverage Loss:  0.352176025390625\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 829: \tAverage Loss:  0.35247076416015627\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 830: \tAverage Loss:  0.3517728271484375\t ACC train:  0.8875\t ACC test:  0.8133333333333334\n",
      "\tEpoch 831: \tAverage Loss:  0.35195660400390627\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 832: \tAverage Loss:  0.3521796875\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 833: \tAverage Loss:  0.3516549072265625\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 834: \tAverage Loss:  0.3517019958496094\t ACC train:  0.9\t ACC test:  0.8088888888888889\n",
      "\tEpoch 835: \tAverage Loss:  0.35158572387695314\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 836: \tAverage Loss:  0.35138189697265626\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 837: \tAverage Loss:  0.35157308959960937\t ACC train:  0.9\t ACC test:  0.8222222222222222\n",
      "\tEpoch 838: \tAverage Loss:  0.3517039489746094\t ACC train:  0.9\t ACC test:  0.82\n",
      "\tEpoch 839: \tAverage Loss:  0.35133071899414064\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 840: \tAverage Loss:  0.35106491088867187\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 841: \tAverage Loss:  0.35147796630859374\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 842: \tAverage Loss:  0.351342529296875\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 843: \tAverage Loss:  0.3509844970703125\t ACC train:  0.9\t ACC test:  0.8244444444444444\n",
      "\tEpoch 844: \tAverage Loss:  0.3511647644042969\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 845: \tAverage Loss:  0.3509085693359375\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 846: \tAverage Loss:  0.35099197387695313\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 847: \tAverage Loss:  0.3508231506347656\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 848: \tAverage Loss:  0.3511942138671875\t ACC train:  0.8875\t ACC test:  0.8177777777777778\n",
      "\tEpoch 849: \tAverage Loss:  0.3507434387207031\t ACC train:  0.9\t ACC test:  0.8044444444444444\n",
      "\tEpoch 850: \tAverage Loss:  0.35064959716796873\t ACC train:  0.9\t ACC test:  0.82\n",
      "\tEpoch 851: \tAverage Loss:  0.350966552734375\t ACC train:  0.9125\t ACC test:  0.8066666666666666\n",
      "\tEpoch 852: \tAverage Loss:  0.35042132568359374\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 853: \tAverage Loss:  0.3509190979003906\t ACC train:  0.8875\t ACC test:  0.8155555555555556\n",
      "\tEpoch 854: \tAverage Loss:  0.3507724609375\t ACC train:  0.9\t ACC test:  0.8088888888888889\n",
      "\tEpoch 855: \tAverage Loss:  0.35052359008789064\t ACC train:  0.9125\t ACC test:  0.8066666666666666\n",
      "\tEpoch 856: \tAverage Loss:  0.350775390625\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 857: \tAverage Loss:  0.3509093017578125\t ACC train:  0.9\t ACC test:  0.8044444444444444\n",
      "\tEpoch 858: \tAverage Loss:  0.35007940673828125\t ACC train:  0.875\t ACC test:  0.8222222222222222\n",
      "\tEpoch 859: \tAverage Loss:  0.35167245483398435\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 860: \tAverage Loss:  0.35152603149414063\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 861: \tAverage Loss:  0.3500508728027344\t ACC train:  0.9125\t ACC test:  0.8066666666666666\n",
      "\tEpoch 862: \tAverage Loss:  0.35034573364257815\t ACC train:  0.8875\t ACC test:  0.8133333333333334\n",
      "\tEpoch 863: \tAverage Loss:  0.34990899658203123\t ACC train:  0.8875\t ACC test:  0.8155555555555556\n",
      "\tEpoch 864: \tAverage Loss:  0.3503585205078125\t ACC train:  0.9\t ACC test:  0.8088888888888889\n",
      "\tEpoch 865: \tAverage Loss:  0.3499189147949219\t ACC train:  0.9\t ACC test:  0.8088888888888889\n",
      "\tEpoch 866: \tAverage Loss:  0.349679443359375\t ACC train:  0.8875\t ACC test:  0.8155555555555556\n",
      "\tEpoch 867: \tAverage Loss:  0.3496466064453125\t ACC train:  0.925\t ACC test:  0.8177777777777778\n",
      "\tEpoch 868: \tAverage Loss:  0.3496393737792969\t ACC train:  0.925\t ACC test:  0.82\n",
      "\tEpoch 869: \tAverage Loss:  0.34967266845703127\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 870: \tAverage Loss:  0.349796875\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 871: \tAverage Loss:  0.3497883605957031\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 872: \tAverage Loss:  0.34973654174804686\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 873: \tAverage Loss:  0.3493236083984375\t ACC train:  0.9125\t ACC test:  0.82\n",
      "\tEpoch 874: \tAverage Loss:  0.3489980773925781\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 875: \tAverage Loss:  0.3490234069824219\t ACC train:  0.925\t ACC test:  0.8088888888888889\n",
      "\tEpoch 876: \tAverage Loss:  0.34918341064453123\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 877: \tAverage Loss:  0.3486910400390625\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 878: \tAverage Loss:  0.3489799499511719\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 879: \tAverage Loss:  0.34911993408203124\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 880: \tAverage Loss:  0.34893045043945314\t ACC train:  0.9\t ACC test:  0.8066666666666666\n",
      "\tEpoch 881: \tAverage Loss:  0.3485758056640625\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 882: \tAverage Loss:  0.34847021484375\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 883: \tAverage Loss:  0.34839157104492186\t ACC train:  0.9125\t ACC test:  0.8022222222222222\n",
      "\tEpoch 884: \tAverage Loss:  0.3486171264648438\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 885: \tAverage Loss:  0.3489749755859375\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 886: \tAverage Loss:  0.34881396484375\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 887: \tAverage Loss:  0.3482061462402344\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 888: \tAverage Loss:  0.34857492065429685\t ACC train:  0.9125\t ACC test:  0.8066666666666666\n",
      "\tEpoch 889: \tAverage Loss:  0.3484923706054687\t ACC train:  0.9125\t ACC test:  0.8177777777777778\n",
      "\tEpoch 890: \tAverage Loss:  0.3477724914550781\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 891: \tAverage Loss:  0.348497314453125\t ACC train:  0.8875\t ACC test:  0.8111111111111111\n",
      "\tEpoch 892: \tAverage Loss:  0.34918276977539064\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 893: \tAverage Loss:  0.3485231323242188\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 894: \tAverage Loss:  0.34803033447265624\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 895: \tAverage Loss:  0.3486848449707031\t ACC train:  0.9125\t ACC test:  0.8177777777777778\n",
      "\tEpoch 896: \tAverage Loss:  0.34846856689453126\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 897: \tAverage Loss:  0.34800051879882815\t ACC train:  0.9125\t ACC test:  0.8066666666666666\n",
      "\tEpoch 898: \tAverage Loss:  0.34844647216796876\t ACC train:  0.9\t ACC test:  0.8044444444444444\n",
      "\tEpoch 899: \tAverage Loss:  0.3478071594238281\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 900: \tAverage Loss:  0.34786172485351563\t ACC train:  0.925\t ACC test:  0.8044444444444444\n",
      "\tEpoch 901: \tAverage Loss:  0.34838803100585936\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 902: \tAverage Loss:  0.3479372253417969\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 903: \tAverage Loss:  0.34726678466796873\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 904: \tAverage Loss:  0.3486322937011719\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 905: \tAverage Loss:  0.34858639526367186\t ACC train:  0.925\t ACC test:  0.8111111111111111\n",
      "\tEpoch 906: \tAverage Loss:  0.3475706787109375\t ACC train:  0.925\t ACC test:  0.8155555555555556\n",
      "\tEpoch 907: \tAverage Loss:  0.34727627563476565\t ACC train:  0.9125\t ACC test:  0.8044444444444444\n",
      "\tEpoch 908: \tAverage Loss:  0.34836593627929685\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 909: \tAverage Loss:  0.347924072265625\t ACC train:  0.925\t ACC test:  0.8222222222222222\n",
      "\tEpoch 910: \tAverage Loss:  0.34732455444335936\t ACC train:  0.9\t ACC test:  0.82\n",
      "\tEpoch 911: \tAverage Loss:  0.34738357543945314\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 912: \tAverage Loss:  0.3475497131347656\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 913: \tAverage Loss:  0.34749822998046875\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 914: \tAverage Loss:  0.34646954345703124\t ACC train:  0.875\t ACC test:  0.8088888888888889\n",
      "\tEpoch 915: \tAverage Loss:  0.34732733154296874\t ACC train:  0.925\t ACC test:  0.8177777777777778\n",
      "\tEpoch 916: \tAverage Loss:  0.3482447509765625\t ACC train:  0.925\t ACC test:  0.8022222222222222\n",
      "\tEpoch 917: \tAverage Loss:  0.34765960693359377\t ACC train:  0.9125\t ACC test:  0.8155555555555556\n",
      "\tEpoch 918: \tAverage Loss:  0.3468212890625\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 919: \tAverage Loss:  0.3500444641113281\t ACC train:  0.9\t ACC test:  0.8044444444444444\n",
      "\tEpoch 920: \tAverage Loss:  0.3476085510253906\t ACC train:  0.925\t ACC test:  0.8022222222222222\n",
      "\tEpoch 921: \tAverage Loss:  0.34716595458984373\t ACC train:  0.925\t ACC test:  0.8088888888888889\n",
      "\tEpoch 922: \tAverage Loss:  0.34678854370117185\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 923: \tAverage Loss:  0.34695120239257815\t ACC train:  0.925\t ACC test:  0.8066666666666666\n",
      "\tEpoch 924: \tAverage Loss:  0.3462895202636719\t ACC train:  0.9375\t ACC test:  0.8088888888888889\n",
      "\tEpoch 925: \tAverage Loss:  0.34686761474609373\t ACC train:  0.925\t ACC test:  0.8311111111111111\n",
      "\tEpoch 926: \tAverage Loss:  0.3464494323730469\t ACC train:  0.925\t ACC test:  0.8088888888888889\n",
      "\tEpoch 927: \tAverage Loss:  0.3469337768554687\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 928: \tAverage Loss:  0.3461348571777344\t ACC train:  0.925\t ACC test:  0.8088888888888889\n",
      "\tEpoch 929: \tAverage Loss:  0.346341796875\t ACC train:  0.925\t ACC test:  0.8111111111111111\n",
      "\tEpoch 930: \tAverage Loss:  0.3465191955566406\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 931: \tAverage Loss:  0.34727783203125\t ACC train:  0.9375\t ACC test:  0.8066666666666666\n",
      "\tEpoch 932: \tAverage Loss:  0.3463387451171875\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 933: \tAverage Loss:  0.34578289794921874\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 934: \tAverage Loss:  0.3462171325683594\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 935: \tAverage Loss:  0.3461780700683594\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 936: \tAverage Loss:  0.34588775634765623\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 937: \tAverage Loss:  0.34619009399414064\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 938: \tAverage Loss:  0.34646759033203123\t ACC train:  0.9375\t ACC test:  0.8133333333333334\n",
      "\tEpoch 939: \tAverage Loss:  0.3458143005371094\t ACC train:  0.925\t ACC test:  0.8177777777777778\n",
      "\tEpoch 940: \tAverage Loss:  0.34565695190429685\t ACC train:  0.925\t ACC test:  0.8111111111111111\n",
      "\tEpoch 941: \tAverage Loss:  0.34588946533203124\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 942: \tAverage Loss:  0.34573590087890627\t ACC train:  0.8875\t ACC test:  0.8066666666666666\n",
      "\tEpoch 943: \tAverage Loss:  0.3459969482421875\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 944: \tAverage Loss:  0.3457099304199219\t ACC train:  0.9125\t ACC test:  0.8133333333333334\n",
      "\tEpoch 945: \tAverage Loss:  0.34593264770507814\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 946: \tAverage Loss:  0.34498464965820314\t ACC train:  0.925\t ACC test:  0.8155555555555556\n",
      "\tEpoch 947: \tAverage Loss:  0.3453715515136719\t ACC train:  0.9375\t ACC test:  0.8088888888888889\n",
      "\tEpoch 948: \tAverage Loss:  0.34582110595703125\t ACC train:  0.925\t ACC test:  0.8044444444444444\n",
      "\tEpoch 949: \tAverage Loss:  0.34593695068359376\t ACC train:  0.925\t ACC test:  0.8088888888888889\n",
      "\tEpoch 950: \tAverage Loss:  0.34503640747070313\t ACC train:  0.925\t ACC test:  0.8111111111111111\n",
      "\tEpoch 951: \tAverage Loss:  0.344934326171875\t ACC train:  0.9\t ACC test:  0.8155555555555556\n",
      "\tEpoch 952: \tAverage Loss:  0.345110107421875\t ACC train:  0.9125\t ACC test:  0.7977777777777778\n",
      "\tEpoch 953: \tAverage Loss:  0.34523587036132813\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 954: \tAverage Loss:  0.3448469543457031\t ACC train:  0.925\t ACC test:  0.8044444444444444\n",
      "\tEpoch 955: \tAverage Loss:  0.3454395751953125\t ACC train:  0.925\t ACC test:  0.8066666666666666\n",
      "\tEpoch 956: \tAverage Loss:  0.3452888488769531\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 957: \tAverage Loss:  0.3450361022949219\t ACC train:  0.9375\t ACC test:  0.8155555555555556\n",
      "\tEpoch 958: \tAverage Loss:  0.344540771484375\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 959: \tAverage Loss:  0.34507681274414065\t ACC train:  0.925\t ACC test:  0.8066666666666666\n",
      "\tEpoch 960: \tAverage Loss:  0.3448202209472656\t ACC train:  0.9375\t ACC test:  0.8022222222222222\n",
      "\tEpoch 961: \tAverage Loss:  0.34488577270507814\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 962: \tAverage Loss:  0.3456238098144531\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 963: \tAverage Loss:  0.34449627685546874\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 964: \tAverage Loss:  0.34482305908203126\t ACC train:  0.9375\t ACC test:  0.8066666666666666\n",
      "\tEpoch 965: \tAverage Loss:  0.3449007568359375\t ACC train:  0.925\t ACC test:  0.8088888888888889\n",
      "\tEpoch 966: \tAverage Loss:  0.3448558349609375\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 967: \tAverage Loss:  0.3441390380859375\t ACC train:  0.925\t ACC test:  0.8088888888888889\n",
      "\tEpoch 968: \tAverage Loss:  0.34471798706054685\t ACC train:  0.925\t ACC test:  0.8022222222222222\n",
      "\tEpoch 969: \tAverage Loss:  0.34489599609375\t ACC train:  0.925\t ACC test:  0.8022222222222222\n",
      "\tEpoch 970: \tAverage Loss:  0.3447565002441406\t ACC train:  0.925\t ACC test:  0.8111111111111111\n",
      "\tEpoch 971: \tAverage Loss:  0.34444064331054686\t ACC train:  0.9375\t ACC test:  0.82\n",
      "\tEpoch 972: \tAverage Loss:  0.34509591674804685\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 973: \tAverage Loss:  0.34453134155273435\t ACC train:  0.925\t ACC test:  0.8\n",
      "\tEpoch 974: \tAverage Loss:  0.34403179931640626\t ACC train:  0.95\t ACC test:  0.8155555555555556\n",
      "\tEpoch 975: \tAverage Loss:  0.3444724731445313\t ACC train:  0.9375\t ACC test:  0.8044444444444444\n",
      "\tEpoch 976: \tAverage Loss:  0.34449063110351563\t ACC train:  0.925\t ACC test:  0.8066666666666666\n",
      "\tEpoch 977: \tAverage Loss:  0.3442008361816406\t ACC train:  0.925\t ACC test:  0.8155555555555556\n",
      "\tEpoch 978: \tAverage Loss:  0.34407351684570314\t ACC train:  0.925\t ACC test:  0.8111111111111111\n",
      "\tEpoch 979: \tAverage Loss:  0.34446258544921876\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 980: \tAverage Loss:  0.3440303039550781\t ACC train:  0.925\t ACC test:  0.8\n",
      "\tEpoch 981: \tAverage Loss:  0.3443661804199219\t ACC train:  0.9375\t ACC test:  0.8088888888888889\n",
      "\tEpoch 982: \tAverage Loss:  0.34369793701171875\t ACC train:  0.925\t ACC test:  0.8177777777777778\n",
      "\tEpoch 983: \tAverage Loss:  0.344081298828125\t ACC train:  0.9375\t ACC test:  0.8244444444444444\n",
      "\tEpoch 984: \tAverage Loss:  0.3438943176269531\t ACC train:  0.9375\t ACC test:  0.8088888888888889\n",
      "\tEpoch 985: \tAverage Loss:  0.3445924072265625\t ACC train:  0.925\t ACC test:  0.8155555555555556\n",
      "\tEpoch 986: \tAverage Loss:  0.3430615844726562\t ACC train:  0.9375\t ACC test:  0.8155555555555556\n",
      "\tEpoch 987: \tAverage Loss:  0.34418319702148437\t ACC train:  0.9125\t ACC test:  0.7977777777777778\n",
      "\tEpoch 988: \tAverage Loss:  0.3440498657226562\t ACC train:  0.9375\t ACC test:  0.82\n",
      "\tEpoch 989: \tAverage Loss:  0.3436770935058594\t ACC train:  0.9375\t ACC test:  0.8066666666666666\n",
      "\tEpoch 990: \tAverage Loss:  0.3431744689941406\t ACC train:  0.9375\t ACC test:  0.8177777777777778\n",
      "\tEpoch 991: \tAverage Loss:  0.34363040161132813\t ACC train:  0.925\t ACC test:  0.82\n",
      "\tEpoch 992: \tAverage Loss:  0.34462326049804687\t ACC train:  0.9375\t ACC test:  0.8088888888888889\n",
      "\tEpoch 993: \tAverage Loss:  0.34318960571289064\t ACC train:  0.9375\t ACC test:  0.82\n",
      "\tEpoch 994: \tAverage Loss:  0.3429299926757812\t ACC train:  0.9375\t ACC test:  0.82\n",
      "\tEpoch 995: \tAverage Loss:  0.34319085693359375\t ACC train:  0.9375\t ACC test:  0.8177777777777778\n",
      "\tEpoch 996: \tAverage Loss:  0.34303802490234375\t ACC train:  0.9375\t ACC test:  0.8177777777777778\n",
      "\tEpoch 997: \tAverage Loss:  0.3428704833984375\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 998: \tAverage Loss:  0.34282583618164064\t ACC train:  0.925\t ACC test:  0.8155555555555556\n",
      "\tEpoch 999: \tAverage Loss:  0.342533203125\t ACC train:  0.95\t ACC test:  0.8088888888888889\n",
      "\tEpoch 1000: \tAverage Loss:  0.3432182922363281\t ACC train:  0.9375\t ACC test:  0.8088888888888889\n",
      "\tEpoch 1001: \tAverage Loss:  0.34333450317382813\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1002: \tAverage Loss:  0.3428108825683594\t ACC train:  0.925\t ACC test:  0.8155555555555556\n",
      "\tEpoch 1003: \tAverage Loss:  0.34246905517578125\t ACC train:  0.9375\t ACC test:  0.82\n",
      "\tEpoch 1004: \tAverage Loss:  0.3428188781738281\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1005: \tAverage Loss:  0.3425335693359375\t ACC train:  0.925\t ACC test:  0.8088888888888889\n",
      "\tEpoch 1006: \tAverage Loss:  0.34238275146484376\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1007: \tAverage Loss:  0.34212847900390625\t ACC train:  0.925\t ACC test:  0.8155555555555556\n",
      "\tEpoch 1008: \tAverage Loss:  0.3422894287109375\t ACC train:  0.9375\t ACC test:  0.8022222222222222\n",
      "\tEpoch 1009: \tAverage Loss:  0.34206878662109375\t ACC train:  0.9375\t ACC test:  0.8155555555555556\n",
      "\tEpoch 1010: \tAverage Loss:  0.3418828430175781\t ACC train:  0.95\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1011: \tAverage Loss:  0.3431731262207031\t ACC train:  0.9375\t ACC test:  0.8111111111111111\n",
      "\tEpoch 1012: \tAverage Loss:  0.34261691284179685\t ACC train:  0.9375\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1013: \tAverage Loss:  0.3417695617675781\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1014: \tAverage Loss:  0.3419581604003906\t ACC train:  0.9375\t ACC test:  0.8066666666666666\n",
      "\tEpoch 1015: \tAverage Loss:  0.3439970703125\t ACC train:  0.95\t ACC test:  0.8022222222222222\n",
      "\tEpoch 1016: \tAverage Loss:  0.3424841918945313\t ACC train:  0.9375\t ACC test:  0.8111111111111111\n",
      "\tEpoch 1017: \tAverage Loss:  0.34191537475585937\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1018: \tAverage Loss:  0.3421414794921875\t ACC train:  0.9125\t ACC test:  0.8111111111111111\n",
      "\tEpoch 1019: \tAverage Loss:  0.3423721618652344\t ACC train:  0.925\t ACC test:  0.8088888888888889\n",
      "\tEpoch 1020: \tAverage Loss:  0.3419065551757812\t ACC train:  0.9375\t ACC test:  0.8066666666666666\n",
      "\tEpoch 1021: \tAverage Loss:  0.34129132080078123\t ACC train:  0.925\t ACC test:  0.82\n",
      "\tEpoch 1022: \tAverage Loss:  0.34133950805664065\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1023: \tAverage Loss:  0.3414986572265625\t ACC train:  0.925\t ACC test:  0.82\n",
      "\tEpoch 1024: \tAverage Loss:  0.3420678405761719\t ACC train:  0.9375\t ACC test:  0.8222222222222222\n",
      "\tEpoch 1025: \tAverage Loss:  0.34140792846679685\t ACC train:  0.9375\t ACC test:  0.8066666666666666\n",
      "\tEpoch 1026: \tAverage Loss:  0.34122821044921875\t ACC train:  0.925\t ACC test:  0.7955555555555556\n",
      "\tEpoch 1027: \tAverage Loss:  0.34275314331054685\t ACC train:  0.925\t ACC test:  0.8111111111111111\n",
      "\tEpoch 1028: \tAverage Loss:  0.34147006225585935\t ACC train:  0.9375\t ACC test:  0.8066666666666666\n",
      "\tEpoch 1029: \tAverage Loss:  0.3408162536621094\t ACC train:  0.9375\t ACC test:  0.8155555555555556\n",
      "\tEpoch 1030: \tAverage Loss:  0.3406751708984375\t ACC train:  0.925\t ACC test:  0.8111111111111111\n",
      "\tEpoch 1031: \tAverage Loss:  0.3433956604003906\t ACC train:  0.95\t ACC test:  0.8155555555555556\n",
      "\tEpoch 1032: \tAverage Loss:  0.3410888366699219\t ACC train:  0.925\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1033: \tAverage Loss:  0.3411132507324219\t ACC train:  0.9125\t ACC test:  0.8088888888888889\n",
      "\tEpoch 1034: \tAverage Loss:  0.3414443359375\t ACC train:  0.9375\t ACC test:  0.8111111111111111\n",
      "\tEpoch 1035: \tAverage Loss:  0.34079598999023436\t ACC train:  0.9375\t ACC test:  0.8066666666666666\n",
      "\tEpoch 1036: \tAverage Loss:  0.3403823547363281\t ACC train:  0.9375\t ACC test:  0.8066666666666666\n",
      "\tEpoch 1037: \tAverage Loss:  0.3406099548339844\t ACC train:  0.9375\t ACC test:  0.8088888888888889\n",
      "\tEpoch 1038: \tAverage Loss:  0.3404024963378906\t ACC train:  0.9375\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1039: \tAverage Loss:  0.3412604675292969\t ACC train:  0.9375\t ACC test:  0.8044444444444444\n",
      "\tEpoch 1040: \tAverage Loss:  0.3401654357910156\t ACC train:  0.925\t ACC test:  0.8177777777777778\n",
      "\tEpoch 1041: \tAverage Loss:  0.34026220703125\t ACC train:  0.95\t ACC test:  0.82\n",
      "\tEpoch 1042: \tAverage Loss:  0.3402616271972656\t ACC train:  0.95\t ACC test:  0.8111111111111111\n",
      "\tEpoch 1043: \tAverage Loss:  0.3402523498535156\t ACC train:  0.9375\t ACC test:  0.8111111111111111\n",
      "Stopping early at epoch 1043. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 90\n",
      "\tEpoch 1: \tAverage Loss:  0.8675114135742188\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 2: \tAverage Loss:  0.8612632446289062\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 3: \tAverage Loss:  0.85617431640625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 4: \tAverage Loss:  0.8511150512695312\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 5: \tAverage Loss:  0.8476810913085937\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 6: \tAverage Loss:  0.8444511108398437\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 7: \tAverage Loss:  0.84174169921875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 8: \tAverage Loss:  0.8391500244140625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 9: \tAverage Loss:  0.836423828125\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 10: \tAverage Loss:  0.834161376953125\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  0.8316322631835937\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  0.8292914428710938\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  0.8267777099609375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  0.8246522827148437\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  0.8222821044921875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  0.819704833984375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  0.8176292114257813\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  0.815468994140625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  0.8129654541015625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  0.8111126708984375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  0.8086505737304688\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  0.8066843872070313\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  0.8046868286132812\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  0.8028660278320312\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  0.800861083984375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  0.7991680908203125\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  0.7970913696289063\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  0.79558154296875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  0.7938655395507812\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  0.792179931640625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  0.790573974609375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  0.7892780151367188\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  0.7877239990234375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  0.7861278076171875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  0.784672607421875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  0.784056396484375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  0.7827937622070312\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  0.7812492065429687\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  0.779898681640625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  0.779054443359375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  0.7780547485351562\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  0.776961669921875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  0.7761758422851562\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  0.7744520263671875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  0.774373291015625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  0.77239501953125\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  0.7718678588867187\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  0.7711190795898437\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  0.769358154296875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  0.7690955200195313\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  0.7673359375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  0.768004638671875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.76642529296875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  0.765455810546875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  0.76532666015625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  0.7644617919921874\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  0.7636400146484374\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  0.7606854858398437\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  0.7612037353515625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  0.7615402221679688\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  0.7600017700195313\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  0.7597500610351563\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  0.7584421997070312\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  0.7581158447265625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  0.7564034423828125\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.7573716430664063\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  0.7579205322265625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  0.7543175659179687\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  0.7551323852539062\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  0.7553843994140625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  0.7538035888671875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  0.7515474853515625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  0.7505712890625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  0.7495786743164062\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  0.75034716796875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  0.7507868041992187\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  0.7485265502929688\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  0.747109130859375\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  0.7483466796875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.7467176513671875\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  0.7479888305664063\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  0.7444488525390625\t ACC train:  0.5555555555555556\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  0.7442386474609375\t ACC train:  0.5555555555555556\t ACC test:  0.4911111111111111\n",
      "\tEpoch 84: \tAverage Loss:  0.7458939819335938\t ACC train:  0.5555555555555556\t ACC test:  0.4888888888888889\n",
      "\tEpoch 85: \tAverage Loss:  0.7410220336914063\t ACC train:  0.5555555555555556\t ACC test:  0.49777777777777776\n",
      "\tEpoch 86: \tAverage Loss:  0.7400513916015625\t ACC train:  0.5555555555555556\t ACC test:  0.4888888888888889\n",
      "\tEpoch 87: \tAverage Loss:  0.7428590087890625\t ACC train:  0.5555555555555556\t ACC test:  0.49333333333333335\n",
      "\tEpoch 88: \tAverage Loss:  0.7381286010742187\t ACC train:  0.5555555555555556\t ACC test:  0.4955555555555556\n",
      "\tEpoch 89: \tAverage Loss:  0.7385479125976563\t ACC train:  0.5555555555555556\t ACC test:  0.5\n",
      "\tEpoch 90: \tAverage Loss:  0.7389329833984375\t ACC train:  0.5666666666666667\t ACC test:  0.5066666666666667\n",
      "\tEpoch 91: \tAverage Loss:  0.7368526000976563\t ACC train:  0.5777777777777777\t ACC test:  0.5088888888888888\n",
      "\tEpoch 92: \tAverage Loss:  0.74035009765625\t ACC train:  0.5888888888888889\t ACC test:  0.5155555555555555\n",
      "\tEpoch 93: \tAverage Loss:  0.736021240234375\t ACC train:  0.6\t ACC test:  0.5266666666666666\n",
      "\tEpoch 94: \tAverage Loss:  0.737075927734375\t ACC train:  0.6111111111111112\t ACC test:  0.5333333333333333\n",
      "\tEpoch 95: \tAverage Loss:  0.7343463745117188\t ACC train:  0.6222222222222222\t ACC test:  0.54\n",
      "\tEpoch 96: \tAverage Loss:  0.7371871337890625\t ACC train:  0.6444444444444445\t ACC test:  0.5577777777777778\n",
      "\tEpoch 97: \tAverage Loss:  0.733740234375\t ACC train:  0.6555555555555556\t ACC test:  0.5488888888888889\n",
      "\tEpoch 98: \tAverage Loss:  0.7325810546875\t ACC train:  0.6444444444444445\t ACC test:  0.5711111111111111\n",
      "\tEpoch 99: \tAverage Loss:  0.7316414794921875\t ACC train:  0.6888888888888889\t ACC test:  0.58\n",
      "\tEpoch 100: \tAverage Loss:  0.7316940307617188\t ACC train:  0.6777777777777778\t ACC test:  0.5844444444444444\n",
      "\tEpoch 101: \tAverage Loss:  0.7239563598632812\t ACC train:  0.7111111111111111\t ACC test:  0.6044444444444445\n",
      "\tEpoch 102: \tAverage Loss:  0.7243242797851562\t ACC train:  0.7222222222222222\t ACC test:  0.6044444444444445\n",
      "\tEpoch 103: \tAverage Loss:  0.72339794921875\t ACC train:  0.7111111111111111\t ACC test:  0.6044444444444445\n",
      "\tEpoch 104: \tAverage Loss:  0.7219065551757813\t ACC train:  0.7222222222222222\t ACC test:  0.6088888888888889\n",
      "\tEpoch 105: \tAverage Loss:  0.7196197509765625\t ACC train:  0.7222222222222222\t ACC test:  0.6333333333333333\n",
      "\tEpoch 106: \tAverage Loss:  0.7219113159179688\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 107: \tAverage Loss:  0.7209805908203125\t ACC train:  0.7333333333333333\t ACC test:  0.6311111111111111\n",
      "\tEpoch 108: \tAverage Loss:  0.7235341796875\t ACC train:  0.7111111111111111\t ACC test:  0.6288888888888889\n",
      "\tEpoch 109: \tAverage Loss:  0.7178353881835937\t ACC train:  0.6777777777777778\t ACC test:  0.6466666666666666\n",
      "\tEpoch 110: \tAverage Loss:  0.71743505859375\t ACC train:  0.7\t ACC test:  0.6466666666666666\n",
      "\tEpoch 111: \tAverage Loss:  0.7125504760742187\t ACC train:  0.7111111111111111\t ACC test:  0.6511111111111111\n",
      "\tEpoch 112: \tAverage Loss:  0.7084076538085937\t ACC train:  0.7\t ACC test:  0.6511111111111111\n",
      "\tEpoch 113: \tAverage Loss:  0.70316064453125\t ACC train:  0.7\t ACC test:  0.6511111111111111\n",
      "\tEpoch 114: \tAverage Loss:  0.7134920654296875\t ACC train:  0.7\t ACC test:  0.6511111111111111\n",
      "\tEpoch 115: \tAverage Loss:  0.7060706787109375\t ACC train:  0.6777777777777778\t ACC test:  0.6488888888888888\n",
      "\tEpoch 116: \tAverage Loss:  0.7005485229492188\t ACC train:  0.7\t ACC test:  0.6555555555555556\n",
      "\tEpoch 117: \tAverage Loss:  0.7111304321289063\t ACC train:  0.7\t ACC test:  0.6466666666666666\n",
      "\tEpoch 118: \tAverage Loss:  0.7043778686523438\t ACC train:  0.6888888888888889\t ACC test:  0.6488888888888888\n",
      "\tEpoch 119: \tAverage Loss:  0.6997054443359375\t ACC train:  0.7\t ACC test:  0.64\n",
      "\tEpoch 120: \tAverage Loss:  0.6961377563476563\t ACC train:  0.7\t ACC test:  0.6422222222222222\n",
      "\tEpoch 121: \tAverage Loss:  0.695456298828125\t ACC train:  0.6888888888888889\t ACC test:  0.6466666666666666\n",
      "\tEpoch 122: \tAverage Loss:  0.6964813842773437\t ACC train:  0.7\t ACC test:  0.6488888888888888\n",
      "\tEpoch 123: \tAverage Loss:  0.6861046142578126\t ACC train:  0.6777777777777778\t ACC test:  0.6488888888888888\n",
      "\tEpoch 124: \tAverage Loss:  0.6811829833984375\t ACC train:  0.6666666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 125: \tAverage Loss:  0.6887913208007812\t ACC train:  0.7\t ACC test:  0.6488888888888888\n",
      "\tEpoch 126: \tAverage Loss:  0.6840400390625\t ACC train:  0.6777777777777778\t ACC test:  0.6466666666666666\n",
      "\tEpoch 127: \tAverage Loss:  0.6734985961914063\t ACC train:  0.7111111111111111\t ACC test:  0.6466666666666666\n",
      "\tEpoch 128: \tAverage Loss:  0.6708251953125\t ACC train:  0.7\t ACC test:  0.64\n",
      "\tEpoch 129: \tAverage Loss:  0.6660592651367188\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 130: \tAverage Loss:  0.6736261596679688\t ACC train:  0.7222222222222222\t ACC test:  0.6533333333333333\n",
      "\tEpoch 131: \tAverage Loss:  0.6698490600585938\t ACC train:  0.7\t ACC test:  0.6466666666666666\n",
      "\tEpoch 132: \tAverage Loss:  0.6648721923828125\t ACC train:  0.7111111111111111\t ACC test:  0.6533333333333333\n",
      "\tEpoch 133: \tAverage Loss:  0.6644200439453125\t ACC train:  0.6777777777777778\t ACC test:  0.6577777777777778\n",
      "\tEpoch 134: \tAverage Loss:  0.67202099609375\t ACC train:  0.7111111111111111\t ACC test:  0.6533333333333333\n",
      "\tEpoch 135: \tAverage Loss:  0.6455105590820313\t ACC train:  0.7111111111111111\t ACC test:  0.6466666666666666\n",
      "\tEpoch 136: \tAverage Loss:  0.6461177978515625\t ACC train:  0.7111111111111111\t ACC test:  0.6644444444444444\n",
      "\tEpoch 137: \tAverage Loss:  0.6438724365234375\t ACC train:  0.6888888888888889\t ACC test:  0.6622222222222223\n",
      "\tEpoch 138: \tAverage Loss:  0.653412109375\t ACC train:  0.6777777777777778\t ACC test:  0.6422222222222222\n",
      "\tEpoch 139: \tAverage Loss:  0.6387482299804688\t ACC train:  0.7\t ACC test:  0.6511111111111111\n",
      "\tEpoch 140: \tAverage Loss:  0.6446727905273437\t ACC train:  0.6888888888888889\t ACC test:  0.6555555555555556\n",
      "\tEpoch 141: \tAverage Loss:  0.6464627685546875\t ACC train:  0.7\t ACC test:  0.6466666666666666\n",
      "\tEpoch 142: \tAverage Loss:  0.6342607421875\t ACC train:  0.7\t ACC test:  0.6555555555555556\n",
      "\tEpoch 143: \tAverage Loss:  0.6338005981445313\t ACC train:  0.6888888888888889\t ACC test:  0.6466666666666666\n",
      "\tEpoch 144: \tAverage Loss:  0.6231026000976563\t ACC train:  0.6666666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 145: \tAverage Loss:  0.6299797973632812\t ACC train:  0.7111111111111111\t ACC test:  0.6244444444444445\n",
      "\tEpoch 146: \tAverage Loss:  0.622678955078125\t ACC train:  0.7222222222222222\t ACC test:  0.6511111111111111\n",
      "\tEpoch 147: \tAverage Loss:  0.6241580200195312\t ACC train:  0.7111111111111111\t ACC test:  0.6488888888888888\n",
      "\tEpoch 148: \tAverage Loss:  0.612963134765625\t ACC train:  0.7\t ACC test:  0.6444444444444445\n",
      "\tEpoch 149: \tAverage Loss:  0.603522216796875\t ACC train:  0.6777777777777778\t ACC test:  0.6511111111111111\n",
      "\tEpoch 150: \tAverage Loss:  0.622863525390625\t ACC train:  0.7\t ACC test:  0.64\n",
      "\tEpoch 151: \tAverage Loss:  0.604784423828125\t ACC train:  0.7\t ACC test:  0.6444444444444445\n",
      "\tEpoch 152: \tAverage Loss:  0.6031156005859375\t ACC train:  0.6666666666666666\t ACC test:  0.6488888888888888\n",
      "\tEpoch 153: \tAverage Loss:  0.609226318359375\t ACC train:  0.7111111111111111\t ACC test:  0.6488888888888888\n",
      "\tEpoch 154: \tAverage Loss:  0.5976904907226562\t ACC train:  0.7\t ACC test:  0.6422222222222222\n",
      "\tEpoch 155: \tAverage Loss:  0.5948817749023437\t ACC train:  0.6888888888888889\t ACC test:  0.6422222222222222\n",
      "\tEpoch 156: \tAverage Loss:  0.5937488403320312\t ACC train:  0.6777777777777778\t ACC test:  0.6488888888888888\n",
      "\tEpoch 157: \tAverage Loss:  0.5866376342773437\t ACC train:  0.6666666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 158: \tAverage Loss:  0.5789442749023438\t ACC train:  0.6555555555555556\t ACC test:  0.6444444444444445\n",
      "\tEpoch 159: \tAverage Loss:  0.5907060546875\t ACC train:  0.6666666666666666\t ACC test:  0.6155555555555555\n",
      "\tEpoch 160: \tAverage Loss:  0.5808619995117188\t ACC train:  0.7111111111111111\t ACC test:  0.6422222222222222\n",
      "\tEpoch 161: \tAverage Loss:  0.569575927734375\t ACC train:  0.6777777777777778\t ACC test:  0.6511111111111111\n",
      "\tEpoch 162: \tAverage Loss:  0.5766055908203125\t ACC train:  0.7\t ACC test:  0.6377777777777778\n",
      "\tEpoch 163: \tAverage Loss:  0.577185302734375\t ACC train:  0.6333333333333333\t ACC test:  0.6577777777777778\n",
      "\tEpoch 164: \tAverage Loss:  0.5670309448242188\t ACC train:  0.7\t ACC test:  0.6422222222222222\n",
      "\tEpoch 165: \tAverage Loss:  0.570311279296875\t ACC train:  0.7111111111111111\t ACC test:  0.6266666666666667\n",
      "\tEpoch 166: \tAverage Loss:  0.563271728515625\t ACC train:  0.7111111111111111\t ACC test:  0.64\n",
      "\tEpoch 167: \tAverage Loss:  0.5671461181640625\t ACC train:  0.6777777777777778\t ACC test:  0.6355555555555555\n",
      "\tEpoch 168: \tAverage Loss:  0.5635761108398437\t ACC train:  0.7\t ACC test:  0.64\n",
      "\tEpoch 169: \tAverage Loss:  0.5565582275390625\t ACC train:  0.6555555555555556\t ACC test:  0.6266666666666667\n",
      "\tEpoch 170: \tAverage Loss:  0.5539823608398438\t ACC train:  0.7111111111111111\t ACC test:  0.6333333333333333\n",
      "\tEpoch 171: \tAverage Loss:  0.5565394287109375\t ACC train:  0.6888888888888889\t ACC test:  0.6244444444444445\n",
      "\tEpoch 172: \tAverage Loss:  0.5445839233398437\t ACC train:  0.6777777777777778\t ACC test:  0.6266666666666667\n",
      "\tEpoch 173: \tAverage Loss:  0.5488883056640625\t ACC train:  0.6666666666666666\t ACC test:  0.6422222222222222\n",
      "\tEpoch 174: \tAverage Loss:  0.54413818359375\t ACC train:  0.6444444444444445\t ACC test:  0.6266666666666667\n",
      "\tEpoch 175: \tAverage Loss:  0.5473344116210938\t ACC train:  0.6777777777777778\t ACC test:  0.6222222222222222\n",
      "\tEpoch 176: \tAverage Loss:  0.5427947387695312\t ACC train:  0.6666666666666666\t ACC test:  0.6244444444444445\n",
      "\tEpoch 177: \tAverage Loss:  0.539177490234375\t ACC train:  0.7222222222222222\t ACC test:  0.6244444444444445\n",
      "\tEpoch 178: \tAverage Loss:  0.5358041381835937\t ACC train:  0.7\t ACC test:  0.6222222222222222\n",
      "\tEpoch 179: \tAverage Loss:  0.5366444702148437\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 180: \tAverage Loss:  0.532070556640625\t ACC train:  0.6888888888888889\t ACC test:  0.6355555555555555\n",
      "\tEpoch 181: \tAverage Loss:  0.5339046630859375\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 182: \tAverage Loss:  0.5316483154296875\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 183: \tAverage Loss:  0.5268275146484375\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 184: \tAverage Loss:  0.5214130859375\t ACC train:  0.6777777777777778\t ACC test:  0.6266666666666667\n",
      "\tEpoch 185: \tAverage Loss:  0.5281636352539063\t ACC train:  0.7222222222222222\t ACC test:  0.62\n",
      "\tEpoch 186: \tAverage Loss:  0.5258861083984375\t ACC train:  0.6666666666666666\t ACC test:  0.6244444444444445\n",
      "\tEpoch 187: \tAverage Loss:  0.5239315185546874\t ACC train:  0.6777777777777778\t ACC test:  0.6088888888888889\n",
      "\tEpoch 188: \tAverage Loss:  0.5211087646484375\t ACC train:  0.6888888888888889\t ACC test:  0.6066666666666667\n",
      "\tEpoch 189: \tAverage Loss:  0.5184168701171875\t ACC train:  0.6777777777777778\t ACC test:  0.6222222222222222\n",
      "\tEpoch 190: \tAverage Loss:  0.5186942749023438\t ACC train:  0.7111111111111111\t ACC test:  0.6111111111111112\n",
      "\tEpoch 191: \tAverage Loss:  0.51707275390625\t ACC train:  0.7222222222222222\t ACC test:  0.6177777777777778\n",
      "\tEpoch 192: \tAverage Loss:  0.5126759643554688\t ACC train:  0.6666666666666666\t ACC test:  0.6088888888888889\n",
      "\tEpoch 193: \tAverage Loss:  0.5116596069335938\t ACC train:  0.6888888888888889\t ACC test:  0.6222222222222222\n",
      "\tEpoch 194: \tAverage Loss:  0.5113005065917968\t ACC train:  0.6666666666666666\t ACC test:  0.6155555555555555\n",
      "\tEpoch 195: \tAverage Loss:  0.5085803527832031\t ACC train:  0.6444444444444445\t ACC test:  0.6177777777777778\n",
      "\tEpoch 196: \tAverage Loss:  0.5106931457519531\t ACC train:  0.6555555555555556\t ACC test:  0.6311111111111111\n",
      "\tEpoch 197: \tAverage Loss:  0.5057189025878907\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 198: \tAverage Loss:  0.5078880920410156\t ACC train:  0.7222222222222222\t ACC test:  0.6177777777777778\n",
      "\tEpoch 199: \tAverage Loss:  0.50395947265625\t ACC train:  0.7111111111111111\t ACC test:  0.6111111111111112\n",
      "\tEpoch 200: \tAverage Loss:  0.503525634765625\t ACC train:  0.6777777777777778\t ACC test:  0.6111111111111112\n",
      "\tEpoch 201: \tAverage Loss:  0.5013249206542969\t ACC train:  0.6888888888888889\t ACC test:  0.6288888888888889\n",
      "\tEpoch 202: \tAverage Loss:  0.5002779235839844\t ACC train:  0.6555555555555556\t ACC test:  0.6288888888888889\n",
      "\tEpoch 203: \tAverage Loss:  0.499251220703125\t ACC train:  0.6555555555555556\t ACC test:  0.6155555555555555\n",
      "\tEpoch 204: \tAverage Loss:  0.5007160034179687\t ACC train:  0.7333333333333333\t ACC test:  0.6066666666666667\n",
      "\tEpoch 205: \tAverage Loss:  0.5023033142089843\t ACC train:  0.7222222222222222\t ACC test:  0.6177777777777778\n",
      "\tEpoch 206: \tAverage Loss:  0.49768426513671876\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 207: \tAverage Loss:  0.495585693359375\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 208: \tAverage Loss:  0.4959033203125\t ACC train:  0.7\t ACC test:  0.6088888888888889\n",
      "\tEpoch 209: \tAverage Loss:  0.4936688232421875\t ACC train:  0.6888888888888889\t ACC test:  0.5977777777777777\n",
      "\tEpoch 210: \tAverage Loss:  0.4919335632324219\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 211: \tAverage Loss:  0.49159716796875\t ACC train:  0.7\t ACC test:  0.6155555555555555\n",
      "\tEpoch 212: \tAverage Loss:  0.49084848022460936\t ACC train:  0.7\t ACC test:  0.6311111111111111\n",
      "\tEpoch 213: \tAverage Loss:  0.4886683044433594\t ACC train:  0.7111111111111111\t ACC test:  0.6044444444444445\n",
      "\tEpoch 214: \tAverage Loss:  0.48995611572265624\t ACC train:  0.6888888888888889\t ACC test:  0.5977777777777777\n",
      "\tEpoch 215: \tAverage Loss:  0.49065338134765624\t ACC train:  0.6888888888888889\t ACC test:  0.6111111111111112\n",
      "\tEpoch 216: \tAverage Loss:  0.48652316284179686\t ACC train:  0.7111111111111111\t ACC test:  0.6177777777777778\n",
      "\tEpoch 217: \tAverage Loss:  0.48867996215820314\t ACC train:  0.7333333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 218: \tAverage Loss:  0.484030029296875\t ACC train:  0.7\t ACC test:  0.6022222222222222\n",
      "\tEpoch 219: \tAverage Loss:  0.48602001953125\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 220: \tAverage Loss:  0.48292095947265623\t ACC train:  0.6777777777777778\t ACC test:  0.6222222222222222\n",
      "\tEpoch 221: \tAverage Loss:  0.4858492431640625\t ACC train:  0.7111111111111111\t ACC test:  0.6177777777777778\n",
      "\tEpoch 222: \tAverage Loss:  0.48080694580078126\t ACC train:  0.6777777777777778\t ACC test:  0.6088888888888889\n",
      "\tEpoch 223: \tAverage Loss:  0.4847813415527344\t ACC train:  0.6777777777777778\t ACC test:  0.6244444444444445\n",
      "\tEpoch 224: \tAverage Loss:  0.48188363647460936\t ACC train:  0.6555555555555556\t ACC test:  0.6111111111111112\n",
      "\tEpoch 225: \tAverage Loss:  0.47874346923828126\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 226: \tAverage Loss:  0.4816356201171875\t ACC train:  0.6888888888888889\t ACC test:  0.6133333333333333\n",
      "\tEpoch 227: \tAverage Loss:  0.47869985961914063\t ACC train:  0.6444444444444445\t ACC test:  0.6133333333333333\n",
      "\tEpoch 228: \tAverage Loss:  0.47764892578125\t ACC train:  0.7\t ACC test:  0.6133333333333333\n",
      "\tEpoch 229: \tAverage Loss:  0.47676461791992186\t ACC train:  0.7111111111111111\t ACC test:  0.6\n",
      "\tEpoch 230: \tAverage Loss:  0.4760683898925781\t ACC train:  0.6888888888888889\t ACC test:  0.6088888888888889\n",
      "\tEpoch 231: \tAverage Loss:  0.4770462646484375\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 232: \tAverage Loss:  0.47570382690429686\t ACC train:  0.6888888888888889\t ACC test:  0.6244444444444445\n",
      "\tEpoch 233: \tAverage Loss:  0.47559661865234376\t ACC train:  0.6777777777777778\t ACC test:  0.6044444444444445\n",
      "\tEpoch 234: \tAverage Loss:  0.47573037719726563\t ACC train:  0.7222222222222222\t ACC test:  0.6222222222222222\n",
      "\tEpoch 235: \tAverage Loss:  0.475973876953125\t ACC train:  0.6777777777777778\t ACC test:  0.6088888888888889\n",
      "\tEpoch 236: \tAverage Loss:  0.47350848388671873\t ACC train:  0.7\t ACC test:  0.6066666666666667\n",
      "\tEpoch 237: \tAverage Loss:  0.47243768310546874\t ACC train:  0.7111111111111111\t ACC test:  0.6266666666666667\n",
      "\tEpoch 238: \tAverage Loss:  0.4724825439453125\t ACC train:  0.6777777777777778\t ACC test:  0.6111111111111112\n",
      "\tEpoch 239: \tAverage Loss:  0.47141754150390625\t ACC train:  0.7111111111111111\t ACC test:  0.6111111111111112\n",
      "\tEpoch 240: \tAverage Loss:  0.47035397338867185\t ACC train:  0.7111111111111111\t ACC test:  0.6244444444444445\n",
      "\tEpoch 241: \tAverage Loss:  0.4707286376953125\t ACC train:  0.6888888888888889\t ACC test:  0.6155555555555555\n",
      "\tEpoch 242: \tAverage Loss:  0.4672904052734375\t ACC train:  0.7\t ACC test:  0.62\n",
      "\tEpoch 243: \tAverage Loss:  0.46888619995117187\t ACC train:  0.7222222222222222\t ACC test:  0.6088888888888889\n",
      "\tEpoch 244: \tAverage Loss:  0.4686698303222656\t ACC train:  0.7111111111111111\t ACC test:  0.6088888888888889\n",
      "\tEpoch 245: \tAverage Loss:  0.4671333312988281\t ACC train:  0.7222222222222222\t ACC test:  0.6088888888888889\n",
      "\tEpoch 246: \tAverage Loss:  0.4675975341796875\t ACC train:  0.7111111111111111\t ACC test:  0.6177777777777778\n",
      "\tEpoch 247: \tAverage Loss:  0.463908203125\t ACC train:  0.7333333333333333\t ACC test:  0.6288888888888889\n",
      "\tEpoch 248: \tAverage Loss:  0.46480181884765626\t ACC train:  0.6777777777777778\t ACC test:  0.62\n",
      "\tEpoch 249: \tAverage Loss:  0.4671214599609375\t ACC train:  0.7444444444444445\t ACC test:  0.6155555555555555\n",
      "\tEpoch 250: \tAverage Loss:  0.4635244140625\t ACC train:  0.7\t ACC test:  0.6177777777777778\n",
      "\tEpoch 251: \tAverage Loss:  0.4642995910644531\t ACC train:  0.7111111111111111\t ACC test:  0.62\n",
      "\tEpoch 252: \tAverage Loss:  0.4658622741699219\t ACC train:  0.6777777777777778\t ACC test:  0.6133333333333333\n",
      "\tEpoch 253: \tAverage Loss:  0.4631893920898438\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 254: \tAverage Loss:  0.46273269653320315\t ACC train:  0.7222222222222222\t ACC test:  0.6222222222222222\n",
      "\tEpoch 255: \tAverage Loss:  0.46445159912109374\t ACC train:  0.6888888888888889\t ACC test:  0.6266666666666667\n",
      "\tEpoch 256: \tAverage Loss:  0.4634530029296875\t ACC train:  0.6666666666666666\t ACC test:  0.6111111111111112\n",
      "\tEpoch 257: \tAverage Loss:  0.46161865234375\t ACC train:  0.6888888888888889\t ACC test:  0.6177777777777778\n",
      "\tEpoch 258: \tAverage Loss:  0.46133563232421876\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 259: \tAverage Loss:  0.4615065612792969\t ACC train:  0.7222222222222222\t ACC test:  0.6266666666666667\n",
      "\tEpoch 260: \tAverage Loss:  0.46002569580078123\t ACC train:  0.7333333333333333\t ACC test:  0.6222222222222222\n",
      "\tEpoch 261: \tAverage Loss:  0.460994384765625\t ACC train:  0.7444444444444445\t ACC test:  0.6155555555555555\n",
      "\tEpoch 262: \tAverage Loss:  0.46005767822265625\t ACC train:  0.7111111111111111\t ACC test:  0.6266666666666667\n",
      "\tEpoch 263: \tAverage Loss:  0.4607874755859375\t ACC train:  0.7333333333333333\t ACC test:  0.6222222222222222\n",
      "\tEpoch 264: \tAverage Loss:  0.45990472412109373\t ACC train:  0.7444444444444445\t ACC test:  0.62\n",
      "\tEpoch 265: \tAverage Loss:  0.45821084594726563\t ACC train:  0.7111111111111111\t ACC test:  0.6266666666666667\n",
      "\tEpoch 266: \tAverage Loss:  0.4590128173828125\t ACC train:  0.7222222222222222\t ACC test:  0.62\n",
      "\tEpoch 267: \tAverage Loss:  0.45751617431640623\t ACC train:  0.7111111111111111\t ACC test:  0.6155555555555555\n",
      "\tEpoch 268: \tAverage Loss:  0.45865484619140623\t ACC train:  0.7222222222222222\t ACC test:  0.6155555555555555\n",
      "\tEpoch 269: \tAverage Loss:  0.4573673095703125\t ACC train:  0.6888888888888889\t ACC test:  0.6133333333333333\n",
      "\tEpoch 270: \tAverage Loss:  0.456770263671875\t ACC train:  0.7111111111111111\t ACC test:  0.6111111111111112\n",
      "\tEpoch 271: \tAverage Loss:  0.4578600158691406\t ACC train:  0.7\t ACC test:  0.6111111111111112\n",
      "\tEpoch 272: \tAverage Loss:  0.45662814331054685\t ACC train:  0.7111111111111111\t ACC test:  0.62\n",
      "\tEpoch 273: \tAverage Loss:  0.45559451293945313\t ACC train:  0.7222222222222222\t ACC test:  0.62\n",
      "\tEpoch 274: \tAverage Loss:  0.4547609558105469\t ACC train:  0.7111111111111111\t ACC test:  0.6155555555555555\n",
      "\tEpoch 275: \tAverage Loss:  0.45532958984375\t ACC train:  0.7222222222222222\t ACC test:  0.62\n",
      "\tEpoch 276: \tAverage Loss:  0.4540078125\t ACC train:  0.7222222222222222\t ACC test:  0.6288888888888889\n",
      "\tEpoch 277: \tAverage Loss:  0.45535882568359376\t ACC train:  0.7111111111111111\t ACC test:  0.6266666666666667\n",
      "\tEpoch 278: \tAverage Loss:  0.45393441772460935\t ACC train:  0.7111111111111111\t ACC test:  0.62\n",
      "\tEpoch 279: \tAverage Loss:  0.4540887451171875\t ACC train:  0.7333333333333333\t ACC test:  0.6244444444444445\n",
      "\tEpoch 280: \tAverage Loss:  0.4546767578125\t ACC train:  0.7\t ACC test:  0.6244444444444445\n",
      "\tEpoch 281: \tAverage Loss:  0.4537604675292969\t ACC train:  0.7\t ACC test:  0.6222222222222222\n",
      "\tEpoch 282: \tAverage Loss:  0.453091064453125\t ACC train:  0.7222222222222222\t ACC test:  0.6311111111111111\n",
      "\tEpoch 283: \tAverage Loss:  0.4517414245605469\t ACC train:  0.7222222222222222\t ACC test:  0.6222222222222222\n",
      "\tEpoch 284: \tAverage Loss:  0.45274127197265623\t ACC train:  0.7111111111111111\t ACC test:  0.62\n",
      "\tEpoch 285: \tAverage Loss:  0.45120944213867187\t ACC train:  0.7222222222222222\t ACC test:  0.6222222222222222\n",
      "\tEpoch 286: \tAverage Loss:  0.45165557861328126\t ACC train:  0.7111111111111111\t ACC test:  0.6333333333333333\n",
      "\tEpoch 287: \tAverage Loss:  0.4503758239746094\t ACC train:  0.7111111111111111\t ACC test:  0.62\n",
      "\tEpoch 288: \tAverage Loss:  0.4518634338378906\t ACC train:  0.7111111111111111\t ACC test:  0.6311111111111111\n",
      "\tEpoch 289: \tAverage Loss:  0.45029544067382815\t ACC train:  0.7333333333333333\t ACC test:  0.6288888888888889\n",
      "\tEpoch 290: \tAverage Loss:  0.45051300048828125\t ACC train:  0.7333333333333333\t ACC test:  0.6222222222222222\n",
      "\tEpoch 291: \tAverage Loss:  0.44975918579101565\t ACC train:  0.7222222222222222\t ACC test:  0.62\n",
      "\tEpoch 292: \tAverage Loss:  0.44983758544921876\t ACC train:  0.7111111111111111\t ACC test:  0.6333333333333333\n",
      "\tEpoch 293: \tAverage Loss:  0.4498634948730469\t ACC train:  0.7333333333333333\t ACC test:  0.6244444444444445\n",
      "\tEpoch 294: \tAverage Loss:  0.4491771240234375\t ACC train:  0.7\t ACC test:  0.6222222222222222\n",
      "\tEpoch 295: \tAverage Loss:  0.4492159423828125\t ACC train:  0.7222222222222222\t ACC test:  0.6266666666666667\n",
      "\tEpoch 296: \tAverage Loss:  0.44786251831054685\t ACC train:  0.7555555555555555\t ACC test:  0.6288888888888889\n",
      "\tEpoch 297: \tAverage Loss:  0.4476040344238281\t ACC train:  0.7222222222222222\t ACC test:  0.62\n",
      "\tEpoch 298: \tAverage Loss:  0.4475675354003906\t ACC train:  0.7222222222222222\t ACC test:  0.6244444444444445\n",
      "\tEpoch 299: \tAverage Loss:  0.44931512451171873\t ACC train:  0.7222222222222222\t ACC test:  0.6311111111111111\n",
      "\tEpoch 300: \tAverage Loss:  0.4471595764160156\t ACC train:  0.7333333333333333\t ACC test:  0.6266666666666667\n",
      "\tEpoch 301: \tAverage Loss:  0.44795578002929687\t ACC train:  0.7222222222222222\t ACC test:  0.6288888888888889\n",
      "\tEpoch 302: \tAverage Loss:  0.4470870361328125\t ACC train:  0.7111111111111111\t ACC test:  0.6377777777777778\n",
      "\tEpoch 303: \tAverage Loss:  0.44646392822265624\t ACC train:  0.7444444444444445\t ACC test:  0.6133333333333333\n",
      "\tEpoch 304: \tAverage Loss:  0.4469151611328125\t ACC train:  0.7222222222222222\t ACC test:  0.6333333333333333\n",
      "\tEpoch 305: \tAverage Loss:  0.44622674560546877\t ACC train:  0.7333333333333333\t ACC test:  0.6266666666666667\n",
      "\tEpoch 306: \tAverage Loss:  0.4459720153808594\t ACC train:  0.7222222222222222\t ACC test:  0.6222222222222222\n",
      "\tEpoch 307: \tAverage Loss:  0.4470090942382812\t ACC train:  0.7222222222222222\t ACC test:  0.6244444444444445\n",
      "\tEpoch 308: \tAverage Loss:  0.4456297607421875\t ACC train:  0.7333333333333333\t ACC test:  0.6244444444444445\n",
      "\tEpoch 309: \tAverage Loss:  0.44505264282226564\t ACC train:  0.7111111111111111\t ACC test:  0.62\n",
      "\tEpoch 310: \tAverage Loss:  0.4463505249023437\t ACC train:  0.7222222222222222\t ACC test:  0.6288888888888889\n",
      "\tEpoch 311: \tAverage Loss:  0.4452137756347656\t ACC train:  0.7444444444444445\t ACC test:  0.6266666666666667\n",
      "\tEpoch 312: \tAverage Loss:  0.44535247802734373\t ACC train:  0.7333333333333333\t ACC test:  0.6311111111111111\n",
      "\tEpoch 313: \tAverage Loss:  0.4446221923828125\t ACC train:  0.7444444444444445\t ACC test:  0.6311111111111111\n",
      "\tEpoch 314: \tAverage Loss:  0.44472698974609376\t ACC train:  0.7444444444444445\t ACC test:  0.6355555555555555\n",
      "\tEpoch 315: \tAverage Loss:  0.44381201171875\t ACC train:  0.7444444444444445\t ACC test:  0.6333333333333333\n",
      "\tEpoch 316: \tAverage Loss:  0.44391632080078125\t ACC train:  0.7333333333333333\t ACC test:  0.6288888888888889\n",
      "\tEpoch 317: \tAverage Loss:  0.4442547607421875\t ACC train:  0.7111111111111111\t ACC test:  0.6333333333333333\n",
      "\tEpoch 318: \tAverage Loss:  0.4441067810058594\t ACC train:  0.7555555555555555\t ACC test:  0.6333333333333333\n",
      "\tEpoch 319: \tAverage Loss:  0.44284121704101564\t ACC train:  0.7444444444444445\t ACC test:  0.6355555555555555\n",
      "\tEpoch 320: \tAverage Loss:  0.44356393432617186\t ACC train:  0.7333333333333333\t ACC test:  0.6266666666666667\n",
      "\tEpoch 321: \tAverage Loss:  0.4426369934082031\t ACC train:  0.7333333333333333\t ACC test:  0.6266666666666667\n",
      "\tEpoch 322: \tAverage Loss:  0.44332537841796876\t ACC train:  0.7333333333333333\t ACC test:  0.6333333333333333\n",
      "\tEpoch 323: \tAverage Loss:  0.4413600463867188\t ACC train:  0.7333333333333333\t ACC test:  0.6377777777777778\n",
      "\tEpoch 324: \tAverage Loss:  0.44130670166015623\t ACC train:  0.7444444444444445\t ACC test:  0.6377777777777778\n",
      "\tEpoch 325: \tAverage Loss:  0.44264739990234375\t ACC train:  0.7555555555555555\t ACC test:  0.6311111111111111\n",
      "\tEpoch 326: \tAverage Loss:  0.4419736938476562\t ACC train:  0.7333333333333333\t ACC test:  0.6311111111111111\n",
      "\tEpoch 327: \tAverage Loss:  0.44147442626953126\t ACC train:  0.7333333333333333\t ACC test:  0.64\n",
      "\tEpoch 328: \tAverage Loss:  0.44094622802734373\t ACC train:  0.7222222222222222\t ACC test:  0.6355555555555555\n",
      "\tEpoch 329: \tAverage Loss:  0.44118328857421873\t ACC train:  0.7333333333333333\t ACC test:  0.6444444444444445\n",
      "\tEpoch 330: \tAverage Loss:  0.4408183288574219\t ACC train:  0.7555555555555555\t ACC test:  0.64\n",
      "\tEpoch 331: \tAverage Loss:  0.44049136352539064\t ACC train:  0.7444444444444445\t ACC test:  0.6333333333333333\n",
      "\tEpoch 332: \tAverage Loss:  0.43986465454101564\t ACC train:  0.7444444444444445\t ACC test:  0.6444444444444445\n",
      "\tEpoch 333: \tAverage Loss:  0.44097735595703125\t ACC train:  0.7444444444444445\t ACC test:  0.6288888888888889\n",
      "\tEpoch 334: \tAverage Loss:  0.4389825439453125\t ACC train:  0.7444444444444445\t ACC test:  0.6288888888888889\n",
      "\tEpoch 335: \tAverage Loss:  0.4395639953613281\t ACC train:  0.7333333333333333\t ACC test:  0.6266666666666667\n",
      "\tEpoch 336: \tAverage Loss:  0.4395738220214844\t ACC train:  0.7444444444444445\t ACC test:  0.6355555555555555\n",
      "\tEpoch 337: \tAverage Loss:  0.43886660766601565\t ACC train:  0.7444444444444445\t ACC test:  0.6288888888888889\n",
      "\tEpoch 338: \tAverage Loss:  0.439326904296875\t ACC train:  0.7555555555555555\t ACC test:  0.64\n",
      "\tEpoch 339: \tAverage Loss:  0.439580078125\t ACC train:  0.7555555555555555\t ACC test:  0.6377777777777778\n",
      "\tEpoch 340: \tAverage Loss:  0.4400561218261719\t ACC train:  0.7444444444444445\t ACC test:  0.6377777777777778\n",
      "\tEpoch 341: \tAverage Loss:  0.4383524169921875\t ACC train:  0.7555555555555555\t ACC test:  0.64\n",
      "\tEpoch 342: \tAverage Loss:  0.438885498046875\t ACC train:  0.7444444444444445\t ACC test:  0.6377777777777778\n",
      "\tEpoch 343: \tAverage Loss:  0.43845382690429685\t ACC train:  0.7555555555555555\t ACC test:  0.6377777777777778\n",
      "\tEpoch 344: \tAverage Loss:  0.43830801391601565\t ACC train:  0.7333333333333333\t ACC test:  0.6311111111111111\n",
      "\tEpoch 345: \tAverage Loss:  0.43793679809570313\t ACC train:  0.7333333333333333\t ACC test:  0.6355555555555555\n",
      "\tEpoch 346: \tAverage Loss:  0.4377023315429687\t ACC train:  0.7555555555555555\t ACC test:  0.6355555555555555\n",
      "\tEpoch 347: \tAverage Loss:  0.43749398803710937\t ACC train:  0.7555555555555555\t ACC test:  0.6377777777777778\n",
      "\tEpoch 348: \tAverage Loss:  0.4376117858886719\t ACC train:  0.7333333333333333\t ACC test:  0.64\n",
      "\tEpoch 349: \tAverage Loss:  0.4370887451171875\t ACC train:  0.7444444444444445\t ACC test:  0.6444444444444445\n",
      "\tEpoch 350: \tAverage Loss:  0.43692486572265626\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 351: \tAverage Loss:  0.4371276550292969\t ACC train:  0.7444444444444445\t ACC test:  0.6466666666666666\n",
      "\tEpoch 352: \tAverage Loss:  0.4368030700683594\t ACC train:  0.7444444444444445\t ACC test:  0.6422222222222222\n",
      "\tEpoch 353: \tAverage Loss:  0.43686053466796876\t ACC train:  0.7444444444444445\t ACC test:  0.6422222222222222\n",
      "\tEpoch 354: \tAverage Loss:  0.436642333984375\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 355: \tAverage Loss:  0.43639947509765625\t ACC train:  0.7555555555555555\t ACC test:  0.6355555555555555\n",
      "\tEpoch 356: \tAverage Loss:  0.4363798522949219\t ACC train:  0.7444444444444445\t ACC test:  0.6444444444444445\n",
      "\tEpoch 357: \tAverage Loss:  0.434929931640625\t ACC train:  0.7555555555555555\t ACC test:  0.64\n",
      "\tEpoch 358: \tAverage Loss:  0.43645462036132815\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 359: \tAverage Loss:  0.4348990478515625\t ACC train:  0.7555555555555555\t ACC test:  0.6422222222222222\n",
      "\tEpoch 360: \tAverage Loss:  0.43557589721679685\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 361: \tAverage Loss:  0.43584375\t ACC train:  0.7444444444444445\t ACC test:  0.6466666666666666\n",
      "\tEpoch 362: \tAverage Loss:  0.43541952514648435\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 363: \tAverage Loss:  0.4349362487792969\t ACC train:  0.7444444444444445\t ACC test:  0.6444444444444445\n",
      "\tEpoch 364: \tAverage Loss:  0.4347724609375\t ACC train:  0.7444444444444445\t ACC test:  0.6377777777777778\n",
      "\tEpoch 365: \tAverage Loss:  0.43514898681640624\t ACC train:  0.7555555555555555\t ACC test:  0.64\n",
      "\tEpoch 366: \tAverage Loss:  0.43491680908203123\t ACC train:  0.7555555555555555\t ACC test:  0.6422222222222222\n",
      "\tEpoch 367: \tAverage Loss:  0.43396286010742186\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 368: \tAverage Loss:  0.434564697265625\t ACC train:  0.7555555555555555\t ACC test:  0.6377777777777778\n",
      "\tEpoch 369: \tAverage Loss:  0.43398361206054686\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 370: \tAverage Loss:  0.43431573486328123\t ACC train:  0.7444444444444445\t ACC test:  0.6488888888888888\n",
      "\tEpoch 371: \tAverage Loss:  0.4343223571777344\t ACC train:  0.7444444444444445\t ACC test:  0.6444444444444445\n",
      "\tEpoch 372: \tAverage Loss:  0.43435848999023435\t ACC train:  0.7555555555555555\t ACC test:  0.6466666666666666\n",
      "\tEpoch 373: \tAverage Loss:  0.433240234375\t ACC train:  0.7444444444444445\t ACC test:  0.6488888888888888\n",
      "\tEpoch 374: \tAverage Loss:  0.43305145263671874\t ACC train:  0.7444444444444445\t ACC test:  0.6422222222222222\n",
      "\tEpoch 375: \tAverage Loss:  0.4323034057617188\t ACC train:  0.7555555555555555\t ACC test:  0.6422222222222222\n",
      "\tEpoch 376: \tAverage Loss:  0.4329500122070313\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 377: \tAverage Loss:  0.4330096435546875\t ACC train:  0.7444444444444445\t ACC test:  0.6466666666666666\n",
      "\tEpoch 378: \tAverage Loss:  0.43279815673828126\t ACC train:  0.7555555555555555\t ACC test:  0.6422222222222222\n",
      "\tEpoch 379: \tAverage Loss:  0.43257769775390625\t ACC train:  0.7444444444444445\t ACC test:  0.6444444444444445\n",
      "\tEpoch 380: \tAverage Loss:  0.4324092102050781\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 381: \tAverage Loss:  0.43203253173828127\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 382: \tAverage Loss:  0.431927490234375\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 383: \tAverage Loss:  0.4317945556640625\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 384: \tAverage Loss:  0.4318016662597656\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 385: \tAverage Loss:  0.43159246826171876\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 386: \tAverage Loss:  0.4315774841308594\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 387: \tAverage Loss:  0.4315172119140625\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 388: \tAverage Loss:  0.43145993041992187\t ACC train:  0.7444444444444445\t ACC test:  0.6488888888888888\n",
      "\tEpoch 389: \tAverage Loss:  0.43091592407226564\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 390: \tAverage Loss:  0.4307391662597656\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 391: \tAverage Loss:  0.43060394287109377\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 392: \tAverage Loss:  0.43104522705078124\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 393: \tAverage Loss:  0.4302446594238281\t ACC train:  0.7444444444444445\t ACC test:  0.6422222222222222\n",
      "\tEpoch 394: \tAverage Loss:  0.43003335571289064\t ACC train:  0.7555555555555555\t ACC test:  0.6466666666666666\n",
      "\tEpoch 395: \tAverage Loss:  0.43010617065429685\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 396: \tAverage Loss:  0.43053182983398436\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 397: \tAverage Loss:  0.42923223876953126\t ACC train:  0.7555555555555555\t ACC test:  0.6444444444444445\n",
      "\tEpoch 398: \tAverage Loss:  0.43015963745117186\t ACC train:  0.7444444444444445\t ACC test:  0.6466666666666666\n",
      "\tEpoch 399: \tAverage Loss:  0.43012969970703124\t ACC train:  0.7555555555555555\t ACC test:  0.6422222222222222\n",
      "\tEpoch 400: \tAverage Loss:  0.4296148376464844\t ACC train:  0.7444444444444445\t ACC test:  0.6511111111111111\n",
      "\tEpoch 401: \tAverage Loss:  0.4293778381347656\t ACC train:  0.7444444444444445\t ACC test:  0.6488888888888888\n",
      "\tEpoch 402: \tAverage Loss:  0.4288353271484375\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 403: \tAverage Loss:  0.4289788513183594\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 404: \tAverage Loss:  0.4288413391113281\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 405: \tAverage Loss:  0.429069580078125\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 406: \tAverage Loss:  0.4283808288574219\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 407: \tAverage Loss:  0.42864874267578124\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 408: \tAverage Loss:  0.42862338256835936\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 409: \tAverage Loss:  0.4283546142578125\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 410: \tAverage Loss:  0.42808551025390623\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 411: \tAverage Loss:  0.4281027526855469\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 412: \tAverage Loss:  0.4279655456542969\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 413: \tAverage Loss:  0.4280413208007813\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 414: \tAverage Loss:  0.4274272766113281\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 415: \tAverage Loss:  0.4273260803222656\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 416: \tAverage Loss:  0.42752340698242186\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 417: \tAverage Loss:  0.4270026245117188\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 418: \tAverage Loss:  0.4271907043457031\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 419: \tAverage Loss:  0.42723699951171873\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 420: \tAverage Loss:  0.4267127075195313\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 421: \tAverage Loss:  0.427052734375\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 422: \tAverage Loss:  0.4265254821777344\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 423: \tAverage Loss:  0.4264290466308594\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 424: \tAverage Loss:  0.426331298828125\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 425: \tAverage Loss:  0.4263541259765625\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 426: \tAverage Loss:  0.42595663452148436\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 427: \tAverage Loss:  0.4261221923828125\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 428: \tAverage Loss:  0.42573138427734375\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 429: \tAverage Loss:  0.42577606201171875\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 430: \tAverage Loss:  0.42554617309570314\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 431: \tAverage Loss:  0.42528857421875\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 432: \tAverage Loss:  0.4251820068359375\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 433: \tAverage Loss:  0.42528076171875\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 434: \tAverage Loss:  0.424979248046875\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 435: \tAverage Loss:  0.4247578125\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 436: \tAverage Loss:  0.42502560424804686\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 437: \tAverage Loss:  0.42491485595703127\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 438: \tAverage Loss:  0.4242197265625\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 439: \tAverage Loss:  0.4245730895996094\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 440: \tAverage Loss:  0.42436810302734373\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 441: \tAverage Loss:  0.4242446594238281\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 442: \tAverage Loss:  0.42367803955078126\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 443: \tAverage Loss:  0.4238621826171875\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 444: \tAverage Loss:  0.42382275390625\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 445: \tAverage Loss:  0.4232875061035156\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 446: \tAverage Loss:  0.4231953125\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 447: \tAverage Loss:  0.4234781799316406\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 448: \tAverage Loss:  0.4231934814453125\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 449: \tAverage Loss:  0.4233698425292969\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 450: \tAverage Loss:  0.42337164306640623\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 451: \tAverage Loss:  0.42276605224609376\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 452: \tAverage Loss:  0.42308248901367185\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 453: \tAverage Loss:  0.4228587341308594\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 454: \tAverage Loss:  0.4227461853027344\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 455: \tAverage Loss:  0.42278753662109375\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 456: \tAverage Loss:  0.42246661376953126\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 457: \tAverage Loss:  0.42232958984375\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 458: \tAverage Loss:  0.42226376342773436\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 459: \tAverage Loss:  0.42218597412109377\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 460: \tAverage Loss:  0.42178582763671874\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 461: \tAverage Loss:  0.4218626708984375\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 462: \tAverage Loss:  0.4214034118652344\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 463: \tAverage Loss:  0.421623291015625\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 464: \tAverage Loss:  0.42153631591796875\t ACC train:  0.7555555555555555\t ACC test:  0.6488888888888888\n",
      "\tEpoch 465: \tAverage Loss:  0.42139398193359373\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 466: \tAverage Loss:  0.42127706909179685\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 467: \tAverage Loss:  0.42131201171875\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 468: \tAverage Loss:  0.42100421142578126\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 469: \tAverage Loss:  0.42100234985351564\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 470: \tAverage Loss:  0.4207950134277344\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 471: \tAverage Loss:  0.42062261962890624\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 472: \tAverage Loss:  0.4205595397949219\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 473: \tAverage Loss:  0.4204122619628906\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 474: \tAverage Loss:  0.4204251708984375\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 475: \tAverage Loss:  0.42015631103515627\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 476: \tAverage Loss:  0.42029757690429687\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 477: \tAverage Loss:  0.41951361083984373\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 478: \tAverage Loss:  0.42015185546875\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 479: \tAverage Loss:  0.419811279296875\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 480: \tAverage Loss:  0.41983416748046876\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 481: \tAverage Loss:  0.41979840087890624\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 482: \tAverage Loss:  0.41960427856445315\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 483: \tAverage Loss:  0.41956988525390626\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 484: \tAverage Loss:  0.4197281494140625\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 485: \tAverage Loss:  0.4192833557128906\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 486: \tAverage Loss:  0.4189715576171875\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 487: \tAverage Loss:  0.4191716003417969\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 488: \tAverage Loss:  0.41908514404296876\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 489: \tAverage Loss:  0.4186665344238281\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 490: \tAverage Loss:  0.41865292358398437\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 491: \tAverage Loss:  0.4185586853027344\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 492: \tAverage Loss:  0.41837060546875\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 493: \tAverage Loss:  0.41800152587890627\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 494: \tAverage Loss:  0.4183560791015625\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 495: \tAverage Loss:  0.41821417236328123\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 496: \tAverage Loss:  0.4181479797363281\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 497: \tAverage Loss:  0.41781680297851564\t ACC train:  0.7555555555555555\t ACC test:  0.6533333333333333\n",
      "\tEpoch 498: \tAverage Loss:  0.41809432983398437\t ACC train:  0.7555555555555555\t ACC test:  0.6511111111111111\n",
      "\tEpoch 499: \tAverage Loss:  0.4177324523925781\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 500: \tAverage Loss:  0.41751651000976564\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 501: \tAverage Loss:  0.4177266845703125\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 502: \tAverage Loss:  0.4175250549316406\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 503: \tAverage Loss:  0.4176612854003906\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 504: \tAverage Loss:  0.41728695678710936\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 505: \tAverage Loss:  0.41718899536132814\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 506: \tAverage Loss:  0.4171617431640625\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 507: \tAverage Loss:  0.41716067504882814\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 508: \tAverage Loss:  0.41696450805664065\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 509: \tAverage Loss:  0.41693618774414065\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 510: \tAverage Loss:  0.41705438232421876\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 511: \tAverage Loss:  0.41664279174804686\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 512: \tAverage Loss:  0.41650082397460936\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 513: \tAverage Loss:  0.416172119140625\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 514: \tAverage Loss:  0.4163527526855469\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 515: \tAverage Loss:  0.4161191711425781\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 516: \tAverage Loss:  0.41604669189453125\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 517: \tAverage Loss:  0.41622640991210935\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 518: \tAverage Loss:  0.41598956298828127\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 519: \tAverage Loss:  0.41582144165039064\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 520: \tAverage Loss:  0.41584698486328125\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 521: \tAverage Loss:  0.41570516967773435\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 522: \tAverage Loss:  0.4156500244140625\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 523: \tAverage Loss:  0.41573651123046873\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 524: \tAverage Loss:  0.415666748046875\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 525: \tAverage Loss:  0.41524844360351565\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 526: \tAverage Loss:  0.41548117065429685\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 527: \tAverage Loss:  0.4152222900390625\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 528: \tAverage Loss:  0.41511944580078125\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 529: \tAverage Loss:  0.41497274780273435\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 530: \tAverage Loss:  0.4149817199707031\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 531: \tAverage Loss:  0.4148733825683594\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 532: \tAverage Loss:  0.41474380493164065\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 533: \tAverage Loss:  0.41486972045898435\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 534: \tAverage Loss:  0.414652587890625\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 535: \tAverage Loss:  0.4145690002441406\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 536: \tAverage Loss:  0.41446746826171876\t ACC train:  0.7555555555555555\t ACC test:  0.6555555555555556\n",
      "\tEpoch 537: \tAverage Loss:  0.4144231262207031\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 538: \tAverage Loss:  0.4144412536621094\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 539: \tAverage Loss:  0.4142821960449219\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 540: \tAverage Loss:  0.41411538696289063\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 541: \tAverage Loss:  0.4143487548828125\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 542: \tAverage Loss:  0.41416168212890625\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 543: \tAverage Loss:  0.4139476013183594\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 544: \tAverage Loss:  0.41401934814453123\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 545: \tAverage Loss:  0.41382321166992186\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 546: \tAverage Loss:  0.4135618286132812\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 547: \tAverage Loss:  0.41352890014648436\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 548: \tAverage Loss:  0.4135128479003906\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 549: \tAverage Loss:  0.4134998474121094\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 550: \tAverage Loss:  0.4132561340332031\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 551: \tAverage Loss:  0.4133435668945312\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 552: \tAverage Loss:  0.41331866455078126\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 553: \tAverage Loss:  0.41326025390625\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 554: \tAverage Loss:  0.4129049072265625\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 555: \tAverage Loss:  0.41281631469726565\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 556: \tAverage Loss:  0.4129441223144531\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 557: \tAverage Loss:  0.4129827880859375\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 558: \tAverage Loss:  0.4128534240722656\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 559: \tAverage Loss:  0.4126370239257813\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 560: \tAverage Loss:  0.4127781982421875\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 561: \tAverage Loss:  0.41241275024414065\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 562: \tAverage Loss:  0.41236746215820314\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 563: \tAverage Loss:  0.41253244018554686\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 564: \tAverage Loss:  0.4122500915527344\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 565: \tAverage Loss:  0.4122450256347656\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 566: \tAverage Loss:  0.4121091003417969\t ACC train:  0.7555555555555555\t ACC test:  0.6577777777777778\n",
      "\tEpoch 567: \tAverage Loss:  0.4120812072753906\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 568: \tAverage Loss:  0.41208663940429685\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 569: \tAverage Loss:  0.4118199462890625\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 570: \tAverage Loss:  0.4118929748535156\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 571: \tAverage Loss:  0.4118118591308594\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 572: \tAverage Loss:  0.4118001403808594\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 573: \tAverage Loss:  0.4116702575683594\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 574: \tAverage Loss:  0.411683349609375\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 575: \tAverage Loss:  0.4112938232421875\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 576: \tAverage Loss:  0.4113430480957031\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 577: \tAverage Loss:  0.4113706970214844\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 578: \tAverage Loss:  0.4111844482421875\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 579: \tAverage Loss:  0.41120452880859376\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 580: \tAverage Loss:  0.41121444702148435\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 581: \tAverage Loss:  0.4109734802246094\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 582: \tAverage Loss:  0.41103598022460935\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 583: \tAverage Loss:  0.41074920654296876\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 584: \tAverage Loss:  0.4107301940917969\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 585: \tAverage Loss:  0.41079217529296874\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 586: \tAverage Loss:  0.410553955078125\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 587: \tAverage Loss:  0.41063101196289065\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 588: \tAverage Loss:  0.41053924560546873\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 589: \tAverage Loss:  0.41048086547851564\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 590: \tAverage Loss:  0.41061529541015623\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 591: \tAverage Loss:  0.4104184265136719\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 592: \tAverage Loss:  0.41030859375\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 593: \tAverage Loss:  0.41011260986328124\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 594: \tAverage Loss:  0.4102745056152344\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 595: \tAverage Loss:  0.4100250549316406\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 596: \tAverage Loss:  0.41010519409179685\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 597: \tAverage Loss:  0.4100849609375\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 598: \tAverage Loss:  0.40995120239257815\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 599: \tAverage Loss:  0.4096996765136719\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 600: \tAverage Loss:  0.4097135925292969\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 601: \tAverage Loss:  0.4097755126953125\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 602: \tAverage Loss:  0.4097802734375\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 603: \tAverage Loss:  0.4093942565917969\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 604: \tAverage Loss:  0.4095980224609375\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 605: \tAverage Loss:  0.409470703125\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 606: \tAverage Loss:  0.4093258666992188\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 607: \tAverage Loss:  0.4094029541015625\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 608: \tAverage Loss:  0.40920401000976564\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 609: \tAverage Loss:  0.4091275939941406\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 610: \tAverage Loss:  0.40914230346679686\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 611: \tAverage Loss:  0.40892791748046875\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 612: \tAverage Loss:  0.40913412475585936\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 613: \tAverage Loss:  0.4088684387207031\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 614: \tAverage Loss:  0.4089508056640625\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 615: \tAverage Loss:  0.40867724609375\t ACC train:  0.7555555555555555\t ACC test:  0.66\n",
      "\tEpoch 616: \tAverage Loss:  0.40878646850585937\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 617: \tAverage Loss:  0.40863607788085937\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 618: \tAverage Loss:  0.4085656433105469\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 619: \tAverage Loss:  0.4086426696777344\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 620: \tAverage Loss:  0.40852780151367185\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 621: \tAverage Loss:  0.40851651000976563\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 622: \tAverage Loss:  0.40831463623046876\t ACC train:  0.7555555555555555\t ACC test:  0.6622222222222223\n",
      "\tEpoch 623: \tAverage Loss:  0.408311279296875\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 624: \tAverage Loss:  0.40836965942382814\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 625: \tAverage Loss:  0.4081850891113281\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 626: \tAverage Loss:  0.40836358642578124\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 627: \tAverage Loss:  0.40806576538085937\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 628: \tAverage Loss:  0.40799502563476564\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 629: \tAverage Loss:  0.4081860046386719\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 630: \tAverage Loss:  0.4078812255859375\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 631: \tAverage Loss:  0.40792828369140627\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 632: \tAverage Loss:  0.40792245483398437\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 633: \tAverage Loss:  0.4078070678710938\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 634: \tAverage Loss:  0.40765216064453125\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 635: \tAverage Loss:  0.4078140869140625\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 636: \tAverage Loss:  0.4075673217773437\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 637: \tAverage Loss:  0.4073822631835938\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 638: \tAverage Loss:  0.40750836181640626\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 639: \tAverage Loss:  0.4075241394042969\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 640: \tAverage Loss:  0.4073783874511719\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 641: \tAverage Loss:  0.40735330200195313\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 642: \tAverage Loss:  0.4072789001464844\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 643: \tAverage Loss:  0.407035400390625\t ACC train:  0.7555555555555555\t ACC test:  0.6755555555555556\n",
      "\tEpoch 644: \tAverage Loss:  0.4070185852050781\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 645: \tAverage Loss:  0.40697271728515627\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 646: \tAverage Loss:  0.4070335083007813\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 647: \tAverage Loss:  0.4070057067871094\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 648: \tAverage Loss:  0.406850341796875\t ACC train:  0.7555555555555555\t ACC test:  0.6644444444444444\n",
      "\tEpoch 649: \tAverage Loss:  0.40682574462890625\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 650: \tAverage Loss:  0.40676589965820314\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 651: \tAverage Loss:  0.40672393798828127\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 652: \tAverage Loss:  0.4065684814453125\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 653: \tAverage Loss:  0.4067246398925781\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 654: \tAverage Loss:  0.4065798645019531\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 655: \tAverage Loss:  0.40640963745117187\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 656: \tAverage Loss:  0.40646917724609377\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 657: \tAverage Loss:  0.40636962890625\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 658: \tAverage Loss:  0.40628839111328124\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 659: \tAverage Loss:  0.40619842529296873\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 660: \tAverage Loss:  0.40618310546875\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 661: \tAverage Loss:  0.406102294921875\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 662: \tAverage Loss:  0.4060726318359375\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 663: \tAverage Loss:  0.40605673217773436\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 664: \tAverage Loss:  0.4060096740722656\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 665: \tAverage Loss:  0.40587692260742186\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 666: \tAverage Loss:  0.4058695373535156\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 667: \tAverage Loss:  0.4058133239746094\t ACC train:  0.7555555555555555\t ACC test:  0.6666666666666666\n",
      "\tEpoch 668: \tAverage Loss:  0.40586703491210935\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 669: \tAverage Loss:  0.40571929931640627\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 670: \tAverage Loss:  0.40572039794921877\t ACC train:  0.7555555555555555\t ACC test:  0.6688888888888889\n",
      "\tEpoch 671: \tAverage Loss:  0.40568994140625\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 672: \tAverage Loss:  0.40551953125\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 673: \tAverage Loss:  0.40547976684570314\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 674: \tAverage Loss:  0.4054687805175781\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 675: \tAverage Loss:  0.40524853515625\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 676: \tAverage Loss:  0.40530441284179686\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 677: \tAverage Loss:  0.4053040771484375\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 678: \tAverage Loss:  0.40510650634765627\t ACC train:  0.7555555555555555\t ACC test:  0.6755555555555556\n",
      "\tEpoch 679: \tAverage Loss:  0.4052330322265625\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 680: \tAverage Loss:  0.4049749145507813\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 681: \tAverage Loss:  0.4049791259765625\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 682: \tAverage Loss:  0.40498681640625\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 683: \tAverage Loss:  0.40500048828125\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 684: \tAverage Loss:  0.40497674560546876\t ACC train:  0.7555555555555555\t ACC test:  0.6755555555555556\n",
      "\tEpoch 685: \tAverage Loss:  0.4047359619140625\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 686: \tAverage Loss:  0.4047673034667969\t ACC train:  0.7555555555555555\t ACC test:  0.6755555555555556\n",
      "\tEpoch 687: \tAverage Loss:  0.4047076416015625\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 688: \tAverage Loss:  0.4046540832519531\t ACC train:  0.7555555555555555\t ACC test:  0.6711111111111111\n",
      "\tEpoch 689: \tAverage Loss:  0.40449832153320314\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 690: \tAverage Loss:  0.4046165771484375\t ACC train:  0.7555555555555555\t ACC test:  0.6777777777777778\n",
      "\tEpoch 691: \tAverage Loss:  0.40447378540039064\t ACC train:  0.7555555555555555\t ACC test:  0.6755555555555556\n",
      "\tEpoch 692: \tAverage Loss:  0.4043704833984375\t ACC train:  0.7555555555555555\t ACC test:  0.6755555555555556\n",
      "\tEpoch 693: \tAverage Loss:  0.4043843078613281\t ACC train:  0.7555555555555555\t ACC test:  0.6755555555555556\n",
      "\tEpoch 694: \tAverage Loss:  0.4043359375\t ACC train:  0.7555555555555555\t ACC test:  0.6777777777777778\n",
      "\tEpoch 695: \tAverage Loss:  0.4042462158203125\t ACC train:  0.7555555555555555\t ACC test:  0.6733333333333333\n",
      "\tEpoch 696: \tAverage Loss:  0.40406869506835935\t ACC train:  0.7555555555555555\t ACC test:  0.68\n",
      "\tEpoch 697: \tAverage Loss:  0.4042692260742187\t ACC train:  0.7555555555555555\t ACC test:  0.68\n",
      "\tEpoch 698: \tAverage Loss:  0.4041201171875\t ACC train:  0.7555555555555555\t ACC test:  0.6844444444444444\n",
      "\tEpoch 699: \tAverage Loss:  0.4040854187011719\t ACC train:  0.7555555555555555\t ACC test:  0.6822222222222222\n",
      "\tEpoch 700: \tAverage Loss:  0.4037578125\t ACC train:  0.7555555555555555\t ACC test:  0.6755555555555556\n",
      "\tEpoch 701: \tAverage Loss:  0.40396417236328125\t ACC train:  0.7555555555555555\t ACC test:  0.68\n",
      "\tEpoch 702: \tAverage Loss:  0.403681396484375\t ACC train:  0.7555555555555555\t ACC test:  0.6822222222222222\n",
      "\tEpoch 703: \tAverage Loss:  0.4037967834472656\t ACC train:  0.7555555555555555\t ACC test:  0.6755555555555556\n",
      "\tEpoch 704: \tAverage Loss:  0.40364300537109377\t ACC train:  0.7555555555555555\t ACC test:  0.6822222222222222\n",
      "\tEpoch 705: \tAverage Loss:  0.40381951904296876\t ACC train:  0.7555555555555555\t ACC test:  0.68\n",
      "\tEpoch 706: \tAverage Loss:  0.4036505126953125\t ACC train:  0.7555555555555555\t ACC test:  0.6844444444444444\n",
      "\tEpoch 707: \tAverage Loss:  0.4038941650390625\t ACC train:  0.7555555555555555\t ACC test:  0.6822222222222222\n",
      "\tEpoch 708: \tAverage Loss:  0.403349365234375\t ACC train:  0.7555555555555555\t ACC test:  0.6777777777777778\n",
      "\tEpoch 709: \tAverage Loss:  0.4034515380859375\t ACC train:  0.7555555555555555\t ACC test:  0.6822222222222222\n",
      "\tEpoch 710: \tAverage Loss:  0.403243896484375\t ACC train:  0.7555555555555555\t ACC test:  0.68\n",
      "\tEpoch 711: \tAverage Loss:  0.4033961181640625\t ACC train:  0.7555555555555555\t ACC test:  0.6822222222222222\n",
      "\tEpoch 712: \tAverage Loss:  0.4032133483886719\t ACC train:  0.7555555555555555\t ACC test:  0.6844444444444444\n",
      "\tEpoch 713: \tAverage Loss:  0.40332009887695314\t ACC train:  0.7555555555555555\t ACC test:  0.68\n",
      "\tEpoch 714: \tAverage Loss:  0.40327871704101564\t ACC train:  0.7555555555555555\t ACC test:  0.68\n",
      "\tEpoch 715: \tAverage Loss:  0.4028619689941406\t ACC train:  0.7555555555555555\t ACC test:  0.6866666666666666\n",
      "\tEpoch 716: \tAverage Loss:  0.4028397216796875\t ACC train:  0.7555555555555555\t ACC test:  0.6844444444444444\n",
      "\tEpoch 717: \tAverage Loss:  0.40312442016601563\t ACC train:  0.7555555555555555\t ACC test:  0.6822222222222222\n",
      "\tEpoch 718: \tAverage Loss:  0.4028280029296875\t ACC train:  0.7555555555555555\t ACC test:  0.6866666666666666\n",
      "\tEpoch 719: \tAverage Loss:  0.4027050476074219\t ACC train:  0.7555555555555555\t ACC test:  0.6888888888888889\n",
      "\tEpoch 720: \tAverage Loss:  0.40218463134765625\t ACC train:  0.7555555555555555\t ACC test:  0.6933333333333334\n",
      "\tEpoch 721: \tAverage Loss:  0.4020859375\t ACC train:  0.7555555555555555\t ACC test:  0.6866666666666666\n",
      "\tEpoch 722: \tAverage Loss:  0.4019808044433594\t ACC train:  0.7666666666666667\t ACC test:  0.6911111111111111\n",
      "\tEpoch 723: \tAverage Loss:  0.4022444458007812\t ACC train:  0.7666666666666667\t ACC test:  0.6911111111111111\n",
      "\tEpoch 724: \tAverage Loss:  0.40231344604492186\t ACC train:  0.7666666666666667\t ACC test:  0.6977777777777778\n",
      "\tEpoch 725: \tAverage Loss:  0.40200497436523436\t ACC train:  0.7666666666666667\t ACC test:  0.7\n",
      "\tEpoch 726: \tAverage Loss:  0.4014486389160156\t ACC train:  0.7666666666666667\t ACC test:  0.6955555555555556\n",
      "\tEpoch 727: \tAverage Loss:  0.4018526000976563\t ACC train:  0.7666666666666667\t ACC test:  0.6977777777777778\n",
      "\tEpoch 728: \tAverage Loss:  0.4007799987792969\t ACC train:  0.7888888888888889\t ACC test:  0.7022222222222222\n",
      "\tEpoch 729: \tAverage Loss:  0.4007408447265625\t ACC train:  0.7777777777777778\t ACC test:  0.7022222222222222\n",
      "\tEpoch 730: \tAverage Loss:  0.40105203247070315\t ACC train:  0.7666666666666667\t ACC test:  0.6977777777777778\n",
      "\tEpoch 731: \tAverage Loss:  0.4011974792480469\t ACC train:  0.7777777777777778\t ACC test:  0.7044444444444444\n",
      "\tEpoch 732: \tAverage Loss:  0.40056576538085936\t ACC train:  0.7888888888888889\t ACC test:  0.7\n",
      "\tEpoch 733: \tAverage Loss:  0.4001828918457031\t ACC train:  0.7888888888888889\t ACC test:  0.7\n",
      "\tEpoch 734: \tAverage Loss:  0.399461669921875\t ACC train:  0.7777777777777778\t ACC test:  0.7044444444444444\n",
      "\tEpoch 735: \tAverage Loss:  0.4005039978027344\t ACC train:  0.7666666666666667\t ACC test:  0.7066666666666667\n",
      "\tEpoch 736: \tAverage Loss:  0.3995928955078125\t ACC train:  0.7888888888888889\t ACC test:  0.7133333333333334\n",
      "\tEpoch 737: \tAverage Loss:  0.40048751831054685\t ACC train:  0.8\t ACC test:  0.7155555555555555\n",
      "\tEpoch 738: \tAverage Loss:  0.39900286865234375\t ACC train:  0.7777777777777778\t ACC test:  0.7088888888888889\n",
      "\tEpoch 739: \tAverage Loss:  0.3998547058105469\t ACC train:  0.8\t ACC test:  0.7111111111111111\n",
      "\tEpoch 740: \tAverage Loss:  0.3982516784667969\t ACC train:  0.8\t ACC test:  0.7111111111111111\n",
      "\tEpoch 741: \tAverage Loss:  0.3992109069824219\t ACC train:  0.8\t ACC test:  0.7022222222222222\n",
      "\tEpoch 742: \tAverage Loss:  0.3986259155273438\t ACC train:  0.8\t ACC test:  0.7111111111111111\n",
      "\tEpoch 743: \tAverage Loss:  0.3986575927734375\t ACC train:  0.8111111111111111\t ACC test:  0.7111111111111111\n",
      "\tEpoch 744: \tAverage Loss:  0.39782363891601563\t ACC train:  0.7888888888888889\t ACC test:  0.7111111111111111\n",
      "\tEpoch 745: \tAverage Loss:  0.3977422485351563\t ACC train:  0.8\t ACC test:  0.7177777777777777\n",
      "\tEpoch 746: \tAverage Loss:  0.39755776977539065\t ACC train:  0.8\t ACC test:  0.7155555555555555\n",
      "\tEpoch 747: \tAverage Loss:  0.39489675903320315\t ACC train:  0.8222222222222222\t ACC test:  0.7088888888888889\n",
      "\tEpoch 748: \tAverage Loss:  0.39626947021484377\t ACC train:  0.8111111111111111\t ACC test:  0.7133333333333334\n",
      "\tEpoch 749: \tAverage Loss:  0.39518328857421875\t ACC train:  0.8222222222222222\t ACC test:  0.7155555555555555\n",
      "\tEpoch 750: \tAverage Loss:  0.39510488891601564\t ACC train:  0.8111111111111111\t ACC test:  0.72\n",
      "\tEpoch 751: \tAverage Loss:  0.3942151184082031\t ACC train:  0.8111111111111111\t ACC test:  0.7244444444444444\n",
      "\tEpoch 752: \tAverage Loss:  0.39302456665039065\t ACC train:  0.8222222222222222\t ACC test:  0.7266666666666667\n",
      "\tEpoch 753: \tAverage Loss:  0.39311593627929686\t ACC train:  0.8222222222222222\t ACC test:  0.7355555555555555\n",
      "\tEpoch 754: \tAverage Loss:  0.39366705322265627\t ACC train:  0.8333333333333334\t ACC test:  0.7422222222222222\n",
      "\tEpoch 755: \tAverage Loss:  0.39160723876953124\t ACC train:  0.8444444444444444\t ACC test:  0.7511111111111111\n",
      "\tEpoch 756: \tAverage Loss:  0.39129339599609375\t ACC train:  0.8555555555555555\t ACC test:  0.76\n",
      "\tEpoch 757: \tAverage Loss:  0.38992684936523436\t ACC train:  0.8666666666666667\t ACC test:  0.7755555555555556\n",
      "\tEpoch 758: \tAverage Loss:  0.3919883422851563\t ACC train:  0.8888888888888888\t ACC test:  0.7888888888888889\n",
      "\tEpoch 759: \tAverage Loss:  0.38566534423828125\t ACC train:  0.9111111111111111\t ACC test:  0.8\n",
      "\tEpoch 760: \tAverage Loss:  0.3878952941894531\t ACC train:  0.8888888888888888\t ACC test:  0.8044444444444444\n",
      "\tEpoch 761: \tAverage Loss:  0.3897230529785156\t ACC train:  0.9\t ACC test:  0.7955555555555556\n",
      "\tEpoch 762: \tAverage Loss:  0.38320672607421874\t ACC train:  0.8888888888888888\t ACC test:  0.8311111111111111\n",
      "\tEpoch 763: \tAverage Loss:  0.3840718078613281\t ACC train:  0.9\t ACC test:  0.8177777777777778\n",
      "\tEpoch 764: \tAverage Loss:  0.3825691223144531\t ACC train:  0.8666666666666667\t ACC test:  0.8577777777777778\n",
      "\tEpoch 765: \tAverage Loss:  0.381865478515625\t ACC train:  0.9333333333333333\t ACC test:  0.8444444444444444\n",
      "\tEpoch 766: \tAverage Loss:  0.3830059814453125\t ACC train:  0.9333333333333333\t ACC test:  0.84\n",
      "\tEpoch 767: \tAverage Loss:  0.38132821655273436\t ACC train:  0.9333333333333333\t ACC test:  0.8577777777777778\n",
      "\tEpoch 768: \tAverage Loss:  0.3797728881835937\t ACC train:  0.9666666666666667\t ACC test:  0.8666666666666667\n",
      "\tEpoch 769: \tAverage Loss:  0.38170166015625\t ACC train:  0.9444444444444444\t ACC test:  0.8777777777777778\n",
      "\tEpoch 770: \tAverage Loss:  0.37817462158203125\t ACC train:  0.9444444444444444\t ACC test:  0.8733333333333333\n",
      "\tEpoch 771: \tAverage Loss:  0.37848678588867185\t ACC train:  0.9555555555555556\t ACC test:  0.9111111111111111\n",
      "\tEpoch 772: \tAverage Loss:  0.37716314697265624\t ACC train:  0.9555555555555556\t ACC test:  0.8977777777777778\n",
      "\tEpoch 773: \tAverage Loss:  0.375568603515625\t ACC train:  0.9555555555555556\t ACC test:  0.9066666666666666\n",
      "\tEpoch 774: \tAverage Loss:  0.37442718505859374\t ACC train:  0.9666666666666667\t ACC test:  0.9222222222222223\n",
      "\tEpoch 775: \tAverage Loss:  0.37444381713867186\t ACC train:  0.9666666666666667\t ACC test:  0.9177777777777778\n",
      "\tEpoch 776: \tAverage Loss:  0.37419390869140623\t ACC train:  0.9666666666666667\t ACC test:  0.9133333333333333\n",
      "\tEpoch 777: \tAverage Loss:  0.3733081970214844\t ACC train:  0.9777777777777777\t ACC test:  0.9133333333333333\n",
      "\tEpoch 778: \tAverage Loss:  0.3724851684570312\t ACC train:  0.9666666666666667\t ACC test:  0.9222222222222223\n",
      "\tEpoch 779: \tAverage Loss:  0.3717563781738281\t ACC train:  0.9777777777777777\t ACC test:  0.92\n",
      "\tEpoch 780: \tAverage Loss:  0.3723421630859375\t ACC train:  0.9666666666666667\t ACC test:  0.9133333333333333\n",
      "\tEpoch 781: \tAverage Loss:  0.3717431640625\t ACC train:  0.9777777777777777\t ACC test:  0.9044444444444445\n",
      "\tEpoch 782: \tAverage Loss:  0.37231027221679686\t ACC train:  0.9666666666666667\t ACC test:  0.9222222222222223\n",
      "\tEpoch 783: \tAverage Loss:  0.3709790954589844\t ACC train:  0.9777777777777777\t ACC test:  0.9177777777777778\n",
      "\tEpoch 784: \tAverage Loss:  0.371349365234375\t ACC train:  0.9777777777777777\t ACC test:  0.9222222222222223\n",
      "\tEpoch 785: \tAverage Loss:  0.3699371948242188\t ACC train:  0.9666666666666667\t ACC test:  0.9133333333333333\n",
      "\tEpoch 786: \tAverage Loss:  0.37104531860351564\t ACC train:  0.9777777777777777\t ACC test:  0.9177777777777778\n",
      "\tEpoch 787: \tAverage Loss:  0.37004083251953124\t ACC train:  0.9777777777777777\t ACC test:  0.9244444444444444\n",
      "\tEpoch 788: \tAverage Loss:  0.36948590087890626\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 789: \tAverage Loss:  0.3698603820800781\t ACC train:  0.9777777777777777\t ACC test:  0.9244444444444444\n",
      "\tEpoch 790: \tAverage Loss:  0.3692579345703125\t ACC train:  0.9777777777777777\t ACC test:  0.9222222222222223\n",
      "\tEpoch 791: \tAverage Loss:  0.36905584716796874\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 792: \tAverage Loss:  0.36854083251953124\t ACC train:  0.9777777777777777\t ACC test:  0.9311111111111111\n",
      "\tEpoch 793: \tAverage Loss:  0.36868820190429685\t ACC train:  0.9777777777777777\t ACC test:  0.9288888888888889\n",
      "\tEpoch 794: \tAverage Loss:  0.36814419555664063\t ACC train:  0.9777777777777777\t ACC test:  0.9222222222222223\n",
      "\tEpoch 795: \tAverage Loss:  0.3681231994628906\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 796: \tAverage Loss:  0.36769256591796873\t ACC train:  0.9777777777777777\t ACC test:  0.9244444444444444\n",
      "\tEpoch 797: \tAverage Loss:  0.36791314697265626\t ACC train:  0.9777777777777777\t ACC test:  0.9288888888888889\n",
      "\tEpoch 798: \tAverage Loss:  0.36734747314453126\t ACC train:  0.9777777777777777\t ACC test:  0.9244444444444444\n",
      "\tEpoch 799: \tAverage Loss:  0.3672344970703125\t ACC train:  0.9777777777777777\t ACC test:  0.92\n",
      "\tEpoch 800: \tAverage Loss:  0.3669473266601562\t ACC train:  0.9777777777777777\t ACC test:  0.9288888888888889\n",
      "\tEpoch 801: \tAverage Loss:  0.366700439453125\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 802: \tAverage Loss:  0.3667840270996094\t ACC train:  0.9777777777777777\t ACC test:  0.9333333333333333\n",
      "\tEpoch 803: \tAverage Loss:  0.36664739990234374\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 804: \tAverage Loss:  0.36635748291015624\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 805: \tAverage Loss:  0.36602423095703124\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 806: \tAverage Loss:  0.3657832641601563\t ACC train:  0.9777777777777777\t ACC test:  0.9311111111111111\n",
      "\tEpoch 807: \tAverage Loss:  0.36591778564453126\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 808: \tAverage Loss:  0.365641845703125\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 809: \tAverage Loss:  0.3655756530761719\t ACC train:  0.9777777777777777\t ACC test:  0.9288888888888889\n",
      "\tEpoch 810: \tAverage Loss:  0.3652212829589844\t ACC train:  0.9777777777777777\t ACC test:  0.9311111111111111\n",
      "\tEpoch 811: \tAverage Loss:  0.36532391357421873\t ACC train:  0.9777777777777777\t ACC test:  0.9288888888888889\n",
      "\tEpoch 812: \tAverage Loss:  0.365050537109375\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 813: \tAverage Loss:  0.36489111328125\t ACC train:  0.9777777777777777\t ACC test:  0.9266666666666666\n",
      "\tEpoch 814: \tAverage Loss:  0.364818603515625\t ACC train:  0.9777777777777777\t ACC test:  0.9288888888888889\n",
      "\tEpoch 815: \tAverage Loss:  0.36467791748046874\t ACC train:  0.9777777777777777\t ACC test:  0.9288888888888889\n",
      "\tEpoch 816: \tAverage Loss:  0.3644412536621094\t ACC train:  0.9777777777777777\t ACC test:  0.9288888888888889\n",
      "\tEpoch 817: \tAverage Loss:  0.36439559936523436\t ACC train:  0.9777777777777777\t ACC test:  0.9311111111111111\n",
      "\tEpoch 818: \tAverage Loss:  0.364271240234375\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 819: \tAverage Loss:  0.36408645629882813\t ACC train:  0.9777777777777777\t ACC test:  0.9311111111111111\n",
      "\tEpoch 820: \tAverage Loss:  0.363989990234375\t ACC train:  0.9777777777777777\t ACC test:  0.9311111111111111\n",
      "\tEpoch 821: \tAverage Loss:  0.36396896362304687\t ACC train:  0.9777777777777777\t ACC test:  0.9288888888888889\n",
      "\tEpoch 822: \tAverage Loss:  0.3637958374023437\t ACC train:  0.9777777777777777\t ACC test:  0.9333333333333333\n",
      "\tEpoch 823: \tAverage Loss:  0.36364849853515624\t ACC train:  0.9777777777777777\t ACC test:  0.9377777777777778\n",
      "\tEpoch 824: \tAverage Loss:  0.3634205017089844\t ACC train:  0.9777777777777777\t ACC test:  0.9333333333333333\n",
      "\tEpoch 825: \tAverage Loss:  0.36346734619140625\t ACC train:  0.9777777777777777\t ACC test:  0.9333333333333333\n",
      "\tEpoch 826: \tAverage Loss:  0.36320693969726564\t ACC train:  0.9777777777777777\t ACC test:  0.9311111111111111\n",
      "\tEpoch 827: \tAverage Loss:  0.36310791015625\t ACC train:  0.9777777777777777\t ACC test:  0.9311111111111111\n",
      "\tEpoch 828: \tAverage Loss:  0.3630506896972656\t ACC train:  0.9777777777777777\t ACC test:  0.9311111111111111\n",
      "\tEpoch 829: \tAverage Loss:  0.3628976745605469\t ACC train:  0.9777777777777777\t ACC test:  0.9333333333333333\n",
      "\tEpoch 830: \tAverage Loss:  0.36265878295898435\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 831: \tAverage Loss:  0.3625958557128906\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 832: \tAverage Loss:  0.3625118408203125\t ACC train:  0.9777777777777777\t ACC test:  0.9377777777777778\n",
      "\tEpoch 833: \tAverage Loss:  0.3623460998535156\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 834: \tAverage Loss:  0.3623507995605469\t ACC train:  0.9777777777777777\t ACC test:  0.9333333333333333\n",
      "\tEpoch 835: \tAverage Loss:  0.36215325927734376\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 836: \tAverage Loss:  0.36204913330078126\t ACC train:  0.9777777777777777\t ACC test:  0.9333333333333333\n",
      "\tEpoch 837: \tAverage Loss:  0.3619029846191406\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 838: \tAverage Loss:  0.36180517578125\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 839: \tAverage Loss:  0.36170809936523435\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 840: \tAverage Loss:  0.3615221252441406\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 841: \tAverage Loss:  0.36145782470703125\t ACC train:  0.9777777777777777\t ACC test:  0.9377777777777778\n",
      "\tEpoch 842: \tAverage Loss:  0.36133236694335935\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 843: \tAverage Loss:  0.3611375732421875\t ACC train:  0.9777777777777777\t ACC test:  0.94\n",
      "\tEpoch 844: \tAverage Loss:  0.36102426147460936\t ACC train:  0.9777777777777777\t ACC test:  0.9422222222222222\n",
      "\tEpoch 845: \tAverage Loss:  0.36084292602539064\t ACC train:  0.9777777777777777\t ACC test:  0.9422222222222222\n",
      "\tEpoch 846: \tAverage Loss:  0.36078054809570315\t ACC train:  0.9777777777777777\t ACC test:  0.9422222222222222\n",
      "\tEpoch 847: \tAverage Loss:  0.3605978088378906\t ACC train:  0.9777777777777777\t ACC test:  0.9377777777777778\n",
      "\tEpoch 848: \tAverage Loss:  0.36046002197265625\t ACC train:  0.9777777777777777\t ACC test:  0.9355555555555556\n",
      "\tEpoch 849: \tAverage Loss:  0.36021646118164063\t ACC train:  0.9777777777777777\t ACC test:  0.94\n",
      "\tEpoch 850: \tAverage Loss:  0.3601207580566406\t ACC train:  0.9777777777777777\t ACC test:  0.9466666666666667\n",
      "\tEpoch 851: \tAverage Loss:  0.35995611572265623\t ACC train:  0.9888888888888889\t ACC test:  0.9466666666666667\n",
      "\tEpoch 852: \tAverage Loss:  0.3597760009765625\t ACC train:  0.9888888888888889\t ACC test:  0.9444444444444444\n",
      "\tEpoch 853: \tAverage Loss:  0.3596663818359375\t ACC train:  0.9888888888888889\t ACC test:  0.9466666666666667\n",
      "\tEpoch 854: \tAverage Loss:  0.35944400024414064\t ACC train:  0.9888888888888889\t ACC test:  0.9466666666666667\n",
      "\tEpoch 855: \tAverage Loss:  0.3594135437011719\t ACC train:  0.9888888888888889\t ACC test:  0.9488888888888889\n",
      "\tEpoch 856: \tAverage Loss:  0.3591504821777344\t ACC train:  0.9888888888888889\t ACC test:  0.9488888888888889\n",
      "\tEpoch 857: \tAverage Loss:  0.3590825500488281\t ACC train:  0.9888888888888889\t ACC test:  0.9488888888888889\n",
      "\tEpoch 858: \tAverage Loss:  0.35879766845703126\t ACC train:  0.9888888888888889\t ACC test:  0.9511111111111111\n",
      "\tEpoch 859: \tAverage Loss:  0.3586846618652344\t ACC train:  0.9888888888888889\t ACC test:  0.9533333333333334\n",
      "\tEpoch 860: \tAverage Loss:  0.35854949951171877\t ACC train:  0.9888888888888889\t ACC test:  0.9533333333333334\n",
      "\tEpoch 861: \tAverage Loss:  0.3583531799316406\t ACC train:  0.9888888888888889\t ACC test:  0.9555555555555556\n",
      "\tEpoch 862: \tAverage Loss:  0.35816268920898436\t ACC train:  0.9888888888888889\t ACC test:  0.9577777777777777\n",
      "\tEpoch 863: \tAverage Loss:  0.3579898376464844\t ACC train:  0.9888888888888889\t ACC test:  0.9577777777777777\n",
      "\tEpoch 864: \tAverage Loss:  0.3577903747558594\t ACC train:  0.9888888888888889\t ACC test:  0.9555555555555556\n",
      "\tEpoch 865: \tAverage Loss:  0.35765469360351565\t ACC train:  0.9888888888888889\t ACC test:  0.96\n",
      "\tEpoch 866: \tAverage Loss:  0.35746456909179686\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 867: \tAverage Loss:  0.3573771057128906\t ACC train:  0.9888888888888889\t ACC test:  0.9533333333333334\n",
      "\tEpoch 868: \tAverage Loss:  0.35706405639648436\t ACC train:  0.9888888888888889\t ACC test:  0.9555555555555556\n",
      "\tEpoch 869: \tAverage Loss:  0.35693472290039063\t ACC train:  0.9888888888888889\t ACC test:  0.9533333333333334\n",
      "\tEpoch 870: \tAverage Loss:  0.3569298095703125\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 871: \tAverage Loss:  0.35652230834960935\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 872: \tAverage Loss:  0.3566083984375\t ACC train:  0.9888888888888889\t ACC test:  0.9577777777777777\n",
      "\tEpoch 873: \tAverage Loss:  0.35630685424804687\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 874: \tAverage Loss:  0.35637628173828123\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 875: \tAverage Loss:  0.35633450317382814\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 876: \tAverage Loss:  0.3559341125488281\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 877: \tAverage Loss:  0.35583676147460935\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 878: \tAverage Loss:  0.3557966003417969\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 879: \tAverage Loss:  0.3555543212890625\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 880: \tAverage Loss:  0.3554985961914062\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 881: \tAverage Loss:  0.3552703857421875\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 882: \tAverage Loss:  0.3549920959472656\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 883: \tAverage Loss:  0.3549502258300781\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 884: \tAverage Loss:  0.3548131103515625\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 885: \tAverage Loss:  0.35466781616210935\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 886: \tAverage Loss:  0.354447509765625\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 887: \tAverage Loss:  0.3543863220214844\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 888: \tAverage Loss:  0.35422930908203126\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 889: \tAverage Loss:  0.35399215698242187\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 890: \tAverage Loss:  0.353890380859375\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 891: \tAverage Loss:  0.35374688720703124\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 892: \tAverage Loss:  0.3536176452636719\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 893: \tAverage Loss:  0.3533193664550781\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 894: \tAverage Loss:  0.3532325439453125\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 895: \tAverage Loss:  0.3530451965332031\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 896: \tAverage Loss:  0.3529093322753906\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 897: \tAverage Loss:  0.3527584228515625\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 898: \tAverage Loss:  0.3525759887695312\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 899: \tAverage Loss:  0.352342041015625\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 900: \tAverage Loss:  0.352205322265625\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 901: \tAverage Loss:  0.3520314636230469\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 902: \tAverage Loss:  0.3519178161621094\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 903: \tAverage Loss:  0.3517287292480469\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 904: \tAverage Loss:  0.3514606628417969\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 905: \tAverage Loss:  0.3513191223144531\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 906: \tAverage Loss:  0.35113116455078125\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 907: \tAverage Loss:  0.35100106811523435\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 908: \tAverage Loss:  0.3508141479492187\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 909: \tAverage Loss:  0.350553466796875\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 910: \tAverage Loss:  0.35057711791992185\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 911: \tAverage Loss:  0.35023410034179686\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 912: \tAverage Loss:  0.34996743774414063\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 913: \tAverage Loss:  0.349945556640625\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 914: \tAverage Loss:  0.34968756103515625\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 915: \tAverage Loss:  0.349417724609375\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 916: \tAverage Loss:  0.3492576599121094\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 917: \tAverage Loss:  0.3490706787109375\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 918: \tAverage Loss:  0.34883447265625\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 919: \tAverage Loss:  0.3486088562011719\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 920: \tAverage Loss:  0.3483779602050781\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 921: \tAverage Loss:  0.34819482421875\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 922: \tAverage Loss:  0.34786965942382814\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 923: \tAverage Loss:  0.3475822448730469\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 924: \tAverage Loss:  0.34740447998046875\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 925: \tAverage Loss:  0.3472513427734375\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 926: \tAverage Loss:  0.3469706115722656\t ACC train:  1.0\t ACC test:  0.9577777777777777\n",
      "\tEpoch 927: \tAverage Loss:  0.34667013549804687\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 928: \tAverage Loss:  0.34636688232421875\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 929: \tAverage Loss:  0.34621597290039063\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 930: \tAverage Loss:  0.346029296875\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 931: \tAverage Loss:  0.34569674682617185\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 932: \tAverage Loss:  0.34533697509765626\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 933: \tAverage Loss:  0.3451459655761719\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 934: \tAverage Loss:  0.3448052978515625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 935: \tAverage Loss:  0.34466815185546873\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 936: \tAverage Loss:  0.3442999877929688\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 937: \tAverage Loss:  0.34402899169921874\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 938: \tAverage Loss:  0.34375872802734375\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 939: \tAverage Loss:  0.34335610961914065\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 940: \tAverage Loss:  0.34315731811523437\t ACC train:  1.0\t ACC test:  0.9555555555555556\n",
      "\tEpoch 941: \tAverage Loss:  0.3427891235351562\t ACC train:  1.0\t ACC test:  0.9511111111111111\n",
      "\tEpoch 942: \tAverage Loss:  0.34240118408203124\t ACC train:  1.0\t ACC test:  0.9488888888888889\n",
      "\tEpoch 943: \tAverage Loss:  0.3420124206542969\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 944: \tAverage Loss:  0.3417927551269531\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 945: \tAverage Loss:  0.34148126220703123\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 946: \tAverage Loss:  0.3410072937011719\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 947: \tAverage Loss:  0.34062704467773436\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 948: \tAverage Loss:  0.34026055908203123\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 949: \tAverage Loss:  0.3400223083496094\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 950: \tAverage Loss:  0.33976437377929686\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 951: \tAverage Loss:  0.3392244873046875\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 952: \tAverage Loss:  0.3388284912109375\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 953: \tAverage Loss:  0.33845220947265625\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 954: \tAverage Loss:  0.33801263427734374\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 955: \tAverage Loss:  0.33762066650390626\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 956: \tAverage Loss:  0.33724774169921873\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 957: \tAverage Loss:  0.3369022521972656\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 958: \tAverage Loss:  0.3364899291992188\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 959: \tAverage Loss:  0.33616094970703125\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 960: \tAverage Loss:  0.33574398803710936\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 961: \tAverage Loss:  0.335310791015625\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 962: \tAverage Loss:  0.3349180908203125\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 963: \tAverage Loss:  0.3345826721191406\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 964: \tAverage Loss:  0.33417376708984375\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 965: \tAverage Loss:  0.3337193908691406\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 966: \tAverage Loss:  0.33334414672851564\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 967: \tAverage Loss:  0.3328832092285156\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 968: \tAverage Loss:  0.3324540100097656\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 969: \tAverage Loss:  0.332116455078125\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 970: \tAverage Loss:  0.33170968627929687\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 971: \tAverage Loss:  0.3312613525390625\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 972: \tAverage Loss:  0.33091619873046874\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 973: \tAverage Loss:  0.3304765625\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 974: \tAverage Loss:  0.33007345581054687\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 975: \tAverage Loss:  0.32969027709960935\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 976: \tAverage Loss:  0.32923538208007813\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 977: \tAverage Loss:  0.3289132385253906\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 978: \tAverage Loss:  0.3284579162597656\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 979: \tAverage Loss:  0.32805133056640623\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 980: \tAverage Loss:  0.32768792724609375\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 981: \tAverage Loss:  0.32719754028320314\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 982: \tAverage Loss:  0.326848876953125\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 983: \tAverage Loss:  0.3264003295898438\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 984: \tAverage Loss:  0.3259801025390625\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 985: \tAverage Loss:  0.3256361083984375\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 986: \tAverage Loss:  0.3251793212890625\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 987: \tAverage Loss:  0.3248678894042969\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 988: \tAverage Loss:  0.32439566040039064\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 989: \tAverage Loss:  0.3240093994140625\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 990: \tAverage Loss:  0.32368731689453123\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 991: \tAverage Loss:  0.323218994140625\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 992: \tAverage Loss:  0.32292724609375\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 993: \tAverage Loss:  0.32258453369140627\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 994: \tAverage Loss:  0.32211410522460937\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 995: \tAverage Loss:  0.32172207641601563\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 996: \tAverage Loss:  0.3214548034667969\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 997: \tAverage Loss:  0.32117633056640627\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 998: \tAverage Loss:  0.3207803649902344\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 999: \tAverage Loss:  0.3204058837890625\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1000: \tAverage Loss:  0.32019332885742186\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1001: \tAverage Loss:  0.3199414978027344\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1002: \tAverage Loss:  0.3195560607910156\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1003: \tAverage Loss:  0.31922201538085937\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1004: \tAverage Loss:  0.31894384765625\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1005: \tAverage Loss:  0.3187225646972656\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1006: \tAverage Loss:  0.318465576171875\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1007: \tAverage Loss:  0.31805908203125\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1008: \tAverage Loss:  0.3178802490234375\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1009: \tAverage Loss:  0.31764688110351563\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1010: \tAverage Loss:  0.3173309326171875\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1011: \tAverage Loss:  0.31716122436523436\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1012: \tAverage Loss:  0.31694100952148435\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1013: \tAverage Loss:  0.3167479248046875\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1014: \tAverage Loss:  0.3165527648925781\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1015: \tAverage Loss:  0.31626312255859373\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1016: \tAverage Loss:  0.3160342102050781\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1017: \tAverage Loss:  0.31573483276367187\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1018: \tAverage Loss:  0.31556881713867185\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1019: \tAverage Loss:  0.31536187744140626\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1020: \tAverage Loss:  0.31511712646484374\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1021: \tAverage Loss:  0.3150107727050781\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1022: \tAverage Loss:  0.3148143615722656\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1023: \tAverage Loss:  0.31463232421875\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1024: \tAverage Loss:  0.3144713134765625\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1025: \tAverage Loss:  0.3141873779296875\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1026: \tAverage Loss:  0.31407470703125\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1027: \tAverage Loss:  0.3139772338867188\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1028: \tAverage Loss:  0.3137147216796875\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1029: \tAverage Loss:  0.31357867431640624\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1030: \tAverage Loss:  0.3133607482910156\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1031: \tAverage Loss:  0.3132206115722656\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1032: \tAverage Loss:  0.3130831298828125\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1033: \tAverage Loss:  0.3129231262207031\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1034: \tAverage Loss:  0.3126930541992187\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1035: \tAverage Loss:  0.31254278564453125\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1036: \tAverage Loss:  0.31242459106445314\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1037: \tAverage Loss:  0.31226239013671875\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1038: \tAverage Loss:  0.312116455078125\t ACC train:  1.0\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1039: \tAverage Loss:  0.3119715881347656\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1040: \tAverage Loss:  0.3118538208007812\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1041: \tAverage Loss:  0.3117270202636719\t ACC train:  1.0\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1042: \tAverage Loss:  0.31157693481445314\t ACC train:  1.0\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1043: \tAverage Loss:  0.3114627685546875\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1044: \tAverage Loss:  0.31134271240234374\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1045: \tAverage Loss:  0.31120053100585937\t ACC train:  1.0\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1046: \tAverage Loss:  0.31108493041992186\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1047: \tAverage Loss:  0.3110243835449219\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1048: \tAverage Loss:  0.310879638671875\t ACC train:  1.0\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1049: \tAverage Loss:  0.31076239013671875\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1050: \tAverage Loss:  0.31059149169921874\t ACC train:  1.0\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1051: \tAverage Loss:  0.3105792236328125\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1052: \tAverage Loss:  0.31040359497070313\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1053: \tAverage Loss:  0.3102825622558594\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1054: \tAverage Loss:  0.3101824951171875\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1055: \tAverage Loss:  0.3100867919921875\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1056: \tAverage Loss:  0.30993951416015625\t ACC train:  1.0\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1057: \tAverage Loss:  0.3098625183105469\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1058: \tAverage Loss:  0.30974234008789064\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1059: \tAverage Loss:  0.30961233520507814\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1060: \tAverage Loss:  0.3095238647460937\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1061: \tAverage Loss:  0.30951699829101564\t ACC train:  1.0\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1062: \tAverage Loss:  0.30935379028320314\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1063: \tAverage Loss:  0.30935150146484375\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1064: \tAverage Loss:  0.3091875915527344\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1065: \tAverage Loss:  0.309116455078125\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1066: \tAverage Loss:  0.30897348022460935\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1067: \tAverage Loss:  0.30888861083984376\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1068: \tAverage Loss:  0.3088253173828125\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1069: \tAverage Loss:  0.30877557373046877\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1070: \tAverage Loss:  0.30858822631835936\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1071: \tAverage Loss:  0.30853073120117186\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1072: \tAverage Loss:  0.30847686767578125\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1073: \tAverage Loss:  0.30839971923828124\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1074: \tAverage Loss:  0.3082958068847656\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1075: \tAverage Loss:  0.30822991943359374\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1076: \tAverage Loss:  0.30817138671875\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1077: \tAverage Loss:  0.30805062866210936\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1078: \tAverage Loss:  0.3080870971679687\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1079: \tAverage Loss:  0.30790521240234375\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1080: \tAverage Loss:  0.3078151245117188\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1081: \tAverage Loss:  0.30774774169921876\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1082: \tAverage Loss:  0.3077077331542969\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1083: \tAverage Loss:  0.30760443115234376\t ACC train:  1.0\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1084: \tAverage Loss:  0.3075523681640625\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1085: \tAverage Loss:  0.30750836181640623\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1086: \tAverage Loss:  0.30741650390625\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1087: \tAverage Loss:  0.307365966796875\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1088: \tAverage Loss:  0.30727252197265625\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1089: \tAverage Loss:  0.307151611328125\t ACC train:  1.0\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1090: \tAverage Loss:  0.30713623046875\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1091: \tAverage Loss:  0.3070885314941406\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1092: \tAverage Loss:  0.306962890625\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1093: \tAverage Loss:  0.30690176391601565\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1094: \tAverage Loss:  0.306870849609375\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1095: \tAverage Loss:  0.3067425537109375\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1096: \tAverage Loss:  0.30675210571289063\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1097: \tAverage Loss:  0.3066943359375\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1098: \tAverage Loss:  0.3065575866699219\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1099: \tAverage Loss:  0.306554443359375\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1100: \tAverage Loss:  0.30651144409179687\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1101: \tAverage Loss:  0.30637908935546876\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1102: \tAverage Loss:  0.3063804931640625\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1103: \tAverage Loss:  0.3063362731933594\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1104: \tAverage Loss:  0.3062008972167969\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1105: \tAverage Loss:  0.30613223266601564\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1106: \tAverage Loss:  0.30607077026367185\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1107: \tAverage Loss:  0.3059932556152344\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1108: \tAverage Loss:  0.30597323608398436\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1109: \tAverage Loss:  0.3059217834472656\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1110: \tAverage Loss:  0.3058435363769531\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1111: \tAverage Loss:  0.305851806640625\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1112: \tAverage Loss:  0.3057818603515625\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1113: \tAverage Loss:  0.3056657409667969\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1114: \tAverage Loss:  0.30561892700195314\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1115: \tAverage Loss:  0.30555545043945315\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1116: \tAverage Loss:  0.30550064086914064\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1117: \tAverage Loss:  0.3054602966308594\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1118: \tAverage Loss:  0.30539889526367187\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1119: \tAverage Loss:  0.305328369140625\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1120: \tAverage Loss:  0.3052644653320313\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1121: \tAverage Loss:  0.3052236328125\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1122: \tAverage Loss:  0.30518240356445314\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1123: \tAverage Loss:  0.305093505859375\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1124: \tAverage Loss:  0.30506430053710937\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1125: \tAverage Loss:  0.30498834228515626\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1126: \tAverage Loss:  0.30492547607421877\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1127: \tAverage Loss:  0.30489947509765625\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1128: \tAverage Loss:  0.3048322448730469\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1129: \tAverage Loss:  0.30479217529296876\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1130: \tAverage Loss:  0.3047585754394531\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1131: \tAverage Loss:  0.30479461669921876\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1132: \tAverage Loss:  0.30462606811523435\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1133: \tAverage Loss:  0.30455517578125\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1134: \tAverage Loss:  0.3046423034667969\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1135: \tAverage Loss:  0.3045718383789062\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1136: \tAverage Loss:  0.30443826293945314\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1137: \tAverage Loss:  0.30441885375976563\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1138: \tAverage Loss:  0.30438406372070315\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1139: \tAverage Loss:  0.3043152160644531\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1140: \tAverage Loss:  0.30426470947265627\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1141: \tAverage Loss:  0.3044471435546875\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1142: \tAverage Loss:  0.30444247436523436\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1143: \tAverage Loss:  0.30408758544921877\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1144: \tAverage Loss:  0.3040331420898438\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1145: \tAverage Loss:  0.30412515258789063\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1146: \tAverage Loss:  0.30403848266601563\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1147: \tAverage Loss:  0.3039275207519531\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1148: \tAverage Loss:  0.3040095520019531\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1149: \tAverage Loss:  0.3037957763671875\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1150: \tAverage Loss:  0.3037702941894531\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1151: \tAverage Loss:  0.3038355407714844\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1152: \tAverage Loss:  0.30367868041992185\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1153: \tAverage Loss:  0.3036376647949219\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1154: \tAverage Loss:  0.30365560913085937\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1155: \tAverage Loss:  0.30352053833007814\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1156: \tAverage Loss:  0.30353753662109373\t ACC train:  1.0\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1157: \tAverage Loss:  0.3035155029296875\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1158: \tAverage Loss:  0.3033828430175781\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1159: \tAverage Loss:  0.30340234375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1160: \tAverage Loss:  0.30340252685546876\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1161: \tAverage Loss:  0.30332330322265627\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1162: \tAverage Loss:  0.30322210693359375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1163: \tAverage Loss:  0.3032803955078125\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1164: \tAverage Loss:  0.30313748168945315\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1165: \tAverage Loss:  0.30311520385742186\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1166: \tAverage Loss:  0.30307077026367185\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1167: \tAverage Loss:  0.303020751953125\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1168: \tAverage Loss:  0.30297271728515623\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1169: \tAverage Loss:  0.3029665222167969\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1170: \tAverage Loss:  0.302845458984375\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1171: \tAverage Loss:  0.3028392639160156\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1172: \tAverage Loss:  0.302821044921875\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1173: \tAverage Loss:  0.3027397766113281\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1174: \tAverage Loss:  0.3027572021484375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1175: \tAverage Loss:  0.3027614440917969\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1176: \tAverage Loss:  0.3026036071777344\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1177: \tAverage Loss:  0.3026180419921875\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1178: \tAverage Loss:  0.3026036376953125\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1179: \tAverage Loss:  0.3024943542480469\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1180: \tAverage Loss:  0.3025052185058594\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1181: \tAverage Loss:  0.3025262451171875\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1182: \tAverage Loss:  0.30239349365234375\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1183: \tAverage Loss:  0.3023358154296875\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1184: \tAverage Loss:  0.3024178466796875\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1185: \tAverage Loss:  0.30228921508789064\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1186: \tAverage Loss:  0.30222000122070314\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1187: \tAverage Loss:  0.3022462158203125\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1188: \tAverage Loss:  0.30213897705078124\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1189: \tAverage Loss:  0.3021390380859375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1190: \tAverage Loss:  0.3021672668457031\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1191: \tAverage Loss:  0.302021240234375\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1192: \tAverage Loss:  0.30207196044921875\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1193: \tAverage Loss:  0.302031005859375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 1194: \tAverage Loss:  0.30185446166992186\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1195: \tAverage Loss:  0.3019927673339844\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1196: \tAverage Loss:  0.30200286865234377\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1197: \tAverage Loss:  0.30179763793945313\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1198: \tAverage Loss:  0.30176678466796875\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1199: \tAverage Loss:  0.301823974609375\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1200: \tAverage Loss:  0.3017020263671875\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1201: \tAverage Loss:  0.3016912841796875\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1202: \tAverage Loss:  0.30161471557617187\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1203: \tAverage Loss:  0.30156396484375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1204: \tAverage Loss:  0.30155035400390623\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1205: \tAverage Loss:  0.30156903076171876\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1206: \tAverage Loss:  0.3014117736816406\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1207: \tAverage Loss:  0.3013746337890625\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1208: \tAverage Loss:  0.3014951171875\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1209: \tAverage Loss:  0.3013155517578125\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1210: \tAverage Loss:  0.30124453735351564\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1211: \tAverage Loss:  0.3012486877441406\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1212: \tAverage Loss:  0.30118255615234374\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1213: \tAverage Loss:  0.30112261962890624\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1214: \tAverage Loss:  0.3011692810058594\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1215: \tAverage Loss:  0.3010992431640625\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1216: \tAverage Loss:  0.30101727294921876\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 1217: \tAverage Loss:  0.3009993591308594\t ACC train:  1.0\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1218: \tAverage Loss:  0.3009610595703125\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1219: \tAverage Loss:  0.3009041748046875\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1220: \tAverage Loss:  0.3008576965332031\t ACC train:  1.0\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1221: \tAverage Loss:  0.30083450317382815\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1222: \tAverage Loss:  0.300800537109375\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1223: \tAverage Loss:  0.3007666015625\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1224: \tAverage Loss:  0.30071478271484375\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1225: \tAverage Loss:  0.3006986083984375\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1226: \tAverage Loss:  0.3006694641113281\t ACC train:  1.0\t ACC test:  0.9422222222222222\n",
      "Stopping early at epoch 1226. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 100\n",
      "\tEpoch 1: \tAverage Loss:  0.9877200317382813\t ACC train:  0.41\t ACC test:  0.49333333333333335\n",
      "\tEpoch 2: \tAverage Loss:  0.983280517578125\t ACC train:  0.47\t ACC test:  0.5066666666666667\n",
      "\tEpoch 3: \tAverage Loss:  0.976616455078125\t ACC train:  0.54\t ACC test:  0.49777777777777776\n",
      "\tEpoch 4: \tAverage Loss:  0.9732301025390625\t ACC train:  0.46\t ACC test:  0.5311111111111111\n",
      "\tEpoch 5: \tAverage Loss:  0.968760986328125\t ACC train:  0.48\t ACC test:  0.54\n",
      "\tEpoch 6: \tAverage Loss:  0.9660701904296874\t ACC train:  0.56\t ACC test:  0.5\n",
      "\tEpoch 7: \tAverage Loss:  0.9611982421875\t ACC train:  0.49\t ACC test:  0.4955555555555556\n",
      "\tEpoch 8: \tAverage Loss:  0.9590385131835938\t ACC train:  0.49\t ACC test:  0.4822222222222222\n",
      "\tEpoch 9: \tAverage Loss:  0.9548441772460937\t ACC train:  0.55\t ACC test:  0.4777777777777778\n",
      "\tEpoch 10: \tAverage Loss:  0.9522077026367187\t ACC train:  0.56\t ACC test:  0.48444444444444446\n",
      "\tEpoch 11: \tAverage Loss:  0.9491240844726563\t ACC train:  0.53\t ACC test:  0.4888888888888889\n",
      "\tEpoch 12: \tAverage Loss:  0.9469721069335938\t ACC train:  0.54\t ACC test:  0.48\n",
      "\tEpoch 13: \tAverage Loss:  0.9436795043945313\t ACC train:  0.54\t ACC test:  0.4822222222222222\n",
      "\tEpoch 14: \tAverage Loss:  0.9404519653320312\t ACC train:  0.54\t ACC test:  0.4911111111111111\n",
      "\tEpoch 15: \tAverage Loss:  0.9375880126953124\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  0.9359873046875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  0.932645263671875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  0.9305101318359374\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  0.9282512817382812\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  0.9251318359375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  0.92392724609375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  0.9202721557617187\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  0.9194603271484375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  0.917565673828125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  0.9152667846679687\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  0.91340966796875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  0.9114520874023437\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  0.91013134765625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  0.9079463500976562\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  0.9058212890625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  0.9032907104492187\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  0.9013478393554688\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  0.9012329711914062\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  0.8991973266601563\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  0.8969085693359375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  0.8967192993164063\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  0.8955067138671875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  0.8929673461914063\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  0.890935791015625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  0.889932861328125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  0.8883997802734375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  0.8875189208984375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  0.885371337890625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  0.8843567504882812\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  0.88240087890625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  0.8818970336914063\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  0.879765869140625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  0.8798466186523437\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  0.8791963500976563\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  0.8772346801757812\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  0.8772471923828125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  0.874728515625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  0.8720238037109375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  0.873070068359375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  0.8718023681640625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  0.8717218627929687\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  0.8707405395507812\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  0.8698783569335937\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  0.8680590209960938\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  0.86830126953125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  0.865356689453125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  0.8658621826171875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  0.8642462768554687\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  0.86314013671875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  0.8624924926757812\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  0.8608924560546874\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  0.8623440551757813\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  0.8596810302734375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  0.8600721435546875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  0.8587337036132813\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  0.8573424682617188\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  0.8567935180664062\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  0.8587188110351562\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  0.8554991455078125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  0.8549896240234375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  0.8538209838867188\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  0.8545203247070312\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  0.8512349243164062\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  0.8528165283203125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  0.852307373046875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  0.8491756591796875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  0.8483916015625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  0.8495130004882813\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 84: \tAverage Loss:  0.8490661010742188\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 85: \tAverage Loss:  0.8479096069335937\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 86: \tAverage Loss:  0.8473209228515625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 87: \tAverage Loss:  0.8473080444335938\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 88: \tAverage Loss:  0.8454241333007813\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 89: \tAverage Loss:  0.8456047973632812\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 90: \tAverage Loss:  0.8420050659179688\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 91: \tAverage Loss:  0.8438034057617188\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 92: \tAverage Loss:  0.845784912109375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 93: \tAverage Loss:  0.8427778930664063\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 94: \tAverage Loss:  0.8414209594726563\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 95: \tAverage Loss:  0.839404052734375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 96: \tAverage Loss:  0.840892333984375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 97: \tAverage Loss:  0.8387742309570313\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 98: \tAverage Loss:  0.83861328125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 99: \tAverage Loss:  0.8347365112304688\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 100: \tAverage Loss:  0.8344677124023437\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  0.8337149658203125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 102: \tAverage Loss:  0.832394775390625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 103: \tAverage Loss:  0.8309396362304687\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 104: \tAverage Loss:  0.829173828125\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 105: \tAverage Loss:  0.8284620361328126\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 106: \tAverage Loss:  0.8279578857421875\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 107: \tAverage Loss:  0.8242576904296876\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 108: \tAverage Loss:  0.825810302734375\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 109: \tAverage Loss:  0.827484619140625\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 110: \tAverage Loss:  0.8196063842773438\t ACC train:  0.54\t ACC test:  0.4888888888888889\n",
      "\tEpoch 111: \tAverage Loss:  0.8188671875\t ACC train:  0.54\t ACC test:  0.4888888888888889\n",
      "\tEpoch 112: \tAverage Loss:  0.8178413696289063\t ACC train:  0.54\t ACC test:  0.4866666666666667\n",
      "\tEpoch 113: \tAverage Loss:  0.8166889038085937\t ACC train:  0.54\t ACC test:  0.4911111111111111\n",
      "\tEpoch 114: \tAverage Loss:  0.8170393676757812\t ACC train:  0.54\t ACC test:  0.49333333333333335\n",
      "\tEpoch 115: \tAverage Loss:  0.815156005859375\t ACC train:  0.54\t ACC test:  0.4911111111111111\n",
      "\tEpoch 116: \tAverage Loss:  0.810529296875\t ACC train:  0.55\t ACC test:  0.4888888888888889\n",
      "\tEpoch 117: \tAverage Loss:  0.8097321166992187\t ACC train:  0.54\t ACC test:  0.49333333333333335\n",
      "\tEpoch 118: \tAverage Loss:  0.8075331420898437\t ACC train:  0.56\t ACC test:  0.5\n",
      "\tEpoch 119: \tAverage Loss:  0.8026871337890625\t ACC train:  0.55\t ACC test:  0.49777777777777776\n",
      "\tEpoch 120: \tAverage Loss:  0.805651611328125\t ACC train:  0.54\t ACC test:  0.5\n",
      "\tEpoch 121: \tAverage Loss:  0.8051556396484375\t ACC train:  0.57\t ACC test:  0.5044444444444445\n",
      "\tEpoch 122: \tAverage Loss:  0.7989237670898437\t ACC train:  0.57\t ACC test:  0.5044444444444445\n",
      "\tEpoch 123: \tAverage Loss:  0.79600830078125\t ACC train:  0.58\t ACC test:  0.5311111111111111\n",
      "\tEpoch 124: \tAverage Loss:  0.7953897705078125\t ACC train:  0.62\t ACC test:  0.5377777777777778\n",
      "\tEpoch 125: \tAverage Loss:  0.79357421875\t ACC train:  0.64\t ACC test:  0.5333333333333333\n",
      "\tEpoch 126: \tAverage Loss:  0.791429931640625\t ACC train:  0.59\t ACC test:  0.56\n",
      "\tEpoch 127: \tAverage Loss:  0.7864342651367188\t ACC train:  0.64\t ACC test:  0.5533333333333333\n",
      "\tEpoch 128: \tAverage Loss:  0.7853380737304687\t ACC train:  0.62\t ACC test:  0.5755555555555556\n",
      "\tEpoch 129: \tAverage Loss:  0.7803777465820313\t ACC train:  0.65\t ACC test:  0.5911111111111111\n",
      "\tEpoch 130: \tAverage Loss:  0.7822113037109375\t ACC train:  0.66\t ACC test:  0.5777777777777777\n",
      "\tEpoch 131: \tAverage Loss:  0.7801294555664062\t ACC train:  0.62\t ACC test:  0.5755555555555556\n",
      "\tEpoch 132: \tAverage Loss:  0.7758297729492187\t ACC train:  0.66\t ACC test:  0.58\n",
      "\tEpoch 133: \tAverage Loss:  0.7736195678710938\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 134: \tAverage Loss:  0.7671175537109375\t ACC train:  0.64\t ACC test:  0.5955555555555555\n",
      "\tEpoch 135: \tAverage Loss:  0.7665828857421875\t ACC train:  0.69\t ACC test:  0.6111111111111112\n",
      "\tEpoch 136: \tAverage Loss:  0.75777099609375\t ACC train:  0.65\t ACC test:  0.5933333333333334\n",
      "\tEpoch 137: \tAverage Loss:  0.7561668701171875\t ACC train:  0.64\t ACC test:  0.6066666666666667\n",
      "\tEpoch 138: \tAverage Loss:  0.7531119995117187\t ACC train:  0.67\t ACC test:  0.5977777777777777\n",
      "\tEpoch 139: \tAverage Loss:  0.75013427734375\t ACC train:  0.64\t ACC test:  0.5911111111111111\n",
      "\tEpoch 140: \tAverage Loss:  0.74578955078125\t ACC train:  0.63\t ACC test:  0.5888888888888889\n",
      "\tEpoch 141: \tAverage Loss:  0.7422063598632812\t ACC train:  0.62\t ACC test:  0.6088888888888889\n",
      "\tEpoch 142: \tAverage Loss:  0.7408975219726562\t ACC train:  0.63\t ACC test:  0.6155555555555555\n",
      "\tEpoch 143: \tAverage Loss:  0.7386370239257812\t ACC train:  0.65\t ACC test:  0.6022222222222222\n",
      "\tEpoch 144: \tAverage Loss:  0.727610595703125\t ACC train:  0.64\t ACC test:  0.5911111111111111\n",
      "\tEpoch 145: \tAverage Loss:  0.72838525390625\t ACC train:  0.64\t ACC test:  0.5955555555555555\n",
      "\tEpoch 146: \tAverage Loss:  0.7215258178710937\t ACC train:  0.63\t ACC test:  0.6\n",
      "\tEpoch 147: \tAverage Loss:  0.7193275756835937\t ACC train:  0.65\t ACC test:  0.6088888888888889\n",
      "\tEpoch 148: \tAverage Loss:  0.7129871215820313\t ACC train:  0.63\t ACC test:  0.5955555555555555\n",
      "\tEpoch 149: \tAverage Loss:  0.7099083251953126\t ACC train:  0.62\t ACC test:  0.6044444444444445\n",
      "\tEpoch 150: \tAverage Loss:  0.7052474365234375\t ACC train:  0.64\t ACC test:  0.5977777777777777\n",
      "\tEpoch 151: \tAverage Loss:  0.7010498046875\t ACC train:  0.62\t ACC test:  0.6022222222222222\n",
      "\tEpoch 152: \tAverage Loss:  0.696171630859375\t ACC train:  0.62\t ACC test:  0.6022222222222222\n",
      "\tEpoch 153: \tAverage Loss:  0.6961586303710937\t ACC train:  0.61\t ACC test:  0.6022222222222222\n",
      "\tEpoch 154: \tAverage Loss:  0.68872607421875\t ACC train:  0.63\t ACC test:  0.6\n",
      "\tEpoch 155: \tAverage Loss:  0.6857407836914062\t ACC train:  0.62\t ACC test:  0.5888888888888889\n",
      "\tEpoch 156: \tAverage Loss:  0.6805750732421875\t ACC train:  0.65\t ACC test:  0.5977777777777777\n",
      "\tEpoch 157: \tAverage Loss:  0.6734696655273438\t ACC train:  0.66\t ACC test:  0.6022222222222222\n",
      "\tEpoch 158: \tAverage Loss:  0.6740045166015625\t ACC train:  0.63\t ACC test:  0.6\n",
      "\tEpoch 159: \tAverage Loss:  0.6701884765625\t ACC train:  0.65\t ACC test:  0.6044444444444445\n",
      "\tEpoch 160: \tAverage Loss:  0.6678682250976562\t ACC train:  0.66\t ACC test:  0.6044444444444445\n",
      "\tEpoch 161: \tAverage Loss:  0.6679351196289063\t ACC train:  0.66\t ACC test:  0.6022222222222222\n",
      "\tEpoch 162: \tAverage Loss:  0.6580120849609375\t ACC train:  0.65\t ACC test:  0.6155555555555555\n",
      "\tEpoch 163: \tAverage Loss:  0.6542610473632813\t ACC train:  0.67\t ACC test:  0.5888888888888889\n",
      "\tEpoch 164: \tAverage Loss:  0.6524805908203125\t ACC train:  0.66\t ACC test:  0.6044444444444445\n",
      "\tEpoch 165: \tAverage Loss:  0.6458892211914062\t ACC train:  0.64\t ACC test:  0.6066666666666667\n",
      "\tEpoch 166: \tAverage Loss:  0.6456162719726563\t ACC train:  0.62\t ACC test:  0.6022222222222222\n",
      "\tEpoch 167: \tAverage Loss:  0.6416759033203125\t ACC train:  0.63\t ACC test:  0.6044444444444445\n",
      "\tEpoch 168: \tAverage Loss:  0.634695068359375\t ACC train:  0.67\t ACC test:  0.6088888888888889\n",
      "\tEpoch 169: \tAverage Loss:  0.6413898315429688\t ACC train:  0.64\t ACC test:  0.6111111111111112\n",
      "\tEpoch 170: \tAverage Loss:  0.63489306640625\t ACC train:  0.64\t ACC test:  0.6088888888888889\n",
      "\tEpoch 171: \tAverage Loss:  0.6314658203125\t ACC train:  0.65\t ACC test:  0.6222222222222222\n",
      "\tEpoch 172: \tAverage Loss:  0.628233642578125\t ACC train:  0.64\t ACC test:  0.6066666666666667\n",
      "\tEpoch 173: \tAverage Loss:  0.62546728515625\t ACC train:  0.67\t ACC test:  0.6111111111111112\n",
      "\tEpoch 174: \tAverage Loss:  0.6235811157226563\t ACC train:  0.67\t ACC test:  0.6\n",
      "\tEpoch 175: \tAverage Loss:  0.6231342163085938\t ACC train:  0.65\t ACC test:  0.5955555555555555\n",
      "\tEpoch 176: \tAverage Loss:  0.615731689453125\t ACC train:  0.65\t ACC test:  0.6044444444444445\n",
      "\tEpoch 177: \tAverage Loss:  0.6142313232421875\t ACC train:  0.65\t ACC test:  0.6088888888888889\n",
      "\tEpoch 178: \tAverage Loss:  0.6160549926757812\t ACC train:  0.65\t ACC test:  0.6133333333333333\n",
      "\tEpoch 179: \tAverage Loss:  0.6106636962890625\t ACC train:  0.66\t ACC test:  0.6111111111111112\n",
      "\tEpoch 180: \tAverage Loss:  0.6069078979492187\t ACC train:  0.68\t ACC test:  0.6133333333333333\n",
      "\tEpoch 181: \tAverage Loss:  0.6022185668945312\t ACC train:  0.68\t ACC test:  0.6111111111111112\n",
      "\tEpoch 182: \tAverage Loss:  0.6008934936523438\t ACC train:  0.66\t ACC test:  0.6066666666666667\n",
      "\tEpoch 183: \tAverage Loss:  0.6007909545898438\t ACC train:  0.63\t ACC test:  0.6088888888888889\n",
      "\tEpoch 184: \tAverage Loss:  0.5928458251953125\t ACC train:  0.65\t ACC test:  0.6266666666666667\n",
      "\tEpoch 185: \tAverage Loss:  0.5975093383789063\t ACC train:  0.68\t ACC test:  0.6177777777777778\n",
      "\tEpoch 186: \tAverage Loss:  0.5891963500976563\t ACC train:  0.68\t ACC test:  0.6133333333333333\n",
      "\tEpoch 187: \tAverage Loss:  0.5924031982421875\t ACC train:  0.68\t ACC test:  0.6177777777777778\n",
      "\tEpoch 188: \tAverage Loss:  0.589563720703125\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 189: \tAverage Loss:  0.585507568359375\t ACC train:  0.66\t ACC test:  0.62\n",
      "\tEpoch 190: \tAverage Loss:  0.5843250732421875\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 191: \tAverage Loss:  0.5832182006835938\t ACC train:  0.68\t ACC test:  0.6177777777777778\n",
      "\tEpoch 192: \tAverage Loss:  0.5796259765625\t ACC train:  0.67\t ACC test:  0.6155555555555555\n",
      "\tEpoch 193: \tAverage Loss:  0.5771524047851563\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 194: \tAverage Loss:  0.5787379150390625\t ACC train:  0.64\t ACC test:  0.6133333333333333\n",
      "\tEpoch 195: \tAverage Loss:  0.5718892822265625\t ACC train:  0.65\t ACC test:  0.6222222222222222\n",
      "\tEpoch 196: \tAverage Loss:  0.5768690185546875\t ACC train:  0.65\t ACC test:  0.6155555555555555\n",
      "\tEpoch 197: \tAverage Loss:  0.57005126953125\t ACC train:  0.66\t ACC test:  0.6111111111111112\n",
      "\tEpoch 198: \tAverage Loss:  0.568922607421875\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 199: \tAverage Loss:  0.5685057983398437\t ACC train:  0.65\t ACC test:  0.6222222222222222\n",
      "\tEpoch 200: \tAverage Loss:  0.5691248168945312\t ACC train:  0.67\t ACC test:  0.62\n",
      "\tEpoch 201: \tAverage Loss:  0.56577783203125\t ACC train:  0.67\t ACC test:  0.6088888888888889\n",
      "\tEpoch 202: \tAverage Loss:  0.563240478515625\t ACC train:  0.67\t ACC test:  0.6044444444444445\n",
      "\tEpoch 203: \tAverage Loss:  0.5634320068359375\t ACC train:  0.65\t ACC test:  0.6088888888888889\n",
      "\tEpoch 204: \tAverage Loss:  0.5651141357421875\t ACC train:  0.64\t ACC test:  0.6066666666666667\n",
      "\tEpoch 205: \tAverage Loss:  0.5628724365234375\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 206: \tAverage Loss:  0.5620155639648438\t ACC train:  0.66\t ACC test:  0.6044444444444445\n",
      "\tEpoch 207: \tAverage Loss:  0.55687353515625\t ACC train:  0.66\t ACC test:  0.6088888888888889\n",
      "\tEpoch 208: \tAverage Loss:  0.55695263671875\t ACC train:  0.64\t ACC test:  0.6155555555555555\n",
      "\tEpoch 209: \tAverage Loss:  0.5528638916015625\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 210: \tAverage Loss:  0.5554185791015624\t ACC train:  0.67\t ACC test:  0.6111111111111112\n",
      "\tEpoch 211: \tAverage Loss:  0.5560538330078125\t ACC train:  0.66\t ACC test:  0.6133333333333333\n",
      "\tEpoch 212: \tAverage Loss:  0.5553353271484375\t ACC train:  0.66\t ACC test:  0.62\n",
      "\tEpoch 213: \tAverage Loss:  0.5523154907226563\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 214: \tAverage Loss:  0.550632568359375\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 215: \tAverage Loss:  0.5490283813476563\t ACC train:  0.68\t ACC test:  0.6088888888888889\n",
      "\tEpoch 216: \tAverage Loss:  0.548281005859375\t ACC train:  0.68\t ACC test:  0.6177777777777778\n",
      "\tEpoch 217: \tAverage Loss:  0.54891845703125\t ACC train:  0.69\t ACC test:  0.6022222222222222\n",
      "\tEpoch 218: \tAverage Loss:  0.5476683959960937\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 219: \tAverage Loss:  0.5440906982421875\t ACC train:  0.68\t ACC test:  0.6177777777777778\n",
      "\tEpoch 220: \tAverage Loss:  0.5464649658203125\t ACC train:  0.67\t ACC test:  0.6111111111111112\n",
      "\tEpoch 221: \tAverage Loss:  0.5437891235351563\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 222: \tAverage Loss:  0.5442945556640625\t ACC train:  0.67\t ACC test:  0.6088888888888889\n",
      "\tEpoch 223: \tAverage Loss:  0.5388263549804687\t ACC train:  0.66\t ACC test:  0.6133333333333333\n",
      "\tEpoch 224: \tAverage Loss:  0.5417199096679688\t ACC train:  0.67\t ACC test:  0.6066666666666667\n",
      "\tEpoch 225: \tAverage Loss:  0.5392994384765625\t ACC train:  0.64\t ACC test:  0.6133333333333333\n",
      "\tEpoch 226: \tAverage Loss:  0.541748046875\t ACC train:  0.67\t ACC test:  0.6111111111111112\n",
      "\tEpoch 227: \tAverage Loss:  0.5388618774414062\t ACC train:  0.65\t ACC test:  0.6155555555555555\n",
      "\tEpoch 228: \tAverage Loss:  0.537731689453125\t ACC train:  0.67\t ACC test:  0.6133333333333333\n",
      "\tEpoch 229: \tAverage Loss:  0.5372922973632812\t ACC train:  0.67\t ACC test:  0.6288888888888889\n",
      "\tEpoch 230: \tAverage Loss:  0.5380631713867188\t ACC train:  0.68\t ACC test:  0.6088888888888889\n",
      "\tEpoch 231: \tAverage Loss:  0.5370549926757813\t ACC train:  0.66\t ACC test:  0.6244444444444445\n",
      "\tEpoch 232: \tAverage Loss:  0.5360943603515625\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 233: \tAverage Loss:  0.5361707763671875\t ACC train:  0.66\t ACC test:  0.6266666666666667\n",
      "\tEpoch 234: \tAverage Loss:  0.5356329345703125\t ACC train:  0.67\t ACC test:  0.6311111111111111\n",
      "\tEpoch 235: \tAverage Loss:  0.5333773193359375\t ACC train:  0.66\t ACC test:  0.62\n",
      "\tEpoch 236: \tAverage Loss:  0.532892333984375\t ACC train:  0.68\t ACC test:  0.6222222222222222\n",
      "\tEpoch 237: \tAverage Loss:  0.53197607421875\t ACC train:  0.67\t ACC test:  0.6288888888888889\n",
      "\tEpoch 238: \tAverage Loss:  0.534042724609375\t ACC train:  0.67\t ACC test:  0.6155555555555555\n",
      "\tEpoch 239: \tAverage Loss:  0.5296876831054688\t ACC train:  0.65\t ACC test:  0.6222222222222222\n",
      "\tEpoch 240: \tAverage Loss:  0.529135498046875\t ACC train:  0.66\t ACC test:  0.6022222222222222\n",
      "\tEpoch 241: \tAverage Loss:  0.529571044921875\t ACC train:  0.67\t ACC test:  0.6222222222222222\n",
      "\tEpoch 242: \tAverage Loss:  0.52752197265625\t ACC train:  0.65\t ACC test:  0.6222222222222222\n",
      "\tEpoch 243: \tAverage Loss:  0.5280813598632812\t ACC train:  0.68\t ACC test:  0.6133333333333333\n",
      "\tEpoch 244: \tAverage Loss:  0.5282576293945312\t ACC train:  0.65\t ACC test:  0.6222222222222222\n",
      "\tEpoch 245: \tAverage Loss:  0.526080322265625\t ACC train:  0.68\t ACC test:  0.6222222222222222\n",
      "\tEpoch 246: \tAverage Loss:  0.5249677734375\t ACC train:  0.65\t ACC test:  0.6266666666666667\n",
      "\tEpoch 247: \tAverage Loss:  0.52579638671875\t ACC train:  0.71\t ACC test:  0.6111111111111112\n",
      "\tEpoch 248: \tAverage Loss:  0.5261463623046875\t ACC train:  0.66\t ACC test:  0.6222222222222222\n",
      "\tEpoch 249: \tAverage Loss:  0.5233265380859375\t ACC train:  0.66\t ACC test:  0.6266666666666667\n",
      "\tEpoch 250: \tAverage Loss:  0.5238082275390625\t ACC train:  0.67\t ACC test:  0.6222222222222222\n",
      "\tEpoch 251: \tAverage Loss:  0.5239379272460938\t ACC train:  0.68\t ACC test:  0.6266666666666667\n",
      "\tEpoch 252: \tAverage Loss:  0.5244841918945312\t ACC train:  0.65\t ACC test:  0.6133333333333333\n",
      "\tEpoch 253: \tAverage Loss:  0.5216102905273438\t ACC train:  0.68\t ACC test:  0.6288888888888889\n",
      "\tEpoch 254: \tAverage Loss:  0.5243899536132812\t ACC train:  0.67\t ACC test:  0.6222222222222222\n",
      "\tEpoch 255: \tAverage Loss:  0.5213504638671875\t ACC train:  0.68\t ACC test:  0.62\n",
      "\tEpoch 256: \tAverage Loss:  0.5206373291015625\t ACC train:  0.64\t ACC test:  0.6222222222222222\n",
      "\tEpoch 257: \tAverage Loss:  0.5199633178710937\t ACC train:  0.65\t ACC test:  0.6222222222222222\n",
      "\tEpoch 258: \tAverage Loss:  0.5216484985351563\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 259: \tAverage Loss:  0.52030078125\t ACC train:  0.67\t ACC test:  0.6311111111111111\n",
      "\tEpoch 260: \tAverage Loss:  0.5195748291015625\t ACC train:  0.69\t ACC test:  0.6244444444444445\n",
      "\tEpoch 261: \tAverage Loss:  0.5198924560546875\t ACC train:  0.68\t ACC test:  0.62\n",
      "\tEpoch 262: \tAverage Loss:  0.5188230590820313\t ACC train:  0.67\t ACC test:  0.6333333333333333\n",
      "\tEpoch 263: \tAverage Loss:  0.5175411376953125\t ACC train:  0.68\t ACC test:  0.64\n",
      "\tEpoch 264: \tAverage Loss:  0.5177976684570312\t ACC train:  0.67\t ACC test:  0.6311111111111111\n",
      "\tEpoch 265: \tAverage Loss:  0.5171827392578126\t ACC train:  0.68\t ACC test:  0.6222222222222222\n",
      "\tEpoch 266: \tAverage Loss:  0.5170150146484375\t ACC train:  0.71\t ACC test:  0.6244444444444445\n",
      "\tEpoch 267: \tAverage Loss:  0.5180301513671876\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 268: \tAverage Loss:  0.5191940307617188\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 269: \tAverage Loss:  0.5160372314453125\t ACC train:  0.68\t ACC test:  0.6311111111111111\n",
      "\tEpoch 270: \tAverage Loss:  0.51648583984375\t ACC train:  0.69\t ACC test:  0.6355555555555555\n",
      "\tEpoch 271: \tAverage Loss:  0.5142308349609375\t ACC train:  0.71\t ACC test:  0.6288888888888889\n",
      "\tEpoch 272: \tAverage Loss:  0.5142496337890625\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 273: \tAverage Loss:  0.5149227294921875\t ACC train:  0.67\t ACC test:  0.6222222222222222\n",
      "\tEpoch 274: \tAverage Loss:  0.5130665283203125\t ACC train:  0.71\t ACC test:  0.6333333333333333\n",
      "\tEpoch 275: \tAverage Loss:  0.51401611328125\t ACC train:  0.69\t ACC test:  0.6244444444444445\n",
      "\tEpoch 276: \tAverage Loss:  0.51326025390625\t ACC train:  0.71\t ACC test:  0.6288888888888889\n",
      "\tEpoch 277: \tAverage Loss:  0.5128905639648438\t ACC train:  0.71\t ACC test:  0.6377777777777778\n",
      "\tEpoch 278: \tAverage Loss:  0.5114179077148437\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 279: \tAverage Loss:  0.5113853759765625\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 280: \tAverage Loss:  0.5128701171875\t ACC train:  0.69\t ACC test:  0.6377777777777778\n",
      "\tEpoch 281: \tAverage Loss:  0.5117719421386718\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 282: \tAverage Loss:  0.5110968322753906\t ACC train:  0.67\t ACC test:  0.6311111111111111\n",
      "\tEpoch 283: \tAverage Loss:  0.5096048889160156\t ACC train:  0.7\t ACC test:  0.6377777777777778\n",
      "\tEpoch 284: \tAverage Loss:  0.5104964904785156\t ACC train:  0.71\t ACC test:  0.64\n",
      "\tEpoch 285: \tAverage Loss:  0.5103026733398438\t ACC train:  0.71\t ACC test:  0.6377777777777778\n",
      "\tEpoch 286: \tAverage Loss:  0.5102220458984374\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 287: \tAverage Loss:  0.5089662170410156\t ACC train:  0.69\t ACC test:  0.6288888888888889\n",
      "\tEpoch 288: \tAverage Loss:  0.5096281127929687\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 289: \tAverage Loss:  0.5096734619140625\t ACC train:  0.71\t ACC test:  0.6288888888888889\n",
      "\tEpoch 290: \tAverage Loss:  0.5086144714355468\t ACC train:  0.68\t ACC test:  0.6311111111111111\n",
      "\tEpoch 291: \tAverage Loss:  0.5074505920410156\t ACC train:  0.7\t ACC test:  0.6311111111111111\n",
      "\tEpoch 292: \tAverage Loss:  0.5073408203125\t ACC train:  0.7\t ACC test:  0.64\n",
      "\tEpoch 293: \tAverage Loss:  0.5082888793945313\t ACC train:  0.71\t ACC test:  0.6422222222222222\n",
      "\tEpoch 294: \tAverage Loss:  0.5087732543945312\t ACC train:  0.67\t ACC test:  0.6377777777777778\n",
      "\tEpoch 295: \tAverage Loss:  0.5074752502441406\t ACC train:  0.7\t ACC test:  0.64\n",
      "\tEpoch 296: \tAverage Loss:  0.5066607360839843\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 297: \tAverage Loss:  0.5079564819335938\t ACC train:  0.71\t ACC test:  0.6266666666666667\n",
      "\tEpoch 298: \tAverage Loss:  0.5068808288574219\t ACC train:  0.72\t ACC test:  0.6444444444444445\n",
      "\tEpoch 299: \tAverage Loss:  0.5058631591796875\t ACC train:  0.7\t ACC test:  0.64\n",
      "\tEpoch 300: \tAverage Loss:  0.5064302673339843\t ACC train:  0.73\t ACC test:  0.6422222222222222\n",
      "\tEpoch 301: \tAverage Loss:  0.5046264343261718\t ACC train:  0.71\t ACC test:  0.6311111111111111\n",
      "\tEpoch 302: \tAverage Loss:  0.5049129638671875\t ACC train:  0.7\t ACC test:  0.6422222222222222\n",
      "\tEpoch 303: \tAverage Loss:  0.5053753662109375\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 304: \tAverage Loss:  0.5053995666503907\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 305: \tAverage Loss:  0.5036489868164062\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 306: \tAverage Loss:  0.5045310974121093\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 307: \tAverage Loss:  0.5025320129394532\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 308: \tAverage Loss:  0.5030802612304688\t ACC train:  0.7\t ACC test:  0.6311111111111111\n",
      "\tEpoch 309: \tAverage Loss:  0.5025778503417969\t ACC train:  0.71\t ACC test:  0.6422222222222222\n",
      "\tEpoch 310: \tAverage Loss:  0.5022221069335937\t ACC train:  0.7\t ACC test:  0.6355555555555555\n",
      "\tEpoch 311: \tAverage Loss:  0.5029447937011718\t ACC train:  0.7\t ACC test:  0.64\n",
      "\tEpoch 312: \tAverage Loss:  0.5031353759765625\t ACC train:  0.71\t ACC test:  0.6311111111111111\n",
      "\tEpoch 313: \tAverage Loss:  0.5019364013671875\t ACC train:  0.7\t ACC test:  0.64\n",
      "\tEpoch 314: \tAverage Loss:  0.5013309020996094\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 315: \tAverage Loss:  0.502615234375\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 316: \tAverage Loss:  0.5018082275390625\t ACC train:  0.71\t ACC test:  0.6311111111111111\n",
      "\tEpoch 317: \tAverage Loss:  0.5026611328125\t ACC train:  0.71\t ACC test:  0.6311111111111111\n",
      "\tEpoch 318: \tAverage Loss:  0.5007579345703125\t ACC train:  0.7\t ACC test:  0.6422222222222222\n",
      "\tEpoch 319: \tAverage Loss:  0.49896478271484374\t ACC train:  0.69\t ACC test:  0.6377777777777778\n",
      "\tEpoch 320: \tAverage Loss:  0.5004644470214844\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 321: \tAverage Loss:  0.4997872314453125\t ACC train:  0.71\t ACC test:  0.64\n",
      "\tEpoch 322: \tAverage Loss:  0.4995623779296875\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 323: \tAverage Loss:  0.49932772827148436\t ACC train:  0.7\t ACC test:  0.6355555555555555\n",
      "\tEpoch 324: \tAverage Loss:  0.499718505859375\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 325: \tAverage Loss:  0.4987753295898438\t ACC train:  0.71\t ACC test:  0.6266666666666667\n",
      "\tEpoch 326: \tAverage Loss:  0.4992852783203125\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 327: \tAverage Loss:  0.498406982421875\t ACC train:  0.7\t ACC test:  0.6377777777777778\n",
      "\tEpoch 328: \tAverage Loss:  0.5000705871582031\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 329: \tAverage Loss:  0.49824395751953127\t ACC train:  0.71\t ACC test:  0.64\n",
      "\tEpoch 330: \tAverage Loss:  0.49837408447265624\t ACC train:  0.71\t ACC test:  0.6333333333333333\n",
      "\tEpoch 331: \tAverage Loss:  0.5001263732910156\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 332: \tAverage Loss:  0.49856951904296876\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 333: \tAverage Loss:  0.4985167236328125\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 334: \tAverage Loss:  0.4972243347167969\t ACC train:  0.71\t ACC test:  0.6377777777777778\n",
      "\tEpoch 335: \tAverage Loss:  0.49752490234375\t ACC train:  0.71\t ACC test:  0.6422222222222222\n",
      "\tEpoch 336: \tAverage Loss:  0.497573974609375\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 337: \tAverage Loss:  0.4973943786621094\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 338: \tAverage Loss:  0.49641329956054686\t ACC train:  0.7\t ACC test:  0.6266666666666667\n",
      "\tEpoch 339: \tAverage Loss:  0.4977153015136719\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 340: \tAverage Loss:  0.4950640563964844\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 341: \tAverage Loss:  0.49793072509765623\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 342: \tAverage Loss:  0.49575631713867185\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 343: \tAverage Loss:  0.49494873046875\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 344: \tAverage Loss:  0.49518325805664065\t ACC train:  0.71\t ACC test:  0.6311111111111111\n",
      "\tEpoch 345: \tAverage Loss:  0.49569631958007815\t ACC train:  0.7\t ACC test:  0.6311111111111111\n",
      "\tEpoch 346: \tAverage Loss:  0.4947044677734375\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 347: \tAverage Loss:  0.4949324951171875\t ACC train:  0.71\t ACC test:  0.6333333333333333\n",
      "\tEpoch 348: \tAverage Loss:  0.4959870910644531\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 349: \tAverage Loss:  0.49454901123046874\t ACC train:  0.71\t ACC test:  0.6311111111111111\n",
      "\tEpoch 350: \tAverage Loss:  0.4963041687011719\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 351: \tAverage Loss:  0.49495687866210936\t ACC train:  0.71\t ACC test:  0.6311111111111111\n",
      "\tEpoch 352: \tAverage Loss:  0.49616409301757813\t ACC train:  0.71\t ACC test:  0.6333333333333333\n",
      "\tEpoch 353: \tAverage Loss:  0.4936292419433594\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 354: \tAverage Loss:  0.49299560546875\t ACC train:  0.71\t ACC test:  0.6377777777777778\n",
      "\tEpoch 355: \tAverage Loss:  0.4933463439941406\t ACC train:  0.69\t ACC test:  0.6333333333333333\n",
      "\tEpoch 356: \tAverage Loss:  0.49357101440429685\t ACC train:  0.71\t ACC test:  0.6288888888888889\n",
      "\tEpoch 357: \tAverage Loss:  0.4925597839355469\t ACC train:  0.7\t ACC test:  0.6288888888888889\n",
      "\tEpoch 358: \tAverage Loss:  0.492463134765625\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 359: \tAverage Loss:  0.4928089904785156\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 360: \tAverage Loss:  0.4937553405761719\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 361: \tAverage Loss:  0.4927308349609375\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 362: \tAverage Loss:  0.49229501342773435\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 363: \tAverage Loss:  0.49189010620117185\t ACC train:  0.71\t ACC test:  0.6244444444444445\n",
      "\tEpoch 364: \tAverage Loss:  0.4936524658203125\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 365: \tAverage Loss:  0.49259326171875\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 366: \tAverage Loss:  0.4934237365722656\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 367: \tAverage Loss:  0.4925435791015625\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 368: \tAverage Loss:  0.4922120361328125\t ACC train:  0.72\t ACC test:  0.6422222222222222\n",
      "\tEpoch 369: \tAverage Loss:  0.4925329895019531\t ACC train:  0.72\t ACC test:  0.6266666666666667\n",
      "\tEpoch 370: \tAverage Loss:  0.4917677001953125\t ACC train:  0.71\t ACC test:  0.6244444444444445\n",
      "\tEpoch 371: \tAverage Loss:  0.49119918823242187\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 372: \tAverage Loss:  0.4912751770019531\t ACC train:  0.72\t ACC test:  0.6266666666666667\n",
      "\tEpoch 373: \tAverage Loss:  0.49053915405273435\t ACC train:  0.71\t ACC test:  0.6377777777777778\n",
      "\tEpoch 374: \tAverage Loss:  0.4906082763671875\t ACC train:  0.7\t ACC test:  0.6333333333333333\n",
      "\tEpoch 375: \tAverage Loss:  0.4901092529296875\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 376: \tAverage Loss:  0.4905984802246094\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 377: \tAverage Loss:  0.490761474609375\t ACC train:  0.71\t ACC test:  0.6377777777777778\n",
      "\tEpoch 378: \tAverage Loss:  0.49067117309570313\t ACC train:  0.71\t ACC test:  0.6355555555555555\n",
      "\tEpoch 379: \tAverage Loss:  0.4922358093261719\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 380: \tAverage Loss:  0.4892765197753906\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 381: \tAverage Loss:  0.48925909423828123\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 382: \tAverage Loss:  0.48892242431640626\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 383: \tAverage Loss:  0.4888509521484375\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 384: \tAverage Loss:  0.4896602783203125\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 385: \tAverage Loss:  0.48994720458984375\t ACC train:  0.71\t ACC test:  0.64\n",
      "\tEpoch 386: \tAverage Loss:  0.49014260864257814\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 387: \tAverage Loss:  0.49008468627929686\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 388: \tAverage Loss:  0.4914120788574219\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 389: \tAverage Loss:  0.4892902526855469\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 390: \tAverage Loss:  0.48916217041015625\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 391: \tAverage Loss:  0.48843026733398437\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 392: \tAverage Loss:  0.48796963500976565\t ACC train:  0.71\t ACC test:  0.6311111111111111\n",
      "\tEpoch 393: \tAverage Loss:  0.4888528137207031\t ACC train:  0.71\t ACC test:  0.6222222222222222\n",
      "\tEpoch 394: \tAverage Loss:  0.4885140380859375\t ACC train:  0.71\t ACC test:  0.6288888888888889\n",
      "\tEpoch 395: \tAverage Loss:  0.4878814086914062\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 396: \tAverage Loss:  0.48711444091796874\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 397: \tAverage Loss:  0.48686703491210936\t ACC train:  0.73\t ACC test:  0.6422222222222222\n",
      "\tEpoch 398: \tAverage Loss:  0.48684344482421876\t ACC train:  0.71\t ACC test:  0.6333333333333333\n",
      "\tEpoch 399: \tAverage Loss:  0.4876578369140625\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 400: \tAverage Loss:  0.4876572265625\t ACC train:  0.72\t ACC test:  0.6288888888888889\n",
      "\tEpoch 401: \tAverage Loss:  0.4870353393554688\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 402: \tAverage Loss:  0.4865286865234375\t ACC train:  0.73\t ACC test:  0.6266666666666667\n",
      "\tEpoch 403: \tAverage Loss:  0.4872664794921875\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 404: \tAverage Loss:  0.4863541259765625\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 405: \tAverage Loss:  0.4875425720214844\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 406: \tAverage Loss:  0.4865632629394531\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 407: \tAverage Loss:  0.48640313720703127\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 408: \tAverage Loss:  0.48783074951171873\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 409: \tAverage Loss:  0.4866590270996094\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 410: \tAverage Loss:  0.48559576416015626\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 411: \tAverage Loss:  0.4859705810546875\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 412: \tAverage Loss:  0.4861568298339844\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 413: \tAverage Loss:  0.4862630615234375\t ACC train:  0.72\t ACC test:  0.6266666666666667\n",
      "\tEpoch 414: \tAverage Loss:  0.48539410400390626\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 415: \tAverage Loss:  0.4861980285644531\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 416: \tAverage Loss:  0.48621453857421876\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 417: \tAverage Loss:  0.48462380981445313\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 418: \tAverage Loss:  0.4851627197265625\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 419: \tAverage Loss:  0.4839041748046875\t ACC train:  0.73\t ACC test:  0.6266666666666667\n",
      "\tEpoch 420: \tAverage Loss:  0.483842529296875\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 421: \tAverage Loss:  0.48534335327148437\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 422: \tAverage Loss:  0.48593572998046874\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 423: \tAverage Loss:  0.48487435913085936\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 424: \tAverage Loss:  0.48335174560546873\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 425: \tAverage Loss:  0.4843276062011719\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 426: \tAverage Loss:  0.4848512878417969\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 427: \tAverage Loss:  0.48446929931640625\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 428: \tAverage Loss:  0.48362152099609373\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 429: \tAverage Loss:  0.48291400146484376\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 430: \tAverage Loss:  0.4841437683105469\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 431: \tAverage Loss:  0.4833922119140625\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 432: \tAverage Loss:  0.48438128662109375\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 433: \tAverage Loss:  0.4837249755859375\t ACC train:  0.71\t ACC test:  0.6377777777777778\n",
      "\tEpoch 434: \tAverage Loss:  0.48316842651367187\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 435: \tAverage Loss:  0.48302627563476563\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 436: \tAverage Loss:  0.4835326538085937\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 437: \tAverage Loss:  0.48345269775390626\t ACC train:  0.72\t ACC test:  0.6266666666666667\n",
      "\tEpoch 438: \tAverage Loss:  0.4835162048339844\t ACC train:  0.72\t ACC test:  0.6266666666666667\n",
      "\tEpoch 439: \tAverage Loss:  0.4834822998046875\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 440: \tAverage Loss:  0.4809735107421875\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 441: \tAverage Loss:  0.48288363647460936\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 442: \tAverage Loss:  0.48224807739257813\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 443: \tAverage Loss:  0.4813372497558594\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 444: \tAverage Loss:  0.4819795227050781\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 445: \tAverage Loss:  0.4815343322753906\t ACC train:  0.73\t ACC test:  0.6266666666666667\n",
      "\tEpoch 446: \tAverage Loss:  0.48114413452148436\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 447: \tAverage Loss:  0.4810186767578125\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 448: \tAverage Loss:  0.48133853149414063\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 449: \tAverage Loss:  0.48093341064453127\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 450: \tAverage Loss:  0.48061181640625\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 451: \tAverage Loss:  0.47984771728515624\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 452: \tAverage Loss:  0.48133053588867186\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 453: \tAverage Loss:  0.48061669921875\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 454: \tAverage Loss:  0.48140127563476565\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 455: \tAverage Loss:  0.4805480651855469\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 456: \tAverage Loss:  0.4811391296386719\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 457: \tAverage Loss:  0.4795250244140625\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 458: \tAverage Loss:  0.4817999267578125\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 459: \tAverage Loss:  0.4802647705078125\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 460: \tAverage Loss:  0.4798915100097656\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 461: \tAverage Loss:  0.4798636169433594\t ACC train:  0.73\t ACC test:  0.6266666666666667\n",
      "\tEpoch 462: \tAverage Loss:  0.4804496765136719\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 463: \tAverage Loss:  0.4794588928222656\t ACC train:  0.73\t ACC test:  0.6244444444444445\n",
      "\tEpoch 464: \tAverage Loss:  0.4804908447265625\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 465: \tAverage Loss:  0.47911279296875\t ACC train:  0.72\t ACC test:  0.6266666666666667\n",
      "\tEpoch 466: \tAverage Loss:  0.478922607421875\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 467: \tAverage Loss:  0.4789289855957031\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 468: \tAverage Loss:  0.4788146667480469\t ACC train:  0.72\t ACC test:  0.6266666666666667\n",
      "\tEpoch 469: \tAverage Loss:  0.47992913818359373\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 470: \tAverage Loss:  0.478996337890625\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 471: \tAverage Loss:  0.47876007080078126\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 472: \tAverage Loss:  0.47886663818359376\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 473: \tAverage Loss:  0.4778374938964844\t ACC train:  0.73\t ACC test:  0.6266666666666667\n",
      "\tEpoch 474: \tAverage Loss:  0.4781568298339844\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 475: \tAverage Loss:  0.4779135437011719\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 476: \tAverage Loss:  0.47833270263671873\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 477: \tAverage Loss:  0.47874075317382814\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 478: \tAverage Loss:  0.47798617553710937\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 479: \tAverage Loss:  0.4771929016113281\t ACC train:  0.73\t ACC test:  0.6266666666666667\n",
      "\tEpoch 480: \tAverage Loss:  0.4777262878417969\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 481: \tAverage Loss:  0.47700259399414063\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 482: \tAverage Loss:  0.4775323486328125\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 483: \tAverage Loss:  0.4775977783203125\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 484: \tAverage Loss:  0.4769639587402344\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 485: \tAverage Loss:  0.4772709045410156\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 486: \tAverage Loss:  0.477573486328125\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 487: \tAverage Loss:  0.47609054565429687\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 488: \tAverage Loss:  0.47673309326171875\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 489: \tAverage Loss:  0.47557257080078125\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 490: \tAverage Loss:  0.47580270385742185\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 491: \tAverage Loss:  0.4764400634765625\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 492: \tAverage Loss:  0.4752572021484375\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 493: \tAverage Loss:  0.47571343994140625\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 494: \tAverage Loss:  0.4755390625\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 495: \tAverage Loss:  0.4761147766113281\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 496: \tAverage Loss:  0.47538739013671877\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 497: \tAverage Loss:  0.4756339111328125\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 498: \tAverage Loss:  0.475228515625\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 499: \tAverage Loss:  0.4748527526855469\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 500: \tAverage Loss:  0.47526705932617186\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 501: \tAverage Loss:  0.47454046630859376\t ACC train:  0.72\t ACC test:  0.6311111111111111\n",
      "\tEpoch 502: \tAverage Loss:  0.47514627075195315\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 503: \tAverage Loss:  0.474831787109375\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 504: \tAverage Loss:  0.47472540283203124\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 505: \tAverage Loss:  0.4738215637207031\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 506: \tAverage Loss:  0.4744693298339844\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 507: \tAverage Loss:  0.47334490966796877\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 508: \tAverage Loss:  0.4739111022949219\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 509: \tAverage Loss:  0.47326116943359375\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 510: \tAverage Loss:  0.47389114379882813\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 511: \tAverage Loss:  0.4743072204589844\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 512: \tAverage Loss:  0.47298202514648435\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 513: \tAverage Loss:  0.47237557983398437\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 514: \tAverage Loss:  0.47326007080078125\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 515: \tAverage Loss:  0.4728829650878906\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 516: \tAverage Loss:  0.4725709533691406\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 517: \tAverage Loss:  0.47412408447265625\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 518: \tAverage Loss:  0.47311212158203125\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 519: \tAverage Loss:  0.4722486267089844\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 520: \tAverage Loss:  0.4711424560546875\t ACC train:  0.73\t ACC test:  0.6422222222222222\n",
      "\tEpoch 521: \tAverage Loss:  0.47283248901367186\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 522: \tAverage Loss:  0.47139794921875\t ACC train:  0.73\t ACC test:  0.6288888888888889\n",
      "\tEpoch 523: \tAverage Loss:  0.47179254150390626\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 524: \tAverage Loss:  0.4720020446777344\t ACC train:  0.73\t ACC test:  0.6422222222222222\n",
      "\tEpoch 525: \tAverage Loss:  0.4720672912597656\t ACC train:  0.73\t ACC test:  0.6422222222222222\n",
      "\tEpoch 526: \tAverage Loss:  0.47065274047851563\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 527: \tAverage Loss:  0.47139639282226564\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 528: \tAverage Loss:  0.4711060791015625\t ACC train:  0.72\t ACC test:  0.6422222222222222\n",
      "\tEpoch 529: \tAverage Loss:  0.4703215637207031\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 530: \tAverage Loss:  0.4703208312988281\t ACC train:  0.73\t ACC test:  0.6422222222222222\n",
      "\tEpoch 531: \tAverage Loss:  0.4707242126464844\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 532: \tAverage Loss:  0.470624755859375\t ACC train:  0.73\t ACC test:  0.6422222222222222\n",
      "\tEpoch 533: \tAverage Loss:  0.4706437072753906\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 534: \tAverage Loss:  0.4705451354980469\t ACC train:  0.72\t ACC test:  0.6333333333333333\n",
      "\tEpoch 535: \tAverage Loss:  0.46910791015625\t ACC train:  0.73\t ACC test:  0.6422222222222222\n",
      "\tEpoch 536: \tAverage Loss:  0.470216552734375\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 537: \tAverage Loss:  0.46979193115234374\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 538: \tAverage Loss:  0.46866513061523435\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 539: \tAverage Loss:  0.4697704162597656\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 540: \tAverage Loss:  0.46893710327148436\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 541: \tAverage Loss:  0.469089111328125\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 542: \tAverage Loss:  0.4683818664550781\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 543: \tAverage Loss:  0.4688260192871094\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 544: \tAverage Loss:  0.46895770263671877\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 545: \tAverage Loss:  0.46858184814453124\t ACC train:  0.73\t ACC test:  0.6333333333333333\n",
      "\tEpoch 546: \tAverage Loss:  0.46868521118164064\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 547: \tAverage Loss:  0.46862686157226563\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 548: \tAverage Loss:  0.4687670288085938\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 549: \tAverage Loss:  0.4677355651855469\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 550: \tAverage Loss:  0.4689577941894531\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 551: \tAverage Loss:  0.46872119140625\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 552: \tAverage Loss:  0.4679756164550781\t ACC train:  0.72\t ACC test:  0.64\n",
      "\tEpoch 553: \tAverage Loss:  0.4698249206542969\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 554: \tAverage Loss:  0.46768411254882813\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 555: \tAverage Loss:  0.46744952392578126\t ACC train:  0.72\t ACC test:  0.6444444444444445\n",
      "\tEpoch 556: \tAverage Loss:  0.4683026123046875\t ACC train:  0.72\t ACC test:  0.6377777777777778\n",
      "\tEpoch 557: \tAverage Loss:  0.4681847534179687\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 558: \tAverage Loss:  0.46747689819335936\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 559: \tAverage Loss:  0.4676499328613281\t ACC train:  0.72\t ACC test:  0.6355555555555555\n",
      "\tEpoch 560: \tAverage Loss:  0.4665137939453125\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 561: \tAverage Loss:  0.46720660400390623\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 562: \tAverage Loss:  0.4668927307128906\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 563: \tAverage Loss:  0.4673822937011719\t ACC train:  0.73\t ACC test:  0.6377777777777778\n",
      "\tEpoch 564: \tAverage Loss:  0.4666083984375\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 565: \tAverage Loss:  0.46631881713867185\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 566: \tAverage Loss:  0.46723831176757813\t ACC train:  0.73\t ACC test:  0.6422222222222222\n",
      "\tEpoch 567: \tAverage Loss:  0.46587741088867185\t ACC train:  0.73\t ACC test:  0.64\n",
      "\tEpoch 568: \tAverage Loss:  0.46677899169921877\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 569: \tAverage Loss:  0.466220703125\t ACC train:  0.73\t ACC test:  0.6311111111111111\n",
      "\tEpoch 570: \tAverage Loss:  0.46565576171875\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 571: \tAverage Loss:  0.46617315673828125\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 572: \tAverage Loss:  0.46524868774414063\t ACC train:  0.73\t ACC test:  0.6355555555555555\n",
      "\tEpoch 573: \tAverage Loss:  0.465267578125\t ACC train:  0.73\t ACC test:  0.6466666666666666\n",
      "\tEpoch 574: \tAverage Loss:  0.46590518188476565\t ACC train:  0.76\t ACC test:  0.6444444444444445\n",
      "\tEpoch 575: \tAverage Loss:  0.4655023193359375\t ACC train:  0.77\t ACC test:  0.6355555555555555\n",
      "\tEpoch 576: \tAverage Loss:  0.464446533203125\t ACC train:  0.75\t ACC test:  0.6511111111111111\n",
      "\tEpoch 577: \tAverage Loss:  0.4664220581054688\t ACC train:  0.76\t ACC test:  0.6577777777777778\n",
      "\tEpoch 578: \tAverage Loss:  0.46496435546875\t ACC train:  0.78\t ACC test:  0.66\n",
      "\tEpoch 579: \tAverage Loss:  0.46485888671875\t ACC train:  0.75\t ACC test:  0.6577777777777778\n",
      "\tEpoch 580: \tAverage Loss:  0.46406610107421875\t ACC train:  0.76\t ACC test:  0.6733333333333333\n",
      "\tEpoch 581: \tAverage Loss:  0.4663692932128906\t ACC train:  0.76\t ACC test:  0.6666666666666666\n",
      "\tEpoch 582: \tAverage Loss:  0.46632830810546877\t ACC train:  0.76\t ACC test:  0.6666666666666666\n",
      "\tEpoch 583: \tAverage Loss:  0.4639614562988281\t ACC train:  0.76\t ACC test:  0.6666666666666666\n",
      "\tEpoch 584: \tAverage Loss:  0.46443923950195315\t ACC train:  0.79\t ACC test:  0.6622222222222223\n",
      "\tEpoch 585: \tAverage Loss:  0.4648865661621094\t ACC train:  0.74\t ACC test:  0.6755555555555556\n",
      "\tEpoch 586: \tAverage Loss:  0.46384600830078127\t ACC train:  0.75\t ACC test:  0.6711111111111111\n",
      "\tEpoch 587: \tAverage Loss:  0.46401776123046873\t ACC train:  0.74\t ACC test:  0.6844444444444444\n",
      "\tEpoch 588: \tAverage Loss:  0.46308648681640624\t ACC train:  0.76\t ACC test:  0.6777777777777778\n",
      "\tEpoch 589: \tAverage Loss:  0.4632411499023438\t ACC train:  0.75\t ACC test:  0.7\n",
      "\tEpoch 590: \tAverage Loss:  0.46246408081054685\t ACC train:  0.76\t ACC test:  0.6844444444444444\n",
      "\tEpoch 591: \tAverage Loss:  0.46291162109375\t ACC train:  0.76\t ACC test:  0.6822222222222222\n",
      "\tEpoch 592: \tAverage Loss:  0.46361599731445313\t ACC train:  0.74\t ACC test:  0.7022222222222222\n",
      "\tEpoch 593: \tAverage Loss:  0.46318658447265626\t ACC train:  0.77\t ACC test:  0.6933333333333334\n",
      "\tEpoch 594: \tAverage Loss:  0.4627675476074219\t ACC train:  0.75\t ACC test:  0.6911111111111111\n",
      "\tEpoch 595: \tAverage Loss:  0.4634948425292969\t ACC train:  0.75\t ACC test:  0.7088888888888889\n",
      "\tEpoch 596: \tAverage Loss:  0.4622268371582031\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 597: \tAverage Loss:  0.46306289672851564\t ACC train:  0.76\t ACC test:  0.7244444444444444\n",
      "\tEpoch 598: \tAverage Loss:  0.4624144287109375\t ACC train:  0.77\t ACC test:  0.7266666666666667\n",
      "\tEpoch 599: \tAverage Loss:  0.46240576171875\t ACC train:  0.76\t ACC test:  0.7155555555555555\n",
      "\tEpoch 600: \tAverage Loss:  0.4627734680175781\t ACC train:  0.78\t ACC test:  0.7088888888888889\n",
      "\tEpoch 601: \tAverage Loss:  0.46184027099609376\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 602: \tAverage Loss:  0.4623432312011719\t ACC train:  0.76\t ACC test:  0.72\n",
      "\tEpoch 603: \tAverage Loss:  0.4623169250488281\t ACC train:  0.77\t ACC test:  0.74\n",
      "\tEpoch 604: \tAverage Loss:  0.46186248779296873\t ACC train:  0.78\t ACC test:  0.7511111111111111\n",
      "\tEpoch 605: \tAverage Loss:  0.46215106201171874\t ACC train:  0.79\t ACC test:  0.7577777777777778\n",
      "\tEpoch 606: \tAverage Loss:  0.4609606628417969\t ACC train:  0.81\t ACC test:  0.7577777777777778\n",
      "\tEpoch 607: \tAverage Loss:  0.4619522705078125\t ACC train:  0.8\t ACC test:  0.7644444444444445\n",
      "\tEpoch 608: \tAverage Loss:  0.4620479431152344\t ACC train:  0.8\t ACC test:  0.7377777777777778\n",
      "\tEpoch 609: \tAverage Loss:  0.46208837890625\t ACC train:  0.8\t ACC test:  0.74\n",
      "\tEpoch 610: \tAverage Loss:  0.4625417785644531\t ACC train:  0.8\t ACC test:  0.7422222222222222\n",
      "\tEpoch 611: \tAverage Loss:  0.4613514404296875\t ACC train:  0.79\t ACC test:  0.7555555555555555\n",
      "\tEpoch 612: \tAverage Loss:  0.46050787353515626\t ACC train:  0.8\t ACC test:  0.7644444444444445\n",
      "\tEpoch 613: \tAverage Loss:  0.4612076721191406\t ACC train:  0.8\t ACC test:  0.7488888888888889\n",
      "\tEpoch 614: \tAverage Loss:  0.46132583618164064\t ACC train:  0.81\t ACC test:  0.7644444444444445\n",
      "\tEpoch 615: \tAverage Loss:  0.46016860961914063\t ACC train:  0.83\t ACC test:  0.7733333333333333\n",
      "\tEpoch 616: \tAverage Loss:  0.45996539306640627\t ACC train:  0.79\t ACC test:  0.7777777777777778\n",
      "\tEpoch 617: \tAverage Loss:  0.45981219482421876\t ACC train:  0.81\t ACC test:  0.7844444444444445\n",
      "\tEpoch 618: \tAverage Loss:  0.45993560791015625\t ACC train:  0.82\t ACC test:  0.7622222222222222\n",
      "\tEpoch 619: \tAverage Loss:  0.46018453979492185\t ACC train:  0.82\t ACC test:  0.7711111111111111\n",
      "\tEpoch 620: \tAverage Loss:  0.4599808349609375\t ACC train:  0.82\t ACC test:  0.76\n",
      "\tEpoch 621: \tAverage Loss:  0.45961279296875\t ACC train:  0.82\t ACC test:  0.7866666666666666\n",
      "\tEpoch 622: \tAverage Loss:  0.45969281005859375\t ACC train:  0.8\t ACC test:  0.7866666666666666\n",
      "\tEpoch 623: \tAverage Loss:  0.4599969177246094\t ACC train:  0.82\t ACC test:  0.8\n",
      "\tEpoch 624: \tAverage Loss:  0.45948138427734375\t ACC train:  0.81\t ACC test:  0.7955555555555556\n",
      "\tEpoch 625: \tAverage Loss:  0.459221435546875\t ACC train:  0.82\t ACC test:  0.8022222222222222\n",
      "\tEpoch 626: \tAverage Loss:  0.459516845703125\t ACC train:  0.84\t ACC test:  0.7955555555555556\n",
      "\tEpoch 627: \tAverage Loss:  0.4602053527832031\t ACC train:  0.84\t ACC test:  0.8022222222222222\n",
      "\tEpoch 628: \tAverage Loss:  0.46024581909179685\t ACC train:  0.82\t ACC test:  0.7933333333333333\n",
      "\tEpoch 629: \tAverage Loss:  0.4596903381347656\t ACC train:  0.83\t ACC test:  0.7933333333333333\n",
      "\tEpoch 630: \tAverage Loss:  0.4581282958984375\t ACC train:  0.86\t ACC test:  0.7866666666666666\n",
      "\tEpoch 631: \tAverage Loss:  0.45887353515625\t ACC train:  0.85\t ACC test:  0.7777777777777778\n",
      "\tEpoch 632: \tAverage Loss:  0.4586198425292969\t ACC train:  0.85\t ACC test:  0.7977777777777778\n",
      "\tEpoch 633: \tAverage Loss:  0.46007745361328123\t ACC train:  0.83\t ACC test:  0.7866666666666666\n",
      "\tEpoch 634: \tAverage Loss:  0.45934597778320313\t ACC train:  0.82\t ACC test:  0.7866666666666666\n",
      "\tEpoch 635: \tAverage Loss:  0.4588724975585938\t ACC train:  0.82\t ACC test:  0.7844444444444445\n",
      "\tEpoch 636: \tAverage Loss:  0.45798651123046874\t ACC train:  0.83\t ACC test:  0.8088888888888889\n",
      "\tEpoch 637: \tAverage Loss:  0.4575849609375\t ACC train:  0.84\t ACC test:  0.7822222222222223\n",
      "\tEpoch 638: \tAverage Loss:  0.45900277709960935\t ACC train:  0.84\t ACC test:  0.7844444444444445\n",
      "\tEpoch 639: \tAverage Loss:  0.45854083251953126\t ACC train:  0.84\t ACC test:  0.7866666666666666\n",
      "\tEpoch 640: \tAverage Loss:  0.45746002197265623\t ACC train:  0.83\t ACC test:  0.7844444444444445\n",
      "\tEpoch 641: \tAverage Loss:  0.4574572448730469\t ACC train:  0.85\t ACC test:  0.7977777777777778\n",
      "\tEpoch 642: \tAverage Loss:  0.4566848449707031\t ACC train:  0.83\t ACC test:  0.7977777777777778\n",
      "\tEpoch 643: \tAverage Loss:  0.4579544677734375\t ACC train:  0.83\t ACC test:  0.7955555555555556\n",
      "\tEpoch 644: \tAverage Loss:  0.4583009948730469\t ACC train:  0.86\t ACC test:  0.7844444444444445\n",
      "\tEpoch 645: \tAverage Loss:  0.45774578857421877\t ACC train:  0.86\t ACC test:  0.7955555555555556\n",
      "\tEpoch 646: \tAverage Loss:  0.45730172729492186\t ACC train:  0.83\t ACC test:  0.8177777777777778\n",
      "\tEpoch 647: \tAverage Loss:  0.45701602172851563\t ACC train:  0.86\t ACC test:  0.8\n",
      "\tEpoch 648: \tAverage Loss:  0.45694537353515624\t ACC train:  0.86\t ACC test:  0.8133333333333334\n",
      "\tEpoch 649: \tAverage Loss:  0.4577617492675781\t ACC train:  0.88\t ACC test:  0.8133333333333334\n",
      "\tEpoch 650: \tAverage Loss:  0.4579552307128906\t ACC train:  0.87\t ACC test:  0.8044444444444444\n",
      "\tEpoch 651: \tAverage Loss:  0.4568457946777344\t ACC train:  0.85\t ACC test:  0.82\n",
      "\tEpoch 652: \tAverage Loss:  0.45721209716796873\t ACC train:  0.86\t ACC test:  0.8088888888888889\n",
      "\tEpoch 653: \tAverage Loss:  0.4572772216796875\t ACC train:  0.86\t ACC test:  0.7955555555555556\n",
      "\tEpoch 654: \tAverage Loss:  0.4576359558105469\t ACC train:  0.88\t ACC test:  0.8\n",
      "\tEpoch 655: \tAverage Loss:  0.45691253662109377\t ACC train:  0.88\t ACC test:  0.8088888888888889\n",
      "\tEpoch 656: \tAverage Loss:  0.4574428100585938\t ACC train:  0.86\t ACC test:  0.8133333333333334\n",
      "\tEpoch 657: \tAverage Loss:  0.4584149169921875\t ACC train:  0.86\t ACC test:  0.8066666666666666\n",
      "\tEpoch 658: \tAverage Loss:  0.4568924560546875\t ACC train:  0.85\t ACC test:  0.8088888888888889\n",
      "\tEpoch 659: \tAverage Loss:  0.45507073974609374\t ACC train:  0.86\t ACC test:  0.8022222222222222\n",
      "\tEpoch 660: \tAverage Loss:  0.4558173828125\t ACC train:  0.87\t ACC test:  0.8177777777777778\n",
      "\tEpoch 661: \tAverage Loss:  0.45559402465820314\t ACC train:  0.86\t ACC test:  0.82\n",
      "\tEpoch 662: \tAverage Loss:  0.4552481689453125\t ACC train:  0.86\t ACC test:  0.82\n",
      "\tEpoch 663: \tAverage Loss:  0.4558118896484375\t ACC train:  0.86\t ACC test:  0.8311111111111111\n",
      "\tEpoch 664: \tAverage Loss:  0.45554318237304686\t ACC train:  0.9\t ACC test:  0.8133333333333334\n",
      "\tEpoch 665: \tAverage Loss:  0.454951904296875\t ACC train:  0.87\t ACC test:  0.8222222222222222\n",
      "\tEpoch 666: \tAverage Loss:  0.45512808227539064\t ACC train:  0.89\t ACC test:  0.8177777777777778\n",
      "\tEpoch 667: \tAverage Loss:  0.4549840393066406\t ACC train:  0.88\t ACC test:  0.8111111111111111\n",
      "\tEpoch 668: \tAverage Loss:  0.4550817565917969\t ACC train:  0.89\t ACC test:  0.8266666666666667\n",
      "\tEpoch 669: \tAverage Loss:  0.45457852172851565\t ACC train:  0.89\t ACC test:  0.8244444444444444\n",
      "\tEpoch 670: \tAverage Loss:  0.4549271240234375\t ACC train:  0.88\t ACC test:  0.82\n",
      "\tEpoch 671: \tAverage Loss:  0.45448190307617187\t ACC train:  0.88\t ACC test:  0.82\n",
      "\tEpoch 672: \tAverage Loss:  0.45422369384765626\t ACC train:  0.87\t ACC test:  0.8155555555555556\n",
      "\tEpoch 673: \tAverage Loss:  0.4541504516601563\t ACC train:  0.87\t ACC test:  0.8\n",
      "\tEpoch 674: \tAverage Loss:  0.4531344299316406\t ACC train:  0.89\t ACC test:  0.82\n",
      "\tEpoch 675: \tAverage Loss:  0.45631536865234373\t ACC train:  0.88\t ACC test:  0.8288888888888889\n",
      "\tEpoch 676: \tAverage Loss:  0.45512326049804686\t ACC train:  0.89\t ACC test:  0.8244444444444444\n",
      "\tEpoch 677: \tAverage Loss:  0.4536671142578125\t ACC train:  0.9\t ACC test:  0.8377777777777777\n",
      "\tEpoch 678: \tAverage Loss:  0.4536604309082031\t ACC train:  0.91\t ACC test:  0.8311111111111111\n",
      "\tEpoch 679: \tAverage Loss:  0.4541299743652344\t ACC train:  0.88\t ACC test:  0.8311111111111111\n",
      "\tEpoch 680: \tAverage Loss:  0.45451956176757813\t ACC train:  0.9\t ACC test:  0.82\n",
      "\tEpoch 681: \tAverage Loss:  0.45509088134765624\t ACC train:  0.9\t ACC test:  0.8311111111111111\n",
      "\tEpoch 682: \tAverage Loss:  0.45438201904296877\t ACC train:  0.9\t ACC test:  0.8244444444444444\n",
      "\tEpoch 683: \tAverage Loss:  0.4540540161132812\t ACC train:  0.88\t ACC test:  0.8222222222222222\n",
      "\tEpoch 684: \tAverage Loss:  0.453355712890625\t ACC train:  0.92\t ACC test:  0.8311111111111111\n",
      "\tEpoch 685: \tAverage Loss:  0.45385214233398435\t ACC train:  0.87\t ACC test:  0.8266666666666667\n",
      "\tEpoch 686: \tAverage Loss:  0.45479019165039064\t ACC train:  0.9\t ACC test:  0.8311111111111111\n",
      "\tEpoch 687: \tAverage Loss:  0.45318917846679685\t ACC train:  0.88\t ACC test:  0.82\n",
      "\tEpoch 688: \tAverage Loss:  0.4527681579589844\t ACC train:  0.9\t ACC test:  0.84\n",
      "\tEpoch 689: \tAverage Loss:  0.453357666015625\t ACC train:  0.86\t ACC test:  0.8377777777777777\n",
      "\tEpoch 690: \tAverage Loss:  0.45295721435546876\t ACC train:  0.89\t ACC test:  0.8177777777777778\n",
      "\tEpoch 691: \tAverage Loss:  0.45375421142578126\t ACC train:  0.88\t ACC test:  0.8311111111111111\n",
      "\tEpoch 692: \tAverage Loss:  0.4548623962402344\t ACC train:  0.86\t ACC test:  0.8355555555555556\n",
      "\tEpoch 693: \tAverage Loss:  0.452128662109375\t ACC train:  0.88\t ACC test:  0.8466666666666667\n",
      "\tEpoch 694: \tAverage Loss:  0.45247015380859373\t ACC train:  0.91\t ACC test:  0.8244444444444444\n",
      "\tEpoch 695: \tAverage Loss:  0.45318978881835936\t ACC train:  0.91\t ACC test:  0.8288888888888889\n",
      "\tEpoch 696: \tAverage Loss:  0.4536573791503906\t ACC train:  0.9\t ACC test:  0.8222222222222222\n",
      "\tEpoch 697: \tAverage Loss:  0.4527002868652344\t ACC train:  0.88\t ACC test:  0.8311111111111111\n",
      "\tEpoch 698: \tAverage Loss:  0.451885009765625\t ACC train:  0.87\t ACC test:  0.8444444444444444\n",
      "\tEpoch 699: \tAverage Loss:  0.4525954284667969\t ACC train:  0.9\t ACC test:  0.8311111111111111\n",
      "\tEpoch 700: \tAverage Loss:  0.4520188598632813\t ACC train:  0.89\t ACC test:  0.82\n",
      "\tEpoch 701: \tAverage Loss:  0.4519730834960938\t ACC train:  0.9\t ACC test:  0.8222222222222222\n",
      "\tEpoch 702: \tAverage Loss:  0.45195870971679686\t ACC train:  0.9\t ACC test:  0.8244444444444444\n",
      "\tEpoch 703: \tAverage Loss:  0.45196493530273435\t ACC train:  0.88\t ACC test:  0.8288888888888889\n",
      "\tEpoch 704: \tAverage Loss:  0.4527277526855469\t ACC train:  0.89\t ACC test:  0.84\n",
      "\tEpoch 705: \tAverage Loss:  0.45143374633789063\t ACC train:  0.88\t ACC test:  0.8311111111111111\n",
      "\tEpoch 706: \tAverage Loss:  0.4522789611816406\t ACC train:  0.9\t ACC test:  0.8266666666666667\n",
      "\tEpoch 707: \tAverage Loss:  0.451961181640625\t ACC train:  0.87\t ACC test:  0.8355555555555556\n",
      "\tEpoch 708: \tAverage Loss:  0.45011941528320315\t ACC train:  0.88\t ACC test:  0.8355555555555556\n",
      "\tEpoch 709: \tAverage Loss:  0.4513013000488281\t ACC train:  0.91\t ACC test:  0.8311111111111111\n",
      "\tEpoch 710: \tAverage Loss:  0.4505830383300781\t ACC train:  0.9\t ACC test:  0.8222222222222222\n",
      "\tEpoch 711: \tAverage Loss:  0.4505771179199219\t ACC train:  0.89\t ACC test:  0.8333333333333334\n",
      "\tEpoch 712: \tAverage Loss:  0.4518536376953125\t ACC train:  0.89\t ACC test:  0.8355555555555556\n",
      "\tEpoch 713: \tAverage Loss:  0.4502135925292969\t ACC train:  0.88\t ACC test:  0.8355555555555556\n",
      "\tEpoch 714: \tAverage Loss:  0.4503169555664063\t ACC train:  0.89\t ACC test:  0.8244444444444444\n",
      "\tEpoch 715: \tAverage Loss:  0.450765869140625\t ACC train:  0.89\t ACC test:  0.8355555555555556\n",
      "\tEpoch 716: \tAverage Loss:  0.45107794189453126\t ACC train:  0.9\t ACC test:  0.8355555555555556\n",
      "\tEpoch 717: \tAverage Loss:  0.4512452087402344\t ACC train:  0.89\t ACC test:  0.8311111111111111\n",
      "\tEpoch 718: \tAverage Loss:  0.45113009643554686\t ACC train:  0.87\t ACC test:  0.8355555555555556\n",
      "\tEpoch 719: \tAverage Loss:  0.45096688842773436\t ACC train:  0.9\t ACC test:  0.8422222222222222\n",
      "\tEpoch 720: \tAverage Loss:  0.44986322021484376\t ACC train:  0.88\t ACC test:  0.8288888888888889\n",
      "\tEpoch 721: \tAverage Loss:  0.4522305908203125\t ACC train:  0.9\t ACC test:  0.8422222222222222\n",
      "\tEpoch 722: \tAverage Loss:  0.45171502685546877\t ACC train:  0.89\t ACC test:  0.8155555555555556\n",
      "\tEpoch 723: \tAverage Loss:  0.4492195129394531\t ACC train:  0.88\t ACC test:  0.8377777777777777\n",
      "\tEpoch 724: \tAverage Loss:  0.44995248413085936\t ACC train:  0.89\t ACC test:  0.8266666666666667\n",
      "\tEpoch 725: \tAverage Loss:  0.45043182373046875\t ACC train:  0.88\t ACC test:  0.84\n",
      "\tEpoch 726: \tAverage Loss:  0.45132781982421877\t ACC train:  0.89\t ACC test:  0.8244444444444444\n",
      "\tEpoch 727: \tAverage Loss:  0.4514838562011719\t ACC train:  0.89\t ACC test:  0.8533333333333334\n",
      "\tEpoch 728: \tAverage Loss:  0.44982272338867185\t ACC train:  0.89\t ACC test:  0.8288888888888889\n",
      "\tEpoch 729: \tAverage Loss:  0.4508249816894531\t ACC train:  0.91\t ACC test:  0.8311111111111111\n",
      "\tEpoch 730: \tAverage Loss:  0.45135537719726565\t ACC train:  0.89\t ACC test:  0.8288888888888889\n",
      "\tEpoch 731: \tAverage Loss:  0.44933023071289063\t ACC train:  0.89\t ACC test:  0.8222222222222222\n",
      "\tEpoch 732: \tAverage Loss:  0.44928244018554686\t ACC train:  0.91\t ACC test:  0.8355555555555556\n",
      "\tEpoch 733: \tAverage Loss:  0.4481170043945312\t ACC train:  0.88\t ACC test:  0.8155555555555556\n",
      "\tEpoch 734: \tAverage Loss:  0.44968450927734377\t ACC train:  0.89\t ACC test:  0.8311111111111111\n",
      "\tEpoch 735: \tAverage Loss:  0.449002685546875\t ACC train:  0.91\t ACC test:  0.8355555555555556\n",
      "\tEpoch 736: \tAverage Loss:  0.4491697082519531\t ACC train:  0.89\t ACC test:  0.8377777777777777\n",
      "\tEpoch 737: \tAverage Loss:  0.44854092407226565\t ACC train:  0.89\t ACC test:  0.8266666666666667\n",
      "\tEpoch 738: \tAverage Loss:  0.4485595703125\t ACC train:  0.91\t ACC test:  0.8311111111111111\n",
      "\tEpoch 739: \tAverage Loss:  0.4482306213378906\t ACC train:  0.88\t ACC test:  0.8266666666666667\n",
      "\tEpoch 740: \tAverage Loss:  0.44950982666015626\t ACC train:  0.89\t ACC test:  0.8377777777777777\n",
      "\tEpoch 741: \tAverage Loss:  0.4500475158691406\t ACC train:  0.92\t ACC test:  0.8333333333333334\n",
      "\tEpoch 742: \tAverage Loss:  0.44810784912109375\t ACC train:  0.93\t ACC test:  0.8311111111111111\n",
      "\tEpoch 743: \tAverage Loss:  0.4490472412109375\t ACC train:  0.91\t ACC test:  0.8288888888888889\n",
      "\tEpoch 744: \tAverage Loss:  0.4498167114257812\t ACC train:  0.92\t ACC test:  0.8377777777777777\n",
      "\tEpoch 745: \tAverage Loss:  0.4482323913574219\t ACC train:  0.9\t ACC test:  0.8466666666666667\n",
      "\tEpoch 746: \tAverage Loss:  0.44713845825195314\t ACC train:  0.89\t ACC test:  0.8311111111111111\n",
      "\tEpoch 747: \tAverage Loss:  0.447498291015625\t ACC train:  0.91\t ACC test:  0.8355555555555556\n",
      "\tEpoch 748: \tAverage Loss:  0.4485782470703125\t ACC train:  0.92\t ACC test:  0.8222222222222222\n",
      "\tEpoch 749: \tAverage Loss:  0.4491866455078125\t ACC train:  0.9\t ACC test:  0.8111111111111111\n",
      "\tEpoch 750: \tAverage Loss:  0.44939227294921874\t ACC train:  0.87\t ACC test:  0.84\n",
      "\tEpoch 751: \tAverage Loss:  0.4480503845214844\t ACC train:  0.91\t ACC test:  0.8222222222222222\n",
      "\tEpoch 752: \tAverage Loss:  0.4487294921875\t ACC train:  0.91\t ACC test:  0.8266666666666667\n",
      "\tEpoch 753: \tAverage Loss:  0.4476343688964844\t ACC train:  0.88\t ACC test:  0.8311111111111111\n",
      "\tEpoch 754: \tAverage Loss:  0.44745022583007815\t ACC train:  0.9\t ACC test:  0.82\n",
      "\tEpoch 755: \tAverage Loss:  0.4480220947265625\t ACC train:  0.93\t ACC test:  0.84\n",
      "\tEpoch 756: \tAverage Loss:  0.448276123046875\t ACC train:  0.92\t ACC test:  0.8266666666666667\n",
      "\tEpoch 757: \tAverage Loss:  0.4486505126953125\t ACC train:  0.92\t ACC test:  0.8288888888888889\n",
      "\tEpoch 758: \tAverage Loss:  0.4467831726074219\t ACC train:  0.92\t ACC test:  0.8222222222222222\n",
      "\tEpoch 759: \tAverage Loss:  0.44683831787109374\t ACC train:  0.92\t ACC test:  0.8333333333333334\n",
      "\tEpoch 760: \tAverage Loss:  0.44729962158203124\t ACC train:  0.93\t ACC test:  0.8222222222222222\n",
      "\tEpoch 761: \tAverage Loss:  0.4475678405761719\t ACC train:  0.92\t ACC test:  0.8466666666666667\n",
      "\tEpoch 762: \tAverage Loss:  0.44716744995117186\t ACC train:  0.92\t ACC test:  0.8155555555555556\n",
      "\tEpoch 763: \tAverage Loss:  0.44814910888671877\t ACC train:  0.91\t ACC test:  0.8288888888888889\n",
      "\tEpoch 764: \tAverage Loss:  0.44650265502929687\t ACC train:  0.9\t ACC test:  0.8244444444444444\n",
      "\tEpoch 765: \tAverage Loss:  0.44668475341796876\t ACC train:  0.9\t ACC test:  0.8422222222222222\n",
      "\tEpoch 766: \tAverage Loss:  0.4470216064453125\t ACC train:  0.93\t ACC test:  0.8266666666666667\n",
      "\tEpoch 767: \tAverage Loss:  0.4465159912109375\t ACC train:  0.93\t ACC test:  0.8422222222222222\n",
      "\tEpoch 768: \tAverage Loss:  0.4457794189453125\t ACC train:  0.91\t ACC test:  0.8266666666666667\n",
      "\tEpoch 769: \tAverage Loss:  0.4468209228515625\t ACC train:  0.92\t ACC test:  0.8333333333333334\n",
      "\tEpoch 770: \tAverage Loss:  0.44613323974609376\t ACC train:  0.91\t ACC test:  0.8444444444444444\n",
      "\tEpoch 771: \tAverage Loss:  0.4469057312011719\t ACC train:  0.9\t ACC test:  0.8266666666666667\n",
      "\tEpoch 772: \tAverage Loss:  0.446212890625\t ACC train:  0.91\t ACC test:  0.8333333333333334\n",
      "\tEpoch 773: \tAverage Loss:  0.4458281860351562\t ACC train:  0.91\t ACC test:  0.8222222222222222\n",
      "\tEpoch 774: \tAverage Loss:  0.4455166015625\t ACC train:  0.91\t ACC test:  0.8355555555555556\n",
      "\tEpoch 775: \tAverage Loss:  0.4456867980957031\t ACC train:  0.9\t ACC test:  0.8266666666666667\n",
      "\tEpoch 776: \tAverage Loss:  0.44578372192382815\t ACC train:  0.92\t ACC test:  0.8311111111111111\n",
      "\tEpoch 777: \tAverage Loss:  0.4460758666992187\t ACC train:  0.91\t ACC test:  0.8444444444444444\n",
      "\tEpoch 778: \tAverage Loss:  0.4462230224609375\t ACC train:  0.94\t ACC test:  0.8288888888888889\n",
      "\tEpoch 779: \tAverage Loss:  0.44590380859375\t ACC train:  0.92\t ACC test:  0.8422222222222222\n",
      "\tEpoch 780: \tAverage Loss:  0.4460480346679688\t ACC train:  0.94\t ACC test:  0.8422222222222222\n",
      "\tEpoch 781: \tAverage Loss:  0.44564175415039065\t ACC train:  0.92\t ACC test:  0.8422222222222222\n",
      "\tEpoch 782: \tAverage Loss:  0.44506475830078124\t ACC train:  0.93\t ACC test:  0.8311111111111111\n",
      "\tEpoch 783: \tAverage Loss:  0.44539633178710936\t ACC train:  0.94\t ACC test:  0.8444444444444444\n",
      "\tEpoch 784: \tAverage Loss:  0.4463615417480469\t ACC train:  0.94\t ACC test:  0.8311111111111111\n",
      "\tEpoch 785: \tAverage Loss:  0.44477978515625\t ACC train:  0.9\t ACC test:  0.8266666666666667\n",
      "\tEpoch 786: \tAverage Loss:  0.446593994140625\t ACC train:  0.92\t ACC test:  0.8377777777777777\n",
      "\tEpoch 787: \tAverage Loss:  0.4454835510253906\t ACC train:  0.91\t ACC test:  0.8444444444444444\n",
      "\tEpoch 788: \tAverage Loss:  0.4446265258789063\t ACC train:  0.91\t ACC test:  0.8266666666666667\n",
      "\tEpoch 789: \tAverage Loss:  0.44411764526367187\t ACC train:  0.92\t ACC test:  0.8244444444444444\n",
      "\tEpoch 790: \tAverage Loss:  0.4442303771972656\t ACC train:  0.95\t ACC test:  0.8266666666666667\n",
      "\tEpoch 791: \tAverage Loss:  0.4454853515625\t ACC train:  0.92\t ACC test:  0.8377777777777777\n",
      "\tEpoch 792: \tAverage Loss:  0.4450001220703125\t ACC train:  0.93\t ACC test:  0.8422222222222222\n",
      "\tEpoch 793: \tAverage Loss:  0.44455221557617186\t ACC train:  0.93\t ACC test:  0.84\n",
      "\tEpoch 794: \tAverage Loss:  0.4440505676269531\t ACC train:  0.93\t ACC test:  0.8377777777777777\n",
      "\tEpoch 795: \tAverage Loss:  0.4438997802734375\t ACC train:  0.91\t ACC test:  0.8422222222222222\n",
      "\tEpoch 796: \tAverage Loss:  0.4444682922363281\t ACC train:  0.91\t ACC test:  0.8377777777777777\n",
      "\tEpoch 797: \tAverage Loss:  0.4444798583984375\t ACC train:  0.92\t ACC test:  0.8355555555555556\n",
      "\tEpoch 798: \tAverage Loss:  0.4454725341796875\t ACC train:  0.92\t ACC test:  0.8311111111111111\n",
      "\tEpoch 799: \tAverage Loss:  0.44395111083984373\t ACC train:  0.93\t ACC test:  0.8422222222222222\n",
      "\tEpoch 800: \tAverage Loss:  0.44329620361328126\t ACC train:  0.92\t ACC test:  0.8288888888888889\n",
      "\tEpoch 801: \tAverage Loss:  0.44480517578125\t ACC train:  0.92\t ACC test:  0.8355555555555556\n",
      "Stopping early at epoch 801. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 200\n",
      "\tEpoch 1: \tAverage Loss:  1.7571422119140625\t ACC train:  0.49\t ACC test:  0.5155555555555555\n",
      "\tEpoch 2: \tAverage Loss:  1.749580322265625\t ACC train:  0.52\t ACC test:  0.5466666666666666\n",
      "\tEpoch 3: \tAverage Loss:  1.741384521484375\t ACC train:  0.48\t ACC test:  0.5111111111111111\n",
      "\tEpoch 4: \tAverage Loss:  1.7344517822265626\t ACC train:  0.555\t ACC test:  0.5\n",
      "\tEpoch 5: \tAverage Loss:  1.7263519287109375\t ACC train:  0.495\t ACC test:  0.5155555555555555\n",
      "\tEpoch 6: \tAverage Loss:  1.71839599609375\t ACC train:  0.53\t ACC test:  0.4866666666666667\n",
      "\tEpoch 7: \tAverage Loss:  1.712467041015625\t ACC train:  0.515\t ACC test:  0.49777777777777776\n",
      "\tEpoch 8: \tAverage Loss:  1.704883056640625\t ACC train:  0.5\t ACC test:  0.4911111111111111\n",
      "\tEpoch 9: \tAverage Loss:  1.6990628662109375\t ACC train:  0.52\t ACC test:  0.48444444444444446\n",
      "\tEpoch 10: \tAverage Loss:  1.6925726318359375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  1.687217041015625\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  1.6815584716796874\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  1.6760599365234374\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  1.670923828125\t ACC train:  0.515\t ACC test:  0.4888888888888889\n",
      "\tEpoch 15: \tAverage Loss:  1.6662659912109374\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  1.660181640625\t ACC train:  0.515\t ACC test:  0.48444444444444446\n",
      "\tEpoch 17: \tAverage Loss:  1.6573209228515624\t ACC train:  0.515\t ACC test:  0.4911111111111111\n",
      "\tEpoch 18: \tAverage Loss:  1.65237548828125\t ACC train:  0.5\t ACC test:  0.49333333333333335\n",
      "\tEpoch 19: \tAverage Loss:  1.64746533203125\t ACC train:  0.525\t ACC test:  0.4911111111111111\n",
      "\tEpoch 20: \tAverage Loss:  1.6438682861328124\t ACC train:  0.52\t ACC test:  0.49777777777777776\n",
      "\tEpoch 21: \tAverage Loss:  1.640237060546875\t ACC train:  0.535\t ACC test:  0.4822222222222222\n",
      "\tEpoch 22: \tAverage Loss:  1.6379425048828125\t ACC train:  0.52\t ACC test:  0.4955555555555556\n",
      "\tEpoch 23: \tAverage Loss:  1.6340413818359374\t ACC train:  0.495\t ACC test:  0.5155555555555555\n",
      "\tEpoch 24: \tAverage Loss:  1.6312490234375\t ACC train:  0.555\t ACC test:  0.49777777777777776\n",
      "\tEpoch 25: \tAverage Loss:  1.6263682861328126\t ACC train:  0.56\t ACC test:  0.49333333333333335\n",
      "\tEpoch 26: \tAverage Loss:  1.6263602294921875\t ACC train:  0.5\t ACC test:  0.5244444444444445\n",
      "\tEpoch 27: \tAverage Loss:  1.6227125244140626\t ACC train:  0.545\t ACC test:  0.5177777777777778\n",
      "\tEpoch 28: \tAverage Loss:  1.6186962890625\t ACC train:  0.555\t ACC test:  0.4955555555555556\n",
      "\tEpoch 29: \tAverage Loss:  1.61706787109375\t ACC train:  0.5\t ACC test:  0.4911111111111111\n",
      "\tEpoch 30: \tAverage Loss:  1.6157352294921874\t ACC train:  0.47\t ACC test:  0.4888888888888889\n",
      "\tEpoch 31: \tAverage Loss:  1.613913330078125\t ACC train:  0.58\t ACC test:  0.5022222222222222\n",
      "\tEpoch 32: \tAverage Loss:  1.61025732421875\t ACC train:  0.505\t ACC test:  0.5133333333333333\n",
      "\tEpoch 33: \tAverage Loss:  1.6098623046875\t ACC train:  0.58\t ACC test:  0.4888888888888889\n",
      "\tEpoch 34: \tAverage Loss:  1.6070540771484374\t ACC train:  0.5\t ACC test:  0.5333333333333333\n",
      "\tEpoch 35: \tAverage Loss:  1.6047037353515625\t ACC train:  0.475\t ACC test:  0.5333333333333333\n",
      "\tEpoch 36: \tAverage Loss:  1.6014427490234375\t ACC train:  0.525\t ACC test:  0.48444444444444446\n",
      "\tEpoch 37: \tAverage Loss:  1.59998876953125\t ACC train:  0.565\t ACC test:  0.5\n",
      "\tEpoch 38: \tAverage Loss:  1.594504150390625\t ACC train:  0.535\t ACC test:  0.54\n",
      "\tEpoch 39: \tAverage Loss:  1.593515625\t ACC train:  0.55\t ACC test:  0.5088888888888888\n",
      "\tEpoch 40: \tAverage Loss:  1.591561279296875\t ACC train:  0.58\t ACC test:  0.5288888888888889\n",
      "\tEpoch 41: \tAverage Loss:  1.5894686279296875\t ACC train:  0.505\t ACC test:  0.5044444444444445\n",
      "\tEpoch 42: \tAverage Loss:  1.5892489013671875\t ACC train:  0.575\t ACC test:  0.5333333333333333\n",
      "\tEpoch 43: \tAverage Loss:  1.5881458740234375\t ACC train:  0.535\t ACC test:  0.5266666666666666\n",
      "\tEpoch 44: \tAverage Loss:  1.587033203125\t ACC train:  0.525\t ACC test:  0.49333333333333335\n",
      "\tEpoch 45: \tAverage Loss:  1.583135009765625\t ACC train:  0.585\t ACC test:  0.5488888888888889\n",
      "\tEpoch 46: \tAverage Loss:  1.5809378662109375\t ACC train:  0.555\t ACC test:  0.5377777777777778\n",
      "\tEpoch 47: \tAverage Loss:  1.5783436279296874\t ACC train:  0.545\t ACC test:  0.5155555555555555\n",
      "\tEpoch 48: \tAverage Loss:  1.58071142578125\t ACC train:  0.55\t ACC test:  0.5488888888888889\n",
      "\tEpoch 49: \tAverage Loss:  1.5712508544921875\t ACC train:  0.56\t ACC test:  0.5288888888888889\n",
      "\tEpoch 50: \tAverage Loss:  1.5730301513671876\t ACC train:  0.57\t ACC test:  0.5333333333333333\n",
      "\tEpoch 51: \tAverage Loss:  1.571529052734375\t ACC train:  0.57\t ACC test:  0.5288888888888889\n",
      "\tEpoch 52: \tAverage Loss:  1.5711614990234375\t ACC train:  0.56\t ACC test:  0.5311111111111111\n",
      "\tEpoch 53: \tAverage Loss:  1.575068603515625\t ACC train:  0.535\t ACC test:  0.54\n",
      "\tEpoch 54: \tAverage Loss:  1.5681973876953126\t ACC train:  0.62\t ACC test:  0.56\n",
      "\tEpoch 55: \tAverage Loss:  1.5679703369140625\t ACC train:  0.555\t ACC test:  0.5311111111111111\n",
      "\tEpoch 56: \tAverage Loss:  1.56793603515625\t ACC train:  0.535\t ACC test:  0.5777777777777777\n",
      "\tEpoch 57: \tAverage Loss:  1.5610416259765625\t ACC train:  0.585\t ACC test:  0.5422222222222223\n",
      "\tEpoch 58: \tAverage Loss:  1.5545008544921874\t ACC train:  0.57\t ACC test:  0.58\n",
      "\tEpoch 59: \tAverage Loss:  1.559337158203125\t ACC train:  0.555\t ACC test:  0.5111111111111111\n",
      "\tEpoch 60: \tAverage Loss:  1.55899560546875\t ACC train:  0.535\t ACC test:  0.5755555555555556\n",
      "\tEpoch 61: \tAverage Loss:  1.559949951171875\t ACC train:  0.555\t ACC test:  0.5533333333333333\n",
      "\tEpoch 62: \tAverage Loss:  1.5559486083984375\t ACC train:  0.575\t ACC test:  0.5555555555555556\n",
      "\tEpoch 63: \tAverage Loss:  1.5521185302734375\t ACC train:  0.605\t ACC test:  0.5666666666666667\n",
      "\tEpoch 64: \tAverage Loss:  1.5508167724609374\t ACC train:  0.56\t ACC test:  0.5666666666666667\n",
      "\tEpoch 65: \tAverage Loss:  1.550131591796875\t ACC train:  0.58\t ACC test:  0.5622222222222222\n",
      "\tEpoch 66: \tAverage Loss:  1.5472962646484374\t ACC train:  0.585\t ACC test:  0.5511111111111111\n",
      "\tEpoch 67: \tAverage Loss:  1.5458095703125\t ACC train:  0.57\t ACC test:  0.5644444444444444\n",
      "\tEpoch 68: \tAverage Loss:  1.5434383544921875\t ACC train:  0.575\t ACC test:  0.5644444444444444\n",
      "\tEpoch 69: \tAverage Loss:  1.5356484375\t ACC train:  0.58\t ACC test:  0.5533333333333333\n",
      "\tEpoch 70: \tAverage Loss:  1.5389949951171875\t ACC train:  0.59\t ACC test:  0.5688888888888889\n",
      "\tEpoch 71: \tAverage Loss:  1.53222021484375\t ACC train:  0.59\t ACC test:  0.56\n",
      "\tEpoch 72: \tAverage Loss:  1.5289849853515625\t ACC train:  0.53\t ACC test:  0.5288888888888889\n",
      "\tEpoch 73: \tAverage Loss:  1.5287298583984374\t ACC train:  0.545\t ACC test:  0.5822222222222222\n",
      "\tEpoch 74: \tAverage Loss:  1.5290225830078126\t ACC train:  0.575\t ACC test:  0.5755555555555556\n",
      "\tEpoch 75: \tAverage Loss:  1.5238206787109374\t ACC train:  0.585\t ACC test:  0.54\n",
      "\tEpoch 76: \tAverage Loss:  1.52525146484375\t ACC train:  0.56\t ACC test:  0.5755555555555556\n",
      "\tEpoch 77: \tAverage Loss:  1.5170565185546876\t ACC train:  0.585\t ACC test:  0.5911111111111111\n",
      "\tEpoch 78: \tAverage Loss:  1.51881640625\t ACC train:  0.58\t ACC test:  0.5733333333333334\n",
      "\tEpoch 79: \tAverage Loss:  1.5156439208984376\t ACC train:  0.6\t ACC test:  0.5777777777777777\n",
      "\tEpoch 80: \tAverage Loss:  1.5099503173828126\t ACC train:  0.615\t ACC test:  0.5844444444444444\n",
      "\tEpoch 81: \tAverage Loss:  1.5037603759765625\t ACC train:  0.575\t ACC test:  0.5977777777777777\n",
      "\tEpoch 82: \tAverage Loss:  1.504775146484375\t ACC train:  0.615\t ACC test:  0.5777777777777777\n",
      "\tEpoch 83: \tAverage Loss:  1.498146728515625\t ACC train:  0.595\t ACC test:  0.6022222222222222\n",
      "\tEpoch 84: \tAverage Loss:  1.4923985595703124\t ACC train:  0.58\t ACC test:  0.5844444444444444\n",
      "\tEpoch 85: \tAverage Loss:  1.49074560546875\t ACC train:  0.575\t ACC test:  0.5777777777777777\n",
      "\tEpoch 86: \tAverage Loss:  1.4890458984375\t ACC train:  0.61\t ACC test:  0.5955555555555555\n",
      "\tEpoch 87: \tAverage Loss:  1.48763671875\t ACC train:  0.585\t ACC test:  0.5933333333333334\n",
      "\tEpoch 88: \tAverage Loss:  1.483786376953125\t ACC train:  0.595\t ACC test:  0.5888888888888889\n",
      "\tEpoch 89: \tAverage Loss:  1.4728499755859374\t ACC train:  0.585\t ACC test:  0.6022222222222222\n",
      "\tEpoch 90: \tAverage Loss:  1.472621826171875\t ACC train:  0.58\t ACC test:  0.5977777777777777\n",
      "\tEpoch 91: \tAverage Loss:  1.4647916259765625\t ACC train:  0.63\t ACC test:  0.5955555555555555\n",
      "\tEpoch 92: \tAverage Loss:  1.46048779296875\t ACC train:  0.58\t ACC test:  0.6\n",
      "\tEpoch 93: \tAverage Loss:  1.454224365234375\t ACC train:  0.605\t ACC test:  0.6133333333333333\n",
      "\tEpoch 94: \tAverage Loss:  1.4453682861328125\t ACC train:  0.605\t ACC test:  0.6133333333333333\n",
      "\tEpoch 95: \tAverage Loss:  1.44794970703125\t ACC train:  0.615\t ACC test:  0.6066666666666667\n",
      "\tEpoch 96: \tAverage Loss:  1.4460986328125\t ACC train:  0.605\t ACC test:  0.6088888888888889\n",
      "\tEpoch 97: \tAverage Loss:  1.44108837890625\t ACC train:  0.61\t ACC test:  0.6044444444444445\n",
      "\tEpoch 98: \tAverage Loss:  1.4362923583984375\t ACC train:  0.625\t ACC test:  0.6177777777777778\n",
      "\tEpoch 99: \tAverage Loss:  1.42995458984375\t ACC train:  0.64\t ACC test:  0.6044444444444445\n",
      "\tEpoch 100: \tAverage Loss:  1.4257381591796876\t ACC train:  0.625\t ACC test:  0.6266666666666667\n",
      "\tEpoch 101: \tAverage Loss:  1.426711669921875\t ACC train:  0.61\t ACC test:  0.6111111111111112\n",
      "\tEpoch 102: \tAverage Loss:  1.4090103759765624\t ACC train:  0.62\t ACC test:  0.6222222222222222\n",
      "\tEpoch 103: \tAverage Loss:  1.41912548828125\t ACC train:  0.625\t ACC test:  0.6222222222222222\n",
      "\tEpoch 104: \tAverage Loss:  1.403263916015625\t ACC train:  0.61\t ACC test:  0.6222222222222222\n",
      "\tEpoch 105: \tAverage Loss:  1.39539990234375\t ACC train:  0.63\t ACC test:  0.6288888888888889\n",
      "\tEpoch 106: \tAverage Loss:  1.39491552734375\t ACC train:  0.635\t ACC test:  0.6177777777777778\n",
      "\tEpoch 107: \tAverage Loss:  1.387717041015625\t ACC train:  0.62\t ACC test:  0.6222222222222222\n",
      "\tEpoch 108: \tAverage Loss:  1.37993505859375\t ACC train:  0.61\t ACC test:  0.6111111111111112\n",
      "\tEpoch 109: \tAverage Loss:  1.3796453857421875\t ACC train:  0.625\t ACC test:  0.6288888888888889\n",
      "\tEpoch 110: \tAverage Loss:  1.36896240234375\t ACC train:  0.625\t ACC test:  0.6088888888888889\n",
      "\tEpoch 111: \tAverage Loss:  1.36891455078125\t ACC train:  0.625\t ACC test:  0.6022222222222222\n",
      "\tEpoch 112: \tAverage Loss:  1.3657283935546876\t ACC train:  0.645\t ACC test:  0.6355555555555555\n",
      "\tEpoch 113: \tAverage Loss:  1.361877685546875\t ACC train:  0.625\t ACC test:  0.62\n",
      "\tEpoch 114: \tAverage Loss:  1.3538775634765625\t ACC train:  0.615\t ACC test:  0.6088888888888889\n",
      "\tEpoch 115: \tAverage Loss:  1.3516298828125\t ACC train:  0.595\t ACC test:  0.6022222222222222\n",
      "\tEpoch 116: \tAverage Loss:  1.3393197021484375\t ACC train:  0.605\t ACC test:  0.6111111111111112\n",
      "\tEpoch 117: \tAverage Loss:  1.33562548828125\t ACC train:  0.61\t ACC test:  0.5955555555555555\n",
      "\tEpoch 118: \tAverage Loss:  1.3367022705078124\t ACC train:  0.59\t ACC test:  0.5933333333333334\n",
      "\tEpoch 119: \tAverage Loss:  1.330120849609375\t ACC train:  0.59\t ACC test:  0.6022222222222222\n",
      "\tEpoch 120: \tAverage Loss:  1.3235718994140624\t ACC train:  0.58\t ACC test:  0.6\n",
      "\tEpoch 121: \tAverage Loss:  1.3180269775390625\t ACC train:  0.58\t ACC test:  0.5844444444444444\n",
      "\tEpoch 122: \tAverage Loss:  1.3111951904296875\t ACC train:  0.58\t ACC test:  0.58\n",
      "\tEpoch 123: \tAverage Loss:  1.30280712890625\t ACC train:  0.6\t ACC test:  0.58\n",
      "\tEpoch 124: \tAverage Loss:  1.30090673828125\t ACC train:  0.58\t ACC test:  0.5955555555555555\n",
      "\tEpoch 125: \tAverage Loss:  1.2969964599609376\t ACC train:  0.58\t ACC test:  0.5777777777777777\n",
      "\tEpoch 126: \tAverage Loss:  1.289538818359375\t ACC train:  0.575\t ACC test:  0.5844444444444444\n",
      "\tEpoch 127: \tAverage Loss:  1.2888564453125\t ACC train:  0.55\t ACC test:  0.5844444444444444\n",
      "\tEpoch 128: \tAverage Loss:  1.281676025390625\t ACC train:  0.57\t ACC test:  0.5866666666666667\n",
      "\tEpoch 129: \tAverage Loss:  1.2728800048828126\t ACC train:  0.575\t ACC test:  0.5644444444444444\n",
      "\tEpoch 130: \tAverage Loss:  1.270777587890625\t ACC train:  0.565\t ACC test:  0.5666666666666667\n",
      "\tEpoch 131: \tAverage Loss:  1.26495166015625\t ACC train:  0.58\t ACC test:  0.5688888888888889\n",
      "\tEpoch 132: \tAverage Loss:  1.265331787109375\t ACC train:  0.56\t ACC test:  0.5622222222222222\n",
      "\tEpoch 133: \tAverage Loss:  1.2574298095703125\t ACC train:  0.575\t ACC test:  0.5577777777777778\n",
      "\tEpoch 134: \tAverage Loss:  1.2516710205078125\t ACC train:  0.56\t ACC test:  0.5555555555555556\n",
      "\tEpoch 135: \tAverage Loss:  1.24404248046875\t ACC train:  0.56\t ACC test:  0.5511111111111111\n",
      "\tEpoch 136: \tAverage Loss:  1.2414276123046875\t ACC train:  0.555\t ACC test:  0.5488888888888889\n",
      "\tEpoch 137: \tAverage Loss:  1.2407322998046875\t ACC train:  0.55\t ACC test:  0.5577777777777778\n",
      "\tEpoch 138: \tAverage Loss:  1.2322847900390625\t ACC train:  0.545\t ACC test:  0.5466666666666666\n",
      "\tEpoch 139: \tAverage Loss:  1.2269349365234374\t ACC train:  0.53\t ACC test:  0.5422222222222223\n",
      "\tEpoch 140: \tAverage Loss:  1.2211954345703124\t ACC train:  0.535\t ACC test:  0.5488888888888889\n",
      "\tEpoch 141: \tAverage Loss:  1.2204140625\t ACC train:  0.545\t ACC test:  0.5422222222222223\n",
      "\tEpoch 142: \tAverage Loss:  1.216008544921875\t ACC train:  0.54\t ACC test:  0.5355555555555556\n",
      "\tEpoch 143: \tAverage Loss:  1.2085721435546875\t ACC train:  0.53\t ACC test:  0.5333333333333333\n",
      "\tEpoch 144: \tAverage Loss:  1.2090406494140624\t ACC train:  0.54\t ACC test:  0.54\n",
      "\tEpoch 145: \tAverage Loss:  1.2078720703125\t ACC train:  0.545\t ACC test:  0.5422222222222223\n",
      "\tEpoch 146: \tAverage Loss:  1.199704833984375\t ACC train:  0.52\t ACC test:  0.54\n",
      "\tEpoch 147: \tAverage Loss:  1.195827880859375\t ACC train:  0.545\t ACC test:  0.54\n",
      "\tEpoch 148: \tAverage Loss:  1.1913223876953125\t ACC train:  0.54\t ACC test:  0.5333333333333333\n",
      "\tEpoch 149: \tAverage Loss:  1.184494140625\t ACC train:  0.545\t ACC test:  0.5333333333333333\n",
      "\tEpoch 150: \tAverage Loss:  1.18601708984375\t ACC train:  0.54\t ACC test:  0.5311111111111111\n",
      "\tEpoch 151: \tAverage Loss:  1.1794412841796875\t ACC train:  0.525\t ACC test:  0.5266666666666666\n",
      "\tEpoch 152: \tAverage Loss:  1.1745169677734375\t ACC train:  0.515\t ACC test:  0.54\n",
      "\tEpoch 153: \tAverage Loss:  1.168999267578125\t ACC train:  0.52\t ACC test:  0.5355555555555556\n",
      "\tEpoch 154: \tAverage Loss:  1.1681065673828126\t ACC train:  0.545\t ACC test:  0.5377777777777778\n",
      "\tEpoch 155: \tAverage Loss:  1.162129638671875\t ACC train:  0.52\t ACC test:  0.5311111111111111\n",
      "\tEpoch 156: \tAverage Loss:  1.16052978515625\t ACC train:  0.54\t ACC test:  0.5244444444444445\n",
      "\tEpoch 157: \tAverage Loss:  1.1539210205078125\t ACC train:  0.525\t ACC test:  0.5333333333333333\n",
      "\tEpoch 158: \tAverage Loss:  1.1525845947265625\t ACC train:  0.525\t ACC test:  0.5288888888888889\n",
      "\tEpoch 159: \tAverage Loss:  1.14888671875\t ACC train:  0.5\t ACC test:  0.52\n",
      "\tEpoch 160: \tAverage Loss:  1.1455531005859374\t ACC train:  0.505\t ACC test:  0.5222222222222223\n",
      "\tEpoch 161: \tAverage Loss:  1.1420865478515625\t ACC train:  0.53\t ACC test:  0.5333333333333333\n",
      "\tEpoch 162: \tAverage Loss:  1.1397476806640625\t ACC train:  0.52\t ACC test:  0.5244444444444445\n",
      "\tEpoch 163: \tAverage Loss:  1.137818603515625\t ACC train:  0.525\t ACC test:  0.5244444444444445\n",
      "\tEpoch 164: \tAverage Loss:  1.13223486328125\t ACC train:  0.515\t ACC test:  0.5288888888888889\n",
      "\tEpoch 165: \tAverage Loss:  1.1295970458984375\t ACC train:  0.51\t ACC test:  0.5244444444444445\n",
      "\tEpoch 166: \tAverage Loss:  1.125097900390625\t ACC train:  0.495\t ACC test:  0.5111111111111111\n",
      "\tEpoch 167: \tAverage Loss:  1.1240140380859376\t ACC train:  0.52\t ACC test:  0.5244444444444445\n",
      "\tEpoch 168: \tAverage Loss:  1.1210042724609375\t ACC train:  0.51\t ACC test:  0.5133333333333333\n",
      "\tEpoch 169: \tAverage Loss:  1.1174964599609376\t ACC train:  0.515\t ACC test:  0.5155555555555555\n",
      "\tEpoch 170: \tAverage Loss:  1.115191650390625\t ACC train:  0.515\t ACC test:  0.5244444444444445\n",
      "\tEpoch 171: \tAverage Loss:  1.1136510009765626\t ACC train:  0.51\t ACC test:  0.52\n",
      "\tEpoch 172: \tAverage Loss:  1.10971142578125\t ACC train:  0.51\t ACC test:  0.5155555555555555\n",
      "\tEpoch 173: \tAverage Loss:  1.1076083984375\t ACC train:  0.51\t ACC test:  0.52\n",
      "\tEpoch 174: \tAverage Loss:  1.1041358642578125\t ACC train:  0.515\t ACC test:  0.5155555555555555\n",
      "\tEpoch 175: \tAverage Loss:  1.1011033935546874\t ACC train:  0.505\t ACC test:  0.5222222222222223\n",
      "\tEpoch 176: \tAverage Loss:  1.100037109375\t ACC train:  0.495\t ACC test:  0.5155555555555555\n",
      "\tEpoch 177: \tAverage Loss:  1.0970631103515625\t ACC train:  0.51\t ACC test:  0.5222222222222223\n",
      "\tEpoch 178: \tAverage Loss:  1.0945565185546875\t ACC train:  0.505\t ACC test:  0.5133333333333333\n",
      "\tEpoch 179: \tAverage Loss:  1.0930347900390625\t ACC train:  0.51\t ACC test:  0.5155555555555555\n",
      "\tEpoch 180: \tAverage Loss:  1.09052978515625\t ACC train:  0.49\t ACC test:  0.5155555555555555\n",
      "\tEpoch 181: \tAverage Loss:  1.0913157958984374\t ACC train:  0.52\t ACC test:  0.5155555555555555\n",
      "\tEpoch 182: \tAverage Loss:  1.0875313720703126\t ACC train:  0.515\t ACC test:  0.5333333333333333\n",
      "\tEpoch 183: \tAverage Loss:  1.083640625\t ACC train:  0.49\t ACC test:  0.5177777777777778\n",
      "\tEpoch 184: \tAverage Loss:  1.083841552734375\t ACC train:  0.505\t ACC test:  0.5133333333333333\n",
      "\tEpoch 185: \tAverage Loss:  1.079228515625\t ACC train:  0.505\t ACC test:  0.5222222222222223\n",
      "\tEpoch 186: \tAverage Loss:  1.0798125\t ACC train:  0.51\t ACC test:  0.5133333333333333\n",
      "\tEpoch 187: \tAverage Loss:  1.07765869140625\t ACC train:  0.51\t ACC test:  0.5\n",
      "\tEpoch 188: \tAverage Loss:  1.0754107666015624\t ACC train:  0.505\t ACC test:  0.5133333333333333\n",
      "\tEpoch 189: \tAverage Loss:  1.072809814453125\t ACC train:  0.51\t ACC test:  0.52\n",
      "\tEpoch 190: \tAverage Loss:  1.0718660888671876\t ACC train:  0.5\t ACC test:  0.5088888888888888\n",
      "\tEpoch 191: \tAverage Loss:  1.0705872802734375\t ACC train:  0.51\t ACC test:  0.5066666666666667\n",
      "\tEpoch 192: \tAverage Loss:  1.0680994873046874\t ACC train:  0.495\t ACC test:  0.5022222222222222\n",
      "\tEpoch 193: \tAverage Loss:  1.064232666015625\t ACC train:  0.505\t ACC test:  0.5066666666666667\n",
      "\tEpoch 194: \tAverage Loss:  1.065298583984375\t ACC train:  0.5\t ACC test:  0.5088888888888888\n",
      "\tEpoch 195: \tAverage Loss:  1.0629349365234375\t ACC train:  0.495\t ACC test:  0.5022222222222222\n",
      "\tEpoch 196: \tAverage Loss:  1.0623546142578124\t ACC train:  0.51\t ACC test:  0.5044444444444445\n",
      "\tEpoch 197: \tAverage Loss:  1.0624066162109376\t ACC train:  0.485\t ACC test:  0.5111111111111111\n",
      "\tEpoch 198: \tAverage Loss:  1.058060546875\t ACC train:  0.505\t ACC test:  0.5088888888888888\n",
      "\tEpoch 199: \tAverage Loss:  1.056839111328125\t ACC train:  0.495\t ACC test:  0.5066666666666667\n",
      "\tEpoch 200: \tAverage Loss:  1.0554810791015625\t ACC train:  0.495\t ACC test:  0.5088888888888888\n",
      "\tEpoch 201: \tAverage Loss:  1.05420361328125\t ACC train:  0.505\t ACC test:  0.5044444444444445\n",
      "\tEpoch 202: \tAverage Loss:  1.052859375\t ACC train:  0.5\t ACC test:  0.5111111111111111\n",
      "\tEpoch 203: \tAverage Loss:  1.0505791015625\t ACC train:  0.49\t ACC test:  0.5066666666666667\n",
      "\tEpoch 204: \tAverage Loss:  1.04993603515625\t ACC train:  0.505\t ACC test:  0.5088888888888888\n",
      "\tEpoch 205: \tAverage Loss:  1.047061767578125\t ACC train:  0.495\t ACC test:  0.5155555555555555\n",
      "\tEpoch 206: \tAverage Loss:  1.0461468505859375\t ACC train:  0.495\t ACC test:  0.5111111111111111\n",
      "\tEpoch 207: \tAverage Loss:  1.0446759033203126\t ACC train:  0.49\t ACC test:  0.5066666666666667\n",
      "\tEpoch 208: \tAverage Loss:  1.0455394287109374\t ACC train:  0.485\t ACC test:  0.5088888888888888\n",
      "\tEpoch 209: \tAverage Loss:  1.042219482421875\t ACC train:  0.51\t ACC test:  0.5044444444444445\n",
      "\tEpoch 210: \tAverage Loss:  1.0417840576171875\t ACC train:  0.51\t ACC test:  0.5044444444444445\n",
      "\tEpoch 211: \tAverage Loss:  1.0408468017578125\t ACC train:  0.485\t ACC test:  0.49777777777777776\n",
      "\tEpoch 212: \tAverage Loss:  1.0390323486328126\t ACC train:  0.515\t ACC test:  0.5044444444444445\n",
      "\tEpoch 213: \tAverage Loss:  1.03803662109375\t ACC train:  0.495\t ACC test:  0.5044444444444445\n",
      "\tEpoch 214: \tAverage Loss:  1.0361312255859374\t ACC train:  0.5\t ACC test:  0.5066666666666667\n",
      "\tEpoch 215: \tAverage Loss:  1.0342711181640625\t ACC train:  0.49\t ACC test:  0.5111111111111111\n",
      "\tEpoch 216: \tAverage Loss:  1.034455810546875\t ACC train:  0.485\t ACC test:  0.5044444444444445\n",
      "\tEpoch 217: \tAverage Loss:  1.0338408203125\t ACC train:  0.49\t ACC test:  0.5044444444444445\n",
      "\tEpoch 218: \tAverage Loss:  1.0323543701171876\t ACC train:  0.5\t ACC test:  0.5044444444444445\n",
      "\tEpoch 219: \tAverage Loss:  1.03236865234375\t ACC train:  0.5\t ACC test:  0.5022222222222222\n",
      "\tEpoch 220: \tAverage Loss:  1.0322099609375\t ACC train:  0.49\t ACC test:  0.5044444444444445\n",
      "\tEpoch 221: \tAverage Loss:  1.0298082275390625\t ACC train:  0.49\t ACC test:  0.5066666666666667\n",
      "\tEpoch 222: \tAverage Loss:  1.029814453125\t ACC train:  0.495\t ACC test:  0.5\n",
      "\tEpoch 223: \tAverage Loss:  1.0281734619140626\t ACC train:  0.49\t ACC test:  0.5088888888888888\n",
      "\tEpoch 224: \tAverage Loss:  1.0267073974609375\t ACC train:  0.485\t ACC test:  0.5066666666666667\n",
      "\tEpoch 225: \tAverage Loss:  1.025079833984375\t ACC train:  0.49\t ACC test:  0.5044444444444445\n",
      "\tEpoch 226: \tAverage Loss:  1.0250989990234376\t ACC train:  0.505\t ACC test:  0.5\n",
      "\tEpoch 227: \tAverage Loss:  1.024087890625\t ACC train:  0.485\t ACC test:  0.5111111111111111\n",
      "\tEpoch 228: \tAverage Loss:  1.0224942626953124\t ACC train:  0.49\t ACC test:  0.5\n",
      "\tEpoch 229: \tAverage Loss:  1.0225663452148437\t ACC train:  0.485\t ACC test:  0.5022222222222222\n",
      "\tEpoch 230: \tAverage Loss:  1.02111083984375\t ACC train:  0.5\t ACC test:  0.5066666666666667\n",
      "\tEpoch 231: \tAverage Loss:  1.0212830200195313\t ACC train:  0.475\t ACC test:  0.5044444444444445\n",
      "\tEpoch 232: \tAverage Loss:  1.019282958984375\t ACC train:  0.5\t ACC test:  0.5\n",
      "\tEpoch 233: \tAverage Loss:  1.01865771484375\t ACC train:  0.485\t ACC test:  0.5044444444444445\n",
      "\tEpoch 234: \tAverage Loss:  1.01821923828125\t ACC train:  0.485\t ACC test:  0.5066666666666667\n",
      "\tEpoch 235: \tAverage Loss:  1.018059326171875\t ACC train:  0.495\t ACC test:  0.4955555555555556\n",
      "\tEpoch 236: \tAverage Loss:  1.01718017578125\t ACC train:  0.49\t ACC test:  0.5\n",
      "\tEpoch 237: \tAverage Loss:  1.016000732421875\t ACC train:  0.495\t ACC test:  0.5066666666666667\n",
      "\tEpoch 238: \tAverage Loss:  1.015290771484375\t ACC train:  0.48\t ACC test:  0.5066666666666667\n",
      "\tEpoch 239: \tAverage Loss:  1.0128385009765626\t ACC train:  0.485\t ACC test:  0.49777777777777776\n",
      "\tEpoch 240: \tAverage Loss:  1.0123065795898438\t ACC train:  0.475\t ACC test:  0.4955555555555556\n",
      "\tEpoch 241: \tAverage Loss:  1.0124395751953126\t ACC train:  0.49\t ACC test:  0.5\n",
      "\tEpoch 242: \tAverage Loss:  1.0115875854492187\t ACC train:  0.48\t ACC test:  0.49777777777777776\n",
      "\tEpoch 243: \tAverage Loss:  1.0109247436523439\t ACC train:  0.5\t ACC test:  0.5088888888888888\n",
      "\tEpoch 244: \tAverage Loss:  1.010229736328125\t ACC train:  0.48\t ACC test:  0.4955555555555556\n",
      "\tEpoch 245: \tAverage Loss:  1.009599609375\t ACC train:  0.49\t ACC test:  0.5\n",
      "\tEpoch 246: \tAverage Loss:  1.0083397216796874\t ACC train:  0.48\t ACC test:  0.5066666666666667\n",
      "\tEpoch 247: \tAverage Loss:  1.0091163940429688\t ACC train:  0.5\t ACC test:  0.5022222222222222\n",
      "\tEpoch 248: \tAverage Loss:  1.0068421020507812\t ACC train:  0.49\t ACC test:  0.5044444444444445\n",
      "\tEpoch 249: \tAverage Loss:  1.0068917236328125\t ACC train:  0.495\t ACC test:  0.5022222222222222\n",
      "\tEpoch 250: \tAverage Loss:  1.006023681640625\t ACC train:  0.49\t ACC test:  0.5022222222222222\n",
      "\tEpoch 251: \tAverage Loss:  1.0066112060546875\t ACC train:  0.495\t ACC test:  0.5111111111111111\n",
      "\tEpoch 252: \tAverage Loss:  1.0050724487304687\t ACC train:  0.485\t ACC test:  0.49777777777777776\n",
      "\tEpoch 253: \tAverage Loss:  1.0043341064453124\t ACC train:  0.485\t ACC test:  0.4955555555555556\n",
      "\tEpoch 254: \tAverage Loss:  1.0027365112304687\t ACC train:  0.49\t ACC test:  0.49777777777777776\n",
      "\tEpoch 255: \tAverage Loss:  1.0031944580078125\t ACC train:  0.495\t ACC test:  0.4955555555555556\n",
      "\tEpoch 256: \tAverage Loss:  1.0021552734375\t ACC train:  0.485\t ACC test:  0.5044444444444445\n",
      "\tEpoch 257: \tAverage Loss:  1.0018549194335937\t ACC train:  0.495\t ACC test:  0.5044444444444445\n",
      "\tEpoch 258: \tAverage Loss:  1.0016739501953125\t ACC train:  0.495\t ACC test:  0.49333333333333335\n",
      "\tEpoch 259: \tAverage Loss:  1.0005834350585938\t ACC train:  0.475\t ACC test:  0.5022222222222222\n",
      "\tEpoch 260: \tAverage Loss:  0.99967333984375\t ACC train:  0.49\t ACC test:  0.49333333333333335\n",
      "\tEpoch 261: \tAverage Loss:  0.9993175659179687\t ACC train:  0.49\t ACC test:  0.5088888888888888\n",
      "\tEpoch 262: \tAverage Loss:  0.9985404663085937\t ACC train:  0.485\t ACC test:  0.4955555555555556\n",
      "\tEpoch 263: \tAverage Loss:  0.9977750244140625\t ACC train:  0.485\t ACC test:  0.4955555555555556\n",
      "\tEpoch 264: \tAverage Loss:  0.997554443359375\t ACC train:  0.48\t ACC test:  0.5\n",
      "\tEpoch 265: \tAverage Loss:  0.9975316162109376\t ACC train:  0.485\t ACC test:  0.5022222222222222\n",
      "\tEpoch 266: \tAverage Loss:  0.9968785400390625\t ACC train:  0.485\t ACC test:  0.5\n",
      "\tEpoch 267: \tAverage Loss:  0.9965806884765624\t ACC train:  0.485\t ACC test:  0.5\n",
      "\tEpoch 268: \tAverage Loss:  0.995334716796875\t ACC train:  0.495\t ACC test:  0.5044444444444445\n",
      "\tEpoch 269: \tAverage Loss:  0.9954673461914062\t ACC train:  0.49\t ACC test:  0.5066666666666667\n",
      "\tEpoch 270: \tAverage Loss:  0.9956334838867188\t ACC train:  0.49\t ACC test:  0.5\n",
      "\tEpoch 271: \tAverage Loss:  0.9942831420898437\t ACC train:  0.49\t ACC test:  0.5\n",
      "\tEpoch 272: \tAverage Loss:  0.99323583984375\t ACC train:  0.49\t ACC test:  0.5022222222222222\n",
      "\tEpoch 273: \tAverage Loss:  0.992752197265625\t ACC train:  0.495\t ACC test:  0.5066666666666667\n",
      "\tEpoch 274: \tAverage Loss:  0.992730224609375\t ACC train:  0.485\t ACC test:  0.5155555555555555\n",
      "\tEpoch 275: \tAverage Loss:  0.9925816040039063\t ACC train:  0.49\t ACC test:  0.5044444444444445\n",
      "\tEpoch 276: \tAverage Loss:  0.9915614013671875\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 277: \tAverage Loss:  0.9906740112304687\t ACC train:  0.5\t ACC test:  0.5022222222222222\n",
      "\tEpoch 278: \tAverage Loss:  0.9901864013671875\t ACC train:  0.505\t ACC test:  0.5111111111111111\n",
      "\tEpoch 279: \tAverage Loss:  0.9913759765625\t ACC train:  0.49\t ACC test:  0.5022222222222222\n",
      "\tEpoch 280: \tAverage Loss:  0.9900790405273437\t ACC train:  0.485\t ACC test:  0.49777777777777776\n",
      "\tEpoch 281: \tAverage Loss:  0.9891195068359375\t ACC train:  0.485\t ACC test:  0.5044444444444445\n",
      "\tEpoch 282: \tAverage Loss:  0.9882657470703125\t ACC train:  0.5\t ACC test:  0.5066666666666667\n",
      "\tEpoch 283: \tAverage Loss:  0.9879976196289062\t ACC train:  0.495\t ACC test:  0.5066666666666667\n",
      "\tEpoch 284: \tAverage Loss:  0.9880150756835937\t ACC train:  0.495\t ACC test:  0.5066666666666667\n",
      "\tEpoch 285: \tAverage Loss:  0.9876748046875\t ACC train:  0.485\t ACC test:  0.5044444444444445\n",
      "\tEpoch 286: \tAverage Loss:  0.98751904296875\t ACC train:  0.49\t ACC test:  0.5\n",
      "\tEpoch 287: \tAverage Loss:  0.9862685546875\t ACC train:  0.49\t ACC test:  0.5022222222222222\n",
      "\tEpoch 288: \tAverage Loss:  0.9863899536132813\t ACC train:  0.48\t ACC test:  0.5022222222222222\n",
      "\tEpoch 289: \tAverage Loss:  0.9858848876953125\t ACC train:  0.495\t ACC test:  0.5066666666666667\n",
      "\tEpoch 290: \tAverage Loss:  0.9852943115234375\t ACC train:  0.495\t ACC test:  0.5111111111111111\n",
      "\tEpoch 291: \tAverage Loss:  0.9846925048828125\t ACC train:  0.49\t ACC test:  0.5022222222222222\n",
      "\tEpoch 292: \tAverage Loss:  0.9848023071289063\t ACC train:  0.5\t ACC test:  0.5133333333333333\n",
      "\tEpoch 293: \tAverage Loss:  0.9837716674804687\t ACC train:  0.49\t ACC test:  0.5111111111111111\n",
      "\tEpoch 294: \tAverage Loss:  0.9832659912109375\t ACC train:  0.5\t ACC test:  0.5111111111111111\n",
      "\tEpoch 295: \tAverage Loss:  0.9826508178710938\t ACC train:  0.5\t ACC test:  0.5111111111111111\n",
      "\tEpoch 296: \tAverage Loss:  0.9827939453125\t ACC train:  0.5\t ACC test:  0.5133333333333333\n",
      "\tEpoch 297: \tAverage Loss:  0.982011962890625\t ACC train:  0.5\t ACC test:  0.5177777777777778\n",
      "\tEpoch 298: \tAverage Loss:  0.982078857421875\t ACC train:  0.49\t ACC test:  0.5066666666666667\n",
      "\tEpoch 299: \tAverage Loss:  0.9816343383789062\t ACC train:  0.5\t ACC test:  0.5088888888888888\n",
      "\tEpoch 300: \tAverage Loss:  0.9812743530273438\t ACC train:  0.495\t ACC test:  0.5111111111111111\n",
      "\tEpoch 301: \tAverage Loss:  0.9806494140625\t ACC train:  0.495\t ACC test:  0.5111111111111111\n",
      "\tEpoch 302: \tAverage Loss:  0.9802125854492187\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 303: \tAverage Loss:  0.9804893798828125\t ACC train:  0.495\t ACC test:  0.5088888888888888\n",
      "\tEpoch 304: \tAverage Loss:  0.97991796875\t ACC train:  0.49\t ACC test:  0.5133333333333333\n",
      "\tEpoch 305: \tAverage Loss:  0.9792534790039062\t ACC train:  0.49\t ACC test:  0.5\n",
      "\tEpoch 306: \tAverage Loss:  0.9785928344726562\t ACC train:  0.495\t ACC test:  0.5066666666666667\n",
      "\tEpoch 307: \tAverage Loss:  0.9788004760742187\t ACC train:  0.49\t ACC test:  0.5133333333333333\n",
      "\tEpoch 308: \tAverage Loss:  0.9780586547851563\t ACC train:  0.51\t ACC test:  0.5155555555555555\n",
      "\tEpoch 309: \tAverage Loss:  0.9779756469726563\t ACC train:  0.51\t ACC test:  0.5133333333333333\n",
      "\tEpoch 310: \tAverage Loss:  0.97769921875\t ACC train:  0.515\t ACC test:  0.5155555555555555\n",
      "\tEpoch 311: \tAverage Loss:  0.9773257446289062\t ACC train:  0.52\t ACC test:  0.52\n",
      "\tEpoch 312: \tAverage Loss:  0.977213623046875\t ACC train:  0.525\t ACC test:  0.5133333333333333\n",
      "\tEpoch 313: \tAverage Loss:  0.976923828125\t ACC train:  0.52\t ACC test:  0.5177777777777778\n",
      "\tEpoch 314: \tAverage Loss:  0.9761484375\t ACC train:  0.525\t ACC test:  0.5155555555555555\n",
      "\tEpoch 315: \tAverage Loss:  0.9760735473632812\t ACC train:  0.51\t ACC test:  0.5088888888888888\n",
      "\tEpoch 316: \tAverage Loss:  0.975858642578125\t ACC train:  0.525\t ACC test:  0.5133333333333333\n",
      "\tEpoch 317: \tAverage Loss:  0.9757498168945312\t ACC train:  0.51\t ACC test:  0.5066666666666667\n",
      "\tEpoch 318: \tAverage Loss:  0.9751160888671875\t ACC train:  0.51\t ACC test:  0.5088888888888888\n",
      "\tEpoch 319: \tAverage Loss:  0.9741965942382812\t ACC train:  0.52\t ACC test:  0.5133333333333333\n",
      "\tEpoch 320: \tAverage Loss:  0.974777587890625\t ACC train:  0.535\t ACC test:  0.5111111111111111\n",
      "\tEpoch 321: \tAverage Loss:  0.9745667724609375\t ACC train:  0.535\t ACC test:  0.5222222222222223\n",
      "\tEpoch 322: \tAverage Loss:  0.9740889892578125\t ACC train:  0.52\t ACC test:  0.5111111111111111\n",
      "\tEpoch 323: \tAverage Loss:  0.973298095703125\t ACC train:  0.515\t ACC test:  0.5155555555555555\n",
      "\tEpoch 324: \tAverage Loss:  0.9730668334960938\t ACC train:  0.51\t ACC test:  0.5111111111111111\n",
      "\tEpoch 325: \tAverage Loss:  0.9729713745117188\t ACC train:  0.53\t ACC test:  0.5133333333333333\n",
      "\tEpoch 326: \tAverage Loss:  0.972257568359375\t ACC train:  0.53\t ACC test:  0.5133333333333333\n",
      "\tEpoch 327: \tAverage Loss:  0.9720989990234375\t ACC train:  0.53\t ACC test:  0.5177777777777778\n",
      "\tEpoch 328: \tAverage Loss:  0.97184619140625\t ACC train:  0.53\t ACC test:  0.5177777777777778\n",
      "\tEpoch 329: \tAverage Loss:  0.9717713012695313\t ACC train:  0.54\t ACC test:  0.52\n",
      "\tEpoch 330: \tAverage Loss:  0.970870361328125\t ACC train:  0.53\t ACC test:  0.52\n",
      "\tEpoch 331: \tAverage Loss:  0.9706034545898438\t ACC train:  0.535\t ACC test:  0.52\n",
      "\tEpoch 332: \tAverage Loss:  0.9704413452148437\t ACC train:  0.53\t ACC test:  0.52\n",
      "\tEpoch 333: \tAverage Loss:  0.9705297241210937\t ACC train:  0.535\t ACC test:  0.5177777777777778\n",
      "\tEpoch 334: \tAverage Loss:  0.9699183959960938\t ACC train:  0.54\t ACC test:  0.5244444444444445\n",
      "\tEpoch 335: \tAverage Loss:  0.96954638671875\t ACC train:  0.545\t ACC test:  0.5222222222222223\n",
      "\tEpoch 336: \tAverage Loss:  0.9691589965820312\t ACC train:  0.54\t ACC test:  0.5266666666666666\n",
      "\tEpoch 337: \tAverage Loss:  0.969500732421875\t ACC train:  0.545\t ACC test:  0.5288888888888889\n",
      "\tEpoch 338: \tAverage Loss:  0.9687525024414062\t ACC train:  0.545\t ACC test:  0.52\n",
      "\tEpoch 339: \tAverage Loss:  0.9685126953125\t ACC train:  0.55\t ACC test:  0.5244444444444445\n",
      "\tEpoch 340: \tAverage Loss:  0.9685277099609375\t ACC train:  0.565\t ACC test:  0.5311111111111111\n",
      "\tEpoch 341: \tAverage Loss:  0.9682554321289063\t ACC train:  0.555\t ACC test:  0.5288888888888889\n",
      "\tEpoch 342: \tAverage Loss:  0.9674515380859375\t ACC train:  0.565\t ACC test:  0.5222222222222223\n",
      "\tEpoch 343: \tAverage Loss:  0.96761767578125\t ACC train:  0.56\t ACC test:  0.5288888888888889\n",
      "\tEpoch 344: \tAverage Loss:  0.9671611938476562\t ACC train:  0.565\t ACC test:  0.5333333333333333\n",
      "\tEpoch 345: \tAverage Loss:  0.9664607543945313\t ACC train:  0.57\t ACC test:  0.54\n",
      "\tEpoch 346: \tAverage Loss:  0.9663745727539063\t ACC train:  0.56\t ACC test:  0.5355555555555556\n",
      "\tEpoch 347: \tAverage Loss:  0.966221435546875\t ACC train:  0.565\t ACC test:  0.5288888888888889\n",
      "\tEpoch 348: \tAverage Loss:  0.9663506469726563\t ACC train:  0.565\t ACC test:  0.5266666666666666\n",
      "\tEpoch 349: \tAverage Loss:  0.9658703002929687\t ACC train:  0.565\t ACC test:  0.5288888888888889\n",
      "\tEpoch 350: \tAverage Loss:  0.9656082153320312\t ACC train:  0.56\t ACC test:  0.5288888888888889\n",
      "\tEpoch 351: \tAverage Loss:  0.965364013671875\t ACC train:  0.57\t ACC test:  0.5377777777777778\n",
      "\tEpoch 352: \tAverage Loss:  0.9649892578125\t ACC train:  0.55\t ACC test:  0.5333333333333333\n",
      "\tEpoch 353: \tAverage Loss:  0.9650155639648438\t ACC train:  0.56\t ACC test:  0.5266666666666666\n",
      "\tEpoch 354: \tAverage Loss:  0.9646965942382812\t ACC train:  0.56\t ACC test:  0.5244444444444445\n",
      "\tEpoch 355: \tAverage Loss:  0.9645331420898438\t ACC train:  0.565\t ACC test:  0.5333333333333333\n",
      "\tEpoch 356: \tAverage Loss:  0.9635834350585938\t ACC train:  0.565\t ACC test:  0.5355555555555556\n",
      "\tEpoch 357: \tAverage Loss:  0.9637408447265625\t ACC train:  0.565\t ACC test:  0.5355555555555556\n",
      "\tEpoch 358: \tAverage Loss:  0.9635814208984375\t ACC train:  0.57\t ACC test:  0.5355555555555556\n",
      "\tEpoch 359: \tAverage Loss:  0.9637393798828126\t ACC train:  0.565\t ACC test:  0.5288888888888889\n",
      "\tEpoch 360: \tAverage Loss:  0.9633660888671876\t ACC train:  0.565\t ACC test:  0.54\n",
      "\tEpoch 361: \tAverage Loss:  0.963285888671875\t ACC train:  0.575\t ACC test:  0.54\n",
      "\tEpoch 362: \tAverage Loss:  0.9627866821289063\t ACC train:  0.57\t ACC test:  0.5466666666666666\n",
      "\tEpoch 363: \tAverage Loss:  0.9624630737304688\t ACC train:  0.565\t ACC test:  0.5444444444444444\n",
      "\tEpoch 364: \tAverage Loss:  0.962255859375\t ACC train:  0.565\t ACC test:  0.5377777777777778\n",
      "\tEpoch 365: \tAverage Loss:  0.961935546875\t ACC train:  0.57\t ACC test:  0.54\n",
      "\tEpoch 366: \tAverage Loss:  0.9617164306640625\t ACC train:  0.57\t ACC test:  0.5511111111111111\n",
      "\tEpoch 367: \tAverage Loss:  0.9610299682617187\t ACC train:  0.575\t ACC test:  0.5488888888888889\n",
      "\tEpoch 368: \tAverage Loss:  0.9610502319335937\t ACC train:  0.585\t ACC test:  0.5511111111111111\n",
      "\tEpoch 369: \tAverage Loss:  0.9610408935546875\t ACC train:  0.57\t ACC test:  0.5511111111111111\n",
      "\tEpoch 370: \tAverage Loss:  0.9605909423828125\t ACC train:  0.575\t ACC test:  0.5466666666666666\n",
      "\tEpoch 371: \tAverage Loss:  0.9602560424804687\t ACC train:  0.575\t ACC test:  0.5488888888888889\n",
      "\tEpoch 372: \tAverage Loss:  0.9599591674804687\t ACC train:  0.57\t ACC test:  0.5555555555555556\n",
      "\tEpoch 373: \tAverage Loss:  0.9599873657226563\t ACC train:  0.585\t ACC test:  0.56\n",
      "\tEpoch 374: \tAverage Loss:  0.95971826171875\t ACC train:  0.595\t ACC test:  0.5644444444444444\n",
      "\tEpoch 375: \tAverage Loss:  0.9595413208007812\t ACC train:  0.59\t ACC test:  0.5666666666666667\n",
      "\tEpoch 376: \tAverage Loss:  0.9594285888671875\t ACC train:  0.59\t ACC test:  0.56\n",
      "\tEpoch 377: \tAverage Loss:  0.9589296875\t ACC train:  0.6\t ACC test:  0.5666666666666667\n",
      "\tEpoch 378: \tAverage Loss:  0.9588667602539063\t ACC train:  0.6\t ACC test:  0.5711111111111111\n",
      "\tEpoch 379: \tAverage Loss:  0.9586719970703125\t ACC train:  0.6\t ACC test:  0.5688888888888889\n",
      "\tEpoch 380: \tAverage Loss:  0.9586924438476563\t ACC train:  0.6\t ACC test:  0.5711111111111111\n",
      "\tEpoch 381: \tAverage Loss:  0.9581849365234375\t ACC train:  0.61\t ACC test:  0.5711111111111111\n",
      "\tEpoch 382: \tAverage Loss:  0.9578538818359374\t ACC train:  0.61\t ACC test:  0.5777777777777777\n",
      "\tEpoch 383: \tAverage Loss:  0.9579039306640625\t ACC train:  0.615\t ACC test:  0.5777777777777777\n",
      "\tEpoch 384: \tAverage Loss:  0.9572384643554688\t ACC train:  0.615\t ACC test:  0.58\n",
      "\tEpoch 385: \tAverage Loss:  0.95743408203125\t ACC train:  0.625\t ACC test:  0.5755555555555556\n",
      "\tEpoch 386: \tAverage Loss:  0.95701904296875\t ACC train:  0.625\t ACC test:  0.5733333333333334\n",
      "\tEpoch 387: \tAverage Loss:  0.9565928955078125\t ACC train:  0.62\t ACC test:  0.58\n",
      "\tEpoch 388: \tAverage Loss:  0.956361083984375\t ACC train:  0.625\t ACC test:  0.58\n",
      "\tEpoch 389: \tAverage Loss:  0.9565377197265625\t ACC train:  0.62\t ACC test:  0.5822222222222222\n",
      "\tEpoch 390: \tAverage Loss:  0.9559859008789062\t ACC train:  0.615\t ACC test:  0.58\n",
      "\tEpoch 391: \tAverage Loss:  0.9558534545898437\t ACC train:  0.62\t ACC test:  0.5711111111111111\n",
      "\tEpoch 392: \tAverage Loss:  0.9557180786132813\t ACC train:  0.62\t ACC test:  0.5822222222222222\n",
      "\tEpoch 393: \tAverage Loss:  0.9554364013671875\t ACC train:  0.625\t ACC test:  0.5755555555555556\n",
      "\tEpoch 394: \tAverage Loss:  0.9550088500976562\t ACC train:  0.63\t ACC test:  0.5844444444444444\n",
      "\tEpoch 395: \tAverage Loss:  0.9547354736328125\t ACC train:  0.635\t ACC test:  0.58\n",
      "\tEpoch 396: \tAverage Loss:  0.9546309204101563\t ACC train:  0.635\t ACC test:  0.5866666666666667\n",
      "\tEpoch 397: \tAverage Loss:  0.9546454467773438\t ACC train:  0.645\t ACC test:  0.5844444444444444\n",
      "\tEpoch 398: \tAverage Loss:  0.954240234375\t ACC train:  0.645\t ACC test:  0.5888888888888889\n",
      "\tEpoch 399: \tAverage Loss:  0.954368896484375\t ACC train:  0.65\t ACC test:  0.5888888888888889\n",
      "\tEpoch 400: \tAverage Loss:  0.9540134887695313\t ACC train:  0.635\t ACC test:  0.5844444444444444\n",
      "\tEpoch 401: \tAverage Loss:  0.9540667724609375\t ACC train:  0.635\t ACC test:  0.5955555555555555\n",
      "\tEpoch 402: \tAverage Loss:  0.9532977905273438\t ACC train:  0.64\t ACC test:  0.58\n",
      "\tEpoch 403: \tAverage Loss:  0.9534530639648438\t ACC train:  0.64\t ACC test:  0.5822222222222222\n",
      "\tEpoch 404: \tAverage Loss:  0.953291015625\t ACC train:  0.635\t ACC test:  0.5844444444444444\n",
      "\tEpoch 405: \tAverage Loss:  0.9528718872070312\t ACC train:  0.64\t ACC test:  0.5888888888888889\n",
      "\tEpoch 406: \tAverage Loss:  0.9524267578125\t ACC train:  0.645\t ACC test:  0.5844444444444444\n",
      "\tEpoch 407: \tAverage Loss:  0.9527172241210937\t ACC train:  0.635\t ACC test:  0.5933333333333334\n",
      "\tEpoch 408: \tAverage Loss:  0.9523845825195313\t ACC train:  0.64\t ACC test:  0.5888888888888889\n",
      "\tEpoch 409: \tAverage Loss:  0.9518634643554688\t ACC train:  0.64\t ACC test:  0.5866666666666667\n",
      "\tEpoch 410: \tAverage Loss:  0.9518810424804688\t ACC train:  0.65\t ACC test:  0.5888888888888889\n",
      "\tEpoch 411: \tAverage Loss:  0.9515852661132812\t ACC train:  0.64\t ACC test:  0.5933333333333334\n",
      "\tEpoch 412: \tAverage Loss:  0.9513538818359375\t ACC train:  0.64\t ACC test:  0.5955555555555555\n",
      "\tEpoch 413: \tAverage Loss:  0.951105712890625\t ACC train:  0.645\t ACC test:  0.6022222222222222\n",
      "\tEpoch 414: \tAverage Loss:  0.9508783569335938\t ACC train:  0.635\t ACC test:  0.5866666666666667\n",
      "\tEpoch 415: \tAverage Loss:  0.950478515625\t ACC train:  0.645\t ACC test:  0.5911111111111111\n",
      "\tEpoch 416: \tAverage Loss:  0.95069189453125\t ACC train:  0.64\t ACC test:  0.5955555555555555\n",
      "\tEpoch 417: \tAverage Loss:  0.9502977905273438\t ACC train:  0.64\t ACC test:  0.6066666666666667\n",
      "\tEpoch 418: \tAverage Loss:  0.949887939453125\t ACC train:  0.645\t ACC test:  0.5977777777777777\n",
      "\tEpoch 419: \tAverage Loss:  0.9499707641601562\t ACC train:  0.645\t ACC test:  0.5977777777777777\n",
      "\tEpoch 420: \tAverage Loss:  0.9497109985351563\t ACC train:  0.64\t ACC test:  0.5933333333333334\n",
      "\tEpoch 421: \tAverage Loss:  0.9495093994140625\t ACC train:  0.64\t ACC test:  0.6022222222222222\n",
      "\tEpoch 422: \tAverage Loss:  0.9495264892578125\t ACC train:  0.65\t ACC test:  0.6044444444444445\n",
      "\tEpoch 423: \tAverage Loss:  0.9493240356445313\t ACC train:  0.65\t ACC test:  0.5977777777777777\n",
      "\tEpoch 424: \tAverage Loss:  0.9493062133789063\t ACC train:  0.645\t ACC test:  0.5955555555555555\n",
      "\tEpoch 425: \tAverage Loss:  0.9486400756835938\t ACC train:  0.65\t ACC test:  0.5977777777777777\n",
      "\tEpoch 426: \tAverage Loss:  0.9484395141601563\t ACC train:  0.645\t ACC test:  0.6044444444444445\n",
      "\tEpoch 427: \tAverage Loss:  0.9483790893554688\t ACC train:  0.645\t ACC test:  0.5955555555555555\n",
      "\tEpoch 428: \tAverage Loss:  0.947932373046875\t ACC train:  0.655\t ACC test:  0.6044444444444445\n",
      "\tEpoch 429: \tAverage Loss:  0.9475884399414063\t ACC train:  0.645\t ACC test:  0.6044444444444445\n",
      "\tEpoch 430: \tAverage Loss:  0.9474376831054687\t ACC train:  0.65\t ACC test:  0.6\n",
      "\tEpoch 431: \tAverage Loss:  0.9473219604492188\t ACC train:  0.655\t ACC test:  0.6\n",
      "\tEpoch 432: \tAverage Loss:  0.9468894653320312\t ACC train:  0.645\t ACC test:  0.6088888888888889\n",
      "\tEpoch 433: \tAverage Loss:  0.9468593139648438\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 434: \tAverage Loss:  0.9465751342773437\t ACC train:  0.65\t ACC test:  0.6\n",
      "\tEpoch 435: \tAverage Loss:  0.9464867553710937\t ACC train:  0.645\t ACC test:  0.6066666666666667\n",
      "\tEpoch 436: \tAverage Loss:  0.9461665649414063\t ACC train:  0.65\t ACC test:  0.6022222222222222\n",
      "\tEpoch 437: \tAverage Loss:  0.9460313720703125\t ACC train:  0.65\t ACC test:  0.6066666666666667\n",
      "\tEpoch 438: \tAverage Loss:  0.946140380859375\t ACC train:  0.65\t ACC test:  0.6\n",
      "\tEpoch 439: \tAverage Loss:  0.94572314453125\t ACC train:  0.65\t ACC test:  0.6088888888888889\n",
      "\tEpoch 440: \tAverage Loss:  0.94555029296875\t ACC train:  0.655\t ACC test:  0.6066666666666667\n",
      "\tEpoch 441: \tAverage Loss:  0.9458369140625\t ACC train:  0.655\t ACC test:  0.6044444444444445\n",
      "\tEpoch 442: \tAverage Loss:  0.9449945068359376\t ACC train:  0.65\t ACC test:  0.5977777777777777\n",
      "\tEpoch 443: \tAverage Loss:  0.9449164428710938\t ACC train:  0.655\t ACC test:  0.6044444444444445\n",
      "\tEpoch 444: \tAverage Loss:  0.945066162109375\t ACC train:  0.655\t ACC test:  0.6133333333333333\n",
      "\tEpoch 445: \tAverage Loss:  0.94491943359375\t ACC train:  0.65\t ACC test:  0.6111111111111112\n",
      "\tEpoch 446: \tAverage Loss:  0.9443336181640625\t ACC train:  0.66\t ACC test:  0.6066666666666667\n",
      "\tEpoch 447: \tAverage Loss:  0.9448130493164062\t ACC train:  0.65\t ACC test:  0.6088888888888889\n",
      "\tEpoch 448: \tAverage Loss:  0.9441604614257812\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 449: \tAverage Loss:  0.9433486328125\t ACC train:  0.66\t ACC test:  0.6111111111111112\n",
      "\tEpoch 450: \tAverage Loss:  0.9434793701171875\t ACC train:  0.655\t ACC test:  0.6133333333333333\n",
      "\tEpoch 451: \tAverage Loss:  0.9444570922851563\t ACC train:  0.65\t ACC test:  0.6044444444444445\n",
      "\tEpoch 452: \tAverage Loss:  0.9427969360351562\t ACC train:  0.655\t ACC test:  0.6155555555555555\n",
      "\tEpoch 453: \tAverage Loss:  0.9426707763671875\t ACC train:  0.66\t ACC test:  0.6222222222222222\n",
      "\tEpoch 454: \tAverage Loss:  0.9432986450195312\t ACC train:  0.65\t ACC test:  0.6177777777777778\n",
      "\tEpoch 455: \tAverage Loss:  0.9421761474609375\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 456: \tAverage Loss:  0.94263427734375\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 457: \tAverage Loss:  0.9419937744140625\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 458: \tAverage Loss:  0.9422177124023438\t ACC train:  0.665\t ACC test:  0.6177777777777778\n",
      "\tEpoch 459: \tAverage Loss:  0.9414901123046875\t ACC train:  0.65\t ACC test:  0.62\n",
      "\tEpoch 460: \tAverage Loss:  0.9413695678710937\t ACC train:  0.655\t ACC test:  0.6066666666666667\n",
      "\tEpoch 461: \tAverage Loss:  0.9414068603515625\t ACC train:  0.66\t ACC test:  0.6133333333333333\n",
      "\tEpoch 462: \tAverage Loss:  0.9408458862304687\t ACC train:  0.675\t ACC test:  0.6133333333333333\n",
      "\tEpoch 463: \tAverage Loss:  0.940619384765625\t ACC train:  0.66\t ACC test:  0.6133333333333333\n",
      "\tEpoch 464: \tAverage Loss:  0.940475830078125\t ACC train:  0.66\t ACC test:  0.6111111111111112\n",
      "\tEpoch 465: \tAverage Loss:  0.940258544921875\t ACC train:  0.665\t ACC test:  0.6155555555555555\n",
      "\tEpoch 466: \tAverage Loss:  0.9402494506835938\t ACC train:  0.67\t ACC test:  0.62\n",
      "\tEpoch 467: \tAverage Loss:  0.9394094848632812\t ACC train:  0.665\t ACC test:  0.6288888888888889\n",
      "\tEpoch 468: \tAverage Loss:  0.9396534423828125\t ACC train:  0.665\t ACC test:  0.6333333333333333\n",
      "\tEpoch 469: \tAverage Loss:  0.9392903442382813\t ACC train:  0.66\t ACC test:  0.6222222222222222\n",
      "\tEpoch 470: \tAverage Loss:  0.9390748901367187\t ACC train:  0.665\t ACC test:  0.6222222222222222\n",
      "\tEpoch 471: \tAverage Loss:  0.9389561767578125\t ACC train:  0.66\t ACC test:  0.6155555555555555\n",
      "\tEpoch 472: \tAverage Loss:  0.9382162475585938\t ACC train:  0.66\t ACC test:  0.6244444444444445\n",
      "\tEpoch 473: \tAverage Loss:  0.9383710327148438\t ACC train:  0.665\t ACC test:  0.6266666666666667\n",
      "\tEpoch 474: \tAverage Loss:  0.937820556640625\t ACC train:  0.655\t ACC test:  0.6133333333333333\n",
      "\tEpoch 475: \tAverage Loss:  0.9379880981445312\t ACC train:  0.655\t ACC test:  0.6133333333333333\n",
      "\tEpoch 476: \tAverage Loss:  0.9374756469726563\t ACC train:  0.67\t ACC test:  0.6266666666666667\n",
      "\tEpoch 477: \tAverage Loss:  0.9373563232421875\t ACC train:  0.67\t ACC test:  0.6288888888888889\n",
      "\tEpoch 478: \tAverage Loss:  0.936716552734375\t ACC train:  0.67\t ACC test:  0.6288888888888889\n",
      "\tEpoch 479: \tAverage Loss:  0.936560546875\t ACC train:  0.675\t ACC test:  0.6266666666666667\n",
      "\tEpoch 480: \tAverage Loss:  0.93695068359375\t ACC train:  0.67\t ACC test:  0.6266666666666667\n",
      "\tEpoch 481: \tAverage Loss:  0.9361231079101563\t ACC train:  0.67\t ACC test:  0.6355555555555555\n",
      "\tEpoch 482: \tAverage Loss:  0.9359270629882812\t ACC train:  0.67\t ACC test:  0.6311111111111111\n",
      "\tEpoch 483: \tAverage Loss:  0.936136962890625\t ACC train:  0.67\t ACC test:  0.6288888888888889\n",
      "\tEpoch 484: \tAverage Loss:  0.9355149536132813\t ACC train:  0.665\t ACC test:  0.6266666666666667\n",
      "\tEpoch 485: \tAverage Loss:  0.9354393920898437\t ACC train:  0.675\t ACC test:  0.64\n",
      "\tEpoch 486: \tAverage Loss:  0.9353433837890625\t ACC train:  0.675\t ACC test:  0.6355555555555555\n",
      "\tEpoch 487: \tAverage Loss:  0.9346337890625\t ACC train:  0.67\t ACC test:  0.6377777777777778\n",
      "\tEpoch 488: \tAverage Loss:  0.9346161499023438\t ACC train:  0.665\t ACC test:  0.6355555555555555\n",
      "\tEpoch 489: \tAverage Loss:  0.9344777221679688\t ACC train:  0.675\t ACC test:  0.64\n",
      "\tEpoch 490: \tAverage Loss:  0.9338720703125\t ACC train:  0.67\t ACC test:  0.6377777777777778\n",
      "\tEpoch 491: \tAverage Loss:  0.9338343505859374\t ACC train:  0.675\t ACC test:  0.6355555555555555\n",
      "\tEpoch 492: \tAverage Loss:  0.9337999267578125\t ACC train:  0.675\t ACC test:  0.6444444444444445\n",
      "\tEpoch 493: \tAverage Loss:  0.9332581787109375\t ACC train:  0.67\t ACC test:  0.6377777777777778\n",
      "\tEpoch 494: \tAverage Loss:  0.9330714111328124\t ACC train:  0.675\t ACC test:  0.6333333333333333\n",
      "\tEpoch 495: \tAverage Loss:  0.932939208984375\t ACC train:  0.68\t ACC test:  0.6333333333333333\n",
      "\tEpoch 496: \tAverage Loss:  0.9331266479492187\t ACC train:  0.685\t ACC test:  0.6355555555555555\n",
      "\tEpoch 497: \tAverage Loss:  0.93235205078125\t ACC train:  0.68\t ACC test:  0.64\n",
      "\tEpoch 498: \tAverage Loss:  0.9320297241210938\t ACC train:  0.68\t ACC test:  0.6377777777777778\n",
      "\tEpoch 499: \tAverage Loss:  0.9320618286132812\t ACC train:  0.67\t ACC test:  0.6377777777777778\n",
      "\tEpoch 500: \tAverage Loss:  0.9312777709960938\t ACC train:  0.69\t ACC test:  0.6333333333333333\n",
      "\tEpoch 501: \tAverage Loss:  0.9315923461914063\t ACC train:  0.68\t ACC test:  0.64\n",
      "\tEpoch 502: \tAverage Loss:  0.9312933959960937\t ACC train:  0.68\t ACC test:  0.64\n",
      "\tEpoch 503: \tAverage Loss:  0.930571044921875\t ACC train:  0.68\t ACC test:  0.6422222222222222\n",
      "\tEpoch 504: \tAverage Loss:  0.9300697631835938\t ACC train:  0.685\t ACC test:  0.6422222222222222\n",
      "\tEpoch 505: \tAverage Loss:  0.9303395385742188\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 506: \tAverage Loss:  0.9299256591796875\t ACC train:  0.685\t ACC test:  0.64\n",
      "\tEpoch 507: \tAverage Loss:  0.9294429931640625\t ACC train:  0.69\t ACC test:  0.6466666666666666\n",
      "\tEpoch 508: \tAverage Loss:  0.92956103515625\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 509: \tAverage Loss:  0.9294402465820313\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 510: \tAverage Loss:  0.928687744140625\t ACC train:  0.69\t ACC test:  0.6488888888888888\n",
      "\tEpoch 511: \tAverage Loss:  0.9286524658203125\t ACC train:  0.69\t ACC test:  0.6422222222222222\n",
      "\tEpoch 512: \tAverage Loss:  0.9294108276367188\t ACC train:  0.69\t ACC test:  0.6377777777777778\n",
      "\tEpoch 513: \tAverage Loss:  0.9278272094726563\t ACC train:  0.69\t ACC test:  0.6466666666666666\n",
      "\tEpoch 514: \tAverage Loss:  0.9284313354492187\t ACC train:  0.69\t ACC test:  0.64\n",
      "\tEpoch 515: \tAverage Loss:  0.9287166748046874\t ACC train:  0.69\t ACC test:  0.6422222222222222\n",
      "\tEpoch 516: \tAverage Loss:  0.9269566650390625\t ACC train:  0.685\t ACC test:  0.6422222222222222\n",
      "\tEpoch 517: \tAverage Loss:  0.92668994140625\t ACC train:  0.685\t ACC test:  0.6422222222222222\n",
      "\tEpoch 518: \tAverage Loss:  0.9269055786132813\t ACC train:  0.69\t ACC test:  0.6466666666666666\n",
      "\tEpoch 519: \tAverage Loss:  0.9267962036132813\t ACC train:  0.69\t ACC test:  0.6466666666666666\n",
      "\tEpoch 520: \tAverage Loss:  0.925762939453125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 521: \tAverage Loss:  0.9256455688476563\t ACC train:  0.68\t ACC test:  0.6422222222222222\n",
      "\tEpoch 522: \tAverage Loss:  0.9264456787109375\t ACC train:  0.69\t ACC test:  0.6533333333333333\n",
      "\tEpoch 523: \tAverage Loss:  0.9251346435546876\t ACC train:  0.725\t ACC test:  0.6688888888888889\n",
      "\tEpoch 524: \tAverage Loss:  0.9250285034179687\t ACC train:  0.725\t ACC test:  0.6777777777777778\n",
      "\tEpoch 525: \tAverage Loss:  0.9248336791992188\t ACC train:  0.72\t ACC test:  0.7066666666666667\n",
      "\tEpoch 526: \tAverage Loss:  0.92417919921875\t ACC train:  0.74\t ACC test:  0.7222222222222222\n",
      "\tEpoch 527: \tAverage Loss:  0.9242218017578125\t ACC train:  0.74\t ACC test:  0.7244444444444444\n",
      "\tEpoch 528: \tAverage Loss:  0.92397119140625\t ACC train:  0.755\t ACC test:  0.74\n",
      "\tEpoch 529: \tAverage Loss:  0.9239124145507812\t ACC train:  0.755\t ACC test:  0.7466666666666667\n",
      "\tEpoch 530: \tAverage Loss:  0.9236236572265625\t ACC train:  0.77\t ACC test:  0.7466666666666667\n",
      "\tEpoch 531: \tAverage Loss:  0.9227947998046875\t ACC train:  0.775\t ACC test:  0.7466666666666667\n",
      "\tEpoch 532: \tAverage Loss:  0.9226655883789062\t ACC train:  0.785\t ACC test:  0.7444444444444445\n",
      "\tEpoch 533: \tAverage Loss:  0.9217774658203125\t ACC train:  0.78\t ACC test:  0.7555555555555555\n",
      "\tEpoch 534: \tAverage Loss:  0.9221124877929687\t ACC train:  0.78\t ACC test:  0.7577777777777778\n",
      "\tEpoch 535: \tAverage Loss:  0.9217206420898437\t ACC train:  0.785\t ACC test:  0.7555555555555555\n",
      "\tEpoch 536: \tAverage Loss:  0.9212530517578125\t ACC train:  0.785\t ACC test:  0.7533333333333333\n",
      "\tEpoch 537: \tAverage Loss:  0.9209348754882812\t ACC train:  0.785\t ACC test:  0.7622222222222222\n",
      "\tEpoch 538: \tAverage Loss:  0.92101123046875\t ACC train:  0.78\t ACC test:  0.7644444444444445\n",
      "\tEpoch 539: \tAverage Loss:  0.9203422241210938\t ACC train:  0.805\t ACC test:  0.7755555555555556\n",
      "\tEpoch 540: \tAverage Loss:  0.9201314697265625\t ACC train:  0.815\t ACC test:  0.7844444444444445\n",
      "\tEpoch 541: \tAverage Loss:  0.9201502075195312\t ACC train:  0.81\t ACC test:  0.7866666666666666\n",
      "\tEpoch 542: \tAverage Loss:  0.9197607421875\t ACC train:  0.82\t ACC test:  0.7977777777777778\n",
      "\tEpoch 543: \tAverage Loss:  0.9191646118164063\t ACC train:  0.82\t ACC test:  0.7933333333333333\n",
      "\tEpoch 544: \tAverage Loss:  0.9190225830078125\t ACC train:  0.815\t ACC test:  0.7955555555555556\n",
      "\tEpoch 545: \tAverage Loss:  0.9187882690429687\t ACC train:  0.83\t ACC test:  0.7955555555555556\n",
      "\tEpoch 546: \tAverage Loss:  0.9184037475585938\t ACC train:  0.825\t ACC test:  0.8\n",
      "\tEpoch 547: \tAverage Loss:  0.9182186279296874\t ACC train:  0.83\t ACC test:  0.7977777777777778\n",
      "\tEpoch 548: \tAverage Loss:  0.9175231323242188\t ACC train:  0.835\t ACC test:  0.8066666666666666\n",
      "\tEpoch 549: \tAverage Loss:  0.9175116577148438\t ACC train:  0.835\t ACC test:  0.8066666666666666\n",
      "\tEpoch 550: \tAverage Loss:  0.9169829711914063\t ACC train:  0.84\t ACC test:  0.7911111111111111\n",
      "\tEpoch 551: \tAverage Loss:  0.917327392578125\t ACC train:  0.835\t ACC test:  0.8111111111111111\n",
      "\tEpoch 552: \tAverage Loss:  0.9163599853515625\t ACC train:  0.835\t ACC test:  0.8088888888888889\n",
      "\tEpoch 553: \tAverage Loss:  0.916087646484375\t ACC train:  0.84\t ACC test:  0.8088888888888889\n",
      "\tEpoch 554: \tAverage Loss:  0.9159039916992188\t ACC train:  0.855\t ACC test:  0.8066666666666666\n",
      "\tEpoch 555: \tAverage Loss:  0.9152992553710938\t ACC train:  0.845\t ACC test:  0.8066666666666666\n",
      "\tEpoch 556: \tAverage Loss:  0.9150196533203125\t ACC train:  0.835\t ACC test:  0.8111111111111111\n",
      "\tEpoch 557: \tAverage Loss:  0.91468310546875\t ACC train:  0.835\t ACC test:  0.8155555555555556\n",
      "\tEpoch 558: \tAverage Loss:  0.9148821411132813\t ACC train:  0.855\t ACC test:  0.82\n",
      "\tEpoch 559: \tAverage Loss:  0.9141619873046875\t ACC train:  0.86\t ACC test:  0.8133333333333334\n",
      "\tEpoch 560: \tAverage Loss:  0.91394921875\t ACC train:  0.87\t ACC test:  0.8177777777777778\n",
      "\tEpoch 561: \tAverage Loss:  0.9136114501953125\t ACC train:  0.86\t ACC test:  0.8133333333333334\n",
      "\tEpoch 562: \tAverage Loss:  0.9132501220703125\t ACC train:  0.86\t ACC test:  0.8111111111111111\n",
      "\tEpoch 563: \tAverage Loss:  0.9131925048828125\t ACC train:  0.855\t ACC test:  0.82\n",
      "\tEpoch 564: \tAverage Loss:  0.9126859130859375\t ACC train:  0.865\t ACC test:  0.8177777777777778\n",
      "\tEpoch 565: \tAverage Loss:  0.9126007690429687\t ACC train:  0.87\t ACC test:  0.8066666666666666\n",
      "\tEpoch 566: \tAverage Loss:  0.9119581298828126\t ACC train:  0.865\t ACC test:  0.8155555555555556\n",
      "\tEpoch 567: \tAverage Loss:  0.9120896606445312\t ACC train:  0.855\t ACC test:  0.82\n",
      "\tEpoch 568: \tAverage Loss:  0.9114754028320312\t ACC train:  0.875\t ACC test:  0.8244444444444444\n",
      "\tEpoch 569: \tAverage Loss:  0.910875732421875\t ACC train:  0.87\t ACC test:  0.82\n",
      "\tEpoch 570: \tAverage Loss:  0.9106470947265625\t ACC train:  0.865\t ACC test:  0.8155555555555556\n",
      "\tEpoch 571: \tAverage Loss:  0.910579345703125\t ACC train:  0.865\t ACC test:  0.8244444444444444\n",
      "\tEpoch 572: \tAverage Loss:  0.9099977416992188\t ACC train:  0.865\t ACC test:  0.8222222222222222\n",
      "\tEpoch 573: \tAverage Loss:  0.909278076171875\t ACC train:  0.875\t ACC test:  0.8288888888888889\n",
      "\tEpoch 574: \tAverage Loss:  0.9100907592773437\t ACC train:  0.87\t ACC test:  0.8288888888888889\n",
      "\tEpoch 575: \tAverage Loss:  0.908687744140625\t ACC train:  0.88\t ACC test:  0.8333333333333334\n",
      "\tEpoch 576: \tAverage Loss:  0.9087351684570313\t ACC train:  0.875\t ACC test:  0.8266666666666667\n",
      "\tEpoch 577: \tAverage Loss:  0.9083133544921875\t ACC train:  0.87\t ACC test:  0.8333333333333334\n",
      "\tEpoch 578: \tAverage Loss:  0.9085121459960938\t ACC train:  0.875\t ACC test:  0.8377777777777777\n",
      "\tEpoch 579: \tAverage Loss:  0.9079326171875\t ACC train:  0.885\t ACC test:  0.84\n",
      "\tEpoch 580: \tAverage Loss:  0.9075833129882812\t ACC train:  0.88\t ACC test:  0.8422222222222222\n",
      "\tEpoch 581: \tAverage Loss:  0.9068047485351562\t ACC train:  0.885\t ACC test:  0.8333333333333334\n",
      "\tEpoch 582: \tAverage Loss:  0.90806494140625\t ACC train:  0.885\t ACC test:  0.84\n",
      "\tEpoch 583: \tAverage Loss:  0.9062354125976563\t ACC train:  0.875\t ACC test:  0.8311111111111111\n",
      "\tEpoch 584: \tAverage Loss:  0.9081043090820312\t ACC train:  0.88\t ACC test:  0.8377777777777777\n",
      "\tEpoch 585: \tAverage Loss:  0.9067357788085938\t ACC train:  0.885\t ACC test:  0.8355555555555556\n",
      "\tEpoch 586: \tAverage Loss:  0.9058506469726563\t ACC train:  0.89\t ACC test:  0.84\n",
      "\tEpoch 587: \tAverage Loss:  0.905048828125\t ACC train:  0.865\t ACC test:  0.8311111111111111\n",
      "\tEpoch 588: \tAverage Loss:  0.9058584594726562\t ACC train:  0.89\t ACC test:  0.84\n",
      "\tEpoch 589: \tAverage Loss:  0.9061461791992188\t ACC train:  0.89\t ACC test:  0.84\n",
      "\tEpoch 590: \tAverage Loss:  0.9044946899414062\t ACC train:  0.88\t ACC test:  0.8422222222222222\n",
      "\tEpoch 591: \tAverage Loss:  0.90431982421875\t ACC train:  0.875\t ACC test:  0.8377777777777777\n",
      "\tEpoch 592: \tAverage Loss:  0.9034156494140625\t ACC train:  0.89\t ACC test:  0.8533333333333334\n",
      "\tEpoch 593: \tAverage Loss:  0.903339111328125\t ACC train:  0.89\t ACC test:  0.8444444444444444\n",
      "\tEpoch 594: \tAverage Loss:  0.9028936767578125\t ACC train:  0.89\t ACC test:  0.8511111111111112\n",
      "\tEpoch 595: \tAverage Loss:  0.9030667114257812\t ACC train:  0.9\t ACC test:  0.8444444444444444\n",
      "\tEpoch 596: \tAverage Loss:  0.9022686767578125\t ACC train:  0.895\t ACC test:  0.8444444444444444\n",
      "\tEpoch 597: \tAverage Loss:  0.9015823364257812\t ACC train:  0.895\t ACC test:  0.8466666666666667\n",
      "\tEpoch 598: \tAverage Loss:  0.901764892578125\t ACC train:  0.895\t ACC test:  0.8466666666666667\n",
      "\tEpoch 599: \tAverage Loss:  0.9014263305664062\t ACC train:  0.895\t ACC test:  0.8466666666666667\n",
      "\tEpoch 600: \tAverage Loss:  0.9014017333984375\t ACC train:  0.895\t ACC test:  0.8444444444444444\n",
      "\tEpoch 601: \tAverage Loss:  0.9005150146484375\t ACC train:  0.89\t ACC test:  0.8533333333333334\n",
      "\tEpoch 602: \tAverage Loss:  0.9005059814453125\t ACC train:  0.895\t ACC test:  0.8466666666666667\n",
      "\tEpoch 603: \tAverage Loss:  0.900134033203125\t ACC train:  0.9\t ACC test:  0.8511111111111112\n",
      "\tEpoch 604: \tAverage Loss:  0.8990956420898437\t ACC train:  0.9\t ACC test:  0.8555555555555555\n",
      "\tEpoch 605: \tAverage Loss:  0.8992384033203125\t ACC train:  0.895\t ACC test:  0.8555555555555555\n",
      "\tEpoch 606: \tAverage Loss:  0.8987901611328125\t ACC train:  0.89\t ACC test:  0.8422222222222222\n",
      "\tEpoch 607: \tAverage Loss:  0.8987307739257813\t ACC train:  0.895\t ACC test:  0.8466666666666667\n",
      "\tEpoch 608: \tAverage Loss:  0.8986063232421875\t ACC train:  0.895\t ACC test:  0.8422222222222222\n",
      "\tEpoch 609: \tAverage Loss:  0.8977355346679687\t ACC train:  0.895\t ACC test:  0.8511111111111112\n",
      "\tEpoch 610: \tAverage Loss:  0.8977779541015625\t ACC train:  0.9\t ACC test:  0.8533333333333334\n",
      "\tEpoch 611: \tAverage Loss:  0.8973881225585938\t ACC train:  0.895\t ACC test:  0.8511111111111112\n",
      "\tEpoch 612: \tAverage Loss:  0.8969791259765625\t ACC train:  0.895\t ACC test:  0.8533333333333334\n",
      "\tEpoch 613: \tAverage Loss:  0.8969043579101562\t ACC train:  0.895\t ACC test:  0.8644444444444445\n",
      "\tEpoch 614: \tAverage Loss:  0.8961504516601563\t ACC train:  0.9\t ACC test:  0.8577777777777778\n",
      "\tEpoch 615: \tAverage Loss:  0.89599267578125\t ACC train:  0.895\t ACC test:  0.8577777777777778\n",
      "\tEpoch 616: \tAverage Loss:  0.895767333984375\t ACC train:  0.915\t ACC test:  0.8644444444444445\n",
      "\tEpoch 617: \tAverage Loss:  0.8953781127929688\t ACC train:  0.91\t ACC test:  0.8622222222222222\n",
      "\tEpoch 618: \tAverage Loss:  0.8951619262695313\t ACC train:  0.9\t ACC test:  0.86\n",
      "\tEpoch 619: \tAverage Loss:  0.8945068969726563\t ACC train:  0.9\t ACC test:  0.8622222222222222\n",
      "\tEpoch 620: \tAverage Loss:  0.894266357421875\t ACC train:  0.895\t ACC test:  0.8577777777777778\n",
      "\tEpoch 621: \tAverage Loss:  0.8939547119140625\t ACC train:  0.895\t ACC test:  0.8555555555555555\n",
      "\tEpoch 622: \tAverage Loss:  0.895087158203125\t ACC train:  0.89\t ACC test:  0.8622222222222222\n",
      "\tEpoch 623: \tAverage Loss:  0.8932151489257812\t ACC train:  0.895\t ACC test:  0.8622222222222222\n",
      "\tEpoch 624: \tAverage Loss:  0.893109375\t ACC train:  0.895\t ACC test:  0.8577777777777778\n",
      "\tEpoch 625: \tAverage Loss:  0.893199951171875\t ACC train:  0.9\t ACC test:  0.8577777777777778\n",
      "\tEpoch 626: \tAverage Loss:  0.892320556640625\t ACC train:  0.9\t ACC test:  0.8622222222222222\n",
      "\tEpoch 627: \tAverage Loss:  0.8920721435546874\t ACC train:  0.905\t ACC test:  0.8622222222222222\n",
      "\tEpoch 628: \tAverage Loss:  0.8919317626953125\t ACC train:  0.9\t ACC test:  0.8644444444444445\n",
      "\tEpoch 629: \tAverage Loss:  0.8914208984375\t ACC train:  0.91\t ACC test:  0.86\n",
      "\tEpoch 630: \tAverage Loss:  0.891392578125\t ACC train:  0.91\t ACC test:  0.8644444444444445\n",
      "\tEpoch 631: \tAverage Loss:  0.8907952880859376\t ACC train:  0.91\t ACC test:  0.8666666666666667\n",
      "\tEpoch 632: \tAverage Loss:  0.89100830078125\t ACC train:  0.915\t ACC test:  0.8711111111111111\n",
      "\tEpoch 633: \tAverage Loss:  0.8904163818359375\t ACC train:  0.905\t ACC test:  0.8622222222222222\n",
      "\tEpoch 634: \tAverage Loss:  0.88939990234375\t ACC train:  0.9\t ACC test:  0.8644444444444445\n",
      "\tEpoch 635: \tAverage Loss:  0.8896052856445312\t ACC train:  0.905\t ACC test:  0.8622222222222222\n",
      "\tEpoch 636: \tAverage Loss:  0.8893552856445313\t ACC train:  0.91\t ACC test:  0.8688888888888889\n",
      "\tEpoch 637: \tAverage Loss:  0.8887554321289063\t ACC train:  0.91\t ACC test:  0.8688888888888889\n",
      "\tEpoch 638: \tAverage Loss:  0.8881915893554687\t ACC train:  0.905\t ACC test:  0.86\n",
      "\tEpoch 639: \tAverage Loss:  0.8881331176757813\t ACC train:  0.91\t ACC test:  0.8555555555555555\n",
      "\tEpoch 640: \tAverage Loss:  0.8875517578125\t ACC train:  0.91\t ACC test:  0.8666666666666667\n",
      "\tEpoch 641: \tAverage Loss:  0.8874595947265626\t ACC train:  0.905\t ACC test:  0.8666666666666667\n",
      "\tEpoch 642: \tAverage Loss:  0.8870263671875\t ACC train:  0.91\t ACC test:  0.8688888888888889\n",
      "\tEpoch 643: \tAverage Loss:  0.886890380859375\t ACC train:  0.915\t ACC test:  0.8622222222222222\n",
      "\tEpoch 644: \tAverage Loss:  0.8865147705078125\t ACC train:  0.91\t ACC test:  0.8644444444444445\n",
      "\tEpoch 645: \tAverage Loss:  0.8863480834960937\t ACC train:  0.905\t ACC test:  0.8711111111111111\n",
      "\tEpoch 646: \tAverage Loss:  0.8858140869140625\t ACC train:  0.91\t ACC test:  0.8666666666666667\n",
      "\tEpoch 647: \tAverage Loss:  0.8853948974609375\t ACC train:  0.9\t ACC test:  0.8644444444444445\n",
      "\tEpoch 648: \tAverage Loss:  0.8849464721679687\t ACC train:  0.91\t ACC test:  0.8711111111111111\n",
      "\tEpoch 649: \tAverage Loss:  0.8844846801757813\t ACC train:  0.905\t ACC test:  0.8711111111111111\n",
      "\tEpoch 650: \tAverage Loss:  0.8842335205078125\t ACC train:  0.91\t ACC test:  0.8666666666666667\n",
      "\tEpoch 651: \tAverage Loss:  0.8844618530273437\t ACC train:  0.91\t ACC test:  0.8733333333333333\n",
      "\tEpoch 652: \tAverage Loss:  0.883985595703125\t ACC train:  0.91\t ACC test:  0.8688888888888889\n",
      "\tEpoch 653: \tAverage Loss:  0.8836015014648437\t ACC train:  0.91\t ACC test:  0.8688888888888889\n",
      "\tEpoch 654: \tAverage Loss:  0.8830509033203126\t ACC train:  0.915\t ACC test:  0.88\n",
      "\tEpoch 655: \tAverage Loss:  0.8829258422851562\t ACC train:  0.91\t ACC test:  0.8711111111111111\n",
      "\tEpoch 656: \tAverage Loss:  0.88242431640625\t ACC train:  0.915\t ACC test:  0.8711111111111111\n",
      "\tEpoch 657: \tAverage Loss:  0.882310302734375\t ACC train:  0.91\t ACC test:  0.8711111111111111\n",
      "\tEpoch 658: \tAverage Loss:  0.8814336547851562\t ACC train:  0.91\t ACC test:  0.8733333333333333\n",
      "\tEpoch 659: \tAverage Loss:  0.8812491455078125\t ACC train:  0.915\t ACC test:  0.8755555555555555\n",
      "\tEpoch 660: \tAverage Loss:  0.8812637939453125\t ACC train:  0.92\t ACC test:  0.8733333333333333\n",
      "\tEpoch 661: \tAverage Loss:  0.8804910888671875\t ACC train:  0.91\t ACC test:  0.8733333333333333\n",
      "\tEpoch 662: \tAverage Loss:  0.88071337890625\t ACC train:  0.91\t ACC test:  0.8622222222222222\n",
      "\tEpoch 663: \tAverage Loss:  0.8806062622070312\t ACC train:  0.91\t ACC test:  0.8711111111111111\n",
      "\tEpoch 664: \tAverage Loss:  0.880018798828125\t ACC train:  0.91\t ACC test:  0.8711111111111111\n",
      "\tEpoch 665: \tAverage Loss:  0.8792588500976563\t ACC train:  0.915\t ACC test:  0.8755555555555555\n",
      "\tEpoch 666: \tAverage Loss:  0.8788499145507812\t ACC train:  0.91\t ACC test:  0.8688888888888889\n",
      "\tEpoch 667: \tAverage Loss:  0.8789000854492187\t ACC train:  0.92\t ACC test:  0.8733333333333333\n",
      "\tEpoch 668: \tAverage Loss:  0.8787537231445313\t ACC train:  0.91\t ACC test:  0.8755555555555555\n",
      "\tEpoch 669: \tAverage Loss:  0.8782235717773438\t ACC train:  0.91\t ACC test:  0.8733333333333333\n",
      "\tEpoch 670: \tAverage Loss:  0.87814501953125\t ACC train:  0.91\t ACC test:  0.8733333333333333\n",
      "\tEpoch 671: \tAverage Loss:  0.8775404663085937\t ACC train:  0.915\t ACC test:  0.8711111111111111\n",
      "\tEpoch 672: \tAverage Loss:  0.8774602661132812\t ACC train:  0.915\t ACC test:  0.8777777777777778\n",
      "\tEpoch 673: \tAverage Loss:  0.8768982543945313\t ACC train:  0.92\t ACC test:  0.8733333333333333\n",
      "\tEpoch 674: \tAverage Loss:  0.8762772827148437\t ACC train:  0.915\t ACC test:  0.8733333333333333\n",
      "\tEpoch 675: \tAverage Loss:  0.8765040893554688\t ACC train:  0.915\t ACC test:  0.8777777777777778\n",
      "\tEpoch 676: \tAverage Loss:  0.8761923217773437\t ACC train:  0.92\t ACC test:  0.8688888888888889\n",
      "\tEpoch 677: \tAverage Loss:  0.8753602905273438\t ACC train:  0.92\t ACC test:  0.8733333333333333\n",
      "\tEpoch 678: \tAverage Loss:  0.8752135009765625\t ACC train:  0.915\t ACC test:  0.88\n",
      "\tEpoch 679: \tAverage Loss:  0.8749827880859375\t ACC train:  0.915\t ACC test:  0.88\n",
      "\tEpoch 680: \tAverage Loss:  0.8751178588867188\t ACC train:  0.92\t ACC test:  0.8777777777777778\n",
      "\tEpoch 681: \tAverage Loss:  0.8746180419921875\t ACC train:  0.92\t ACC test:  0.8711111111111111\n",
      "\tEpoch 682: \tAverage Loss:  0.8739576416015625\t ACC train:  0.92\t ACC test:  0.8733333333333333\n",
      "\tEpoch 683: \tAverage Loss:  0.8745474853515625\t ACC train:  0.92\t ACC test:  0.8777777777777778\n",
      "\tEpoch 684: \tAverage Loss:  0.8733341064453125\t ACC train:  0.925\t ACC test:  0.8755555555555555\n",
      "\tEpoch 685: \tAverage Loss:  0.872780029296875\t ACC train:  0.915\t ACC test:  0.8755555555555555\n",
      "\tEpoch 686: \tAverage Loss:  0.87359619140625\t ACC train:  0.92\t ACC test:  0.8688888888888889\n",
      "\tEpoch 687: \tAverage Loss:  0.87263330078125\t ACC train:  0.92\t ACC test:  0.8777777777777778\n",
      "\tEpoch 688: \tAverage Loss:  0.871833740234375\t ACC train:  0.925\t ACC test:  0.88\n",
      "\tEpoch 689: \tAverage Loss:  0.8723953857421874\t ACC train:  0.925\t ACC test:  0.8755555555555555\n",
      "\tEpoch 690: \tAverage Loss:  0.87252490234375\t ACC train:  0.935\t ACC test:  0.8755555555555555\n",
      "\tEpoch 691: \tAverage Loss:  0.8718566284179687\t ACC train:  0.925\t ACC test:  0.8711111111111111\n",
      "\tEpoch 692: \tAverage Loss:  0.8717838134765625\t ACC train:  0.93\t ACC test:  0.8755555555555555\n",
      "\tEpoch 693: \tAverage Loss:  0.8707459106445312\t ACC train:  0.925\t ACC test:  0.8711111111111111\n",
      "\tEpoch 694: \tAverage Loss:  0.8707901611328125\t ACC train:  0.93\t ACC test:  0.8755555555555555\n",
      "\tEpoch 695: \tAverage Loss:  0.8699580078125\t ACC train:  0.935\t ACC test:  0.88\n",
      "\tEpoch 696: \tAverage Loss:  0.8695873413085937\t ACC train:  0.935\t ACC test:  0.88\n",
      "\tEpoch 697: \tAverage Loss:  0.8691004638671875\t ACC train:  0.93\t ACC test:  0.8777777777777778\n",
      "\tEpoch 698: \tAverage Loss:  0.869169677734375\t ACC train:  0.92\t ACC test:  0.8777777777777778\n",
      "\tEpoch 699: \tAverage Loss:  0.8695282592773438\t ACC train:  0.93\t ACC test:  0.88\n",
      "\tEpoch 700: \tAverage Loss:  0.8687780151367187\t ACC train:  0.935\t ACC test:  0.8777777777777778\n",
      "\tEpoch 701: \tAverage Loss:  0.868064697265625\t ACC train:  0.925\t ACC test:  0.8822222222222222\n",
      "\tEpoch 702: \tAverage Loss:  0.868239501953125\t ACC train:  0.94\t ACC test:  0.8755555555555555\n",
      "\tEpoch 703: \tAverage Loss:  0.8679853515625\t ACC train:  0.935\t ACC test:  0.8733333333333333\n",
      "\tEpoch 704: \tAverage Loss:  0.86749755859375\t ACC train:  0.93\t ACC test:  0.8711111111111111\n",
      "\tEpoch 705: \tAverage Loss:  0.8670919189453125\t ACC train:  0.945\t ACC test:  0.88\n",
      "\tEpoch 706: \tAverage Loss:  0.8676304321289062\t ACC train:  0.935\t ACC test:  0.8711111111111111\n",
      "\tEpoch 707: \tAverage Loss:  0.8668562622070313\t ACC train:  0.94\t ACC test:  0.8755555555555555\n",
      "\tEpoch 708: \tAverage Loss:  0.866505126953125\t ACC train:  0.95\t ACC test:  0.8822222222222222\n",
      "\tEpoch 709: \tAverage Loss:  0.8664133911132812\t ACC train:  0.945\t ACC test:  0.8777777777777778\n",
      "\tEpoch 710: \tAverage Loss:  0.8661212158203125\t ACC train:  0.94\t ACC test:  0.88\n",
      "\tEpoch 711: \tAverage Loss:  0.8652492065429688\t ACC train:  0.945\t ACC test:  0.8711111111111111\n",
      "\tEpoch 712: \tAverage Loss:  0.8650977172851563\t ACC train:  0.945\t ACC test:  0.8822222222222222\n",
      "\tEpoch 713: \tAverage Loss:  0.865489990234375\t ACC train:  0.94\t ACC test:  0.8777777777777778\n",
      "\tEpoch 714: \tAverage Loss:  0.86486083984375\t ACC train:  0.94\t ACC test:  0.8777777777777778\n",
      "\tEpoch 715: \tAverage Loss:  0.86503759765625\t ACC train:  0.95\t ACC test:  0.8777777777777778\n",
      "\tEpoch 716: \tAverage Loss:  0.86426171875\t ACC train:  0.94\t ACC test:  0.8844444444444445\n",
      "\tEpoch 717: \tAverage Loss:  0.86396337890625\t ACC train:  0.955\t ACC test:  0.88\n",
      "\tEpoch 718: \tAverage Loss:  0.8654927368164063\t ACC train:  0.95\t ACC test:  0.8777777777777778\n",
      "\tEpoch 719: \tAverage Loss:  0.8632283935546875\t ACC train:  0.945\t ACC test:  0.8777777777777778\n",
      "\tEpoch 720: \tAverage Loss:  0.862817138671875\t ACC train:  0.955\t ACC test:  0.88\n",
      "\tEpoch 721: \tAverage Loss:  0.8626546020507813\t ACC train:  0.945\t ACC test:  0.88\n",
      "\tEpoch 722: \tAverage Loss:  0.8631051025390625\t ACC train:  0.96\t ACC test:  0.8755555555555555\n",
      "\tEpoch 723: \tAverage Loss:  0.8628096923828125\t ACC train:  0.955\t ACC test:  0.88\n",
      "\tEpoch 724: \tAverage Loss:  0.861708740234375\t ACC train:  0.96\t ACC test:  0.8755555555555555\n",
      "\tEpoch 725: \tAverage Loss:  0.8617011108398438\t ACC train:  0.955\t ACC test:  0.88\n",
      "\tEpoch 726: \tAverage Loss:  0.8628241577148438\t ACC train:  0.955\t ACC test:  0.88\n",
      "\tEpoch 727: \tAverage Loss:  0.8617616577148437\t ACC train:  0.955\t ACC test:  0.8822222222222222\n",
      "\tEpoch 728: \tAverage Loss:  0.8615111694335937\t ACC train:  0.955\t ACC test:  0.8755555555555555\n",
      "\tEpoch 729: \tAverage Loss:  0.861337646484375\t ACC train:  0.955\t ACC test:  0.8777777777777778\n",
      "\tEpoch 730: \tAverage Loss:  0.8608656005859375\t ACC train:  0.955\t ACC test:  0.8733333333333333\n",
      "\tEpoch 731: \tAverage Loss:  0.8605849609375\t ACC train:  0.945\t ACC test:  0.8822222222222222\n",
      "\tEpoch 732: \tAverage Loss:  0.8597362670898437\t ACC train:  0.955\t ACC test:  0.8822222222222222\n",
      "\tEpoch 733: \tAverage Loss:  0.8605265502929688\t ACC train:  0.955\t ACC test:  0.8755555555555555\n",
      "\tEpoch 734: \tAverage Loss:  0.8593555908203125\t ACC train:  0.95\t ACC test:  0.88\n",
      "\tEpoch 735: \tAverage Loss:  0.8589004516601563\t ACC train:  0.955\t ACC test:  0.88\n",
      "\tEpoch 736: \tAverage Loss:  0.8600939331054688\t ACC train:  0.95\t ACC test:  0.8777777777777778\n",
      "\tEpoch 737: \tAverage Loss:  0.8594906616210938\t ACC train:  0.955\t ACC test:  0.8822222222222222\n",
      "\tEpoch 738: \tAverage Loss:  0.8591354370117188\t ACC train:  0.955\t ACC test:  0.8844444444444445\n",
      "\tEpoch 739: \tAverage Loss:  0.8576160888671875\t ACC train:  0.95\t ACC test:  0.88\n",
      "\tEpoch 740: \tAverage Loss:  0.8582418212890625\t ACC train:  0.965\t ACC test:  0.88\n",
      "\tEpoch 741: \tAverage Loss:  0.8573699340820312\t ACC train:  0.955\t ACC test:  0.8755555555555555\n",
      "\tEpoch 742: \tAverage Loss:  0.858313232421875\t ACC train:  0.95\t ACC test:  0.88\n",
      "\tEpoch 743: \tAverage Loss:  0.8571375732421875\t ACC train:  0.955\t ACC test:  0.8755555555555555\n",
      "\tEpoch 744: \tAverage Loss:  0.8567271118164063\t ACC train:  0.965\t ACC test:  0.8777777777777778\n",
      "\tEpoch 745: \tAverage Loss:  0.8561287841796875\t ACC train:  0.965\t ACC test:  0.88\n",
      "\tEpoch 746: \tAverage Loss:  0.8567876586914063\t ACC train:  0.96\t ACC test:  0.8755555555555555\n",
      "\tEpoch 747: \tAverage Loss:  0.8560230712890625\t ACC train:  0.955\t ACC test:  0.8777777777777778\n",
      "\tEpoch 748: \tAverage Loss:  0.8560709838867188\t ACC train:  0.96\t ACC test:  0.8777777777777778\n",
      "\tEpoch 749: \tAverage Loss:  0.8550531616210938\t ACC train:  0.96\t ACC test:  0.8777777777777778\n",
      "\tEpoch 750: \tAverage Loss:  0.8550711059570313\t ACC train:  0.955\t ACC test:  0.8822222222222222\n",
      "\tEpoch 751: \tAverage Loss:  0.854805908203125\t ACC train:  0.95\t ACC test:  0.8822222222222222\n",
      "\tEpoch 752: \tAverage Loss:  0.85459326171875\t ACC train:  0.965\t ACC test:  0.8844444444444445\n",
      "\tEpoch 753: \tAverage Loss:  0.8548788452148437\t ACC train:  0.965\t ACC test:  0.8822222222222222\n",
      "\tEpoch 754: \tAverage Loss:  0.8547388305664062\t ACC train:  0.955\t ACC test:  0.8777777777777778\n",
      "\tEpoch 755: \tAverage Loss:  0.8539161376953125\t ACC train:  0.955\t ACC test:  0.8822222222222222\n",
      "\tEpoch 756: \tAverage Loss:  0.854081298828125\t ACC train:  0.97\t ACC test:  0.8844444444444445\n",
      "\tEpoch 757: \tAverage Loss:  0.8534169311523437\t ACC train:  0.955\t ACC test:  0.8844444444444445\n",
      "\tEpoch 758: \tAverage Loss:  0.8531611938476562\t ACC train:  0.955\t ACC test:  0.88\n",
      "\tEpoch 759: \tAverage Loss:  0.8533858032226562\t ACC train:  0.96\t ACC test:  0.8822222222222222\n",
      "\tEpoch 760: \tAverage Loss:  0.8526143798828125\t ACC train:  0.965\t ACC test:  0.88\n",
      "\tEpoch 761: \tAverage Loss:  0.8526119384765625\t ACC train:  0.965\t ACC test:  0.8866666666666667\n",
      "\tEpoch 762: \tAverage Loss:  0.8522398071289062\t ACC train:  0.965\t ACC test:  0.8866666666666667\n",
      "\tEpoch 763: \tAverage Loss:  0.8522222900390625\t ACC train:  0.96\t ACC test:  0.8777777777777778\n",
      "\tEpoch 764: \tAverage Loss:  0.8519307250976562\t ACC train:  0.965\t ACC test:  0.8866666666666667\n",
      "\tEpoch 765: \tAverage Loss:  0.851257080078125\t ACC train:  0.965\t ACC test:  0.8844444444444445\n",
      "\tEpoch 766: \tAverage Loss:  0.851527587890625\t ACC train:  0.965\t ACC test:  0.8844444444444445\n",
      "\tEpoch 767: \tAverage Loss:  0.8511498413085937\t ACC train:  0.96\t ACC test:  0.8822222222222222\n",
      "\tEpoch 768: \tAverage Loss:  0.8510138549804688\t ACC train:  0.96\t ACC test:  0.88\n",
      "\tEpoch 769: \tAverage Loss:  0.8508651123046875\t ACC train:  0.965\t ACC test:  0.8866666666666667\n",
      "\tEpoch 770: \tAverage Loss:  0.8508167114257813\t ACC train:  0.96\t ACC test:  0.8866666666666667\n",
      "\tEpoch 771: \tAverage Loss:  0.84997802734375\t ACC train:  0.97\t ACC test:  0.8822222222222222\n",
      "\tEpoch 772: \tAverage Loss:  0.8502984619140626\t ACC train:  0.97\t ACC test:  0.8822222222222222\n",
      "\tEpoch 773: \tAverage Loss:  0.8503278198242188\t ACC train:  0.965\t ACC test:  0.8866666666666667\n",
      "\tEpoch 774: \tAverage Loss:  0.850072998046875\t ACC train:  0.96\t ACC test:  0.8866666666666667\n",
      "\tEpoch 775: \tAverage Loss:  0.8495816040039063\t ACC train:  0.97\t ACC test:  0.8822222222222222\n",
      "\tEpoch 776: \tAverage Loss:  0.8489111328125\t ACC train:  0.975\t ACC test:  0.8844444444444445\n",
      "\tEpoch 777: \tAverage Loss:  0.8489586181640625\t ACC train:  0.96\t ACC test:  0.8911111111111111\n",
      "\tEpoch 778: \tAverage Loss:  0.8490985107421875\t ACC train:  0.965\t ACC test:  0.8888888888888888\n",
      "\tEpoch 779: \tAverage Loss:  0.848294921875\t ACC train:  0.97\t ACC test:  0.8844444444444445\n",
      "\tEpoch 780: \tAverage Loss:  0.8479325561523438\t ACC train:  0.97\t ACC test:  0.8911111111111111\n",
      "\tEpoch 781: \tAverage Loss:  0.847458251953125\t ACC train:  0.965\t ACC test:  0.8866666666666667\n",
      "\tEpoch 782: \tAverage Loss:  0.84799658203125\t ACC train:  0.975\t ACC test:  0.8844444444444445\n",
      "\tEpoch 783: \tAverage Loss:  0.848286376953125\t ACC train:  0.97\t ACC test:  0.8844444444444445\n",
      "\tEpoch 784: \tAverage Loss:  0.84760302734375\t ACC train:  0.97\t ACC test:  0.8844444444444445\n",
      "\tEpoch 785: \tAverage Loss:  0.8470567016601562\t ACC train:  0.97\t ACC test:  0.8888888888888888\n",
      "\tEpoch 786: \tAverage Loss:  0.8468236083984375\t ACC train:  0.975\t ACC test:  0.8844444444444445\n",
      "\tEpoch 787: \tAverage Loss:  0.8467482299804687\t ACC train:  0.975\t ACC test:  0.8911111111111111\n",
      "\tEpoch 788: \tAverage Loss:  0.846435791015625\t ACC train:  0.975\t ACC test:  0.8888888888888888\n",
      "\tEpoch 789: \tAverage Loss:  0.8469181518554687\t ACC train:  0.97\t ACC test:  0.8888888888888888\n",
      "\tEpoch 790: \tAverage Loss:  0.8462741088867187\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 791: \tAverage Loss:  0.8461607666015625\t ACC train:  0.97\t ACC test:  0.8911111111111111\n",
      "\tEpoch 792: \tAverage Loss:  0.8461022338867188\t ACC train:  0.965\t ACC test:  0.8888888888888888\n",
      "\tEpoch 793: \tAverage Loss:  0.8458735961914062\t ACC train:  0.965\t ACC test:  0.8822222222222222\n",
      "\tEpoch 794: \tAverage Loss:  0.8449762573242188\t ACC train:  0.97\t ACC test:  0.8866666666666667\n",
      "\tEpoch 795: \tAverage Loss:  0.845884765625\t ACC train:  0.98\t ACC test:  0.8866666666666667\n",
      "\tEpoch 796: \tAverage Loss:  0.8455355224609375\t ACC train:  0.965\t ACC test:  0.8888888888888888\n",
      "\tEpoch 797: \tAverage Loss:  0.8450511474609375\t ACC train:  0.975\t ACC test:  0.8844444444444445\n",
      "\tEpoch 798: \tAverage Loss:  0.8452915649414062\t ACC train:  0.97\t ACC test:  0.8888888888888888\n",
      "\tEpoch 799: \tAverage Loss:  0.8445432739257812\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 800: \tAverage Loss:  0.843649658203125\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 801: \tAverage Loss:  0.8452054443359375\t ACC train:  0.975\t ACC test:  0.8888888888888888\n",
      "\tEpoch 802: \tAverage Loss:  0.8441700439453125\t ACC train:  0.98\t ACC test:  0.8888888888888888\n",
      "\tEpoch 803: \tAverage Loss:  0.8433619384765625\t ACC train:  0.97\t ACC test:  0.8933333333333333\n",
      "\tEpoch 804: \tAverage Loss:  0.8436207275390625\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 805: \tAverage Loss:  0.8437911987304687\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 806: \tAverage Loss:  0.8433720092773438\t ACC train:  0.97\t ACC test:  0.8888888888888888\n",
      "\tEpoch 807: \tAverage Loss:  0.8427376098632813\t ACC train:  0.97\t ACC test:  0.8955555555555555\n",
      "\tEpoch 808: \tAverage Loss:  0.843344970703125\t ACC train:  0.975\t ACC test:  0.8911111111111111\n",
      "\tEpoch 809: \tAverage Loss:  0.8427650146484374\t ACC train:  0.975\t ACC test:  0.8844444444444445\n",
      "\tEpoch 810: \tAverage Loss:  0.8432523803710937\t ACC train:  0.975\t ACC test:  0.8844444444444445\n",
      "\tEpoch 811: \tAverage Loss:  0.84254931640625\t ACC train:  0.98\t ACC test:  0.8911111111111111\n",
      "\tEpoch 812: \tAverage Loss:  0.8425687255859375\t ACC train:  0.98\t ACC test:  0.8933333333333333\n",
      "\tEpoch 813: \tAverage Loss:  0.8414437866210938\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 814: \tAverage Loss:  0.8422567138671875\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 815: \tAverage Loss:  0.84158203125\t ACC train:  0.975\t ACC test:  0.8844444444444445\n",
      "\tEpoch 816: \tAverage Loss:  0.8410069580078126\t ACC train:  0.975\t ACC test:  0.8888888888888888\n",
      "\tEpoch 817: \tAverage Loss:  0.8412763061523437\t ACC train:  0.985\t ACC test:  0.8911111111111111\n",
      "\tEpoch 818: \tAverage Loss:  0.8411312866210937\t ACC train:  0.98\t ACC test:  0.8933333333333333\n",
      "\tEpoch 819: \tAverage Loss:  0.8409970092773438\t ACC train:  0.975\t ACC test:  0.8911111111111111\n",
      "\tEpoch 820: \tAverage Loss:  0.8401826171875\t ACC train:  0.98\t ACC test:  0.8888888888888888\n",
      "\tEpoch 821: \tAverage Loss:  0.8399178466796875\t ACC train:  0.985\t ACC test:  0.8866666666666667\n",
      "\tEpoch 822: \tAverage Loss:  0.8404417114257813\t ACC train:  0.98\t ACC test:  0.8933333333333333\n",
      "\tEpoch 823: \tAverage Loss:  0.840157470703125\t ACC train:  0.975\t ACC test:  0.8888888888888888\n",
      "\tEpoch 824: \tAverage Loss:  0.8393504638671875\t ACC train:  0.98\t ACC test:  0.8911111111111111\n",
      "\tEpoch 825: \tAverage Loss:  0.8400106811523438\t ACC train:  0.98\t ACC test:  0.8955555555555555\n",
      "\tEpoch 826: \tAverage Loss:  0.839646728515625\t ACC train:  0.975\t ACC test:  0.8955555555555555\n",
      "\tEpoch 827: \tAverage Loss:  0.8393067016601562\t ACC train:  0.98\t ACC test:  0.8977777777777778\n",
      "\tEpoch 828: \tAverage Loss:  0.8393548583984375\t ACC train:  0.98\t ACC test:  0.8911111111111111\n",
      "\tEpoch 829: \tAverage Loss:  0.8398399658203125\t ACC train:  0.98\t ACC test:  0.8933333333333333\n",
      "\tEpoch 830: \tAverage Loss:  0.838700439453125\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 831: \tAverage Loss:  0.8386399536132813\t ACC train:  0.975\t ACC test:  0.8911111111111111\n",
      "\tEpoch 832: \tAverage Loss:  0.8392570190429688\t ACC train:  0.975\t ACC test:  0.8911111111111111\n",
      "\tEpoch 833: \tAverage Loss:  0.8383731689453126\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 834: \tAverage Loss:  0.8382959594726562\t ACC train:  0.97\t ACC test:  0.8955555555555555\n",
      "\tEpoch 835: \tAverage Loss:  0.8387800903320313\t ACC train:  0.98\t ACC test:  0.8866666666666667\n",
      "\tEpoch 836: \tAverage Loss:  0.8375031127929687\t ACC train:  0.98\t ACC test:  0.8888888888888888\n",
      "\tEpoch 837: \tAverage Loss:  0.8378463745117187\t ACC train:  0.975\t ACC test:  0.8888888888888888\n",
      "\tEpoch 838: \tAverage Loss:  0.8382522583007812\t ACC train:  0.98\t ACC test:  0.8955555555555555\n",
      "\tEpoch 839: \tAverage Loss:  0.8376657104492188\t ACC train:  0.975\t ACC test:  0.8955555555555555\n",
      "\tEpoch 840: \tAverage Loss:  0.8370473022460938\t ACC train:  0.98\t ACC test:  0.8955555555555555\n",
      "\tEpoch 841: \tAverage Loss:  0.8373854370117187\t ACC train:  0.985\t ACC test:  0.8955555555555555\n",
      "\tEpoch 842: \tAverage Loss:  0.8373483276367187\t ACC train:  0.985\t ACC test:  0.8933333333333333\n",
      "\tEpoch 843: \tAverage Loss:  0.836622314453125\t ACC train:  0.98\t ACC test:  0.8955555555555555\n",
      "\tEpoch 844: \tAverage Loss:  0.8359960327148438\t ACC train:  0.97\t ACC test:  0.8955555555555555\n",
      "\tEpoch 845: \tAverage Loss:  0.836834228515625\t ACC train:  0.975\t ACC test:  0.8977777777777778\n",
      "\tEpoch 846: \tAverage Loss:  0.8358411254882813\t ACC train:  0.98\t ACC test:  0.8977777777777778\n",
      "\tEpoch 847: \tAverage Loss:  0.8374179077148437\t ACC train:  0.975\t ACC test:  0.9\n",
      "\tEpoch 848: \tAverage Loss:  0.8355250244140625\t ACC train:  0.985\t ACC test:  0.8955555555555555\n",
      "\tEpoch 849: \tAverage Loss:  0.8354071044921875\t ACC train:  0.98\t ACC test:  0.8933333333333333\n",
      "\tEpoch 850: \tAverage Loss:  0.8357782592773437\t ACC train:  0.98\t ACC test:  0.8955555555555555\n",
      "\tEpoch 851: \tAverage Loss:  0.8354598388671876\t ACC train:  0.98\t ACC test:  0.9\n",
      "\tEpoch 852: \tAverage Loss:  0.8352445678710938\t ACC train:  0.975\t ACC test:  0.8933333333333333\n",
      "\tEpoch 853: \tAverage Loss:  0.8346071166992187\t ACC train:  0.98\t ACC test:  0.9\n",
      "\tEpoch 854: \tAverage Loss:  0.8347199096679687\t ACC train:  0.98\t ACC test:  0.8933333333333333\n",
      "\tEpoch 855: \tAverage Loss:  0.83458935546875\t ACC train:  0.975\t ACC test:  0.9\n",
      "\tEpoch 856: \tAverage Loss:  0.8342528686523437\t ACC train:  0.98\t ACC test:  0.8977777777777778\n",
      "\tEpoch 857: \tAverage Loss:  0.8339428100585937\t ACC train:  0.98\t ACC test:  0.8977777777777778\n",
      "\tEpoch 858: \tAverage Loss:  0.8342179565429687\t ACC train:  0.98\t ACC test:  0.8933333333333333\n",
      "\tEpoch 859: \tAverage Loss:  0.8344822387695312\t ACC train:  0.985\t ACC test:  0.8977777777777778\n",
      "\tEpoch 860: \tAverage Loss:  0.8332347412109375\t ACC train:  0.985\t ACC test:  0.8977777777777778\n",
      "\tEpoch 861: \tAverage Loss:  0.8336292114257813\t ACC train:  0.985\t ACC test:  0.8955555555555555\n",
      "\tEpoch 862: \tAverage Loss:  0.83344140625\t ACC train:  0.98\t ACC test:  0.9022222222222223\n",
      "\tEpoch 863: \tAverage Loss:  0.8332131958007812\t ACC train:  0.985\t ACC test:  0.8977777777777778\n",
      "\tEpoch 864: \tAverage Loss:  0.8326438598632813\t ACC train:  0.98\t ACC test:  0.8977777777777778\n",
      "\tEpoch 865: \tAverage Loss:  0.8330850219726562\t ACC train:  0.975\t ACC test:  0.9\n",
      "\tEpoch 866: \tAverage Loss:  0.8328165283203125\t ACC train:  0.985\t ACC test:  0.8955555555555555\n",
      "\tEpoch 867: \tAverage Loss:  0.8329840087890625\t ACC train:  0.985\t ACC test:  0.8933333333333333\n",
      "\tEpoch 868: \tAverage Loss:  0.8326148681640625\t ACC train:  0.985\t ACC test:  0.8977777777777778\n",
      "\tEpoch 869: \tAverage Loss:  0.8326920166015624\t ACC train:  0.985\t ACC test:  0.8977777777777778\n",
      "\tEpoch 870: \tAverage Loss:  0.83157275390625\t ACC train:  0.98\t ACC test:  0.9\n",
      "\tEpoch 871: \tAverage Loss:  0.8314450073242188\t ACC train:  0.985\t ACC test:  0.8955555555555555\n",
      "\tEpoch 872: \tAverage Loss:  0.8316130981445312\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 873: \tAverage Loss:  0.8312167358398438\t ACC train:  0.985\t ACC test:  0.8933333333333333\n",
      "\tEpoch 874: \tAverage Loss:  0.8310523071289062\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 875: \tAverage Loss:  0.8309550170898438\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 876: \tAverage Loss:  0.8312679443359375\t ACC train:  0.985\t ACC test:  0.8955555555555555\n",
      "\tEpoch 877: \tAverage Loss:  0.8310758056640625\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 878: \tAverage Loss:  0.83060205078125\t ACC train:  0.985\t ACC test:  0.8977777777777778\n",
      "\tEpoch 879: \tAverage Loss:  0.8305490112304688\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 880: \tAverage Loss:  0.83057763671875\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 881: \tAverage Loss:  0.8303735961914063\t ACC train:  0.98\t ACC test:  0.9022222222222223\n",
      "\tEpoch 882: \tAverage Loss:  0.83054150390625\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 883: \tAverage Loss:  0.8305263671875\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 884: \tAverage Loss:  0.8304777221679688\t ACC train:  0.98\t ACC test:  0.8977777777777778\n",
      "\tEpoch 885: \tAverage Loss:  0.82994140625\t ACC train:  0.985\t ACC test:  0.8955555555555555\n",
      "\tEpoch 886: \tAverage Loss:  0.8294667358398438\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 887: \tAverage Loss:  0.8302971801757812\t ACC train:  0.98\t ACC test:  0.8977777777777778\n",
      "\tEpoch 888: \tAverage Loss:  0.8295565795898437\t ACC train:  0.985\t ACC test:  0.8977777777777778\n",
      "\tEpoch 889: \tAverage Loss:  0.829151611328125\t ACC train:  0.985\t ACC test:  0.8977777777777778\n",
      "\tEpoch 890: \tAverage Loss:  0.8283643798828125\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 891: \tAverage Loss:  0.8295836181640625\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 892: \tAverage Loss:  0.8282294311523437\t ACC train:  0.98\t ACC test:  0.8977777777777778\n",
      "\tEpoch 893: \tAverage Loss:  0.8290943603515625\t ACC train:  0.985\t ACC test:  0.9088888888888889\n",
      "\tEpoch 894: \tAverage Loss:  0.8288724975585937\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 895: \tAverage Loss:  0.828052734375\t ACC train:  0.98\t ACC test:  0.9\n",
      "\tEpoch 896: \tAverage Loss:  0.829509765625\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 897: \tAverage Loss:  0.8279963989257813\t ACC train:  0.985\t ACC test:  0.8933333333333333\n",
      "\tEpoch 898: \tAverage Loss:  0.82763916015625\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 899: \tAverage Loss:  0.8279330444335937\t ACC train:  0.985\t ACC test:  0.8955555555555555\n",
      "\tEpoch 900: \tAverage Loss:  0.8282965698242187\t ACC train:  0.98\t ACC test:  0.9022222222222223\n",
      "\tEpoch 901: \tAverage Loss:  0.8270585327148438\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 902: \tAverage Loss:  0.8272507934570312\t ACC train:  0.99\t ACC test:  0.8977777777777778\n",
      "\tEpoch 903: \tAverage Loss:  0.8266253662109375\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 904: \tAverage Loss:  0.8276694946289063\t ACC train:  0.985\t ACC test:  0.8977777777777778\n",
      "\tEpoch 905: \tAverage Loss:  0.8270215454101563\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 906: \tAverage Loss:  0.8268689575195313\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 907: \tAverage Loss:  0.82609423828125\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 908: \tAverage Loss:  0.8261637573242188\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 909: \tAverage Loss:  0.82623876953125\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 910: \tAverage Loss:  0.8271182250976562\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 911: \tAverage Loss:  0.8254501953125\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 912: \tAverage Loss:  0.826219970703125\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 913: \tAverage Loss:  0.8251038208007813\t ACC train:  0.99\t ACC test:  0.9022222222222223\n",
      "\tEpoch 914: \tAverage Loss:  0.8257612915039062\t ACC train:  0.985\t ACC test:  0.8955555555555555\n",
      "\tEpoch 915: \tAverage Loss:  0.8254691162109375\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 916: \tAverage Loss:  0.8251534423828125\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 917: \tAverage Loss:  0.8252200927734376\t ACC train:  0.985\t ACC test:  0.9\n",
      "\tEpoch 918: \tAverage Loss:  0.8245065307617188\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 919: \tAverage Loss:  0.8251817626953125\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 920: \tAverage Loss:  0.8249844970703125\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 921: \tAverage Loss:  0.8246859741210938\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 922: \tAverage Loss:  0.8243180541992188\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 923: \tAverage Loss:  0.824484130859375\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 924: \tAverage Loss:  0.8243916015625\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 925: \tAverage Loss:  0.8237758178710938\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 926: \tAverage Loss:  0.82371044921875\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 927: \tAverage Loss:  0.8239506225585937\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 928: \tAverage Loss:  0.8235061645507813\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 929: \tAverage Loss:  0.8236734008789063\t ACC train:  0.99\t ACC test:  0.8977777777777778\n",
      "\tEpoch 930: \tAverage Loss:  0.8227028198242188\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 931: \tAverage Loss:  0.822878662109375\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 932: \tAverage Loss:  0.8227554931640625\t ACC train:  0.99\t ACC test:  0.9022222222222223\n",
      "\tEpoch 933: \tAverage Loss:  0.8227860107421875\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 934: \tAverage Loss:  0.822689453125\t ACC train:  0.985\t ACC test:  0.9022222222222223\n",
      "\tEpoch 935: \tAverage Loss:  0.8225394287109375\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 936: \tAverage Loss:  0.822644287109375\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 937: \tAverage Loss:  0.8223665771484375\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 938: \tAverage Loss:  0.8215474853515625\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 939: \tAverage Loss:  0.8218009033203125\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 940: \tAverage Loss:  0.8220687866210937\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 941: \tAverage Loss:  0.8219200439453125\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 942: \tAverage Loss:  0.8211137084960938\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 943: \tAverage Loss:  0.8219351806640625\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 944: \tAverage Loss:  0.8213651123046875\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 945: \tAverage Loss:  0.8209617309570313\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 946: \tAverage Loss:  0.8211703491210938\t ACC train:  0.995\t ACC test:  0.9044444444444445\n",
      "\tEpoch 947: \tAverage Loss:  0.8211979370117187\t ACC train:  0.985\t ACC test:  0.9044444444444445\n",
      "\tEpoch 948: \tAverage Loss:  0.8209929809570312\t ACC train:  0.985\t ACC test:  0.9066666666666666\n",
      "\tEpoch 949: \tAverage Loss:  0.8208616333007812\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 950: \tAverage Loss:  0.820278564453125\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 951: \tAverage Loss:  0.8202739868164063\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 952: \tAverage Loss:  0.8196024169921875\t ACC train:  0.99\t ACC test:  0.8977777777777778\n",
      "\tEpoch 953: \tAverage Loss:  0.8195380249023437\t ACC train:  0.99\t ACC test:  0.9022222222222223\n",
      "\tEpoch 954: \tAverage Loss:  0.8195175170898438\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 955: \tAverage Loss:  0.8192299194335938\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 956: \tAverage Loss:  0.8194593505859376\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 957: \tAverage Loss:  0.8192426147460937\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 958: \tAverage Loss:  0.8192030639648438\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 959: \tAverage Loss:  0.8194857788085937\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 960: \tAverage Loss:  0.8191746215820312\t ACC train:  0.985\t ACC test:  0.9088888888888889\n",
      "\tEpoch 961: \tAverage Loss:  0.818753662109375\t ACC train:  0.99\t ACC test:  0.9\n",
      "\tEpoch 962: \tAverage Loss:  0.8187210083007812\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 963: \tAverage Loss:  0.8186514892578125\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 964: \tAverage Loss:  0.818214111328125\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 965: \tAverage Loss:  0.818019287109375\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 966: \tAverage Loss:  0.8182928466796875\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 967: \tAverage Loss:  0.8186266479492188\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 968: \tAverage Loss:  0.8185972900390625\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 969: \tAverage Loss:  0.817524658203125\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 970: \tAverage Loss:  0.817443115234375\t ACC train:  0.99\t ACC test:  0.9133333333333333\n",
      "\tEpoch 971: \tAverage Loss:  0.8177096557617187\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 972: \tAverage Loss:  0.8173203125\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 973: \tAverage Loss:  0.817005859375\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 974: \tAverage Loss:  0.816697509765625\t ACC train:  0.99\t ACC test:  0.9022222222222223\n",
      "\tEpoch 975: \tAverage Loss:  0.8176341552734375\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 976: \tAverage Loss:  0.8176133422851563\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 977: \tAverage Loss:  0.8170361328125\t ACC train:  0.99\t ACC test:  0.9133333333333333\n",
      "\tEpoch 978: \tAverage Loss:  0.8167893676757813\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 979: \tAverage Loss:  0.8169375610351562\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 980: \tAverage Loss:  0.8168649291992187\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 981: \tAverage Loss:  0.8161851196289063\t ACC train:  0.99\t ACC test:  0.9\n",
      "\tEpoch 982: \tAverage Loss:  0.8168478393554688\t ACC train:  0.99\t ACC test:  0.9133333333333333\n",
      "\tEpoch 983: \tAverage Loss:  0.815991943359375\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 984: \tAverage Loss:  0.816063720703125\t ACC train:  0.995\t ACC test:  0.9022222222222223\n",
      "\tEpoch 985: \tAverage Loss:  0.8161971435546875\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 986: \tAverage Loss:  0.8151962280273437\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 987: \tAverage Loss:  0.8161072387695313\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 988: \tAverage Loss:  0.815108642578125\t ACC train:  0.985\t ACC test:  0.9088888888888889\n",
      "\tEpoch 989: \tAverage Loss:  0.8153036499023437\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 990: \tAverage Loss:  0.8151010131835937\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 991: \tAverage Loss:  0.8145899047851562\t ACC train:  0.985\t ACC test:  0.9088888888888889\n",
      "\tEpoch 992: \tAverage Loss:  0.8150006103515625\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 993: \tAverage Loss:  0.8153150634765625\t ACC train:  0.99\t ACC test:  0.9133333333333333\n",
      "\tEpoch 994: \tAverage Loss:  0.8144093017578125\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 995: \tAverage Loss:  0.8145697021484375\t ACC train:  0.99\t ACC test:  0.9133333333333333\n",
      "\tEpoch 996: \tAverage Loss:  0.814824462890625\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 997: \tAverage Loss:  0.8143585815429687\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 998: \tAverage Loss:  0.8132003173828125\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 999: \tAverage Loss:  0.8143758544921875\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1000: \tAverage Loss:  0.8139468994140625\t ACC train:  0.99\t ACC test:  0.9\n",
      "\tEpoch 1001: \tAverage Loss:  0.8140966796875\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1002: \tAverage Loss:  0.8134804077148438\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1003: \tAverage Loss:  0.813365478515625\t ACC train:  0.995\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1004: \tAverage Loss:  0.8130753784179687\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1005: \tAverage Loss:  0.8126600341796875\t ACC train:  0.995\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1006: \tAverage Loss:  0.8125724487304687\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1007: \tAverage Loss:  0.813338134765625\t ACC train:  0.99\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1008: \tAverage Loss:  0.812496337890625\t ACC train:  0.995\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1009: \tAverage Loss:  0.8124766845703125\t ACC train:  0.99\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1010: \tAverage Loss:  0.8128199462890625\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1011: \tAverage Loss:  0.8122385864257813\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1012: \tAverage Loss:  0.8123563842773438\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1013: \tAverage Loss:  0.8121063232421875\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1014: \tAverage Loss:  0.8118779907226562\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1015: \tAverage Loss:  0.812444580078125\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1016: \tAverage Loss:  0.8118206176757813\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1017: \tAverage Loss:  0.81140478515625\t ACC train:  0.99\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1018: \tAverage Loss:  0.8116455078125\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1019: \tAverage Loss:  0.8117911376953125\t ACC train:  1.0\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1020: \tAverage Loss:  0.8104929809570313\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1021: \tAverage Loss:  0.8109364013671875\t ACC train:  0.995\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1022: \tAverage Loss:  0.8111251831054688\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1023: \tAverage Loss:  0.8109373779296875\t ACC train:  1.0\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1024: \tAverage Loss:  0.8101983032226563\t ACC train:  0.995\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1025: \tAverage Loss:  0.8105005493164062\t ACC train:  0.995\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1026: \tAverage Loss:  0.810051513671875\t ACC train:  0.995\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1027: \tAverage Loss:  0.8109846801757813\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1028: \tAverage Loss:  0.8101194458007812\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1029: \tAverage Loss:  0.8116768188476563\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1030: \tAverage Loss:  0.8101041870117187\t ACC train:  0.99\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1031: \tAverage Loss:  0.8101973876953125\t ACC train:  0.995\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1032: \tAverage Loss:  0.8096890869140625\t ACC train:  1.0\t ACC test:  0.9\n",
      "\tEpoch 1033: \tAverage Loss:  0.8104075317382813\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1034: \tAverage Loss:  0.8092800903320313\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1035: \tAverage Loss:  0.8089179077148437\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1036: \tAverage Loss:  0.8097264404296876\t ACC train:  0.99\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1037: \tAverage Loss:  0.8094630737304688\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1038: \tAverage Loss:  0.8092435302734375\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1039: \tAverage Loss:  0.80877490234375\t ACC train:  0.995\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1040: \tAverage Loss:  0.8102547607421875\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1041: \tAverage Loss:  0.8094234619140624\t ACC train:  1.0\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1042: \tAverage Loss:  0.8095156860351562\t ACC train:  0.995\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1043: \tAverage Loss:  0.8084427490234375\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1044: \tAverage Loss:  0.8083331909179687\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1045: \tAverage Loss:  0.8079786376953125\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1046: \tAverage Loss:  0.8081539306640625\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1047: \tAverage Loss:  0.8085079956054687\t ACC train:  0.99\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1048: \tAverage Loss:  0.807695068359375\t ACC train:  0.995\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1049: \tAverage Loss:  0.8074893188476563\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1050: \tAverage Loss:  0.8073265380859375\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1051: \tAverage Loss:  0.8067592163085937\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1052: \tAverage Loss:  0.8068152465820313\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1053: \tAverage Loss:  0.80729345703125\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1054: \tAverage Loss:  0.8067051391601563\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1055: \tAverage Loss:  0.807108642578125\t ACC train:  0.995\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1056: \tAverage Loss:  0.8067379150390624\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1057: \tAverage Loss:  0.8064532470703125\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1058: \tAverage Loss:  0.8063927001953125\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1059: \tAverage Loss:  0.8057144775390624\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1060: \tAverage Loss:  0.8063491821289063\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1061: \tAverage Loss:  0.8064065551757813\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1062: \tAverage Loss:  0.8055255126953125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1063: \tAverage Loss:  0.8062564697265625\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1064: \tAverage Loss:  0.8055612182617188\t ACC train:  0.995\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1065: \tAverage Loss:  0.8051900634765625\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1066: \tAverage Loss:  0.805412353515625\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1067: \tAverage Loss:  0.8046422119140625\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1068: \tAverage Loss:  0.8049802856445313\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1069: \tAverage Loss:  0.8045789794921875\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1070: \tAverage Loss:  0.804528564453125\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1071: \tAverage Loss:  0.8041096801757812\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1072: \tAverage Loss:  0.8044724731445313\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1073: \tAverage Loss:  0.8043560180664062\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1074: \tAverage Loss:  0.8044707641601563\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1075: \tAverage Loss:  0.8047586669921875\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1076: \tAverage Loss:  0.8033729858398437\t ACC train:  0.995\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1077: \tAverage Loss:  0.8044103393554688\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1078: \tAverage Loss:  0.8032745361328125\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1079: \tAverage Loss:  0.8042756958007813\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1080: \tAverage Loss:  0.80308349609375\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1081: \tAverage Loss:  0.8030493774414063\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1082: \tAverage Loss:  0.8034684448242188\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1083: \tAverage Loss:  0.8025416870117188\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1084: \tAverage Loss:  0.8031596069335938\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1085: \tAverage Loss:  0.8026669311523438\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1086: \tAverage Loss:  0.8025987548828125\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1087: \tAverage Loss:  0.803\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1088: \tAverage Loss:  0.8026068115234375\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1089: \tAverage Loss:  0.8030518798828125\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1090: \tAverage Loss:  0.802486083984375\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1091: \tAverage Loss:  0.80237353515625\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1092: \tAverage Loss:  0.8027783813476562\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1093: \tAverage Loss:  0.801690673828125\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1094: \tAverage Loss:  0.8027820434570313\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1095: \tAverage Loss:  0.8023189086914062\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1096: \tAverage Loss:  0.8020384521484375\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1097: \tAverage Loss:  0.8009588012695312\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1098: \tAverage Loss:  0.8008869018554687\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1099: \tAverage Loss:  0.8010074462890625\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1100: \tAverage Loss:  0.8011473388671875\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1101: \tAverage Loss:  0.8012605590820312\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1102: \tAverage Loss:  0.8007357788085937\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1103: \tAverage Loss:  0.8003893432617187\t ACC train:  0.995\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1104: \tAverage Loss:  0.8003773193359375\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1105: \tAverage Loss:  0.800245849609375\t ACC train:  0.995\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1106: \tAverage Loss:  0.800100341796875\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1107: \tAverage Loss:  0.8002073974609375\t ACC train:  0.995\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1108: \tAverage Loss:  0.79957373046875\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1109: \tAverage Loss:  0.7992601928710937\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1110: \tAverage Loss:  0.8000466918945313\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1111: \tAverage Loss:  0.7992412719726563\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1112: \tAverage Loss:  0.79966650390625\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1113: \tAverage Loss:  0.8001770629882813\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1114: \tAverage Loss:  0.799111083984375\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1115: \tAverage Loss:  0.7989246215820313\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1116: \tAverage Loss:  0.7995690307617187\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1117: \tAverage Loss:  0.7994775390625\t ACC train:  0.995\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1118: \tAverage Loss:  0.7988446044921875\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1119: \tAverage Loss:  0.7991915283203125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1120: \tAverage Loss:  0.7988342895507813\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1121: \tAverage Loss:  0.7982526245117187\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1122: \tAverage Loss:  0.7985947265625\t ACC train:  0.995\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1123: \tAverage Loss:  0.7985341186523438\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1124: \tAverage Loss:  0.7982777099609375\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1125: \tAverage Loss:  0.7982654418945313\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1126: \tAverage Loss:  0.7984071044921875\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1127: \tAverage Loss:  0.79739892578125\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1128: \tAverage Loss:  0.7973975830078125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1129: \tAverage Loss:  0.7968458251953126\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1130: \tAverage Loss:  0.7973854370117187\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1131: \tAverage Loss:  0.7975492553710938\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1132: \tAverage Loss:  0.797516845703125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1133: \tAverage Loss:  0.7968513793945312\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1134: \tAverage Loss:  0.7969334716796875\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1135: \tAverage Loss:  0.7963600463867188\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1136: \tAverage Loss:  0.7966557006835937\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1137: \tAverage Loss:  0.7968796997070312\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1138: \tAverage Loss:  0.795761474609375\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1139: \tAverage Loss:  0.7962681884765626\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1140: \tAverage Loss:  0.7967950439453125\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1141: \tAverage Loss:  0.7961187744140625\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1142: \tAverage Loss:  0.7951021118164062\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1143: \tAverage Loss:  0.7953423461914062\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1144: \tAverage Loss:  0.7951442260742188\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1145: \tAverage Loss:  0.795018310546875\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1146: \tAverage Loss:  0.7954866943359375\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1147: \tAverage Loss:  0.7943892211914062\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1148: \tAverage Loss:  0.7951416015625\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1149: \tAverage Loss:  0.7946357421875\t ACC train:  0.995\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1150: \tAverage Loss:  0.7951739501953125\t ACC train:  0.995\t ACC test:  0.92\n",
      "\tEpoch 1151: \tAverage Loss:  0.7947908935546875\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1152: \tAverage Loss:  0.7944901733398437\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1153: \tAverage Loss:  0.7944235229492187\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1154: \tAverage Loss:  0.794242919921875\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1155: \tAverage Loss:  0.7943607788085938\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1156: \tAverage Loss:  0.793672607421875\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1157: \tAverage Loss:  0.7940360107421875\t ACC train:  0.995\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1158: \tAverage Loss:  0.7936519775390625\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1159: \tAverage Loss:  0.794288330078125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1160: \tAverage Loss:  0.7935021362304687\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1161: \tAverage Loss:  0.7936116333007812\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1162: \tAverage Loss:  0.7936311645507812\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1163: \tAverage Loss:  0.7934738159179687\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1164: \tAverage Loss:  0.7932886352539062\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1165: \tAverage Loss:  0.793249755859375\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1166: \tAverage Loss:  0.7929283447265625\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1167: \tAverage Loss:  0.7924317626953125\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1168: \tAverage Loss:  0.7933350830078125\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1169: \tAverage Loss:  0.7926840209960937\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1170: \tAverage Loss:  0.7935513916015625\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1171: \tAverage Loss:  0.79353369140625\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1172: \tAverage Loss:  0.7924421997070312\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1173: \tAverage Loss:  0.792834716796875\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1174: \tAverage Loss:  0.7920568237304687\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1175: \tAverage Loss:  0.791801025390625\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1176: \tAverage Loss:  0.7921091918945312\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1177: \tAverage Loss:  0.792459228515625\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1178: \tAverage Loss:  0.791602783203125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1179: \tAverage Loss:  0.7914976196289063\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1180: \tAverage Loss:  0.7919448852539063\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1181: \tAverage Loss:  0.791492431640625\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1182: \tAverage Loss:  0.7912306518554687\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1183: \tAverage Loss:  0.7907913208007813\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1184: \tAverage Loss:  0.790760986328125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1185: \tAverage Loss:  0.7903251342773437\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1186: \tAverage Loss:  0.7902009887695313\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1187: \tAverage Loss:  0.7899771118164063\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1188: \tAverage Loss:  0.7901346435546875\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1189: \tAverage Loss:  0.7897697143554687\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1190: \tAverage Loss:  0.7901237182617188\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1191: \tAverage Loss:  0.7901109619140625\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1192: \tAverage Loss:  0.7896282348632813\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1193: \tAverage Loss:  0.7905923461914063\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1194: \tAverage Loss:  0.7887823486328125\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1195: \tAverage Loss:  0.7894026489257813\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1196: \tAverage Loss:  0.7890823974609374\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1197: \tAverage Loss:  0.7896220092773437\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1198: \tAverage Loss:  0.789797119140625\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1199: \tAverage Loss:  0.7890606079101562\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1200: \tAverage Loss:  0.7895776977539063\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1201: \tAverage Loss:  0.7884448852539062\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1202: \tAverage Loss:  0.7886583862304688\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1203: \tAverage Loss:  0.7881839599609375\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1204: \tAverage Loss:  0.7879625854492187\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1205: \tAverage Loss:  0.7887217407226562\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1206: \tAverage Loss:  0.7880374145507812\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1207: \tAverage Loss:  0.7878547973632812\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1208: \tAverage Loss:  0.78796533203125\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1209: \tAverage Loss:  0.7881951293945313\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1210: \tAverage Loss:  0.7877814331054688\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1211: \tAverage Loss:  0.7876897583007813\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1212: \tAverage Loss:  0.7866954345703125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1213: \tAverage Loss:  0.7876766357421875\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1214: \tAverage Loss:  0.7871306762695313\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1215: \tAverage Loss:  0.7870787353515625\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1216: \tAverage Loss:  0.7866531372070312\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1217: \tAverage Loss:  0.7862769775390624\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1218: \tAverage Loss:  0.7867186279296875\t ACC train:  1.0\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1219: \tAverage Loss:  0.786880126953125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1220: \tAverage Loss:  0.786320068359375\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1221: \tAverage Loss:  0.7870447387695313\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1222: \tAverage Loss:  0.78704931640625\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1223: \tAverage Loss:  0.7855668334960938\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1224: \tAverage Loss:  0.7865628662109375\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1225: \tAverage Loss:  0.7859822998046875\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1226: \tAverage Loss:  0.786382080078125\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1227: \tAverage Loss:  0.7854542846679687\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1228: \tAverage Loss:  0.7853236083984375\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1229: \tAverage Loss:  0.7865438842773438\t ACC train:  0.995\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1230: \tAverage Loss:  0.7877896118164063\t ACC train:  1.0\t ACC test:  0.92\n",
      "\tEpoch 1231: \tAverage Loss:  0.7849429931640625\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1232: \tAverage Loss:  0.7867792358398438\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1233: \tAverage Loss:  0.7854484252929688\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1234: \tAverage Loss:  0.785216552734375\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1235: \tAverage Loss:  0.786809814453125\t ACC train:  0.995\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1236: \tAverage Loss:  0.7846159057617188\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1237: \tAverage Loss:  0.7858322143554688\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1238: \tAverage Loss:  0.7847413940429687\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1239: \tAverage Loss:  0.7852527465820313\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1240: \tAverage Loss:  0.7841154174804688\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1241: \tAverage Loss:  0.7843038330078125\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1242: \tAverage Loss:  0.7844622802734375\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1243: \tAverage Loss:  0.783575439453125\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1244: \tAverage Loss:  0.7840104370117188\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1245: \tAverage Loss:  0.7835677490234375\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1246: \tAverage Loss:  0.7835441284179687\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1247: \tAverage Loss:  0.7834586181640625\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1248: \tAverage Loss:  0.7831123657226563\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1249: \tAverage Loss:  0.7836197509765624\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1250: \tAverage Loss:  0.7827508544921875\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1251: \tAverage Loss:  0.7836116333007812\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1252: \tAverage Loss:  0.7816637573242188\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1253: \tAverage Loss:  0.7825931396484375\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1254: \tAverage Loss:  0.7824949951171875\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1255: \tAverage Loss:  0.782263916015625\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1256: \tAverage Loss:  0.7828071899414063\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1257: \tAverage Loss:  0.7823529052734375\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1258: \tAverage Loss:  0.7822312622070312\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1259: \tAverage Loss:  0.7818738403320312\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1260: \tAverage Loss:  0.7815226440429688\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1261: \tAverage Loss:  0.7815563354492188\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1262: \tAverage Loss:  0.7814607543945312\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1263: \tAverage Loss:  0.780903564453125\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1264: \tAverage Loss:  0.7812469482421875\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1265: \tAverage Loss:  0.7810838012695313\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1266: \tAverage Loss:  0.781002685546875\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1267: \tAverage Loss:  0.7812456665039063\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1268: \tAverage Loss:  0.7803615112304687\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1269: \tAverage Loss:  0.780325439453125\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1270: \tAverage Loss:  0.7807788696289063\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1271: \tAverage Loss:  0.779908447265625\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1272: \tAverage Loss:  0.7796663818359375\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1273: \tAverage Loss:  0.7799015502929687\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1274: \tAverage Loss:  0.779917724609375\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1275: \tAverage Loss:  0.77940283203125\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1276: \tAverage Loss:  0.7792197265625\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1277: \tAverage Loss:  0.7791724243164062\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1278: \tAverage Loss:  0.7789290161132812\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1279: \tAverage Loss:  0.7802913208007812\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1280: \tAverage Loss:  0.7793843383789063\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1281: \tAverage Loss:  0.77800048828125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1282: \tAverage Loss:  0.7789142456054687\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1283: \tAverage Loss:  0.7790639038085938\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1284: \tAverage Loss:  0.7794293212890625\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1285: \tAverage Loss:  0.77899462890625\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1286: \tAverage Loss:  0.7776497802734375\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1287: \tAverage Loss:  0.7793118896484375\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1288: \tAverage Loss:  0.7782345581054687\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1289: \tAverage Loss:  0.7788721923828125\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1290: \tAverage Loss:  0.7778896484375\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1291: \tAverage Loss:  0.7792593383789063\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1292: \tAverage Loss:  0.7774346923828125\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1293: \tAverage Loss:  0.7776792602539062\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1294: \tAverage Loss:  0.777756103515625\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1295: \tAverage Loss:  0.7772951049804687\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1296: \tAverage Loss:  0.7777409057617187\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1297: \tAverage Loss:  0.7764688720703125\t ACC train:  1.0\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1298: \tAverage Loss:  0.7770689086914062\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1299: \tAverage Loss:  0.7774752197265625\t ACC train:  1.0\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1300: \tAverage Loss:  0.776828125\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1301: \tAverage Loss:  0.7766591796875\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1302: \tAverage Loss:  0.776426513671875\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1303: \tAverage Loss:  0.7762686157226563\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1304: \tAverage Loss:  0.7763667602539063\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1305: \tAverage Loss:  0.7769754028320313\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1306: \tAverage Loss:  0.7757280883789063\t ACC train:  1.0\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1307: \tAverage Loss:  0.7764745483398438\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1308: \tAverage Loss:  0.7760161743164062\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1309: \tAverage Loss:  0.7758700561523437\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1310: \tAverage Loss:  0.7753624267578125\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1311: \tAverage Loss:  0.7763782958984375\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1312: \tAverage Loss:  0.7757722778320313\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1313: \tAverage Loss:  0.7754650268554687\t ACC train:  1.0\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1314: \tAverage Loss:  0.7755247802734375\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1315: \tAverage Loss:  0.77524658203125\t ACC train:  1.0\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1316: \tAverage Loss:  0.7751132202148437\t ACC train:  1.0\t ACC test:  0.9133333333333333\n",
      "Stopping early at epoch 1316. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 300\n",
      "\tEpoch 1: \tAverage Loss:  2.8450234375\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 2: \tAverage Loss:  2.82280517578125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 3: \tAverage Loss:  2.79731884765625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 4: \tAverage Loss:  2.77612158203125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 5: \tAverage Loss:  2.754861328125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 6: \tAverage Loss:  2.733012939453125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 7: \tAverage Loss:  2.713395263671875\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 8: \tAverage Loss:  2.691679931640625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 9: \tAverage Loss:  2.673972412109375\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 10: \tAverage Loss:  2.656344482421875\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  2.6380390625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  2.624053955078125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  2.611210205078125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  2.596699951171875\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  2.5832490234375\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  2.570313720703125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  2.55845751953125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  2.547793212890625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  2.537988525390625\t ACC train:  0.5133333333333333\t ACC test:  0.48444444444444446\n",
      "\tEpoch 20: \tAverage Loss:  2.5270341796875\t ACC train:  0.5133333333333333\t ACC test:  0.4888888888888889\n",
      "\tEpoch 21: \tAverage Loss:  2.51761767578125\t ACC train:  0.52\t ACC test:  0.48444444444444446\n",
      "\tEpoch 22: \tAverage Loss:  2.509982421875\t ACC train:  0.52\t ACC test:  0.49333333333333335\n",
      "\tEpoch 23: \tAverage Loss:  2.50107861328125\t ACC train:  0.5166666666666667\t ACC test:  0.5\n",
      "\tEpoch 24: \tAverage Loss:  2.493777587890625\t ACC train:  0.52\t ACC test:  0.5288888888888889\n",
      "\tEpoch 25: \tAverage Loss:  2.487462158203125\t ACC train:  0.58\t ACC test:  0.5377777777777778\n",
      "\tEpoch 26: \tAverage Loss:  2.481348388671875\t ACC train:  0.4866666666666667\t ACC test:  0.56\n",
      "\tEpoch 27: \tAverage Loss:  2.4750244140625\t ACC train:  0.5566666666666666\t ACC test:  0.5355555555555556\n",
      "\tEpoch 28: \tAverage Loss:  2.469047119140625\t ACC train:  0.56\t ACC test:  0.5222222222222223\n",
      "\tEpoch 29: \tAverage Loss:  2.46290283203125\t ACC train:  0.4866666666666667\t ACC test:  0.58\n",
      "\tEpoch 30: \tAverage Loss:  2.459615966796875\t ACC train:  0.52\t ACC test:  0.5244444444444445\n",
      "\tEpoch 31: \tAverage Loss:  2.453757080078125\t ACC train:  0.5633333333333334\t ACC test:  0.5177777777777778\n",
      "\tEpoch 32: \tAverage Loss:  2.448918701171875\t ACC train:  0.5133333333333333\t ACC test:  0.5755555555555556\n",
      "\tEpoch 33: \tAverage Loss:  2.4456845703125\t ACC train:  0.57\t ACC test:  0.5288888888888889\n",
      "\tEpoch 34: \tAverage Loss:  2.439878173828125\t ACC train:  0.52\t ACC test:  0.5622222222222222\n",
      "\tEpoch 35: \tAverage Loss:  2.434679931640625\t ACC train:  0.5866666666666667\t ACC test:  0.5311111111111111\n",
      "\tEpoch 36: \tAverage Loss:  2.430070068359375\t ACC train:  0.5333333333333333\t ACC test:  0.52\n",
      "\tEpoch 37: \tAverage Loss:  2.426605224609375\t ACC train:  0.5366666666666666\t ACC test:  0.4955555555555556\n",
      "\tEpoch 38: \tAverage Loss:  2.42139501953125\t ACC train:  0.5333333333333333\t ACC test:  0.5044444444444445\n",
      "\tEpoch 39: \tAverage Loss:  2.4174326171875\t ACC train:  0.5233333333333333\t ACC test:  0.49777777777777776\n",
      "\tEpoch 40: \tAverage Loss:  2.41296533203125\t ACC train:  0.5166666666666667\t ACC test:  0.48\n",
      "\tEpoch 41: \tAverage Loss:  2.408435302734375\t ACC train:  0.5166666666666667\t ACC test:  0.49333333333333335\n",
      "\tEpoch 42: \tAverage Loss:  2.403286376953125\t ACC train:  0.5133333333333333\t ACC test:  0.4888888888888889\n",
      "\tEpoch 43: \tAverage Loss:  2.399595947265625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  2.39621728515625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  2.391487060546875\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  2.38878515625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  2.383836181640625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  2.3809658203125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  2.3778896484375\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  2.37442822265625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  2.3709365234375\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  2.369030517578125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  2.366000244140625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  2.362833740234375\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  2.360740234375\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  2.358082763671875\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  2.354704833984375\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  2.352680908203125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  2.34986962890625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  2.348260986328125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  2.34542822265625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  2.344296142578125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  2.340857666015625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  2.338808837890625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  2.337297607421875\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  2.334987548828125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  2.33360400390625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  2.331537841796875\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  2.33056494140625\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  2.329348876953125\t ACC train:  0.5133333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  2.326974609375\t ACC train:  0.5133333333333333\t ACC test:  0.4888888888888889\n",
      "\tEpoch 72: \tAverage Loss:  2.325587646484375\t ACC train:  0.51\t ACC test:  0.4955555555555556\n",
      "\tEpoch 73: \tAverage Loss:  2.324111083984375\t ACC train:  0.5133333333333333\t ACC test:  0.4888888888888889\n",
      "\tEpoch 74: \tAverage Loss:  2.32323291015625\t ACC train:  0.51\t ACC test:  0.4888888888888889\n",
      "\tEpoch 75: \tAverage Loss:  2.3212744140625\t ACC train:  0.5133333333333333\t ACC test:  0.48444444444444446\n",
      "\tEpoch 76: \tAverage Loss:  2.320668701171875\t ACC train:  0.51\t ACC test:  0.4911111111111111\n",
      "\tEpoch 77: \tAverage Loss:  2.31869384765625\t ACC train:  0.5133333333333333\t ACC test:  0.4888888888888889\n",
      "\tEpoch 78: \tAverage Loss:  2.317137451171875\t ACC train:  0.5233333333333333\t ACC test:  0.4911111111111111\n",
      "\tEpoch 79: \tAverage Loss:  2.3161904296875\t ACC train:  0.5166666666666667\t ACC test:  0.4888888888888889\n",
      "\tEpoch 80: \tAverage Loss:  2.31555029296875\t ACC train:  0.5166666666666667\t ACC test:  0.49333333333333335\n",
      "\tEpoch 81: \tAverage Loss:  2.314350830078125\t ACC train:  0.52\t ACC test:  0.48444444444444446\n",
      "\tEpoch 82: \tAverage Loss:  2.313613525390625\t ACC train:  0.5166666666666667\t ACC test:  0.4888888888888889\n",
      "\tEpoch 83: \tAverage Loss:  2.312722900390625\t ACC train:  0.5166666666666667\t ACC test:  0.4888888888888889\n",
      "\tEpoch 84: \tAverage Loss:  2.311515625\t ACC train:  0.5133333333333333\t ACC test:  0.4911111111111111\n",
      "\tEpoch 85: \tAverage Loss:  2.310443359375\t ACC train:  0.51\t ACC test:  0.4911111111111111\n",
      "\tEpoch 86: \tAverage Loss:  2.30944384765625\t ACC train:  0.5133333333333333\t ACC test:  0.4955555555555556\n",
      "\tEpoch 87: \tAverage Loss:  2.30833984375\t ACC train:  0.5133333333333333\t ACC test:  0.4911111111111111\n",
      "\tEpoch 88: \tAverage Loss:  2.3081552734375\t ACC train:  0.5166666666666667\t ACC test:  0.4911111111111111\n",
      "\tEpoch 89: \tAverage Loss:  2.306780517578125\t ACC train:  0.5266666666666666\t ACC test:  0.49333333333333335\n",
      "\tEpoch 90: \tAverage Loss:  2.30682470703125\t ACC train:  0.5233333333333333\t ACC test:  0.49777777777777776\n",
      "\tEpoch 91: \tAverage Loss:  2.305487060546875\t ACC train:  0.5266666666666666\t ACC test:  0.5044444444444445\n",
      "\tEpoch 92: \tAverage Loss:  2.304097412109375\t ACC train:  0.5366666666666666\t ACC test:  0.4911111111111111\n",
      "\tEpoch 93: \tAverage Loss:  2.303860595703125\t ACC train:  0.5266666666666666\t ACC test:  0.5\n",
      "\tEpoch 94: \tAverage Loss:  2.30274365234375\t ACC train:  0.5366666666666666\t ACC test:  0.52\n",
      "\tEpoch 95: \tAverage Loss:  2.303210205078125\t ACC train:  0.5733333333333334\t ACC test:  0.52\n",
      "\tEpoch 96: \tAverage Loss:  2.302203857421875\t ACC train:  0.5666666666666667\t ACC test:  0.5466666666666666\n",
      "\tEpoch 97: \tAverage Loss:  2.30080078125\t ACC train:  0.58\t ACC test:  0.5755555555555556\n",
      "\tEpoch 98: \tAverage Loss:  2.300933837890625\t ACC train:  0.5966666666666667\t ACC test:  0.5755555555555556\n",
      "\tEpoch 99: \tAverage Loss:  2.2992294921875\t ACC train:  0.5866666666666667\t ACC test:  0.6022222222222222\n",
      "\tEpoch 100: \tAverage Loss:  2.298650146484375\t ACC train:  0.6733333333333333\t ACC test:  0.6244444444444445\n",
      "\tEpoch 101: \tAverage Loss:  2.297376220703125\t ACC train:  0.6433333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 102: \tAverage Loss:  2.296054931640625\t ACC train:  0.6566666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 103: \tAverage Loss:  2.297664306640625\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 104: \tAverage Loss:  2.295464599609375\t ACC train:  0.68\t ACC test:  0.6422222222222222\n",
      "\tEpoch 105: \tAverage Loss:  2.29403955078125\t ACC train:  0.6666666666666666\t ACC test:  0.6533333333333333\n",
      "\tEpoch 106: \tAverage Loss:  2.2962236328125\t ACC train:  0.6666666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 107: \tAverage Loss:  2.294954833984375\t ACC train:  0.6833333333333333\t ACC test:  0.6488888888888888\n",
      "\tEpoch 108: \tAverage Loss:  2.293859375\t ACC train:  0.6866666666666666\t ACC test:  0.6888888888888889\n",
      "\tEpoch 109: \tAverage Loss:  2.29166064453125\t ACC train:  0.6933333333333334\t ACC test:  0.6866666666666666\n",
      "\tEpoch 110: \tAverage Loss:  2.292097900390625\t ACC train:  0.7\t ACC test:  0.6755555555555556\n",
      "\tEpoch 111: \tAverage Loss:  2.292631103515625\t ACC train:  0.6533333333333333\t ACC test:  0.6888888888888889\n",
      "\tEpoch 112: \tAverage Loss:  2.29148583984375\t ACC train:  0.7166666666666667\t ACC test:  0.6888888888888889\n",
      "\tEpoch 113: \tAverage Loss:  2.289899169921875\t ACC train:  0.6933333333333334\t ACC test:  0.6866666666666666\n",
      "\tEpoch 114: \tAverage Loss:  2.289580810546875\t ACC train:  0.6766666666666666\t ACC test:  0.7222222222222222\n",
      "\tEpoch 115: \tAverage Loss:  2.288165283203125\t ACC train:  0.71\t ACC test:  0.7022222222222222\n",
      "\tEpoch 116: \tAverage Loss:  2.285348876953125\t ACC train:  0.7333333333333333\t ACC test:  0.72\n",
      "\tEpoch 117: \tAverage Loss:  2.285986572265625\t ACC train:  0.7033333333333334\t ACC test:  0.7044444444444444\n",
      "\tEpoch 118: \tAverage Loss:  2.284876708984375\t ACC train:  0.7433333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 119: \tAverage Loss:  2.28623046875\t ACC train:  0.7433333333333333\t ACC test:  0.7555555555555555\n",
      "\tEpoch 120: \tAverage Loss:  2.28357763671875\t ACC train:  0.7133333333333334\t ACC test:  0.7533333333333333\n",
      "\tEpoch 121: \tAverage Loss:  2.27960546875\t ACC train:  0.7333333333333333\t ACC test:  0.76\n",
      "\tEpoch 122: \tAverage Loss:  2.280525634765625\t ACC train:  0.77\t ACC test:  0.7644444444444445\n",
      "\tEpoch 123: \tAverage Loss:  2.281549560546875\t ACC train:  0.74\t ACC test:  0.7466666666666667\n",
      "\tEpoch 124: \tAverage Loss:  2.279161865234375\t ACC train:  0.8066666666666666\t ACC test:  0.7533333333333333\n",
      "\tEpoch 125: \tAverage Loss:  2.277402587890625\t ACC train:  0.7566666666666667\t ACC test:  0.7577777777777778\n",
      "\tEpoch 126: \tAverage Loss:  2.27683447265625\t ACC train:  0.7866666666666666\t ACC test:  0.7555555555555555\n",
      "\tEpoch 127: \tAverage Loss:  2.27501611328125\t ACC train:  0.7466666666666667\t ACC test:  0.7888888888888889\n",
      "\tEpoch 128: \tAverage Loss:  2.275187744140625\t ACC train:  0.77\t ACC test:  0.7844444444444445\n",
      "\tEpoch 129: \tAverage Loss:  2.274790771484375\t ACC train:  0.8033333333333333\t ACC test:  0.7755555555555556\n",
      "\tEpoch 130: \tAverage Loss:  2.2751572265625\t ACC train:  0.7966666666666666\t ACC test:  0.7822222222222223\n",
      "\tEpoch 131: \tAverage Loss:  2.26975146484375\t ACC train:  0.8\t ACC test:  0.7977777777777778\n",
      "\tEpoch 132: \tAverage Loss:  2.269818603515625\t ACC train:  0.8\t ACC test:  0.76\n",
      "\tEpoch 133: \tAverage Loss:  2.26762109375\t ACC train:  0.7833333333333333\t ACC test:  0.8111111111111111\n",
      "\tEpoch 134: \tAverage Loss:  2.265779541015625\t ACC train:  0.8266666666666667\t ACC test:  0.7866666666666666\n",
      "\tEpoch 135: \tAverage Loss:  2.264133056640625\t ACC train:  0.8166666666666667\t ACC test:  0.7933333333333333\n",
      "\tEpoch 136: \tAverage Loss:  2.261548828125\t ACC train:  0.78\t ACC test:  0.8\n",
      "\tEpoch 137: \tAverage Loss:  2.2631337890625\t ACC train:  0.8166666666666667\t ACC test:  0.8044444444444444\n",
      "\tEpoch 138: \tAverage Loss:  2.25923828125\t ACC train:  0.81\t ACC test:  0.8\n",
      "\tEpoch 139: \tAverage Loss:  2.2556982421875\t ACC train:  0.82\t ACC test:  0.8155555555555556\n",
      "\tEpoch 140: \tAverage Loss:  2.25542138671875\t ACC train:  0.8066666666666666\t ACC test:  0.8244444444444444\n",
      "\tEpoch 141: \tAverage Loss:  2.2536318359375\t ACC train:  0.8066666666666666\t ACC test:  0.82\n",
      "\tEpoch 142: \tAverage Loss:  2.248503173828125\t ACC train:  0.8233333333333334\t ACC test:  0.8288888888888889\n",
      "\tEpoch 143: \tAverage Loss:  2.253687255859375\t ACC train:  0.8233333333333334\t ACC test:  0.8155555555555556\n",
      "\tEpoch 144: \tAverage Loss:  2.247946044921875\t ACC train:  0.8233333333333334\t ACC test:  0.8311111111111111\n",
      "\tEpoch 145: \tAverage Loss:  2.2468544921875\t ACC train:  0.8233333333333334\t ACC test:  0.8355555555555556\n",
      "\tEpoch 146: \tAverage Loss:  2.245800048828125\t ACC train:  0.8433333333333334\t ACC test:  0.8444444444444444\n",
      "\tEpoch 147: \tAverage Loss:  2.238175537109375\t ACC train:  0.8233333333333334\t ACC test:  0.8311111111111111\n",
      "\tEpoch 148: \tAverage Loss:  2.235307373046875\t ACC train:  0.86\t ACC test:  0.8511111111111112\n",
      "\tEpoch 149: \tAverage Loss:  2.23804443359375\t ACC train:  0.8266666666666667\t ACC test:  0.8333333333333334\n",
      "\tEpoch 150: \tAverage Loss:  2.236007568359375\t ACC train:  0.86\t ACC test:  0.8577777777777778\n",
      "\tEpoch 151: \tAverage Loss:  2.23093359375\t ACC train:  0.84\t ACC test:  0.8555555555555555\n",
      "\tEpoch 152: \tAverage Loss:  2.232423583984375\t ACC train:  0.8366666666666667\t ACC test:  0.8466666666666667\n",
      "\tEpoch 153: \tAverage Loss:  2.225639404296875\t ACC train:  0.8466666666666667\t ACC test:  0.8533333333333334\n",
      "\tEpoch 154: \tAverage Loss:  2.22380810546875\t ACC train:  0.8633333333333333\t ACC test:  0.86\n",
      "\tEpoch 155: \tAverage Loss:  2.220007080078125\t ACC train:  0.8633333333333333\t ACC test:  0.8466666666666667\n",
      "\tEpoch 156: \tAverage Loss:  2.21894287109375\t ACC train:  0.86\t ACC test:  0.8577777777777778\n",
      "\tEpoch 157: \tAverage Loss:  2.2177958984375\t ACC train:  0.8566666666666667\t ACC test:  0.8488888888888889\n",
      "\tEpoch 158: \tAverage Loss:  2.20855419921875\t ACC train:  0.8666666666666667\t ACC test:  0.8666666666666667\n",
      "\tEpoch 159: \tAverage Loss:  2.2125107421875\t ACC train:  0.83\t ACC test:  0.8533333333333334\n",
      "\tEpoch 160: \tAverage Loss:  2.21749755859375\t ACC train:  0.89\t ACC test:  0.8377777777777777\n",
      "\tEpoch 161: \tAverage Loss:  2.215294189453125\t ACC train:  0.87\t ACC test:  0.8533333333333334\n",
      "\tEpoch 162: \tAverage Loss:  2.202232421875\t ACC train:  0.8566666666666667\t ACC test:  0.8711111111111111\n",
      "\tEpoch 163: \tAverage Loss:  2.208298828125\t ACC train:  0.8733333333333333\t ACC test:  0.8666666666666667\n",
      "\tEpoch 164: \tAverage Loss:  2.199502685546875\t ACC train:  0.8733333333333333\t ACC test:  0.8577777777777778\n",
      "\tEpoch 165: \tAverage Loss:  2.201452392578125\t ACC train:  0.87\t ACC test:  0.8688888888888889\n",
      "\tEpoch 166: \tAverage Loss:  2.200256591796875\t ACC train:  0.86\t ACC test:  0.8577777777777778\n",
      "\tEpoch 167: \tAverage Loss:  2.20020458984375\t ACC train:  0.85\t ACC test:  0.8577777777777778\n",
      "\tEpoch 168: \tAverage Loss:  2.19684326171875\t ACC train:  0.86\t ACC test:  0.8511111111111112\n",
      "\tEpoch 169: \tAverage Loss:  2.185584716796875\t ACC train:  0.8766666666666667\t ACC test:  0.8711111111111111\n",
      "\tEpoch 170: \tAverage Loss:  2.19333837890625\t ACC train:  0.86\t ACC test:  0.8666666666666667\n",
      "\tEpoch 171: \tAverage Loss:  2.1857109375\t ACC train:  0.8866666666666667\t ACC test:  0.8844444444444445\n",
      "\tEpoch 172: \tAverage Loss:  2.19541796875\t ACC train:  0.88\t ACC test:  0.8666666666666667\n",
      "\tEpoch 173: \tAverage Loss:  2.1817783203125\t ACC train:  0.9\t ACC test:  0.8644444444444445\n",
      "\tEpoch 174: \tAverage Loss:  2.18217822265625\t ACC train:  0.8733333333333333\t ACC test:  0.8733333333333333\n",
      "\tEpoch 175: \tAverage Loss:  2.16993115234375\t ACC train:  0.9\t ACC test:  0.86\n",
      "\tEpoch 176: \tAverage Loss:  2.1737978515625\t ACC train:  0.8866666666666667\t ACC test:  0.88\n",
      "\tEpoch 177: \tAverage Loss:  2.174890869140625\t ACC train:  0.9\t ACC test:  0.8577777777777778\n",
      "\tEpoch 178: \tAverage Loss:  2.17129541015625\t ACC train:  0.88\t ACC test:  0.8755555555555555\n",
      "\tEpoch 179: \tAverage Loss:  2.1658544921875\t ACC train:  0.8733333333333333\t ACC test:  0.8733333333333333\n",
      "\tEpoch 180: \tAverage Loss:  2.166561279296875\t ACC train:  0.8733333333333333\t ACC test:  0.8533333333333334\n",
      "\tEpoch 181: \tAverage Loss:  2.169170654296875\t ACC train:  0.8933333333333333\t ACC test:  0.8733333333333333\n",
      "\tEpoch 182: \tAverage Loss:  2.166583251953125\t ACC train:  0.8766666666666667\t ACC test:  0.8822222222222222\n",
      "\tEpoch 183: \tAverage Loss:  2.1631005859375\t ACC train:  0.88\t ACC test:  0.8911111111111111\n",
      "\tEpoch 184: \tAverage Loss:  2.16067041015625\t ACC train:  0.89\t ACC test:  0.8777777777777778\n",
      "\tEpoch 185: \tAverage Loss:  2.15512255859375\t ACC train:  0.88\t ACC test:  0.8733333333333333\n",
      "\tEpoch 186: \tAverage Loss:  2.151441162109375\t ACC train:  0.89\t ACC test:  0.8844444444444445\n",
      "\tEpoch 187: \tAverage Loss:  2.14924462890625\t ACC train:  0.8866666666666667\t ACC test:  0.8866666666666667\n",
      "\tEpoch 188: \tAverage Loss:  2.1389033203125\t ACC train:  0.8766666666666667\t ACC test:  0.8822222222222222\n",
      "\tEpoch 189: \tAverage Loss:  2.147075927734375\t ACC train:  0.8966666666666666\t ACC test:  0.8777777777777778\n",
      "\tEpoch 190: \tAverage Loss:  2.143130859375\t ACC train:  0.88\t ACC test:  0.88\n",
      "\tEpoch 191: \tAverage Loss:  2.144531005859375\t ACC train:  0.8966666666666666\t ACC test:  0.8755555555555555\n",
      "\tEpoch 192: \tAverage Loss:  2.136063720703125\t ACC train:  0.8633333333333333\t ACC test:  0.8777777777777778\n",
      "\tEpoch 193: \tAverage Loss:  2.143999267578125\t ACC train:  0.88\t ACC test:  0.88\n",
      "\tEpoch 194: \tAverage Loss:  2.132705078125\t ACC train:  0.9\t ACC test:  0.8777777777777778\n",
      "\tEpoch 195: \tAverage Loss:  2.132687255859375\t ACC train:  0.8833333333333333\t ACC test:  0.8777777777777778\n",
      "\tEpoch 196: \tAverage Loss:  2.132322021484375\t ACC train:  0.8866666666666667\t ACC test:  0.8822222222222222\n",
      "\tEpoch 197: \tAverage Loss:  2.13033642578125\t ACC train:  0.8833333333333333\t ACC test:  0.8777777777777778\n",
      "\tEpoch 198: \tAverage Loss:  2.12375\t ACC train:  0.8933333333333333\t ACC test:  0.8933333333333333\n",
      "\tEpoch 199: \tAverage Loss:  2.13111865234375\t ACC train:  0.8933333333333333\t ACC test:  0.8822222222222222\n",
      "\tEpoch 200: \tAverage Loss:  2.125114501953125\t ACC train:  0.8933333333333333\t ACC test:  0.8733333333333333\n",
      "\tEpoch 201: \tAverage Loss:  2.113287109375\t ACC train:  0.9033333333333333\t ACC test:  0.8866666666666667\n",
      "\tEpoch 202: \tAverage Loss:  2.1238232421875\t ACC train:  0.8866666666666667\t ACC test:  0.8822222222222222\n",
      "\tEpoch 203: \tAverage Loss:  2.11032666015625\t ACC train:  0.8866666666666667\t ACC test:  0.8844444444444445\n",
      "\tEpoch 204: \tAverage Loss:  2.1088798828125\t ACC train:  0.89\t ACC test:  0.8955555555555555\n",
      "\tEpoch 205: \tAverage Loss:  2.105150146484375\t ACC train:  0.8833333333333333\t ACC test:  0.8911111111111111\n",
      "\tEpoch 206: \tAverage Loss:  2.1003662109375\t ACC train:  0.8833333333333333\t ACC test:  0.8888888888888888\n",
      "\tEpoch 207: \tAverage Loss:  2.09682568359375\t ACC train:  0.8866666666666667\t ACC test:  0.8866666666666667\n",
      "\tEpoch 208: \tAverage Loss:  2.095215576171875\t ACC train:  0.8733333333333333\t ACC test:  0.8911111111111111\n",
      "\tEpoch 209: \tAverage Loss:  2.0890400390625\t ACC train:  0.8933333333333333\t ACC test:  0.8777777777777778\n",
      "\tEpoch 210: \tAverage Loss:  2.086613037109375\t ACC train:  0.8866666666666667\t ACC test:  0.8711111111111111\n",
      "\tEpoch 211: \tAverage Loss:  2.0870302734375\t ACC train:  0.87\t ACC test:  0.8666666666666667\n",
      "\tEpoch 212: \tAverage Loss:  2.08983984375\t ACC train:  0.89\t ACC test:  0.8688888888888889\n",
      "\tEpoch 213: \tAverage Loss:  2.08214697265625\t ACC train:  0.8766666666666667\t ACC test:  0.8822222222222222\n",
      "\tEpoch 214: \tAverage Loss:  2.080338134765625\t ACC train:  0.8566666666666667\t ACC test:  0.8644444444444445\n",
      "\tEpoch 215: \tAverage Loss:  2.081804443359375\t ACC train:  0.8666666666666667\t ACC test:  0.88\n",
      "\tEpoch 216: \tAverage Loss:  2.071760498046875\t ACC train:  0.8833333333333333\t ACC test:  0.8755555555555555\n",
      "\tEpoch 217: \tAverage Loss:  2.0617919921875\t ACC train:  0.8866666666666667\t ACC test:  0.8711111111111111\n",
      "\tEpoch 218: \tAverage Loss:  2.04840234375\t ACC train:  0.89\t ACC test:  0.8711111111111111\n",
      "\tEpoch 219: \tAverage Loss:  2.060259033203125\t ACC train:  0.8633333333333333\t ACC test:  0.86\n",
      "\tEpoch 220: \tAverage Loss:  2.054142578125\t ACC train:  0.8833333333333333\t ACC test:  0.8666666666666667\n",
      "\tEpoch 221: \tAverage Loss:  2.05760986328125\t ACC train:  0.86\t ACC test:  0.8644444444444445\n",
      "\tEpoch 222: \tAverage Loss:  2.049800537109375\t ACC train:  0.8566666666666667\t ACC test:  0.8711111111111111\n",
      "\tEpoch 223: \tAverage Loss:  2.038777099609375\t ACC train:  0.86\t ACC test:  0.8555555555555555\n",
      "\tEpoch 224: \tAverage Loss:  2.030892578125\t ACC train:  0.8666666666666667\t ACC test:  0.8533333333333334\n",
      "\tEpoch 225: \tAverage Loss:  2.026201904296875\t ACC train:  0.86\t ACC test:  0.86\n",
      "\tEpoch 226: \tAverage Loss:  2.031924072265625\t ACC train:  0.8666666666666667\t ACC test:  0.8511111111111112\n",
      "\tEpoch 227: \tAverage Loss:  2.012419189453125\t ACC train:  0.8566666666666667\t ACC test:  0.86\n",
      "\tEpoch 228: \tAverage Loss:  2.021391357421875\t ACC train:  0.87\t ACC test:  0.8533333333333334\n",
      "\tEpoch 229: \tAverage Loss:  2.002509033203125\t ACC train:  0.8733333333333333\t ACC test:  0.8533333333333334\n",
      "\tEpoch 230: \tAverage Loss:  1.992982666015625\t ACC train:  0.8666666666666667\t ACC test:  0.8444444444444444\n",
      "\tEpoch 231: \tAverage Loss:  2.00296240234375\t ACC train:  0.8566666666666667\t ACC test:  0.8422222222222222\n",
      "\tEpoch 232: \tAverage Loss:  1.9955389404296875\t ACC train:  0.85\t ACC test:  0.84\n",
      "\tEpoch 233: \tAverage Loss:  1.9935048828125\t ACC train:  0.8466666666666667\t ACC test:  0.8311111111111111\n",
      "\tEpoch 234: \tAverage Loss:  1.980611083984375\t ACC train:  0.8566666666666667\t ACC test:  0.8355555555555556\n",
      "\tEpoch 235: \tAverage Loss:  1.9781151123046874\t ACC train:  0.8633333333333333\t ACC test:  0.84\n",
      "\tEpoch 236: \tAverage Loss:  1.9745673828125\t ACC train:  0.8433333333333334\t ACC test:  0.8333333333333334\n",
      "\tEpoch 237: \tAverage Loss:  1.9692764892578125\t ACC train:  0.8466666666666667\t ACC test:  0.8333333333333334\n",
      "\tEpoch 238: \tAverage Loss:  1.9747435302734375\t ACC train:  0.8633333333333333\t ACC test:  0.8311111111111111\n",
      "\tEpoch 239: \tAverage Loss:  1.9410728759765625\t ACC train:  0.86\t ACC test:  0.8333333333333334\n",
      "\tEpoch 240: \tAverage Loss:  1.9458758544921875\t ACC train:  0.8566666666666667\t ACC test:  0.8422222222222222\n",
      "\tEpoch 241: \tAverage Loss:  1.9440450439453125\t ACC train:  0.8466666666666667\t ACC test:  0.8355555555555556\n",
      "\tEpoch 242: \tAverage Loss:  1.94633349609375\t ACC train:  0.8433333333333334\t ACC test:  0.8244444444444444\n",
      "\tEpoch 243: \tAverage Loss:  1.9269696044921876\t ACC train:  0.85\t ACC test:  0.8311111111111111\n",
      "\tEpoch 244: \tAverage Loss:  1.929219482421875\t ACC train:  0.8466666666666667\t ACC test:  0.8244444444444444\n",
      "\tEpoch 245: \tAverage Loss:  1.9142608642578125\t ACC train:  0.8366666666666667\t ACC test:  0.8266666666666667\n",
      "\tEpoch 246: \tAverage Loss:  1.905781982421875\t ACC train:  0.8533333333333334\t ACC test:  0.8266666666666667\n",
      "\tEpoch 247: \tAverage Loss:  1.899754638671875\t ACC train:  0.8366666666666667\t ACC test:  0.8288888888888889\n",
      "\tEpoch 248: \tAverage Loss:  1.899730224609375\t ACC train:  0.8366666666666667\t ACC test:  0.8311111111111111\n",
      "\tEpoch 249: \tAverage Loss:  1.894146484375\t ACC train:  0.8366666666666667\t ACC test:  0.8133333333333334\n",
      "\tEpoch 250: \tAverage Loss:  1.878562255859375\t ACC train:  0.8466666666666667\t ACC test:  0.82\n",
      "\tEpoch 251: \tAverage Loss:  1.886113037109375\t ACC train:  0.83\t ACC test:  0.82\n",
      "\tEpoch 252: \tAverage Loss:  1.879149658203125\t ACC train:  0.8366666666666667\t ACC test:  0.8244444444444444\n",
      "\tEpoch 253: \tAverage Loss:  1.8497025146484376\t ACC train:  0.8333333333333334\t ACC test:  0.8222222222222222\n",
      "\tEpoch 254: \tAverage Loss:  1.885259521484375\t ACC train:  0.82\t ACC test:  0.8222222222222222\n",
      "\tEpoch 255: \tAverage Loss:  1.8457894287109375\t ACC train:  0.8366666666666667\t ACC test:  0.8177777777777778\n",
      "\tEpoch 256: \tAverage Loss:  1.8405672607421875\t ACC train:  0.8266666666666667\t ACC test:  0.8155555555555556\n",
      "\tEpoch 257: \tAverage Loss:  1.843208251953125\t ACC train:  0.83\t ACC test:  0.8044444444444444\n",
      "\tEpoch 258: \tAverage Loss:  1.8322366943359376\t ACC train:  0.82\t ACC test:  0.8133333333333334\n",
      "\tEpoch 259: \tAverage Loss:  1.832619873046875\t ACC train:  0.8233333333333334\t ACC test:  0.7955555555555556\n",
      "\tEpoch 260: \tAverage Loss:  1.8202724609375\t ACC train:  0.82\t ACC test:  0.7933333333333333\n",
      "\tEpoch 261: \tAverage Loss:  1.83004931640625\t ACC train:  0.8066666666666666\t ACC test:  0.8066666666666666\n",
      "\tEpoch 262: \tAverage Loss:  1.81579345703125\t ACC train:  0.8033333333333333\t ACC test:  0.8022222222222222\n",
      "\tEpoch 263: \tAverage Loss:  1.815474365234375\t ACC train:  0.82\t ACC test:  0.7955555555555556\n",
      "\tEpoch 264: \tAverage Loss:  1.8099918212890624\t ACC train:  0.8133333333333334\t ACC test:  0.7911111111111111\n",
      "\tEpoch 265: \tAverage Loss:  1.78994580078125\t ACC train:  0.8266666666666667\t ACC test:  0.7866666666666666\n",
      "\tEpoch 266: \tAverage Loss:  1.7803045654296874\t ACC train:  0.83\t ACC test:  0.7888888888888889\n",
      "\tEpoch 267: \tAverage Loss:  1.785482666015625\t ACC train:  0.8133333333333334\t ACC test:  0.78\n",
      "\tEpoch 268: \tAverage Loss:  1.7922369384765624\t ACC train:  0.83\t ACC test:  0.7866666666666666\n",
      "\tEpoch 269: \tAverage Loss:  1.7677723388671875\t ACC train:  0.81\t ACC test:  0.7844444444444445\n",
      "\tEpoch 270: \tAverage Loss:  1.7853336181640624\t ACC train:  0.8\t ACC test:  0.7911111111111111\n",
      "\tEpoch 271: \tAverage Loss:  1.758211669921875\t ACC train:  0.8233333333333334\t ACC test:  0.7888888888888889\n",
      "\tEpoch 272: \tAverage Loss:  1.764954345703125\t ACC train:  0.8166666666666667\t ACC test:  0.7711111111111111\n",
      "\tEpoch 273: \tAverage Loss:  1.7470106201171876\t ACC train:  0.8166666666666667\t ACC test:  0.7822222222222223\n",
      "\tEpoch 274: \tAverage Loss:  1.75710205078125\t ACC train:  0.8066666666666666\t ACC test:  0.78\n",
      "\tEpoch 275: \tAverage Loss:  1.7424339599609375\t ACC train:  0.8166666666666667\t ACC test:  0.7777777777777778\n",
      "\tEpoch 276: \tAverage Loss:  1.7308851318359375\t ACC train:  0.82\t ACC test:  0.78\n",
      "\tEpoch 277: \tAverage Loss:  1.729812255859375\t ACC train:  0.8333333333333334\t ACC test:  0.7822222222222223\n",
      "\tEpoch 278: \tAverage Loss:  1.7121505126953125\t ACC train:  0.83\t ACC test:  0.78\n",
      "\tEpoch 279: \tAverage Loss:  1.711111083984375\t ACC train:  0.81\t ACC test:  0.7711111111111111\n",
      "\tEpoch 280: \tAverage Loss:  1.71500048828125\t ACC train:  0.8133333333333334\t ACC test:  0.7777777777777778\n",
      "\tEpoch 281: \tAverage Loss:  1.708395751953125\t ACC train:  0.8266666666666667\t ACC test:  0.7777777777777778\n",
      "\tEpoch 282: \tAverage Loss:  1.7017587890625\t ACC train:  0.8266666666666667\t ACC test:  0.7866666666666666\n",
      "\tEpoch 283: \tAverage Loss:  1.7018721923828124\t ACC train:  0.83\t ACC test:  0.78\n",
      "\tEpoch 284: \tAverage Loss:  1.6894873046875\t ACC train:  0.8266666666666667\t ACC test:  0.7755555555555556\n",
      "\tEpoch 285: \tAverage Loss:  1.697329833984375\t ACC train:  0.8166666666666667\t ACC test:  0.7755555555555556\n",
      "\tEpoch 286: \tAverage Loss:  1.6829364013671875\t ACC train:  0.82\t ACC test:  0.7755555555555556\n",
      "\tEpoch 287: \tAverage Loss:  1.668864013671875\t ACC train:  0.8266666666666667\t ACC test:  0.7844444444444445\n",
      "\tEpoch 288: \tAverage Loss:  1.67416162109375\t ACC train:  0.82\t ACC test:  0.7844444444444445\n",
      "\tEpoch 289: \tAverage Loss:  1.663416015625\t ACC train:  0.81\t ACC test:  0.7711111111111111\n",
      "\tEpoch 290: \tAverage Loss:  1.6671904296875\t ACC train:  0.82\t ACC test:  0.7666666666666667\n",
      "\tEpoch 291: \tAverage Loss:  1.6687200927734376\t ACC train:  0.8133333333333334\t ACC test:  0.7777777777777778\n",
      "\tEpoch 292: \tAverage Loss:  1.6584722900390625\t ACC train:  0.8233333333333334\t ACC test:  0.7777777777777778\n",
      "\tEpoch 293: \tAverage Loss:  1.643617919921875\t ACC train:  0.8033333333333333\t ACC test:  0.7866666666666666\n",
      "\tEpoch 294: \tAverage Loss:  1.642236083984375\t ACC train:  0.8266666666666667\t ACC test:  0.7822222222222223\n",
      "\tEpoch 295: \tAverage Loss:  1.636838134765625\t ACC train:  0.79\t ACC test:  0.7755555555555556\n",
      "\tEpoch 296: \tAverage Loss:  1.6359813232421876\t ACC train:  0.8233333333333334\t ACC test:  0.7733333333333333\n",
      "\tEpoch 297: \tAverage Loss:  1.628690185546875\t ACC train:  0.8166666666666667\t ACC test:  0.7755555555555556\n",
      "\tEpoch 298: \tAverage Loss:  1.6291890869140624\t ACC train:  0.8166666666666667\t ACC test:  0.7777777777777778\n",
      "\tEpoch 299: \tAverage Loss:  1.625174072265625\t ACC train:  0.8166666666666667\t ACC test:  0.7733333333333333\n",
      "\tEpoch 300: \tAverage Loss:  1.6228548583984375\t ACC train:  0.81\t ACC test:  0.7755555555555556\n",
      "\tEpoch 301: \tAverage Loss:  1.615682373046875\t ACC train:  0.8233333333333334\t ACC test:  0.7822222222222223\n",
      "\tEpoch 302: \tAverage Loss:  1.621402587890625\t ACC train:  0.8266666666666667\t ACC test:  0.7688888888888888\n",
      "\tEpoch 303: \tAverage Loss:  1.6268919677734375\t ACC train:  0.8133333333333334\t ACC test:  0.7844444444444445\n",
      "\tEpoch 304: \tAverage Loss:  1.610087158203125\t ACC train:  0.8166666666666667\t ACC test:  0.7755555555555556\n",
      "\tEpoch 305: \tAverage Loss:  1.6024613037109374\t ACC train:  0.82\t ACC test:  0.7844444444444445\n",
      "\tEpoch 306: \tAverage Loss:  1.6021783447265625\t ACC train:  0.81\t ACC test:  0.7733333333333333\n",
      "\tEpoch 307: \tAverage Loss:  1.5935853271484375\t ACC train:  0.82\t ACC test:  0.78\n",
      "\tEpoch 308: \tAverage Loss:  1.596755615234375\t ACC train:  0.8233333333333334\t ACC test:  0.7844444444444445\n",
      "\tEpoch 309: \tAverage Loss:  1.598061767578125\t ACC train:  0.8133333333333334\t ACC test:  0.7777777777777778\n",
      "\tEpoch 310: \tAverage Loss:  1.59227587890625\t ACC train:  0.8266666666666667\t ACC test:  0.78\n",
      "\tEpoch 311: \tAverage Loss:  1.5935107421875\t ACC train:  0.81\t ACC test:  0.7755555555555556\n",
      "\tEpoch 312: \tAverage Loss:  1.5916240234375\t ACC train:  0.8233333333333334\t ACC test:  0.78\n",
      "\tEpoch 313: \tAverage Loss:  1.5833946533203125\t ACC train:  0.82\t ACC test:  0.7866666666666666\n",
      "\tEpoch 314: \tAverage Loss:  1.5807445068359376\t ACC train:  0.8133333333333334\t ACC test:  0.7888888888888889\n",
      "\tEpoch 315: \tAverage Loss:  1.5808951416015624\t ACC train:  0.8166666666666667\t ACC test:  0.78\n",
      "\tEpoch 316: \tAverage Loss:  1.5767117919921876\t ACC train:  0.81\t ACC test:  0.7711111111111111\n",
      "\tEpoch 317: \tAverage Loss:  1.576397705078125\t ACC train:  0.8133333333333334\t ACC test:  0.7777777777777778\n",
      "\tEpoch 318: \tAverage Loss:  1.5737528076171876\t ACC train:  0.8233333333333334\t ACC test:  0.7866666666666666\n",
      "\tEpoch 319: \tAverage Loss:  1.572071044921875\t ACC train:  0.8066666666666666\t ACC test:  0.7777777777777778\n",
      "\tEpoch 320: \tAverage Loss:  1.5671795654296874\t ACC train:  0.8166666666666667\t ACC test:  0.7866666666666666\n",
      "\tEpoch 321: \tAverage Loss:  1.564727294921875\t ACC train:  0.82\t ACC test:  0.7733333333333333\n",
      "\tEpoch 322: \tAverage Loss:  1.5610498046875\t ACC train:  0.8\t ACC test:  0.7666666666666667\n",
      "\tEpoch 323: \tAverage Loss:  1.55850390625\t ACC train:  0.81\t ACC test:  0.7666666666666667\n",
      "\tEpoch 324: \tAverage Loss:  1.557287841796875\t ACC train:  0.8166666666666667\t ACC test:  0.7666666666666667\n",
      "\tEpoch 325: \tAverage Loss:  1.5557252197265625\t ACC train:  0.81\t ACC test:  0.7622222222222222\n",
      "\tEpoch 326: \tAverage Loss:  1.5617374267578126\t ACC train:  0.81\t ACC test:  0.76\n",
      "\tEpoch 327: \tAverage Loss:  1.5538739013671874\t ACC train:  0.8033333333333333\t ACC test:  0.7577777777777778\n",
      "\tEpoch 328: \tAverage Loss:  1.5483885498046874\t ACC train:  0.7933333333333333\t ACC test:  0.7711111111111111\n",
      "\tEpoch 329: \tAverage Loss:  1.552360595703125\t ACC train:  0.8\t ACC test:  0.7577777777777778\n",
      "\tEpoch 330: \tAverage Loss:  1.5455408935546875\t ACC train:  0.8033333333333333\t ACC test:  0.7533333333333333\n",
      "\tEpoch 331: \tAverage Loss:  1.5451317138671874\t ACC train:  0.8\t ACC test:  0.7622222222222222\n",
      "\tEpoch 332: \tAverage Loss:  1.558129638671875\t ACC train:  0.7866666666666666\t ACC test:  0.7511111111111111\n",
      "\tEpoch 333: \tAverage Loss:  1.5412127685546875\t ACC train:  0.7966666666666666\t ACC test:  0.7333333333333333\n",
      "\tEpoch 334: \tAverage Loss:  1.53565478515625\t ACC train:  0.7833333333333333\t ACC test:  0.74\n",
      "\tEpoch 335: \tAverage Loss:  1.535955322265625\t ACC train:  0.7933333333333333\t ACC test:  0.7422222222222222\n",
      "\tEpoch 336: \tAverage Loss:  1.538511474609375\t ACC train:  0.79\t ACC test:  0.7555555555555555\n",
      "\tEpoch 337: \tAverage Loss:  1.533737060546875\t ACC train:  0.79\t ACC test:  0.7444444444444445\n",
      "\tEpoch 338: \tAverage Loss:  1.534140869140625\t ACC train:  0.7866666666666666\t ACC test:  0.7488888888888889\n",
      "\tEpoch 339: \tAverage Loss:  1.5289837646484374\t ACC train:  0.7866666666666666\t ACC test:  0.7444444444444445\n",
      "\tEpoch 340: \tAverage Loss:  1.5354678955078125\t ACC train:  0.8\t ACC test:  0.7466666666666667\n",
      "\tEpoch 341: \tAverage Loss:  1.5352479248046875\t ACC train:  0.7933333333333333\t ACC test:  0.7533333333333333\n",
      "\tEpoch 342: \tAverage Loss:  1.5345401611328124\t ACC train:  0.7966666666666666\t ACC test:  0.7444444444444445\n",
      "\tEpoch 343: \tAverage Loss:  1.5286038818359375\t ACC train:  0.79\t ACC test:  0.74\n",
      "\tEpoch 344: \tAverage Loss:  1.523206787109375\t ACC train:  0.7866666666666666\t ACC test:  0.7466666666666667\n",
      "\tEpoch 345: \tAverage Loss:  1.524436279296875\t ACC train:  0.7866666666666666\t ACC test:  0.7422222222222222\n",
      "\tEpoch 346: \tAverage Loss:  1.5234510498046876\t ACC train:  0.7833333333333333\t ACC test:  0.7422222222222222\n",
      "\tEpoch 347: \tAverage Loss:  1.5241156005859375\t ACC train:  0.79\t ACC test:  0.7377777777777778\n",
      "\tEpoch 348: \tAverage Loss:  1.51952197265625\t ACC train:  0.7833333333333333\t ACC test:  0.7333333333333333\n",
      "\tEpoch 349: \tAverage Loss:  1.51351904296875\t ACC train:  0.7766666666666666\t ACC test:  0.7333333333333333\n",
      "\tEpoch 350: \tAverage Loss:  1.5205010986328125\t ACC train:  0.78\t ACC test:  0.7311111111111112\n",
      "\tEpoch 351: \tAverage Loss:  1.51493115234375\t ACC train:  0.7833333333333333\t ACC test:  0.7333333333333333\n",
      "\tEpoch 352: \tAverage Loss:  1.5162529296875\t ACC train:  0.7866666666666666\t ACC test:  0.7311111111111112\n",
      "\tEpoch 353: \tAverage Loss:  1.5143060302734375\t ACC train:  0.7766666666666666\t ACC test:  0.7288888888888889\n",
      "\tEpoch 354: \tAverage Loss:  1.512811279296875\t ACC train:  0.7633333333333333\t ACC test:  0.7222222222222222\n",
      "\tEpoch 355: \tAverage Loss:  1.50983935546875\t ACC train:  0.7833333333333333\t ACC test:  0.7288888888888889\n",
      "\tEpoch 356: \tAverage Loss:  1.5090364990234375\t ACC train:  0.7733333333333333\t ACC test:  0.7266666666666667\n",
      "\tEpoch 357: \tAverage Loss:  1.508042236328125\t ACC train:  0.7666666666666667\t ACC test:  0.7244444444444444\n",
      "\tEpoch 358: \tAverage Loss:  1.5054044189453124\t ACC train:  0.7633333333333333\t ACC test:  0.72\n",
      "\tEpoch 359: \tAverage Loss:  1.5061156005859375\t ACC train:  0.7566666666666667\t ACC test:  0.7222222222222222\n",
      "\tEpoch 360: \tAverage Loss:  1.505267822265625\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 361: \tAverage Loss:  1.5043619384765625\t ACC train:  0.7766666666666666\t ACC test:  0.7311111111111112\n",
      "\tEpoch 362: \tAverage Loss:  1.508257568359375\t ACC train:  0.77\t ACC test:  0.72\n",
      "\tEpoch 363: \tAverage Loss:  1.5023134765625\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 364: \tAverage Loss:  1.500584228515625\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 365: \tAverage Loss:  1.50290283203125\t ACC train:  0.7666666666666667\t ACC test:  0.7244444444444444\n",
      "\tEpoch 366: \tAverage Loss:  1.4986668701171875\t ACC train:  0.7766666666666666\t ACC test:  0.7244444444444444\n",
      "\tEpoch 367: \tAverage Loss:  1.4942020263671876\t ACC train:  0.7766666666666666\t ACC test:  0.72\n",
      "\tEpoch 368: \tAverage Loss:  1.497292724609375\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 369: \tAverage Loss:  1.4923299560546874\t ACC train:  0.7533333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 370: \tAverage Loss:  1.4940426025390625\t ACC train:  0.7566666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 371: \tAverage Loss:  1.49311767578125\t ACC train:  0.76\t ACC test:  0.7266666666666667\n",
      "\tEpoch 372: \tAverage Loss:  1.4940823974609374\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 373: \tAverage Loss:  1.489108642578125\t ACC train:  0.7666666666666667\t ACC test:  0.72\n",
      "\tEpoch 374: \tAverage Loss:  1.48483349609375\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 375: \tAverage Loss:  1.4897806396484374\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 376: \tAverage Loss:  1.4879678955078126\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 377: \tAverage Loss:  1.484955810546875\t ACC train:  0.7666666666666667\t ACC test:  0.7244444444444444\n",
      "\tEpoch 378: \tAverage Loss:  1.484367919921875\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 379: \tAverage Loss:  1.482092041015625\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 380: \tAverage Loss:  1.4833360595703124\t ACC train:  0.76\t ACC test:  0.7177777777777777\n",
      "\tEpoch 381: \tAverage Loss:  1.4823973388671876\t ACC train:  0.7666666666666667\t ACC test:  0.7222222222222222\n",
      "\tEpoch 382: \tAverage Loss:  1.4849151611328124\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 383: \tAverage Loss:  1.4835389404296875\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 384: \tAverage Loss:  1.481613037109375\t ACC train:  0.7566666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 385: \tAverage Loss:  1.4814530029296875\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 386: \tAverage Loss:  1.477517333984375\t ACC train:  0.7633333333333333\t ACC test:  0.72\n",
      "\tEpoch 387: \tAverage Loss:  1.48189794921875\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 388: \tAverage Loss:  1.47571630859375\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 389: \tAverage Loss:  1.474542724609375\t ACC train:  0.7566666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 390: \tAverage Loss:  1.478686767578125\t ACC train:  0.76\t ACC test:  0.7155555555555555\n",
      "\tEpoch 391: \tAverage Loss:  1.47650830078125\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 392: \tAverage Loss:  1.4729571533203125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 393: \tAverage Loss:  1.476419677734375\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 394: \tAverage Loss:  1.4728570556640626\t ACC train:  0.77\t ACC test:  0.7066666666666667\n",
      "\tEpoch 395: \tAverage Loss:  1.47623876953125\t ACC train:  0.76\t ACC test:  0.7066666666666667\n",
      "\tEpoch 396: \tAverage Loss:  1.469947265625\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 397: \tAverage Loss:  1.4741510009765626\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 398: \tAverage Loss:  1.4707371826171876\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 399: \tAverage Loss:  1.466983154296875\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 400: \tAverage Loss:  1.472874755859375\t ACC train:  0.7566666666666667\t ACC test:  0.7066666666666667\n",
      "\tEpoch 401: \tAverage Loss:  1.4701226806640626\t ACC train:  0.7633333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 402: \tAverage Loss:  1.467772705078125\t ACC train:  0.77\t ACC test:  0.72\n",
      "\tEpoch 403: \tAverage Loss:  1.468349609375\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 404: \tAverage Loss:  1.4658389892578125\t ACC train:  0.76\t ACC test:  0.7088888888888889\n",
      "\tEpoch 405: \tAverage Loss:  1.46446826171875\t ACC train:  0.7633333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 406: \tAverage Loss:  1.4682164306640626\t ACC train:  0.7633333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 407: \tAverage Loss:  1.463449951171875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 408: \tAverage Loss:  1.467423095703125\t ACC train:  0.77\t ACC test:  0.7088888888888889\n",
      "\tEpoch 409: \tAverage Loss:  1.463387939453125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 410: \tAverage Loss:  1.4622669677734375\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 411: \tAverage Loss:  1.4626131591796876\t ACC train:  0.77\t ACC test:  0.7022222222222222\n",
      "\tEpoch 412: \tAverage Loss:  1.463860107421875\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 413: \tAverage Loss:  1.4587235107421874\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 414: \tAverage Loss:  1.4620155029296875\t ACC train:  0.77\t ACC test:  0.7088888888888889\n",
      "\tEpoch 415: \tAverage Loss:  1.460801025390625\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 416: \tAverage Loss:  1.4611988525390625\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 417: \tAverage Loss:  1.4590343017578125\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 418: \tAverage Loss:  1.458172607421875\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 419: \tAverage Loss:  1.4616116943359374\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 420: \tAverage Loss:  1.4603184814453125\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 421: \tAverage Loss:  1.456364990234375\t ACC train:  0.76\t ACC test:  0.7066666666666667\n",
      "\tEpoch 422: \tAverage Loss:  1.45709521484375\t ACC train:  0.77\t ACC test:  0.7044444444444444\n",
      "\tEpoch 423: \tAverage Loss:  1.4533206787109374\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 424: \tAverage Loss:  1.455480712890625\t ACC train:  0.7566666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 425: \tAverage Loss:  1.45600634765625\t ACC train:  0.7633333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 426: \tAverage Loss:  1.4553380126953126\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 427: \tAverage Loss:  1.453858642578125\t ACC train:  0.76\t ACC test:  0.7044444444444444\n",
      "\tEpoch 428: \tAverage Loss:  1.4524229736328125\t ACC train:  0.7633333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 429: \tAverage Loss:  1.455373779296875\t ACC train:  0.76\t ACC test:  0.7044444444444444\n",
      "\tEpoch 430: \tAverage Loss:  1.4540255126953125\t ACC train:  0.7666666666666667\t ACC test:  0.7044444444444444\n",
      "\tEpoch 431: \tAverage Loss:  1.4504197998046875\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 432: \tAverage Loss:  1.450496826171875\t ACC train:  0.76\t ACC test:  0.7066666666666667\n",
      "\tEpoch 433: \tAverage Loss:  1.4537196044921874\t ACC train:  0.7533333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 434: \tAverage Loss:  1.453324462890625\t ACC train:  0.76\t ACC test:  0.7066666666666667\n",
      "\tEpoch 435: \tAverage Loss:  1.452005615234375\t ACC train:  0.7566666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 436: \tAverage Loss:  1.4516365966796876\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 437: \tAverage Loss:  1.44917236328125\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 438: \tAverage Loss:  1.4506676025390626\t ACC train:  0.76\t ACC test:  0.7044444444444444\n",
      "\tEpoch 439: \tAverage Loss:  1.448796875\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 440: \tAverage Loss:  1.4490546875\t ACC train:  0.76\t ACC test:  0.7066666666666667\n",
      "\tEpoch 441: \tAverage Loss:  1.4507122802734376\t ACC train:  0.7566666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 442: \tAverage Loss:  1.4450628662109375\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 443: \tAverage Loss:  1.4514228515625\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 444: \tAverage Loss:  1.447266845703125\t ACC train:  0.7533333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 445: \tAverage Loss:  1.446912353515625\t ACC train:  0.7566666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 446: \tAverage Loss:  1.4475740966796875\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 447: \tAverage Loss:  1.446936279296875\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 448: \tAverage Loss:  1.4488447265625\t ACC train:  0.76\t ACC test:  0.7088888888888889\n",
      "\tEpoch 449: \tAverage Loss:  1.4474736328125\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 450: \tAverage Loss:  1.4466083984375\t ACC train:  0.7666666666666667\t ACC test:  0.7044444444444444\n",
      "\tEpoch 451: \tAverage Loss:  1.4442288818359375\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 452: \tAverage Loss:  1.443789794921875\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 453: \tAverage Loss:  1.4418184814453125\t ACC train:  0.7633333333333333\t ACC test:  0.7022222222222222\n",
      "\tEpoch 454: \tAverage Loss:  1.44468994140625\t ACC train:  0.76\t ACC test:  0.7088888888888889\n",
      "\tEpoch 455: \tAverage Loss:  1.4429259033203126\t ACC train:  0.7566666666666667\t ACC test:  0.7066666666666667\n",
      "\tEpoch 456: \tAverage Loss:  1.4418834228515625\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 457: \tAverage Loss:  1.4438203125\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 458: \tAverage Loss:  1.441359375\t ACC train:  0.7566666666666667\t ACC test:  0.7066666666666667\n",
      "\tEpoch 459: \tAverage Loss:  1.44358935546875\t ACC train:  0.7566666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 460: \tAverage Loss:  1.442387939453125\t ACC train:  0.7566666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 461: \tAverage Loss:  1.439787109375\t ACC train:  0.77\t ACC test:  0.7088888888888889\n",
      "\tEpoch 462: \tAverage Loss:  1.4396317138671875\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 463: \tAverage Loss:  1.441086181640625\t ACC train:  0.7566666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 464: \tAverage Loss:  1.439719482421875\t ACC train:  0.76\t ACC test:  0.7066666666666667\n",
      "\tEpoch 465: \tAverage Loss:  1.4394329833984374\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 466: \tAverage Loss:  1.4373140869140626\t ACC train:  0.76\t ACC test:  0.7044444444444444\n",
      "\tEpoch 467: \tAverage Loss:  1.4402562255859375\t ACC train:  0.7566666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 468: \tAverage Loss:  1.4381424560546876\t ACC train:  0.7633333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 469: \tAverage Loss:  1.438992919921875\t ACC train:  0.7566666666666667\t ACC test:  0.7066666666666667\n",
      "\tEpoch 470: \tAverage Loss:  1.4367030029296874\t ACC train:  0.7633333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 471: \tAverage Loss:  1.4361453857421875\t ACC train:  0.7633333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 472: \tAverage Loss:  1.4358922119140625\t ACC train:  0.76\t ACC test:  0.7066666666666667\n",
      "\tEpoch 473: \tAverage Loss:  1.4374171142578125\t ACC train:  0.76\t ACC test:  0.7155555555555555\n",
      "\tEpoch 474: \tAverage Loss:  1.43663720703125\t ACC train:  0.76\t ACC test:  0.7088888888888889\n",
      "\tEpoch 475: \tAverage Loss:  1.435941650390625\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 476: \tAverage Loss:  1.4350467529296875\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 477: \tAverage Loss:  1.4349752197265624\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 478: \tAverage Loss:  1.4352652587890624\t ACC train:  0.7566666666666667\t ACC test:  0.7066666666666667\n",
      "\tEpoch 479: \tAverage Loss:  1.4354339599609376\t ACC train:  0.7566666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 480: \tAverage Loss:  1.4350220947265624\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 481: \tAverage Loss:  1.4360758056640626\t ACC train:  0.7666666666666667\t ACC test:  0.7066666666666667\n",
      "\tEpoch 482: \tAverage Loss:  1.435597412109375\t ACC train:  0.7566666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 483: \tAverage Loss:  1.435584228515625\t ACC train:  0.7633333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 484: \tAverage Loss:  1.433986572265625\t ACC train:  0.7633333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 485: \tAverage Loss:  1.434345703125\t ACC train:  0.7566666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 486: \tAverage Loss:  1.43426123046875\t ACC train:  0.7533333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 487: \tAverage Loss:  1.433568359375\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 488: \tAverage Loss:  1.432609375\t ACC train:  0.77\t ACC test:  0.7088888888888889\n",
      "\tEpoch 489: \tAverage Loss:  1.4318641357421875\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 490: \tAverage Loss:  1.430579833984375\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 491: \tAverage Loss:  1.4327359619140625\t ACC train:  0.7566666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 492: \tAverage Loss:  1.430832763671875\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 493: \tAverage Loss:  1.433043212890625\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 494: \tAverage Loss:  1.4333087158203126\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 495: \tAverage Loss:  1.43085888671875\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 496: \tAverage Loss:  1.4318983154296876\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 497: \tAverage Loss:  1.43100732421875\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 498: \tAverage Loss:  1.4310552978515625\t ACC train:  0.76\t ACC test:  0.7066666666666667\n",
      "\tEpoch 499: \tAverage Loss:  1.4318575439453125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 500: \tAverage Loss:  1.4289268798828125\t ACC train:  0.77\t ACC test:  0.7066666666666667\n",
      "\tEpoch 501: \tAverage Loss:  1.428243896484375\t ACC train:  0.76\t ACC test:  0.7066666666666667\n",
      "\tEpoch 502: \tAverage Loss:  1.4292359619140624\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 503: \tAverage Loss:  1.428638427734375\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 504: \tAverage Loss:  1.4283409423828124\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 505: \tAverage Loss:  1.429111572265625\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 506: \tAverage Loss:  1.428168212890625\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 507: \tAverage Loss:  1.4278935546875\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 508: \tAverage Loss:  1.4271981201171875\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 509: \tAverage Loss:  1.4288779296875\t ACC train:  0.7566666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 510: \tAverage Loss:  1.4273572998046875\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 511: \tAverage Loss:  1.42993017578125\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 512: \tAverage Loss:  1.4261973876953125\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 513: \tAverage Loss:  1.4272384033203125\t ACC train:  0.76\t ACC test:  0.7088888888888889\n",
      "\tEpoch 514: \tAverage Loss:  1.42755615234375\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 515: \tAverage Loss:  1.427167724609375\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 516: \tAverage Loss:  1.427001708984375\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 517: \tAverage Loss:  1.4254263916015626\t ACC train:  0.76\t ACC test:  0.7088888888888889\n",
      "\tEpoch 518: \tAverage Loss:  1.4269420166015625\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 519: \tAverage Loss:  1.4252041015625\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 520: \tAverage Loss:  1.423908447265625\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 521: \tAverage Loss:  1.4254217529296875\t ACC train:  0.77\t ACC test:  0.7088888888888889\n",
      "\tEpoch 522: \tAverage Loss:  1.4253865966796875\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 523: \tAverage Loss:  1.4255753173828125\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 524: \tAverage Loss:  1.4262117919921875\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 525: \tAverage Loss:  1.42461865234375\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 526: \tAverage Loss:  1.425192138671875\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 527: \tAverage Loss:  1.4253839111328126\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 528: \tAverage Loss:  1.4245841064453124\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 529: \tAverage Loss:  1.4240223388671875\t ACC train:  0.77\t ACC test:  0.7066666666666667\n",
      "\tEpoch 530: \tAverage Loss:  1.424142333984375\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 531: \tAverage Loss:  1.4260513916015625\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 532: \tAverage Loss:  1.423824462890625\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 533: \tAverage Loss:  1.4239888916015624\t ACC train:  0.77\t ACC test:  0.7066666666666667\n",
      "\tEpoch 534: \tAverage Loss:  1.42098779296875\t ACC train:  0.7566666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 535: \tAverage Loss:  1.4234622802734376\t ACC train:  0.77\t ACC test:  0.7088888888888889\n",
      "\tEpoch 536: \tAverage Loss:  1.42169091796875\t ACC train:  0.77\t ACC test:  0.7088888888888889\n",
      "\tEpoch 537: \tAverage Loss:  1.4236864013671875\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 538: \tAverage Loss:  1.4226070556640624\t ACC train:  0.76\t ACC test:  0.7088888888888889\n",
      "\tEpoch 539: \tAverage Loss:  1.4231690673828126\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 540: \tAverage Loss:  1.4218809814453126\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 541: \tAverage Loss:  1.422171142578125\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 542: \tAverage Loss:  1.42456884765625\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 543: \tAverage Loss:  1.420563232421875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 544: \tAverage Loss:  1.4218607177734375\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 545: \tAverage Loss:  1.423097412109375\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 546: \tAverage Loss:  1.421798583984375\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 547: \tAverage Loss:  1.421845947265625\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 548: \tAverage Loss:  1.419455810546875\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 549: \tAverage Loss:  1.4209613037109374\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 550: \tAverage Loss:  1.4197470703125\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 551: \tAverage Loss:  1.420322509765625\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 552: \tAverage Loss:  1.41876953125\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 553: \tAverage Loss:  1.42056884765625\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 554: \tAverage Loss:  1.419038818359375\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 555: \tAverage Loss:  1.41958349609375\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 556: \tAverage Loss:  1.419427001953125\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 557: \tAverage Loss:  1.4186190185546874\t ACC train:  0.7633333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 558: \tAverage Loss:  1.419677734375\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 559: \tAverage Loss:  1.4187510986328125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 560: \tAverage Loss:  1.41925390625\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 561: \tAverage Loss:  1.41797607421875\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 562: \tAverage Loss:  1.4194993896484376\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 563: \tAverage Loss:  1.417164794921875\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 564: \tAverage Loss:  1.4183701171875\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 565: \tAverage Loss:  1.4182930908203124\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 566: \tAverage Loss:  1.4185914306640626\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 567: \tAverage Loss:  1.4168494873046875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 568: \tAverage Loss:  1.418031005859375\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 569: \tAverage Loss:  1.4187249755859375\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 570: \tAverage Loss:  1.4169088134765624\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 571: \tAverage Loss:  1.415967041015625\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 572: \tAverage Loss:  1.41669873046875\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 573: \tAverage Loss:  1.4152952880859375\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 574: \tAverage Loss:  1.4186072998046875\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 575: \tAverage Loss:  1.4152916259765624\t ACC train:  0.7666666666666667\t ACC test:  0.7088888888888889\n",
      "\tEpoch 576: \tAverage Loss:  1.41660400390625\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 577: \tAverage Loss:  1.4164232177734375\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 578: \tAverage Loss:  1.4172913818359374\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 579: \tAverage Loss:  1.415723388671875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 580: \tAverage Loss:  1.416998291015625\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 581: \tAverage Loss:  1.414244140625\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 582: \tAverage Loss:  1.4164638671875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 583: \tAverage Loss:  1.415104736328125\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 584: \tAverage Loss:  1.41478662109375\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 585: \tAverage Loss:  1.413625732421875\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 586: \tAverage Loss:  1.415014892578125\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 587: \tAverage Loss:  1.4151685791015625\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 588: \tAverage Loss:  1.4175916748046875\t ACC train:  0.76\t ACC test:  0.7111111111111111\n",
      "\tEpoch 589: \tAverage Loss:  1.414073486328125\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 590: \tAverage Loss:  1.413720458984375\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 591: \tAverage Loss:  1.4131175537109375\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 592: \tAverage Loss:  1.4146248779296875\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 593: \tAverage Loss:  1.4131318359375\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 594: \tAverage Loss:  1.4146595458984375\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 595: \tAverage Loss:  1.4132669677734375\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 596: \tAverage Loss:  1.4138167724609374\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 597: \tAverage Loss:  1.4130361328125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 598: \tAverage Loss:  1.412880859375\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 599: \tAverage Loss:  1.413273193359375\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 600: \tAverage Loss:  1.4139022216796875\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 601: \tAverage Loss:  1.4138389892578125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 602: \tAverage Loss:  1.4131114501953126\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 603: \tAverage Loss:  1.4131844482421876\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 604: \tAverage Loss:  1.4130113525390624\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 605: \tAverage Loss:  1.4116834716796876\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 606: \tAverage Loss:  1.41218408203125\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 607: \tAverage Loss:  1.411200439453125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 608: \tAverage Loss:  1.4124844970703125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 609: \tAverage Loss:  1.411741455078125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 610: \tAverage Loss:  1.4110086669921875\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 611: \tAverage Loss:  1.411356201171875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 612: \tAverage Loss:  1.41141162109375\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 613: \tAverage Loss:  1.4118101806640626\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 614: \tAverage Loss:  1.410739013671875\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 615: \tAverage Loss:  1.4101986083984375\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 616: \tAverage Loss:  1.4110194091796875\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 617: \tAverage Loss:  1.4110048828125\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 618: \tAverage Loss:  1.410357177734375\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 619: \tAverage Loss:  1.4096751708984374\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 620: \tAverage Loss:  1.41018359375\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 621: \tAverage Loss:  1.409733154296875\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 622: \tAverage Loss:  1.41001513671875\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 623: \tAverage Loss:  1.4107935791015624\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 624: \tAverage Loss:  1.40953369140625\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 625: \tAverage Loss:  1.4091522216796875\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 626: \tAverage Loss:  1.40910888671875\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 627: \tAverage Loss:  1.408515380859375\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 628: \tAverage Loss:  1.4084796142578124\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 629: \tAverage Loss:  1.409032470703125\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 630: \tAverage Loss:  1.408082763671875\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 631: \tAverage Loss:  1.408930419921875\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 632: \tAverage Loss:  1.408549560546875\t ACC train:  0.77\t ACC test:  0.7088888888888889\n",
      "\tEpoch 633: \tAverage Loss:  1.4083438720703125\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 634: \tAverage Loss:  1.4086981201171875\t ACC train:  0.7666666666666667\t ACC test:  0.7066666666666667\n",
      "\tEpoch 635: \tAverage Loss:  1.407916015625\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 636: \tAverage Loss:  1.4084210205078125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 637: \tAverage Loss:  1.4088623046875\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 638: \tAverage Loss:  1.407737060546875\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 639: \tAverage Loss:  1.407869140625\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 640: \tAverage Loss:  1.406755126953125\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 641: \tAverage Loss:  1.407275146484375\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 642: \tAverage Loss:  1.4063287353515626\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 643: \tAverage Loss:  1.406980712890625\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 644: \tAverage Loss:  1.407810546875\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 645: \tAverage Loss:  1.4076339111328124\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 646: \tAverage Loss:  1.406570556640625\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 647: \tAverage Loss:  1.4069364013671875\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 648: \tAverage Loss:  1.4071219482421875\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 649: \tAverage Loss:  1.4062568359375\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 650: \tAverage Loss:  1.406487060546875\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 651: \tAverage Loss:  1.4075811767578126\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 652: \tAverage Loss:  1.40689501953125\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 653: \tAverage Loss:  1.40644482421875\t ACC train:  0.7633333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 654: \tAverage Loss:  1.40535498046875\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 655: \tAverage Loss:  1.40574755859375\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 656: \tAverage Loss:  1.406326416015625\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 657: \tAverage Loss:  1.4055106201171874\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 658: \tAverage Loss:  1.406144287109375\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 659: \tAverage Loss:  1.4065872802734376\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 660: \tAverage Loss:  1.4067083740234374\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 661: \tAverage Loss:  1.4045347900390626\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 662: \tAverage Loss:  1.40633642578125\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 663: \tAverage Loss:  1.40587841796875\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 664: \tAverage Loss:  1.4043399658203124\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 665: \tAverage Loss:  1.40476220703125\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 666: \tAverage Loss:  1.40415185546875\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 667: \tAverage Loss:  1.4053316650390626\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 668: \tAverage Loss:  1.40356396484375\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 669: \tAverage Loss:  1.404620361328125\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 670: \tAverage Loss:  1.4043839111328125\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 671: \tAverage Loss:  1.404521728515625\t ACC train:  0.7633333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 672: \tAverage Loss:  1.40453515625\t ACC train:  0.76\t ACC test:  0.7177777777777777\n",
      "\tEpoch 673: \tAverage Loss:  1.4044520263671876\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 674: \tAverage Loss:  1.40426025390625\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 675: \tAverage Loss:  1.403704833984375\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 676: \tAverage Loss:  1.4050245361328124\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 677: \tAverage Loss:  1.4038603515625\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 678: \tAverage Loss:  1.404032470703125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 679: \tAverage Loss:  1.4036873779296875\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 680: \tAverage Loss:  1.402552001953125\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 681: \tAverage Loss:  1.4036322021484375\t ACC train:  0.7633333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 682: \tAverage Loss:  1.4026507568359374\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 683: \tAverage Loss:  1.4022314453125\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 684: \tAverage Loss:  1.402673095703125\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 685: \tAverage Loss:  1.4023245849609376\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 686: \tAverage Loss:  1.4032677001953124\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 687: \tAverage Loss:  1.40157421875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 688: \tAverage Loss:  1.403592041015625\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 689: \tAverage Loss:  1.4016351318359375\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 690: \tAverage Loss:  1.401764892578125\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 691: \tAverage Loss:  1.401975341796875\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 692: \tAverage Loss:  1.4024627685546875\t ACC train:  0.7633333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 693: \tAverage Loss:  1.4014913330078125\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 694: \tAverage Loss:  1.401052734375\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 695: \tAverage Loss:  1.4016387939453125\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 696: \tAverage Loss:  1.4014583740234374\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 697: \tAverage Loss:  1.400960205078125\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 698: \tAverage Loss:  1.401423828125\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 699: \tAverage Loss:  1.40064794921875\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 700: \tAverage Loss:  1.4015601806640625\t ACC train:  0.77\t ACC test:  0.7088888888888889\n",
      "\tEpoch 701: \tAverage Loss:  1.401122802734375\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 702: \tAverage Loss:  1.4012711181640625\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 703: \tAverage Loss:  1.4004937744140624\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 704: \tAverage Loss:  1.4006614990234374\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 705: \tAverage Loss:  1.4008526611328125\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 706: \tAverage Loss:  1.400380126953125\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 707: \tAverage Loss:  1.4001217041015626\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 708: \tAverage Loss:  1.4002171630859375\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 709: \tAverage Loss:  1.3999801025390626\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 710: \tAverage Loss:  1.3998699951171876\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 711: \tAverage Loss:  1.399968017578125\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 712: \tAverage Loss:  1.400203125\t ACC train:  0.7666666666666667\t ACC test:  0.7111111111111111\n",
      "\tEpoch 713: \tAverage Loss:  1.39963232421875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 714: \tAverage Loss:  1.3999427490234375\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 715: \tAverage Loss:  1.3995758056640626\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 716: \tAverage Loss:  1.39999853515625\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 717: \tAverage Loss:  1.3991715087890626\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 718: \tAverage Loss:  1.39921044921875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 719: \tAverage Loss:  1.3989012451171876\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 720: \tAverage Loss:  1.3995361328125\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 721: \tAverage Loss:  1.3994544677734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 722: \tAverage Loss:  1.398838623046875\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 723: \tAverage Loss:  1.3986484375\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 724: \tAverage Loss:  1.3985897216796874\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 725: \tAverage Loss:  1.3985115966796875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 726: \tAverage Loss:  1.39841943359375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 727: \tAverage Loss:  1.39770654296875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 728: \tAverage Loss:  1.397713623046875\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 729: \tAverage Loss:  1.398770263671875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 730: \tAverage Loss:  1.3977445068359375\t ACC train:  0.7666666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 731: \tAverage Loss:  1.3977691650390625\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 732: \tAverage Loss:  1.3987403564453125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 733: \tAverage Loss:  1.3977386474609375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 734: \tAverage Loss:  1.397257568359375\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 735: \tAverage Loss:  1.397814208984375\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 736: \tAverage Loss:  1.397739990234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 737: \tAverage Loss:  1.3990419921875\t ACC train:  0.7666666666666667\t ACC test:  0.7133333333333334\n",
      "\tEpoch 738: \tAverage Loss:  1.3983382568359375\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 739: \tAverage Loss:  1.3967403564453125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 740: \tAverage Loss:  1.3977884521484376\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 741: \tAverage Loss:  1.3984210205078125\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 742: \tAverage Loss:  1.3967142333984375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 743: \tAverage Loss:  1.396990234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 744: \tAverage Loss:  1.39644384765625\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 745: \tAverage Loss:  1.396601806640625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 746: \tAverage Loss:  1.3963486328125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 747: \tAverage Loss:  1.396098388671875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 748: \tAverage Loss:  1.3964378662109376\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 749: \tAverage Loss:  1.3963541259765626\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 750: \tAverage Loss:  1.3953865966796875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 751: \tAverage Loss:  1.395701416015625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 752: \tAverage Loss:  1.39499365234375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 753: \tAverage Loss:  1.395466064453125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 754: \tAverage Loss:  1.3965162353515626\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 755: \tAverage Loss:  1.39547998046875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 756: \tAverage Loss:  1.3949857177734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 757: \tAverage Loss:  1.3957313232421875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 758: \tAverage Loss:  1.39483056640625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 759: \tAverage Loss:  1.3951304931640625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 760: \tAverage Loss:  1.3946732177734376\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 761: \tAverage Loss:  1.3945830078125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 762: \tAverage Loss:  1.3950623779296876\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 763: \tAverage Loss:  1.3950306396484375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 764: \tAverage Loss:  1.3943436279296875\t ACC train:  0.77\t ACC test:  0.7133333333333334\n",
      "\tEpoch 765: \tAverage Loss:  1.3951807861328125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 766: \tAverage Loss:  1.394067138671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 767: \tAverage Loss:  1.395020751953125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 768: \tAverage Loss:  1.3956319580078125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 769: \tAverage Loss:  1.394184326171875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 770: \tAverage Loss:  1.393752685546875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 771: \tAverage Loss:  1.3943427734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 772: \tAverage Loss:  1.3939627685546876\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 773: \tAverage Loss:  1.39359716796875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 774: \tAverage Loss:  1.3938402099609375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 775: \tAverage Loss:  1.393916015625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 776: \tAverage Loss:  1.39412255859375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 777: \tAverage Loss:  1.393446044921875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 778: \tAverage Loss:  1.3932982177734374\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 779: \tAverage Loss:  1.3940321044921875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 780: \tAverage Loss:  1.3929556884765626\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 781: \tAverage Loss:  1.3930362548828126\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 782: \tAverage Loss:  1.3928636474609375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 783: \tAverage Loss:  1.3928072509765625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 784: \tAverage Loss:  1.3925140380859375\t ACC train:  0.7666666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 785: \tAverage Loss:  1.3925723876953124\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 786: \tAverage Loss:  1.3927073974609374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 787: \tAverage Loss:  1.3928009033203126\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 788: \tAverage Loss:  1.3930230712890626\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 789: \tAverage Loss:  1.3923134765625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 790: \tAverage Loss:  1.3924935302734376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 791: \tAverage Loss:  1.3922000732421875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 792: \tAverage Loss:  1.3917891845703125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 793: \tAverage Loss:  1.392193359375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 794: \tAverage Loss:  1.392263427734375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 795: \tAverage Loss:  1.39214013671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 796: \tAverage Loss:  1.39166796875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 797: \tAverage Loss:  1.391755615234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 798: \tAverage Loss:  1.39135693359375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 799: \tAverage Loss:  1.391549560546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 800: \tAverage Loss:  1.3918206787109375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 801: \tAverage Loss:  1.3904072265625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 802: \tAverage Loss:  1.3914642333984375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 803: \tAverage Loss:  1.3912823486328125\t ACC train:  0.77\t ACC test:  0.7111111111111111\n",
      "\tEpoch 804: \tAverage Loss:  1.3906697998046875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 805: \tAverage Loss:  1.390939697265625\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 806: \tAverage Loss:  1.3907366943359376\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 807: \tAverage Loss:  1.390570068359375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 808: \tAverage Loss:  1.3909384765625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 809: \tAverage Loss:  1.3903035888671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 810: \tAverage Loss:  1.3899810791015625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 811: \tAverage Loss:  1.39063916015625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 812: \tAverage Loss:  1.389836181640625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 813: \tAverage Loss:  1.39039990234375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 814: \tAverage Loss:  1.3897366943359375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 815: \tAverage Loss:  1.3902132568359375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 816: \tAverage Loss:  1.389869384765625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 817: \tAverage Loss:  1.3901341552734374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 818: \tAverage Loss:  1.3897415771484376\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 819: \tAverage Loss:  1.3899169921875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 820: \tAverage Loss:  1.389662841796875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 821: \tAverage Loss:  1.3894822998046874\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 822: \tAverage Loss:  1.3892432861328126\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 823: \tAverage Loss:  1.3894969482421875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 824: \tAverage Loss:  1.3897144775390624\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 825: \tAverage Loss:  1.389329345703125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 826: \tAverage Loss:  1.3890950927734376\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 827: \tAverage Loss:  1.3887750244140624\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 828: \tAverage Loss:  1.389192138671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 829: \tAverage Loss:  1.388313720703125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 830: \tAverage Loss:  1.388677001953125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 831: \tAverage Loss:  1.3886053466796875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 832: \tAverage Loss:  1.3885565185546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 833: \tAverage Loss:  1.3888251953125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 834: \tAverage Loss:  1.387856689453125\t ACC train:  0.77\t ACC test:  0.7155555555555555\n",
      "\tEpoch 835: \tAverage Loss:  1.38806982421875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 836: \tAverage Loss:  1.3887852783203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 837: \tAverage Loss:  1.3882325439453125\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 838: \tAverage Loss:  1.3880948486328124\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 839: \tAverage Loss:  1.3878568115234375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 840: \tAverage Loss:  1.387873779296875\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 841: \tAverage Loss:  1.3877801513671875\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 842: \tAverage Loss:  1.3881458740234376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 843: \tAverage Loss:  1.3877362060546874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 844: \tAverage Loss:  1.3875816650390624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 845: \tAverage Loss:  1.387779541015625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 846: \tAverage Loss:  1.387703369140625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 847: \tAverage Loss:  1.387457275390625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 848: \tAverage Loss:  1.3875238037109374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 849: \tAverage Loss:  1.3872259521484376\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 850: \tAverage Loss:  1.387168701171875\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 851: \tAverage Loss:  1.3870396728515626\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 852: \tAverage Loss:  1.386175048828125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 853: \tAverage Loss:  1.3865655517578126\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 854: \tAverage Loss:  1.3865477294921875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 855: \tAverage Loss:  1.386271728515625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 856: \tAverage Loss:  1.385896240234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 857: \tAverage Loss:  1.386531982421875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 858: \tAverage Loss:  1.3863006591796876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 859: \tAverage Loss:  1.3858582763671874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 860: \tAverage Loss:  1.386332275390625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 861: \tAverage Loss:  1.3861820068359374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 862: \tAverage Loss:  1.385567138671875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 863: \tAverage Loss:  1.386206787109375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 864: \tAverage Loss:  1.3858056640625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 865: \tAverage Loss:  1.3858538818359376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 866: \tAverage Loss:  1.386134521484375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 867: \tAverage Loss:  1.385185546875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 868: \tAverage Loss:  1.385146728515625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 869: \tAverage Loss:  1.3853314208984375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 870: \tAverage Loss:  1.38532958984375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 871: \tAverage Loss:  1.3856075439453126\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 872: \tAverage Loss:  1.3860960693359374\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 873: \tAverage Loss:  1.3854766845703126\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 874: \tAverage Loss:  1.385023681640625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 875: \tAverage Loss:  1.3847008056640624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 876: \tAverage Loss:  1.3848907470703125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 877: \tAverage Loss:  1.385322021484375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 878: \tAverage Loss:  1.3846710205078125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 879: \tAverage Loss:  1.384403076171875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 880: \tAverage Loss:  1.3839073486328124\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 881: \tAverage Loss:  1.384241943359375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 882: \tAverage Loss:  1.3843775634765625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 883: \tAverage Loss:  1.383870361328125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 884: \tAverage Loss:  1.3842607421875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 885: \tAverage Loss:  1.3839169921875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 886: \tAverage Loss:  1.3833582763671874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 887: \tAverage Loss:  1.3841490478515626\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 888: \tAverage Loss:  1.3843826904296874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 889: \tAverage Loss:  1.38459521484375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 890: \tAverage Loss:  1.38402392578125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 891: \tAverage Loss:  1.3832659912109375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 892: \tAverage Loss:  1.3839468994140625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 893: \tAverage Loss:  1.3835252685546875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 894: \tAverage Loss:  1.3830142822265625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 895: \tAverage Loss:  1.382797119140625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 896: \tAverage Loss:  1.38308251953125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 897: \tAverage Loss:  1.3832884521484374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 898: \tAverage Loss:  1.383060546875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 899: \tAverage Loss:  1.38252734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 900: \tAverage Loss:  1.38291748046875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 901: \tAverage Loss:  1.3832962646484375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 902: \tAverage Loss:  1.383528564453125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 903: \tAverage Loss:  1.38283642578125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 904: \tAverage Loss:  1.3825872802734376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 905: \tAverage Loss:  1.38261083984375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 906: \tAverage Loss:  1.3826728515625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 907: \tAverage Loss:  1.38218798828125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 908: \tAverage Loss:  1.3818023681640625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 909: \tAverage Loss:  1.3821845703125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 910: \tAverage Loss:  1.382581298828125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 911: \tAverage Loss:  1.3812711181640625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 912: \tAverage Loss:  1.3817879638671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 913: \tAverage Loss:  1.3814700927734376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 914: \tAverage Loss:  1.38113330078125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 915: \tAverage Loss:  1.3812301025390625\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 916: \tAverage Loss:  1.381353759765625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 917: \tAverage Loss:  1.3813289794921875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 918: \tAverage Loss:  1.38122607421875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 919: \tAverage Loss:  1.3807601318359375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 920: \tAverage Loss:  1.38079052734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 921: \tAverage Loss:  1.380720458984375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 922: \tAverage Loss:  1.381328125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 923: \tAverage Loss:  1.3806776123046876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 924: \tAverage Loss:  1.3804677734375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 925: \tAverage Loss:  1.380341552734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 926: \tAverage Loss:  1.3805584716796875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 927: \tAverage Loss:  1.380705810546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 928: \tAverage Loss:  1.3802523193359375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 929: \tAverage Loss:  1.3804910888671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 930: \tAverage Loss:  1.38005419921875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 931: \tAverage Loss:  1.3794080810546876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 932: \tAverage Loss:  1.379703857421875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 933: \tAverage Loss:  1.3792093505859375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 934: \tAverage Loss:  1.3794805908203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 935: \tAverage Loss:  1.379359130859375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 936: \tAverage Loss:  1.37935595703125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 937: \tAverage Loss:  1.3792200927734375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 938: \tAverage Loss:  1.3788143310546874\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 939: \tAverage Loss:  1.3788814697265626\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 940: \tAverage Loss:  1.37895361328125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 941: \tAverage Loss:  1.3785230712890626\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 942: \tAverage Loss:  1.3786148681640624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 943: \tAverage Loss:  1.3786158447265624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 944: \tAverage Loss:  1.3785506591796874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 945: \tAverage Loss:  1.3786209716796876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 946: \tAverage Loss:  1.37827392578125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 947: \tAverage Loss:  1.3780860595703126\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 948: \tAverage Loss:  1.378473876953125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 949: \tAverage Loss:  1.378462158203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 950: \tAverage Loss:  1.378010986328125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 951: \tAverage Loss:  1.3780511474609376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 952: \tAverage Loss:  1.3776116943359376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 953: \tAverage Loss:  1.3782186279296875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 954: \tAverage Loss:  1.3776392822265624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 955: \tAverage Loss:  1.3773675537109376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 956: \tAverage Loss:  1.3771688232421875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 957: \tAverage Loss:  1.37738525390625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 958: \tAverage Loss:  1.3771239013671874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 959: \tAverage Loss:  1.3767762451171874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 960: \tAverage Loss:  1.3765472412109374\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 961: \tAverage Loss:  1.3768980712890626\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 962: \tAverage Loss:  1.376497802734375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 963: \tAverage Loss:  1.3763509521484374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 964: \tAverage Loss:  1.3761282958984375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 965: \tAverage Loss:  1.3764947509765626\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 966: \tAverage Loss:  1.3764461669921875\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 967: \tAverage Loss:  1.3762203369140624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 968: \tAverage Loss:  1.3763590087890625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 969: \tAverage Loss:  1.3760362548828124\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 970: \tAverage Loss:  1.375697509765625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 971: \tAverage Loss:  1.3757156982421874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 972: \tAverage Loss:  1.375631103515625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 973: \tAverage Loss:  1.3754039306640624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 974: \tAverage Loss:  1.37525341796875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 975: \tAverage Loss:  1.37521435546875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 976: \tAverage Loss:  1.375406005859375\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 977: \tAverage Loss:  1.37492041015625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 978: \tAverage Loss:  1.3746385498046876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 979: \tAverage Loss:  1.3747442626953126\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 980: \tAverage Loss:  1.37466748046875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 981: \tAverage Loss:  1.3746005859375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 982: \tAverage Loss:  1.37449169921875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 983: \tAverage Loss:  1.374140380859375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 984: \tAverage Loss:  1.374484619140625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 985: \tAverage Loss:  1.3746513671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 986: \tAverage Loss:  1.3744720458984374\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 987: \tAverage Loss:  1.3742640380859374\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 988: \tAverage Loss:  1.3735684814453124\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 989: \tAverage Loss:  1.3733743896484376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 990: \tAverage Loss:  1.3733831787109374\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 991: \tAverage Loss:  1.3740323486328125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 992: \tAverage Loss:  1.3741190185546874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 993: \tAverage Loss:  1.373442138671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 994: \tAverage Loss:  1.373161376953125\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 995: \tAverage Loss:  1.3728092041015625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 996: \tAverage Loss:  1.3733433837890625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 997: \tAverage Loss:  1.373708251953125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 998: \tAverage Loss:  1.372938720703125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 999: \tAverage Loss:  1.3720496826171875\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1000: \tAverage Loss:  1.37248486328125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1001: \tAverage Loss:  1.3723924560546874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1002: \tAverage Loss:  1.3720711669921875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1003: \tAverage Loss:  1.3721121826171876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1004: \tAverage Loss:  1.371679443359375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1005: \tAverage Loss:  1.3713973388671874\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1006: \tAverage Loss:  1.3718135986328126\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1007: \tAverage Loss:  1.3710341796875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1008: \tAverage Loss:  1.3714949951171875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1009: \tAverage Loss:  1.3712652587890626\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1010: \tAverage Loss:  1.3710546875\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1011: \tAverage Loss:  1.3707723388671875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1012: \tAverage Loss:  1.3705556640625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1013: \tAverage Loss:  1.370447998046875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1014: \tAverage Loss:  1.370248291015625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1015: \tAverage Loss:  1.36998193359375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1016: \tAverage Loss:  1.3698165283203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1017: \tAverage Loss:  1.369828857421875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1018: \tAverage Loss:  1.3696256103515625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1019: \tAverage Loss:  1.3694273681640625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1020: \tAverage Loss:  1.369134033203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1021: \tAverage Loss:  1.3694091796875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1022: \tAverage Loss:  1.3689283447265626\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1023: \tAverage Loss:  1.36883642578125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1024: \tAverage Loss:  1.368726806640625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1025: \tAverage Loss:  1.368520751953125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1026: \tAverage Loss:  1.3683602294921875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1027: \tAverage Loss:  1.3683897705078125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1028: \tAverage Loss:  1.3680430908203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1029: \tAverage Loss:  1.3679285888671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1030: \tAverage Loss:  1.3675684814453124\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1031: \tAverage Loss:  1.367541015625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1032: \tAverage Loss:  1.36740771484375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1033: \tAverage Loss:  1.3674354248046876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1034: \tAverage Loss:  1.368191650390625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1035: \tAverage Loss:  1.3687373046875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1036: \tAverage Loss:  1.3689766845703124\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1037: \tAverage Loss:  1.3675706787109374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1038: \tAverage Loss:  1.36670166015625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1039: \tAverage Loss:  1.3668863525390624\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1040: \tAverage Loss:  1.3676710205078124\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1041: \tAverage Loss:  1.3677432861328125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1042: \tAverage Loss:  1.3661356201171875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1043: \tAverage Loss:  1.365855224609375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1044: \tAverage Loss:  1.36643701171875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1045: \tAverage Loss:  1.366566650390625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1046: \tAverage Loss:  1.3658477783203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1047: \tAverage Loss:  1.3650570068359376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1048: \tAverage Loss:  1.3654365234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1049: \tAverage Loss:  1.3661160888671875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1050: \tAverage Loss:  1.365387939453125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1051: \tAverage Loss:  1.3644951171875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1052: \tAverage Loss:  1.3643763427734374\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1053: \tAverage Loss:  1.36498291015625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1054: \tAverage Loss:  1.3644544677734376\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1055: \tAverage Loss:  1.3637740478515625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1056: \tAverage Loss:  1.3638206787109375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1057: \tAverage Loss:  1.364267333984375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1058: \tAverage Loss:  1.3637392578125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1059: \tAverage Loss:  1.3631134033203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1060: \tAverage Loss:  1.3630009765625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1061: \tAverage Loss:  1.3632930908203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1062: \tAverage Loss:  1.36304638671875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1063: \tAverage Loss:  1.3626361083984375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1064: \tAverage Loss:  1.3624921875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1065: \tAverage Loss:  1.3623148193359376\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1066: \tAverage Loss:  1.3621170654296875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1067: \tAverage Loss:  1.361831298828125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1068: \tAverage Loss:  1.3618807373046875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1069: \tAverage Loss:  1.3616181640625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1070: \tAverage Loss:  1.36164013671875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1071: \tAverage Loss:  1.36162060546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1072: \tAverage Loss:  1.361319091796875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1073: \tAverage Loss:  1.360943359375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1074: \tAverage Loss:  1.3610943603515624\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1075: \tAverage Loss:  1.3610831298828125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1076: \tAverage Loss:  1.3608291015625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1077: \tAverage Loss:  1.36077734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1078: \tAverage Loss:  1.3607530517578126\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1079: \tAverage Loss:  1.3608209228515624\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1080: \tAverage Loss:  1.360299560546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1081: \tAverage Loss:  1.3604559326171874\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1082: \tAverage Loss:  1.3606343994140624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1083: \tAverage Loss:  1.3601334228515625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1084: \tAverage Loss:  1.35988916015625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1085: \tAverage Loss:  1.359716796875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1086: \tAverage Loss:  1.3599522705078124\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1087: \tAverage Loss:  1.35962646484375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1088: \tAverage Loss:  1.3592274169921874\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1089: \tAverage Loss:  1.3594005126953126\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1090: \tAverage Loss:  1.3592197265625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1091: \tAverage Loss:  1.3595240478515624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1092: \tAverage Loss:  1.35914990234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1093: \tAverage Loss:  1.358572021484375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1094: \tAverage Loss:  1.3585552978515625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1095: \tAverage Loss:  1.3587850341796874\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1096: \tAverage Loss:  1.3585635986328124\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1097: \tAverage Loss:  1.35812060546875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1098: \tAverage Loss:  1.3581142578125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1099: \tAverage Loss:  1.3588140869140626\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1100: \tAverage Loss:  1.3581854248046874\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1101: \tAverage Loss:  1.3575330810546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1102: \tAverage Loss:  1.35749365234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1103: \tAverage Loss:  1.3580302734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1104: \tAverage Loss:  1.3579908447265625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1105: \tAverage Loss:  1.3574984130859375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1106: \tAverage Loss:  1.356954833984375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1107: \tAverage Loss:  1.3569498291015625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1108: \tAverage Loss:  1.357008544921875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1109: \tAverage Loss:  1.3567603759765625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1110: \tAverage Loss:  1.356625244140625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1111: \tAverage Loss:  1.35629052734375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1112: \tAverage Loss:  1.3562384033203125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1113: \tAverage Loss:  1.3561878662109375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1114: \tAverage Loss:  1.356183837890625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1115: \tAverage Loss:  1.3562091064453126\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1116: \tAverage Loss:  1.3561209716796876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1117: \tAverage Loss:  1.3558148193359374\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1118: \tAverage Loss:  1.355538330078125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1119: \tAverage Loss:  1.3555015869140625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1120: \tAverage Loss:  1.3555126953125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1121: \tAverage Loss:  1.355036376953125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1122: \tAverage Loss:  1.3552852783203124\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1123: \tAverage Loss:  1.35500048828125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1124: \tAverage Loss:  1.354746826171875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1125: \tAverage Loss:  1.3545648193359374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1126: \tAverage Loss:  1.355205078125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1127: \tAverage Loss:  1.3553648681640624\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1128: \tAverage Loss:  1.3542916259765625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1129: \tAverage Loss:  1.3543468017578124\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1130: \tAverage Loss:  1.3546087646484375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1131: \tAverage Loss:  1.35438330078125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1132: \tAverage Loss:  1.353954345703125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1133: \tAverage Loss:  1.35399560546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1134: \tAverage Loss:  1.353998046875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1135: \tAverage Loss:  1.353557373046875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1136: \tAverage Loss:  1.353437255859375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1137: \tAverage Loss:  1.353411865234375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1138: \tAverage Loss:  1.353425537109375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1139: \tAverage Loss:  1.3532127685546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1140: \tAverage Loss:  1.3529737548828125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1141: \tAverage Loss:  1.3528775634765624\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1142: \tAverage Loss:  1.35272119140625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1143: \tAverage Loss:  1.3527930908203125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1144: \tAverage Loss:  1.3525477294921875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1145: \tAverage Loss:  1.3521390380859375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1146: \tAverage Loss:  1.3524208984375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1147: \tAverage Loss:  1.35221728515625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1148: \tAverage Loss:  1.3521990966796875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1149: \tAverage Loss:  1.3520379638671876\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1150: \tAverage Loss:  1.351746337890625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1151: \tAverage Loss:  1.351602294921875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1152: \tAverage Loss:  1.351662841796875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1153: \tAverage Loss:  1.3517728271484375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1154: \tAverage Loss:  1.35138525390625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1155: \tAverage Loss:  1.3512213134765625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1156: \tAverage Loss:  1.3509268798828125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1157: \tAverage Loss:  1.351017822265625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1158: \tAverage Loss:  1.3507236328125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1159: \tAverage Loss:  1.3506856689453124\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1160: \tAverage Loss:  1.3506226806640624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1161: \tAverage Loss:  1.35039599609375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1162: \tAverage Loss:  1.3503717041015626\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1163: \tAverage Loss:  1.3505322265625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1164: \tAverage Loss:  1.350006103515625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1165: \tAverage Loss:  1.3504510498046876\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1166: \tAverage Loss:  1.35056005859375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1167: \tAverage Loss:  1.3500823974609375\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1168: \tAverage Loss:  1.3499326171875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1169: \tAverage Loss:  1.349736572265625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1170: \tAverage Loss:  1.3495614013671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1171: \tAverage Loss:  1.3493114013671874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1172: \tAverage Loss:  1.3492027587890625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1173: \tAverage Loss:  1.349222412109375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1174: \tAverage Loss:  1.348986083984375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1175: \tAverage Loss:  1.348917236328125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1176: \tAverage Loss:  1.3490296630859375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1177: \tAverage Loss:  1.34864990234375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1178: \tAverage Loss:  1.34867138671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1179: \tAverage Loss:  1.3485872802734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1180: \tAverage Loss:  1.3485770263671875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1181: \tAverage Loss:  1.348433837890625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1182: \tAverage Loss:  1.3481453857421875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1183: \tAverage Loss:  1.3477596435546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1184: \tAverage Loss:  1.347650146484375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1185: \tAverage Loss:  1.347766845703125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1186: \tAverage Loss:  1.34789990234375\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1187: \tAverage Loss:  1.347799560546875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1188: \tAverage Loss:  1.3474139404296874\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1189: \tAverage Loss:  1.3473902587890625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1190: \tAverage Loss:  1.34747021484375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1191: \tAverage Loss:  1.3470667724609375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1192: \tAverage Loss:  1.3471658935546875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1193: \tAverage Loss:  1.3467750244140626\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1194: \tAverage Loss:  1.346685791015625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1195: \tAverage Loss:  1.346691162109375\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1196: \tAverage Loss:  1.34677001953125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1197: \tAverage Loss:  1.3466536865234375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1198: \tAverage Loss:  1.3462449951171875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1199: \tAverage Loss:  1.3461375732421874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1200: \tAverage Loss:  1.3457425537109375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1201: \tAverage Loss:  1.3460712890625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1202: \tAverage Loss:  1.3456297607421874\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1203: \tAverage Loss:  1.3456361083984374\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1204: \tAverage Loss:  1.345292724609375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1205: \tAverage Loss:  1.34544677734375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1206: \tAverage Loss:  1.345429931640625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1207: \tAverage Loss:  1.345283203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1208: \tAverage Loss:  1.3451455078125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1209: \tAverage Loss:  1.3449605712890624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1210: \tAverage Loss:  1.34499462890625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1211: \tAverage Loss:  1.3447047119140625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1212: \tAverage Loss:  1.344369873046875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1213: \tAverage Loss:  1.344287353515625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1214: \tAverage Loss:  1.3443076171875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1215: \tAverage Loss:  1.3443631591796874\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1216: \tAverage Loss:  1.3442220458984375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1217: \tAverage Loss:  1.343939697265625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1218: \tAverage Loss:  1.3439742431640624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1219: \tAverage Loss:  1.3437073974609375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1220: \tAverage Loss:  1.3437255859375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1221: \tAverage Loss:  1.3436685791015626\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1222: \tAverage Loss:  1.3435523681640624\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1223: \tAverage Loss:  1.3431568603515625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1224: \tAverage Loss:  1.3432415771484374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1225: \tAverage Loss:  1.3432198486328124\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1226: \tAverage Loss:  1.3431488037109376\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1227: \tAverage Loss:  1.3428626708984375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1228: \tAverage Loss:  1.3427244873046875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1229: \tAverage Loss:  1.3424488525390625\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1230: \tAverage Loss:  1.3423760986328126\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1231: \tAverage Loss:  1.3423370361328124\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1232: \tAverage Loss:  1.342082763671875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1233: \tAverage Loss:  1.3421607666015625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1234: \tAverage Loss:  1.3421458740234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1235: \tAverage Loss:  1.3418529052734376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1236: \tAverage Loss:  1.3415888671875\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1237: \tAverage Loss:  1.3418785400390625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1238: \tAverage Loss:  1.3420706787109375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1239: \tAverage Loss:  1.3415301513671876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1240: \tAverage Loss:  1.3415169677734375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1241: \tAverage Loss:  1.3410914306640624\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1242: \tAverage Loss:  1.3408917236328124\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1243: \tAverage Loss:  1.3410771484375\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1244: \tAverage Loss:  1.34067822265625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1245: \tAverage Loss:  1.3409554443359375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1246: \tAverage Loss:  1.340587646484375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1247: \tAverage Loss:  1.3404110107421876\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1248: \tAverage Loss:  1.3402147216796876\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1249: \tAverage Loss:  1.340233642578125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1250: \tAverage Loss:  1.340039306640625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1251: \tAverage Loss:  1.3396661376953125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1252: \tAverage Loss:  1.3399134521484375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1253: \tAverage Loss:  1.3397613525390626\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1254: \tAverage Loss:  1.33975244140625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1255: \tAverage Loss:  1.33980908203125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1256: \tAverage Loss:  1.3403228759765624\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1257: \tAverage Loss:  1.3396378173828125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1258: \tAverage Loss:  1.3397972412109376\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1259: \tAverage Loss:  1.3395548095703125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1260: \tAverage Loss:  1.3393585205078125\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1261: \tAverage Loss:  1.3389439697265626\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1262: \tAverage Loss:  1.3385078125\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1263: \tAverage Loss:  1.3383204345703126\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1264: \tAverage Loss:  1.3381737060546874\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1265: \tAverage Loss:  1.3380784912109376\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1266: \tAverage Loss:  1.3378162841796875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1267: \tAverage Loss:  1.3380443115234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1268: \tAverage Loss:  1.337864501953125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1269: \tAverage Loss:  1.33792529296875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1270: \tAverage Loss:  1.3378858642578124\t ACC train:  0.7733333333333333\t ACC test:  0.72\n",
      "\tEpoch 1271: \tAverage Loss:  1.3383734130859375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1272: \tAverage Loss:  1.339127685546875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1273: \tAverage Loss:  1.339836669921875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1274: \tAverage Loss:  1.3395601806640625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1275: \tAverage Loss:  1.3384892578125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1276: \tAverage Loss:  1.33692626953125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1277: \tAverage Loss:  1.3367657470703125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1278: \tAverage Loss:  1.3371749267578126\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1279: \tAverage Loss:  1.337800537109375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1280: \tAverage Loss:  1.338146484375\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1281: \tAverage Loss:  1.3371278076171875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1282: \tAverage Loss:  1.336185791015625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1283: \tAverage Loss:  1.3360980224609376\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1284: \tAverage Loss:  1.336055419921875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1285: \tAverage Loss:  1.336538818359375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1286: \tAverage Loss:  1.33634619140625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1287: \tAverage Loss:  1.335666259765625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1288: \tAverage Loss:  1.3352633056640626\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1289: \tAverage Loss:  1.335332763671875\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1290: \tAverage Loss:  1.336002685546875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1291: \tAverage Loss:  1.3356728515625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1292: \tAverage Loss:  1.335013427734375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1293: \tAverage Loss:  1.3346448974609375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1294: \tAverage Loss:  1.3345933837890624\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1295: \tAverage Loss:  1.3342266845703126\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1296: \tAverage Loss:  1.334271240234375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1297: \tAverage Loss:  1.334094482421875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1298: \tAverage Loss:  1.3340379638671875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1299: \tAverage Loss:  1.3343509521484376\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1300: \tAverage Loss:  1.3338251953125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1301: \tAverage Loss:  1.33456298828125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1302: \tAverage Loss:  1.333679931640625\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1303: \tAverage Loss:  1.33384326171875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1304: \tAverage Loss:  1.3333553466796875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1305: \tAverage Loss:  1.3332786865234374\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1306: \tAverage Loss:  1.3329156494140626\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1307: \tAverage Loss:  1.3324346923828125\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1308: \tAverage Loss:  1.3329366455078124\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1309: \tAverage Loss:  1.3324969482421876\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1310: \tAverage Loss:  1.332210693359375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1311: \tAverage Loss:  1.3323087158203124\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1312: \tAverage Loss:  1.3323289794921875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1313: \tAverage Loss:  1.33205029296875\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1314: \tAverage Loss:  1.331386962890625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1315: \tAverage Loss:  1.331369140625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1316: \tAverage Loss:  1.3312261962890626\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1317: \tAverage Loss:  1.331446533203125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1318: \tAverage Loss:  1.33135302734375\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1319: \tAverage Loss:  1.3310335693359374\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1320: \tAverage Loss:  1.331279052734375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1321: \tAverage Loss:  1.331505126953125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1322: \tAverage Loss:  1.3324405517578124\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1323: \tAverage Loss:  1.3326920166015626\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1324: \tAverage Loss:  1.3326317138671875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1325: \tAverage Loss:  1.332055419921875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1326: \tAverage Loss:  1.3311251220703124\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1327: \tAverage Loss:  1.3303031005859376\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1328: \tAverage Loss:  1.3307666015625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1329: \tAverage Loss:  1.33100390625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1330: \tAverage Loss:  1.33135595703125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1331: \tAverage Loss:  1.330603759765625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1332: \tAverage Loss:  1.329205810546875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1333: \tAverage Loss:  1.32977099609375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1334: \tAverage Loss:  1.329985595703125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1335: \tAverage Loss:  1.33049267578125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1336: \tAverage Loss:  1.3299156494140625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1337: \tAverage Loss:  1.3292039794921875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1338: \tAverage Loss:  1.3287281494140626\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1339: \tAverage Loss:  1.3283477783203126\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1340: \tAverage Loss:  1.3288404541015626\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1341: \tAverage Loss:  1.32869287109375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1342: \tAverage Loss:  1.3284306640625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1343: \tAverage Loss:  1.3282296142578125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1344: \tAverage Loss:  1.32747900390625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1345: \tAverage Loss:  1.327780517578125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1346: \tAverage Loss:  1.328104248046875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1347: \tAverage Loss:  1.3284029541015625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1348: \tAverage Loss:  1.3282366943359376\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1349: \tAverage Loss:  1.3269822998046874\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1350: \tAverage Loss:  1.326727294921875\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1351: \tAverage Loss:  1.32627099609375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1352: \tAverage Loss:  1.3272271728515626\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1353: \tAverage Loss:  1.327434814453125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1354: \tAverage Loss:  1.326324462890625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1355: \tAverage Loss:  1.3259698486328124\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1356: \tAverage Loss:  1.3255047607421875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1357: \tAverage Loss:  1.325678466796875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1358: \tAverage Loss:  1.3258291015625\t ACC train:  0.7733333333333333\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1359: \tAverage Loss:  1.325269287109375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1360: \tAverage Loss:  1.3248983154296874\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1361: \tAverage Loss:  1.3247220458984375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1362: \tAverage Loss:  1.3245137939453124\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1363: \tAverage Loss:  1.3246690673828125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1364: \tAverage Loss:  1.3241341552734376\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1365: \tAverage Loss:  1.323982666015625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1366: \tAverage Loss:  1.32445068359375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1367: \tAverage Loss:  1.3238497314453126\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1368: \tAverage Loss:  1.3233624267578126\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1369: \tAverage Loss:  1.3239212646484375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1370: \tAverage Loss:  1.3235653076171876\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1371: \tAverage Loss:  1.3244261474609376\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1372: \tAverage Loss:  1.3232042236328125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1373: \tAverage Loss:  1.323021728515625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1374: \tAverage Loss:  1.3232264404296874\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1375: \tAverage Loss:  1.3229801025390624\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1376: \tAverage Loss:  1.32310986328125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1377: \tAverage Loss:  1.3228814697265625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1378: \tAverage Loss:  1.32264111328125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1379: \tAverage Loss:  1.3227657470703125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1380: \tAverage Loss:  1.32197021484375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1381: \tAverage Loss:  1.3225596923828125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1382: \tAverage Loss:  1.3217025146484376\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1383: \tAverage Loss:  1.3218516845703125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1384: \tAverage Loss:  1.32254296875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1385: \tAverage Loss:  1.321717529296875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1386: \tAverage Loss:  1.321443359375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1387: \tAverage Loss:  1.321140869140625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1388: \tAverage Loss:  1.321097412109375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1389: \tAverage Loss:  1.3209366455078124\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1390: \tAverage Loss:  1.3207237548828126\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1391: \tAverage Loss:  1.32018798828125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1392: \tAverage Loss:  1.3199918212890625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1393: \tAverage Loss:  1.3203822021484375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1394: \tAverage Loss:  1.3199210205078125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1395: \tAverage Loss:  1.319669189453125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1396: \tAverage Loss:  1.31918310546875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1397: \tAverage Loss:  1.31962255859375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1398: \tAverage Loss:  1.3189713134765626\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1399: \tAverage Loss:  1.319024658203125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1400: \tAverage Loss:  1.3193101806640626\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1401: \tAverage Loss:  1.3192081298828124\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1402: \tAverage Loss:  1.3201729736328125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1403: \tAverage Loss:  1.3215909423828125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1404: \tAverage Loss:  1.3244930419921874\t ACC train:  0.7733333333333333\t ACC test:  0.7155555555555555\n",
      "\tEpoch 1405: \tAverage Loss:  1.3249356689453125\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1406: \tAverage Loss:  1.3217154541015625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1407: \tAverage Loss:  1.318243408203125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1408: \tAverage Loss:  1.3176300048828125\t ACC train:  0.7733333333333333\t ACC test:  0.7022222222222222\n",
      "\tEpoch 1409: \tAverage Loss:  1.32097900390625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1410: \tAverage Loss:  1.32106884765625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1411: \tAverage Loss:  1.319427001953125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1412: \tAverage Loss:  1.31719580078125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1413: \tAverage Loss:  1.3178291015625\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1414: \tAverage Loss:  1.3183804931640626\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1415: \tAverage Loss:  1.318172119140625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1416: \tAverage Loss:  1.316738525390625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1417: \tAverage Loss:  1.3159613037109374\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1418: \tAverage Loss:  1.3170374755859375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1419: \tAverage Loss:  1.3180081787109375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1420: \tAverage Loss:  1.317211181640625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1421: \tAverage Loss:  1.31625830078125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1422: \tAverage Loss:  1.315357177734375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1423: \tAverage Loss:  1.3151871337890626\t ACC train:  0.7733333333333333\t ACC test:  0.7022222222222222\n",
      "\tEpoch 1424: \tAverage Loss:  1.3153148193359374\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1425: \tAverage Loss:  1.3146585693359376\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1426: \tAverage Loss:  1.31407421875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1427: \tAverage Loss:  1.314563232421875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1428: \tAverage Loss:  1.3140841064453126\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1429: \tAverage Loss:  1.3147542724609376\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1430: \tAverage Loss:  1.3139666748046874\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1431: \tAverage Loss:  1.3140062255859375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1432: \tAverage Loss:  1.313349609375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1433: \tAverage Loss:  1.3132618408203125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1434: \tAverage Loss:  1.3138966064453126\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1435: \tAverage Loss:  1.3135819091796874\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1436: \tAverage Loss:  1.313811767578125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1437: \tAverage Loss:  1.3127916259765624\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1438: \tAverage Loss:  1.31281787109375\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1439: \tAverage Loss:  1.313920166015625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1440: \tAverage Loss:  1.3139813232421875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1441: \tAverage Loss:  1.31377734375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1442: \tAverage Loss:  1.3128524169921876\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1443: \tAverage Loss:  1.3115262451171874\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1444: \tAverage Loss:  1.312294189453125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1445: \tAverage Loss:  1.31307275390625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1446: \tAverage Loss:  1.313699462890625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1447: \tAverage Loss:  1.311649169921875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1448: \tAverage Loss:  1.31146533203125\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1449: \tAverage Loss:  1.3120484619140624\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1450: \tAverage Loss:  1.31178173828125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1451: \tAverage Loss:  1.31072509765625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1452: \tAverage Loss:  1.310133544921875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1453: \tAverage Loss:  1.31076513671875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1454: \tAverage Loss:  1.310527099609375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1455: \tAverage Loss:  1.31118701171875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1456: \tAverage Loss:  1.3095018310546875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1457: \tAverage Loss:  1.31043408203125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1458: \tAverage Loss:  1.3100062255859375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1459: \tAverage Loss:  1.3096689453125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1460: \tAverage Loss:  1.310046142578125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1461: \tAverage Loss:  1.3095018310546875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1462: \tAverage Loss:  1.3087220458984374\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1463: \tAverage Loss:  1.30955322265625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1464: \tAverage Loss:  1.3101707763671875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1465: \tAverage Loss:  1.310789306640625\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1466: \tAverage Loss:  1.3101636962890626\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1467: \tAverage Loss:  1.3080072021484375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1468: \tAverage Loss:  1.308265380859375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1469: \tAverage Loss:  1.3087755126953124\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1470: \tAverage Loss:  1.309006103515625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1471: \tAverage Loss:  1.3081993408203125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1472: \tAverage Loss:  1.3077301025390624\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1473: \tAverage Loss:  1.307035888671875\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1474: \tAverage Loss:  1.3071917724609374\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1475: \tAverage Loss:  1.308907958984375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1476: \tAverage Loss:  1.3100263671875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1477: \tAverage Loss:  1.30900830078125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1478: \tAverage Loss:  1.306886474609375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1479: \tAverage Loss:  1.3057005615234376\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1480: \tAverage Loss:  1.30665625\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1481: \tAverage Loss:  1.308734375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1482: \tAverage Loss:  1.3085640869140625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1483: \tAverage Loss:  1.3061307373046875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1484: \tAverage Loss:  1.3060621337890626\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1485: \tAverage Loss:  1.308829833984375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1486: \tAverage Loss:  1.309558349609375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1487: \tAverage Loss:  1.306924072265625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1488: \tAverage Loss:  1.305333251953125\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1489: \tAverage Loss:  1.3065098876953125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1490: \tAverage Loss:  1.309866943359375\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1491: \tAverage Loss:  1.309426025390625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1492: \tAverage Loss:  1.305779052734375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1493: \tAverage Loss:  1.30525390625\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1494: \tAverage Loss:  1.305963134765625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1495: \tAverage Loss:  1.3077518310546874\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1496: \tAverage Loss:  1.305593017578125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1497: \tAverage Loss:  1.303951904296875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1498: \tAverage Loss:  1.3046356201171876\t ACC train:  0.7733333333333333\t ACC test:  0.7022222222222222\n",
      "\tEpoch 1499: \tAverage Loss:  1.3049752197265625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1500: \tAverage Loss:  1.3043135986328125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1501: \tAverage Loss:  1.3032578125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1502: \tAverage Loss:  1.3030947265625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1503: \tAverage Loss:  1.3037967529296874\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1504: \tAverage Loss:  1.3029158935546874\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1505: \tAverage Loss:  1.302939697265625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1506: \tAverage Loss:  1.3024066162109376\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1507: \tAverage Loss:  1.30378662109375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1508: \tAverage Loss:  1.302768798828125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1509: \tAverage Loss:  1.302289794921875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1510: \tAverage Loss:  1.3022742919921875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1511: \tAverage Loss:  1.3023741455078126\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1512: \tAverage Loss:  1.302414306640625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1513: \tAverage Loss:  1.3016082763671875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1514: \tAverage Loss:  1.301188720703125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1515: \tAverage Loss:  1.301107177734375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1516: \tAverage Loss:  1.301241455078125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1517: \tAverage Loss:  1.300857666015625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1518: \tAverage Loss:  1.3008939208984376\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1519: \tAverage Loss:  1.300762451171875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1520: \tAverage Loss:  1.3007930908203125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1521: \tAverage Loss:  1.3010235595703126\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1522: \tAverage Loss:  1.300279052734375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1523: \tAverage Loss:  1.2997425537109375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1524: \tAverage Loss:  1.2997125244140626\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1525: \tAverage Loss:  1.3000142822265626\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1526: \tAverage Loss:  1.30015234375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1527: \tAverage Loss:  1.299784423828125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1528: \tAverage Loss:  1.299234619140625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1529: \tAverage Loss:  1.2992469482421876\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1530: \tAverage Loss:  1.2988037109375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1531: \tAverage Loss:  1.2997288818359376\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1532: \tAverage Loss:  1.2994666748046875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1533: \tAverage Loss:  1.2990191650390626\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1534: \tAverage Loss:  1.2984625244140624\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1535: \tAverage Loss:  1.298378662109375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1536: \tAverage Loss:  1.2980777587890624\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1537: \tAverage Loss:  1.298145751953125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1538: \tAverage Loss:  1.2978536376953125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1539: \tAverage Loss:  1.2978807373046874\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1540: \tAverage Loss:  1.2978863525390625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1541: \tAverage Loss:  1.29770654296875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1542: \tAverage Loss:  1.2977310791015626\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1543: \tAverage Loss:  1.2972366943359375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1544: \tAverage Loss:  1.2974903564453124\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1545: \tAverage Loss:  1.2975126953125\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1546: \tAverage Loss:  1.2971771240234375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1547: \tAverage Loss:  1.29739013671875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1548: \tAverage Loss:  1.296615478515625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1549: \tAverage Loss:  1.2962591552734375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1550: \tAverage Loss:  1.2962908935546875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1551: \tAverage Loss:  1.2965892333984375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1552: \tAverage Loss:  1.2966201171875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1553: \tAverage Loss:  1.2957664794921875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1554: \tAverage Loss:  1.2961309814453126\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1555: \tAverage Loss:  1.2963572998046875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1556: \tAverage Loss:  1.2957440185546876\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1557: \tAverage Loss:  1.2953824462890624\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1558: \tAverage Loss:  1.2954876708984375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1559: \tAverage Loss:  1.2953048095703126\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1560: \tAverage Loss:  1.2953529052734376\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1561: \tAverage Loss:  1.294772705078125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1562: \tAverage Loss:  1.2945103759765626\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1563: \tAverage Loss:  1.29468408203125\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1564: \tAverage Loss:  1.295637451171875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1565: \tAverage Loss:  1.2947352294921874\t ACC train:  0.7733333333333333\t ACC test:  0.7022222222222222\n",
      "\tEpoch 1566: \tAverage Loss:  1.29572314453125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1567: \tAverage Loss:  1.29497021484375\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1568: \tAverage Loss:  1.2955400390625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1569: \tAverage Loss:  1.295204345703125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1570: \tAverage Loss:  1.2948414306640625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1571: \tAverage Loss:  1.29373291015625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1572: \tAverage Loss:  1.293939697265625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1573: \tAverage Loss:  1.2928653564453125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1574: \tAverage Loss:  1.293289306640625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1575: \tAverage Loss:  1.2937413330078125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1576: \tAverage Loss:  1.2929801025390626\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1577: \tAverage Loss:  1.2941639404296874\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1578: \tAverage Loss:  1.2953961181640625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1579: \tAverage Loss:  1.2980262451171876\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1580: \tAverage Loss:  1.2972730712890626\t ACC train:  0.7733333333333333\t ACC test:  0.7022222222222222\n",
      "\tEpoch 1581: \tAverage Loss:  1.29476025390625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1582: \tAverage Loss:  1.2929862060546875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1583: \tAverage Loss:  1.291630859375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1584: \tAverage Loss:  1.2922572021484375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1585: \tAverage Loss:  1.294017578125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1586: \tAverage Loss:  1.2939395751953124\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1587: \tAverage Loss:  1.2927567138671876\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1588: \tAverage Loss:  1.2911453857421875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1589: \tAverage Loss:  1.292165771484375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1590: \tAverage Loss:  1.2923511962890626\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1591: \tAverage Loss:  1.2930322265625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1592: \tAverage Loss:  1.293243408203125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1593: \tAverage Loss:  1.29185205078125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1594: \tAverage Loss:  1.2908828125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1595: \tAverage Loss:  1.2904541015625\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1596: \tAverage Loss:  1.2904967041015625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1597: \tAverage Loss:  1.29160546875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1598: \tAverage Loss:  1.2925888671875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1599: \tAverage Loss:  1.2921536865234375\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1600: \tAverage Loss:  1.291673583984375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1601: \tAverage Loss:  1.2901573486328124\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1602: \tAverage Loss:  1.289853271484375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1603: \tAverage Loss:  1.29017724609375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1604: \tAverage Loss:  1.2901143798828125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1605: \tAverage Loss:  1.2894432373046876\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1606: \tAverage Loss:  1.290025390625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1607: \tAverage Loss:  1.2898677978515625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1608: \tAverage Loss:  1.2894310302734375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1609: \tAverage Loss:  1.2889774169921875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1610: \tAverage Loss:  1.2887718505859376\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1611: \tAverage Loss:  1.2891226806640625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1612: \tAverage Loss:  1.289787841796875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1613: \tAverage Loss:  1.2912913818359375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1614: \tAverage Loss:  1.2914798583984375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1615: \tAverage Loss:  1.2914781494140626\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1616: \tAverage Loss:  1.2911937255859376\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1617: \tAverage Loss:  1.2897752685546875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1618: \tAverage Loss:  1.2886514892578125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1619: \tAverage Loss:  1.287725341796875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1620: \tAverage Loss:  1.2893929443359375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1621: \tAverage Loss:  1.289448486328125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1622: \tAverage Loss:  1.2902796630859374\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1623: \tAverage Loss:  1.2883057861328124\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1624: \tAverage Loss:  1.28729638671875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1625: \tAverage Loss:  1.2872318115234376\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1626: \tAverage Loss:  1.2875701904296875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1627: \tAverage Loss:  1.2886226806640626\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1628: \tAverage Loss:  1.2887568359375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1629: \tAverage Loss:  1.288209716796875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1630: \tAverage Loss:  1.28689208984375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1631: \tAverage Loss:  1.286221923828125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1632: \tAverage Loss:  1.2866536865234375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1633: \tAverage Loss:  1.2867054443359376\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1634: \tAverage Loss:  1.2868555908203125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1635: \tAverage Loss:  1.2865513916015625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1636: \tAverage Loss:  1.2864044189453125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1637: \tAverage Loss:  1.2859456787109376\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1638: \tAverage Loss:  1.28667529296875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1639: \tAverage Loss:  1.2859564208984375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1640: \tAverage Loss:  1.2864517822265624\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1641: \tAverage Loss:  1.2864757080078124\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1642: \tAverage Loss:  1.285647216796875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1643: \tAverage Loss:  1.2855911865234375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1644: \tAverage Loss:  1.28501025390625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1645: \tAverage Loss:  1.285563232421875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1646: \tAverage Loss:  1.2848424072265625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1647: \tAverage Loss:  1.2847777099609374\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1648: \tAverage Loss:  1.284914306640625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1649: \tAverage Loss:  1.28484619140625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1650: \tAverage Loss:  1.2853673095703124\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1651: \tAverage Loss:  1.2851614990234375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1652: \tAverage Loss:  1.285451416015625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1653: \tAverage Loss:  1.28622900390625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1654: \tAverage Loss:  1.2870367431640626\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1655: \tAverage Loss:  1.2878170166015626\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1656: \tAverage Loss:  1.288112060546875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1657: \tAverage Loss:  1.2870133056640625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1658: \tAverage Loss:  1.2848284912109376\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1659: \tAverage Loss:  1.28371826171875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1660: \tAverage Loss:  1.2857933349609374\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1661: \tAverage Loss:  1.2879874267578124\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1662: \tAverage Loss:  1.2872598876953125\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1663: \tAverage Loss:  1.285019775390625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1664: \tAverage Loss:  1.28276318359375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1665: \tAverage Loss:  1.28384765625\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1666: \tAverage Loss:  1.2855391845703126\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1667: \tAverage Loss:  1.286963134765625\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1668: \tAverage Loss:  1.2849222412109376\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1669: \tAverage Loss:  1.2836134033203126\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1670: \tAverage Loss:  1.2835733642578124\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1671: \tAverage Loss:  1.285487060546875\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1672: \tAverage Loss:  1.2866533203125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1673: \tAverage Loss:  1.285689208984375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1674: \tAverage Loss:  1.2832099609375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1675: \tAverage Loss:  1.2823389892578125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1676: \tAverage Loss:  1.283806884765625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1677: \tAverage Loss:  1.28502197265625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1678: \tAverage Loss:  1.28498779296875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1679: \tAverage Loss:  1.2829781494140624\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1680: \tAverage Loss:  1.2818399658203126\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1681: \tAverage Loss:  1.2829921875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1682: \tAverage Loss:  1.2844210205078126\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1683: \tAverage Loss:  1.284247802734375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1684: \tAverage Loss:  1.2828419189453124\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1685: \tAverage Loss:  1.2810452880859375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1686: \tAverage Loss:  1.2819620361328126\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1687: \tAverage Loss:  1.28232421875\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1688: \tAverage Loss:  1.282138427734375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1689: \tAverage Loss:  1.2813514404296875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1690: \tAverage Loss:  1.28097119140625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1691: \tAverage Loss:  1.2820159912109375\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1692: \tAverage Loss:  1.282102783203125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1693: \tAverage Loss:  1.281319091796875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1694: \tAverage Loss:  1.2808326416015625\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1695: \tAverage Loss:  1.2804903564453125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1696: \tAverage Loss:  1.2808367919921875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1697: \tAverage Loss:  1.2805526123046875\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1698: \tAverage Loss:  1.280138427734375\t ACC train:  0.7733333333333333\t ACC test:  0.7133333333333334\n",
      "\tEpoch 1699: \tAverage Loss:  1.2801461181640625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1700: \tAverage Loss:  1.2794970703125\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1701: \tAverage Loss:  1.2801463623046876\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1702: \tAverage Loss:  1.27958984375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1703: \tAverage Loss:  1.2793984375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1704: \tAverage Loss:  1.27963623046875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1705: \tAverage Loss:  1.2792550048828124\t ACC train:  0.7733333333333333\t ACC test:  0.7044444444444444\n",
      "\tEpoch 1706: \tAverage Loss:  1.2795777587890624\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1707: \tAverage Loss:  1.278969970703125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1708: \tAverage Loss:  1.27923828125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1709: \tAverage Loss:  1.27866162109375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1710: \tAverage Loss:  1.2790255126953125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1711: \tAverage Loss:  1.2793155517578125\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1712: \tAverage Loss:  1.2791646728515624\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1713: \tAverage Loss:  1.2793182373046874\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1714: \tAverage Loss:  1.2786995849609375\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1715: \tAverage Loss:  1.2791807861328126\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1716: \tAverage Loss:  1.2784879150390625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1717: \tAverage Loss:  1.2781019287109374\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1718: \tAverage Loss:  1.2783070068359375\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1719: \tAverage Loss:  1.278245361328125\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1720: \tAverage Loss:  1.277996826171875\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1721: \tAverage Loss:  1.2786470947265625\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1722: \tAverage Loss:  1.278158447265625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1723: \tAverage Loss:  1.2784783935546875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1724: \tAverage Loss:  1.2778189697265625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "\tEpoch 1725: \tAverage Loss:  1.2778045654296875\t ACC train:  0.7733333333333333\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1726: \tAverage Loss:  1.2779068603515624\t ACC train:  0.7733333333333333\t ACC test:  0.7111111111111111\n",
      "\tEpoch 1727: \tAverage Loss:  1.2775478515625\t ACC train:  0.7733333333333333\t ACC test:  0.7088888888888889\n",
      "Stopping early at epoch 1727. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 400\n",
      "\tEpoch 1: \tAverage Loss:  3.463152099609375\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 2: \tAverage Loss:  3.448716552734375\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 3: \tAverage Loss:  3.436483642578125\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 4: \tAverage Loss:  3.42418798828125\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 5: \tAverage Loss:  3.4119619140625\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 6: \tAverage Loss:  3.40082080078125\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 7: \tAverage Loss:  3.389225341796875\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 8: \tAverage Loss:  3.37970751953125\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 9: \tAverage Loss:  3.36737255859375\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 10: \tAverage Loss:  3.358179931640625\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 11: \tAverage Loss:  3.348451171875\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 12: \tAverage Loss:  3.339073486328125\t ACC train:  0.485\t ACC test:  0.5133333333333333\n",
      "\tEpoch 13: \tAverage Loss:  3.329735595703125\t ACC train:  0.515\t ACC test:  0.48\n",
      "\tEpoch 14: \tAverage Loss:  3.3216767578125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  3.31338330078125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  3.30362060546875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  3.29600537109375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  3.287026123046875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  3.279421630859375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  3.27122998046875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  3.2633056640625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  3.256541259765625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  3.249093505859375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  3.24195166015625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  3.23451611328125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  3.22727294921875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  3.22219140625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  3.21402392578125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  3.208190673828125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  3.202873291015625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  3.195550537109375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  3.189575439453125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  3.184222900390625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  3.17739453125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  3.172321044921875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  3.16636376953125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  3.159895263671875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  3.1565595703125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  3.149634765625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  3.14476025390625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  3.139655029296875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  3.135642333984375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  3.1307783203125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  3.12627978515625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  3.12233837890625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  3.116939453125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  3.112706298828125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  3.1081259765625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  3.103273193359375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  3.09945068359375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  3.094918701171875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  3.091567626953125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  3.08919091796875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  3.082822021484375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  3.079081787109375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  3.07532275390625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  3.073259033203125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  3.069130859375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  3.065781005859375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  3.061123291015625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  3.057158935546875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  3.0507900390625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  3.048623046875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  3.044242431640625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  3.040525146484375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  3.034040283203125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 67: \tAverage Loss:  3.03119921875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  3.02819384765625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  3.01784619140625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  3.015327392578125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 71: \tAverage Loss:  3.011125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  3.001492431640625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 73: \tAverage Loss:  2.999570556640625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  2.992663330078125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  2.984664306640625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 76: \tAverage Loss:  2.97857275390625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  2.969012939453125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  2.962927978515625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 79: \tAverage Loss:  2.961312744140625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 80: \tAverage Loss:  2.947012939453125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 81: \tAverage Loss:  2.94195654296875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 82: \tAverage Loss:  2.930051513671875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 83: \tAverage Loss:  2.92728662109375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 84: \tAverage Loss:  2.91590087890625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 85: \tAverage Loss:  2.90588232421875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 86: \tAverage Loss:  2.900016845703125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 87: \tAverage Loss:  2.8857998046875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 88: \tAverage Loss:  2.879416748046875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 89: \tAverage Loss:  2.86548193359375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 90: \tAverage Loss:  2.858334716796875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 91: \tAverage Loss:  2.848678955078125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 92: \tAverage Loss:  2.834324951171875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 93: \tAverage Loss:  2.829833251953125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 94: \tAverage Loss:  2.815602783203125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 95: \tAverage Loss:  2.807802490234375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 96: \tAverage Loss:  2.7937314453125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 97: \tAverage Loss:  2.78760400390625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 98: \tAverage Loss:  2.7715322265625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 99: \tAverage Loss:  2.759455322265625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 100: \tAverage Loss:  2.752008544921875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  2.73851318359375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 102: \tAverage Loss:  2.723192626953125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 103: \tAverage Loss:  2.712135986328125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 104: \tAverage Loss:  2.700398193359375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 105: \tAverage Loss:  2.694444580078125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 106: \tAverage Loss:  2.682572509765625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 107: \tAverage Loss:  2.664882080078125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 108: \tAverage Loss:  2.65358642578125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 109: \tAverage Loss:  2.6422294921875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 110: \tAverage Loss:  2.629439697265625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 111: \tAverage Loss:  2.622009521484375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 112: \tAverage Loss:  2.598770751953125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 113: \tAverage Loss:  2.589359375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 114: \tAverage Loss:  2.58256494140625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 115: \tAverage Loss:  2.56681298828125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 116: \tAverage Loss:  2.56267822265625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 117: \tAverage Loss:  2.545397216796875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 118: \tAverage Loss:  2.547914306640625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 119: \tAverage Loss:  2.523671142578125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 120: \tAverage Loss:  2.5085966796875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 121: \tAverage Loss:  2.500131591796875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 122: \tAverage Loss:  2.48785546875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 123: \tAverage Loss:  2.478552734375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 124: \tAverage Loss:  2.470396728515625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 125: \tAverage Loss:  2.460763916015625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 126: \tAverage Loss:  2.445336669921875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 127: \tAverage Loss:  2.434976806640625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 128: \tAverage Loss:  2.4286181640625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 129: \tAverage Loss:  2.41914501953125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 130: \tAverage Loss:  2.408458984375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 131: \tAverage Loss:  2.401536865234375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 132: \tAverage Loss:  2.390228515625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 133: \tAverage Loss:  2.377469970703125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 134: \tAverage Loss:  2.37045556640625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 135: \tAverage Loss:  2.357338134765625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 136: \tAverage Loss:  2.349807861328125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 137: \tAverage Loss:  2.344571044921875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 138: \tAverage Loss:  2.338378662109375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 139: \tAverage Loss:  2.32860546875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 140: \tAverage Loss:  2.313978271484375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 141: \tAverage Loss:  2.310348876953125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 142: \tAverage Loss:  2.306167236328125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 143: \tAverage Loss:  2.293858154296875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 144: \tAverage Loss:  2.289194580078125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 145: \tAverage Loss:  2.28115576171875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 146: \tAverage Loss:  2.273993408203125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 147: \tAverage Loss:  2.264017822265625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 148: \tAverage Loss:  2.256307373046875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 149: \tAverage Loss:  2.25047705078125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 150: \tAverage Loss:  2.250434814453125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 151: \tAverage Loss:  2.23572900390625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 152: \tAverage Loss:  2.23369873046875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 153: \tAverage Loss:  2.229805419921875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 154: \tAverage Loss:  2.22095361328125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 155: \tAverage Loss:  2.219981201171875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 156: \tAverage Loss:  2.20835009765625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 157: \tAverage Loss:  2.201019775390625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 158: \tAverage Loss:  2.198578125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 159: \tAverage Loss:  2.193308837890625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 160: \tAverage Loss:  2.1881220703125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 161: \tAverage Loss:  2.184564697265625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 162: \tAverage Loss:  2.175587890625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 163: \tAverage Loss:  2.171372314453125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 164: \tAverage Loss:  2.166088623046875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 165: \tAverage Loss:  2.162092529296875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 166: \tAverage Loss:  2.158137939453125\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 167: \tAverage Loss:  2.15362890625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 168: \tAverage Loss:  2.149935546875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 169: \tAverage Loss:  2.144529296875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 170: \tAverage Loss:  2.13876416015625\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 171: \tAverage Loss:  2.13610888671875\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 172: \tAverage Loss:  2.13307080078125\t ACC train:  0.515\t ACC test:  0.4888888888888889\n",
      "\tEpoch 173: \tAverage Loss:  2.126719970703125\t ACC train:  0.5175\t ACC test:  0.4866666666666667\n",
      "\tEpoch 174: \tAverage Loss:  2.1234365234375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 175: \tAverage Loss:  2.117880859375\t ACC train:  0.515\t ACC test:  0.4866666666666667\n",
      "\tEpoch 176: \tAverage Loss:  2.1155927734375\t ACC train:  0.515\t ACC test:  0.4911111111111111\n",
      "\tEpoch 177: \tAverage Loss:  2.113294189453125\t ACC train:  0.515\t ACC test:  0.4911111111111111\n",
      "\tEpoch 178: \tAverage Loss:  2.1092607421875\t ACC train:  0.5175\t ACC test:  0.4888888888888889\n",
      "\tEpoch 179: \tAverage Loss:  2.106499267578125\t ACC train:  0.5175\t ACC test:  0.4955555555555556\n",
      "\tEpoch 180: \tAverage Loss:  2.1027822265625\t ACC train:  0.52\t ACC test:  0.49777777777777776\n",
      "\tEpoch 181: \tAverage Loss:  2.099087158203125\t ACC train:  0.5175\t ACC test:  0.49777777777777776\n",
      "\tEpoch 182: \tAverage Loss:  2.094821533203125\t ACC train:  0.525\t ACC test:  0.5022222222222222\n",
      "\tEpoch 183: \tAverage Loss:  2.09351123046875\t ACC train:  0.5225\t ACC test:  0.5022222222222222\n",
      "\tEpoch 184: \tAverage Loss:  2.090201904296875\t ACC train:  0.52\t ACC test:  0.5\n",
      "\tEpoch 185: \tAverage Loss:  2.087132568359375\t ACC train:  0.5275\t ACC test:  0.5088888888888888\n",
      "\tEpoch 186: \tAverage Loss:  2.082858154296875\t ACC train:  0.5275\t ACC test:  0.5088888888888888\n",
      "\tEpoch 187: \tAverage Loss:  2.081765625\t ACC train:  0.52\t ACC test:  0.5066666666666667\n",
      "\tEpoch 188: \tAverage Loss:  2.07769091796875\t ACC train:  0.5325\t ACC test:  0.5133333333333333\n",
      "\tEpoch 189: \tAverage Loss:  2.075603271484375\t ACC train:  0.54\t ACC test:  0.5177777777777778\n",
      "\tEpoch 190: \tAverage Loss:  2.07321630859375\t ACC train:  0.535\t ACC test:  0.52\n",
      "\tEpoch 191: \tAverage Loss:  2.071423095703125\t ACC train:  0.5475\t ACC test:  0.5244444444444445\n",
      "\tEpoch 192: \tAverage Loss:  2.06709619140625\t ACC train:  0.5425\t ACC test:  0.5266666666666666\n",
      "\tEpoch 193: \tAverage Loss:  2.065493896484375\t ACC train:  0.55\t ACC test:  0.5266666666666666\n",
      "\tEpoch 194: \tAverage Loss:  2.062091796875\t ACC train:  0.555\t ACC test:  0.5355555555555556\n",
      "\tEpoch 195: \tAverage Loss:  2.060287841796875\t ACC train:  0.56\t ACC test:  0.5422222222222223\n",
      "\tEpoch 196: \tAverage Loss:  2.058584228515625\t ACC train:  0.555\t ACC test:  0.5444444444444444\n",
      "\tEpoch 197: \tAverage Loss:  2.055497314453125\t ACC train:  0.56\t ACC test:  0.5444444444444444\n",
      "\tEpoch 198: \tAverage Loss:  2.0544794921875\t ACC train:  0.5675\t ACC test:  0.5511111111111111\n",
      "\tEpoch 199: \tAverage Loss:  2.0521875\t ACC train:  0.57\t ACC test:  0.5511111111111111\n",
      "\tEpoch 200: \tAverage Loss:  2.048346435546875\t ACC train:  0.5775\t ACC test:  0.56\n",
      "\tEpoch 201: \tAverage Loss:  2.04721923828125\t ACC train:  0.575\t ACC test:  0.56\n",
      "\tEpoch 202: \tAverage Loss:  2.04512060546875\t ACC train:  0.5775\t ACC test:  0.56\n",
      "\tEpoch 203: \tAverage Loss:  2.0425997314453124\t ACC train:  0.5775\t ACC test:  0.5666666666666667\n",
      "\tEpoch 204: \tAverage Loss:  2.041765380859375\t ACC train:  0.585\t ACC test:  0.5711111111111111\n",
      "\tEpoch 205: \tAverage Loss:  2.038610107421875\t ACC train:  0.585\t ACC test:  0.5711111111111111\n",
      "\tEpoch 206: \tAverage Loss:  2.03734619140625\t ACC train:  0.5925\t ACC test:  0.5755555555555556\n",
      "\tEpoch 207: \tAverage Loss:  2.034745361328125\t ACC train:  0.5975\t ACC test:  0.58\n",
      "\tEpoch 208: \tAverage Loss:  2.033466552734375\t ACC train:  0.6075\t ACC test:  0.5822222222222222\n",
      "\tEpoch 209: \tAverage Loss:  2.031791748046875\t ACC train:  0.6025\t ACC test:  0.5866666666666667\n",
      "\tEpoch 210: \tAverage Loss:  2.0301610107421877\t ACC train:  0.605\t ACC test:  0.5844444444444444\n",
      "\tEpoch 211: \tAverage Loss:  2.0287127685546875\t ACC train:  0.61\t ACC test:  0.5888888888888889\n",
      "\tEpoch 212: \tAverage Loss:  2.0269710693359375\t ACC train:  0.6125\t ACC test:  0.5866666666666667\n",
      "\tEpoch 213: \tAverage Loss:  2.02501171875\t ACC train:  0.6175\t ACC test:  0.5888888888888889\n",
      "\tEpoch 214: \tAverage Loss:  2.023077392578125\t ACC train:  0.6125\t ACC test:  0.5888888888888889\n",
      "\tEpoch 215: \tAverage Loss:  2.021505859375\t ACC train:  0.62\t ACC test:  0.5911111111111111\n",
      "\tEpoch 216: \tAverage Loss:  2.0200726318359377\t ACC train:  0.6125\t ACC test:  0.5911111111111111\n",
      "\tEpoch 217: \tAverage Loss:  2.01829833984375\t ACC train:  0.6175\t ACC test:  0.5933333333333334\n",
      "\tEpoch 218: \tAverage Loss:  2.0171259765625\t ACC train:  0.6125\t ACC test:  0.5888888888888889\n",
      "\tEpoch 219: \tAverage Loss:  2.0157579345703125\t ACC train:  0.6175\t ACC test:  0.5933333333333334\n",
      "\tEpoch 220: \tAverage Loss:  2.013908447265625\t ACC train:  0.6175\t ACC test:  0.6\n",
      "\tEpoch 221: \tAverage Loss:  2.0125264892578123\t ACC train:  0.62\t ACC test:  0.5888888888888889\n",
      "\tEpoch 222: \tAverage Loss:  2.0109598388671874\t ACC train:  0.6175\t ACC test:  0.5933333333333334\n",
      "\tEpoch 223: \tAverage Loss:  2.00985595703125\t ACC train:  0.6175\t ACC test:  0.6044444444444445\n",
      "\tEpoch 224: \tAverage Loss:  2.0082305908203124\t ACC train:  0.6175\t ACC test:  0.5933333333333334\n",
      "\tEpoch 225: \tAverage Loss:  2.007178955078125\t ACC train:  0.6125\t ACC test:  0.6044444444444445\n",
      "\tEpoch 226: \tAverage Loss:  2.0062421875\t ACC train:  0.6175\t ACC test:  0.5844444444444444\n",
      "\tEpoch 227: \tAverage Loss:  2.004610107421875\t ACC train:  0.6125\t ACC test:  0.5955555555555555\n",
      "\tEpoch 228: \tAverage Loss:  2.0031065673828126\t ACC train:  0.61\t ACC test:  0.5911111111111111\n",
      "\tEpoch 229: \tAverage Loss:  2.0019881591796875\t ACC train:  0.6075\t ACC test:  0.58\n",
      "\tEpoch 230: \tAverage Loss:  2.0007760009765625\t ACC train:  0.6125\t ACC test:  0.5733333333333334\n",
      "\tEpoch 231: \tAverage Loss:  1.99933740234375\t ACC train:  0.6\t ACC test:  0.5711111111111111\n",
      "\tEpoch 232: \tAverage Loss:  1.99905078125\t ACC train:  0.6025\t ACC test:  0.58\n",
      "\tEpoch 233: \tAverage Loss:  1.9970347900390626\t ACC train:  0.595\t ACC test:  0.5666666666666667\n",
      "\tEpoch 234: \tAverage Loss:  1.99576513671875\t ACC train:  0.595\t ACC test:  0.5733333333333334\n",
      "\tEpoch 235: \tAverage Loss:  1.9952642822265625\t ACC train:  0.5925\t ACC test:  0.5688888888888889\n",
      "\tEpoch 236: \tAverage Loss:  1.9939271240234375\t ACC train:  0.595\t ACC test:  0.5755555555555556\n",
      "\tEpoch 237: \tAverage Loss:  1.9926607666015625\t ACC train:  0.5975\t ACC test:  0.5711111111111111\n",
      "\tEpoch 238: \tAverage Loss:  1.99156201171875\t ACC train:  0.59\t ACC test:  0.5666666666666667\n",
      "\tEpoch 239: \tAverage Loss:  1.990810791015625\t ACC train:  0.5975\t ACC test:  0.5688888888888889\n",
      "\tEpoch 240: \tAverage Loss:  1.98989208984375\t ACC train:  0.6025\t ACC test:  0.5555555555555556\n",
      "\tEpoch 241: \tAverage Loss:  1.98856787109375\t ACC train:  0.5925\t ACC test:  0.56\n",
      "\tEpoch 242: \tAverage Loss:  1.9871337890625\t ACC train:  0.5975\t ACC test:  0.5533333333333333\n",
      "\tEpoch 243: \tAverage Loss:  1.9861282958984374\t ACC train:  0.59\t ACC test:  0.5577777777777778\n",
      "\tEpoch 244: \tAverage Loss:  1.98562060546875\t ACC train:  0.595\t ACC test:  0.5555555555555556\n",
      "\tEpoch 245: \tAverage Loss:  1.98442431640625\t ACC train:  0.595\t ACC test:  0.5555555555555556\n",
      "\tEpoch 246: \tAverage Loss:  1.9834102783203125\t ACC train:  0.5975\t ACC test:  0.5555555555555556\n",
      "\tEpoch 247: \tAverage Loss:  1.9823961181640626\t ACC train:  0.59\t ACC test:  0.5511111111111111\n",
      "\tEpoch 248: \tAverage Loss:  1.9813070068359375\t ACC train:  0.59\t ACC test:  0.5577777777777778\n",
      "\tEpoch 249: \tAverage Loss:  1.9808349609375\t ACC train:  0.5875\t ACC test:  0.5511111111111111\n",
      "\tEpoch 250: \tAverage Loss:  1.97963720703125\t ACC train:  0.59\t ACC test:  0.5555555555555556\n",
      "\tEpoch 251: \tAverage Loss:  1.978548583984375\t ACC train:  0.59\t ACC test:  0.5511111111111111\n",
      "\tEpoch 252: \tAverage Loss:  1.9777357177734376\t ACC train:  0.5875\t ACC test:  0.5422222222222223\n",
      "\tEpoch 253: \tAverage Loss:  1.9772744140625\t ACC train:  0.5875\t ACC test:  0.5511111111111111\n",
      "\tEpoch 254: \tAverage Loss:  1.9763646240234376\t ACC train:  0.585\t ACC test:  0.5444444444444444\n",
      "\tEpoch 255: \tAverage Loss:  1.97541259765625\t ACC train:  0.585\t ACC test:  0.5466666666666666\n",
      "\tEpoch 256: \tAverage Loss:  1.9747420654296874\t ACC train:  0.5825\t ACC test:  0.5533333333333333\n",
      "\tEpoch 257: \tAverage Loss:  1.9736396484375\t ACC train:  0.5825\t ACC test:  0.5533333333333333\n",
      "\tEpoch 258: \tAverage Loss:  1.9724903564453125\t ACC train:  0.5825\t ACC test:  0.5466666666666666\n",
      "\tEpoch 259: \tAverage Loss:  1.972136962890625\t ACC train:  0.5775\t ACC test:  0.5488888888888889\n",
      "\tEpoch 260: \tAverage Loss:  1.9710303955078126\t ACC train:  0.58\t ACC test:  0.5377777777777778\n",
      "\tEpoch 261: \tAverage Loss:  1.9707476806640625\t ACC train:  0.575\t ACC test:  0.5355555555555556\n",
      "\tEpoch 262: \tAverage Loss:  1.96975830078125\t ACC train:  0.575\t ACC test:  0.5377777777777778\n",
      "\tEpoch 263: \tAverage Loss:  1.9684920654296876\t ACC train:  0.575\t ACC test:  0.54\n",
      "\tEpoch 264: \tAverage Loss:  1.967982666015625\t ACC train:  0.5725\t ACC test:  0.5288888888888889\n",
      "\tEpoch 265: \tAverage Loss:  1.967458740234375\t ACC train:  0.57\t ACC test:  0.5311111111111111\n",
      "\tEpoch 266: \tAverage Loss:  1.966637939453125\t ACC train:  0.5625\t ACC test:  0.5311111111111111\n",
      "\tEpoch 267: \tAverage Loss:  1.965872802734375\t ACC train:  0.5675\t ACC test:  0.5222222222222223\n",
      "\tEpoch 268: \tAverage Loss:  1.965005859375\t ACC train:  0.56\t ACC test:  0.5222222222222223\n",
      "\tEpoch 269: \tAverage Loss:  1.9639901123046875\t ACC train:  0.5575\t ACC test:  0.52\n",
      "\tEpoch 270: \tAverage Loss:  1.9640020751953124\t ACC train:  0.5475\t ACC test:  0.5111111111111111\n",
      "\tEpoch 271: \tAverage Loss:  1.96256396484375\t ACC train:  0.5425\t ACC test:  0.5177777777777778\n",
      "\tEpoch 272: \tAverage Loss:  1.962490478515625\t ACC train:  0.54\t ACC test:  0.5133333333333333\n",
      "\tEpoch 273: \tAverage Loss:  1.9616636962890626\t ACC train:  0.5425\t ACC test:  0.5177777777777778\n",
      "\tEpoch 274: \tAverage Loss:  1.9613984375\t ACC train:  0.5475\t ACC test:  0.5133333333333333\n",
      "\tEpoch 275: \tAverage Loss:  1.9603868408203124\t ACC train:  0.5375\t ACC test:  0.5133333333333333\n",
      "\tEpoch 276: \tAverage Loss:  1.9597843017578125\t ACC train:  0.5475\t ACC test:  0.5177777777777778\n",
      "\tEpoch 277: \tAverage Loss:  1.9587928466796876\t ACC train:  0.545\t ACC test:  0.5177777777777778\n",
      "\tEpoch 278: \tAverage Loss:  1.957940185546875\t ACC train:  0.5525\t ACC test:  0.5155555555555555\n",
      "\tEpoch 279: \tAverage Loss:  1.957555908203125\t ACC train:  0.55\t ACC test:  0.5177777777777778\n",
      "\tEpoch 280: \tAverage Loss:  1.9566357421875\t ACC train:  0.5425\t ACC test:  0.5133333333333333\n",
      "\tEpoch 281: \tAverage Loss:  1.9559609375\t ACC train:  0.5375\t ACC test:  0.52\n",
      "\tEpoch 282: \tAverage Loss:  1.955403076171875\t ACC train:  0.5175\t ACC test:  0.5044444444444445\n",
      "\tEpoch 283: \tAverage Loss:  1.954718994140625\t ACC train:  0.52\t ACC test:  0.5022222222222222\n",
      "\tEpoch 284: \tAverage Loss:  1.9543338623046875\t ACC train:  0.51\t ACC test:  0.5\n",
      "\tEpoch 285: \tAverage Loss:  1.9537685546875\t ACC train:  0.5025\t ACC test:  0.49777777777777776\n",
      "\tEpoch 286: \tAverage Loss:  1.9532906494140625\t ACC train:  0.495\t ACC test:  0.49777777777777776\n",
      "\tEpoch 287: \tAverage Loss:  1.9523389892578125\t ACC train:  0.4875\t ACC test:  0.49333333333333335\n",
      "\tEpoch 288: \tAverage Loss:  1.9522208251953126\t ACC train:  0.49\t ACC test:  0.4911111111111111\n",
      "\tEpoch 289: \tAverage Loss:  1.9514051513671875\t ACC train:  0.49\t ACC test:  0.49333333333333335\n",
      "\tEpoch 290: \tAverage Loss:  1.9504853515625\t ACC train:  0.4925\t ACC test:  0.49777777777777776\n",
      "\tEpoch 291: \tAverage Loss:  1.950205322265625\t ACC train:  0.4975\t ACC test:  0.5022222222222222\n",
      "\tEpoch 292: \tAverage Loss:  1.9494739990234375\t ACC train:  0.5075\t ACC test:  0.4955555555555556\n",
      "\tEpoch 293: \tAverage Loss:  1.9486236572265625\t ACC train:  0.5\t ACC test:  0.49777777777777776\n",
      "\tEpoch 294: \tAverage Loss:  1.948127685546875\t ACC train:  0.5\t ACC test:  0.5022222222222222\n",
      "\tEpoch 295: \tAverage Loss:  1.9475455322265625\t ACC train:  0.505\t ACC test:  0.4955555555555556\n",
      "\tEpoch 296: \tAverage Loss:  1.9470748291015625\t ACC train:  0.49\t ACC test:  0.49777777777777776\n",
      "\tEpoch 297: \tAverage Loss:  1.9463868408203124\t ACC train:  0.4825\t ACC test:  0.49333333333333335\n",
      "\tEpoch 298: \tAverage Loss:  1.9459591064453126\t ACC train:  0.4775\t ACC test:  0.4911111111111111\n",
      "\tEpoch 299: \tAverage Loss:  1.9451239013671875\t ACC train:  0.465\t ACC test:  0.49333333333333335\n",
      "\tEpoch 300: \tAverage Loss:  1.944899658203125\t ACC train:  0.4625\t ACC test:  0.4911111111111111\n",
      "\tEpoch 301: \tAverage Loss:  1.9441195068359376\t ACC train:  0.4675\t ACC test:  0.4888888888888889\n",
      "\tEpoch 302: \tAverage Loss:  1.9434520263671875\t ACC train:  0.465\t ACC test:  0.4911111111111111\n",
      "\tEpoch 303: \tAverage Loss:  1.9423970947265625\t ACC train:  0.4775\t ACC test:  0.4888888888888889\n",
      "\tEpoch 304: \tAverage Loss:  1.9428887939453126\t ACC train:  0.4825\t ACC test:  0.4911111111111111\n",
      "\tEpoch 305: \tAverage Loss:  1.941969482421875\t ACC train:  0.495\t ACC test:  0.5\n",
      "\tEpoch 306: \tAverage Loss:  1.94151416015625\t ACC train:  0.505\t ACC test:  0.5022222222222222\n",
      "\tEpoch 307: \tAverage Loss:  1.940615234375\t ACC train:  0.5075\t ACC test:  0.5044444444444445\n",
      "\tEpoch 308: \tAverage Loss:  1.94035009765625\t ACC train:  0.5075\t ACC test:  0.5\n",
      "\tEpoch 309: \tAverage Loss:  1.9397972412109374\t ACC train:  0.51\t ACC test:  0.49777777777777776\n",
      "\tEpoch 310: \tAverage Loss:  1.9394005126953124\t ACC train:  0.5025\t ACC test:  0.49333333333333335\n",
      "\tEpoch 311: \tAverage Loss:  1.9388519287109376\t ACC train:  0.5025\t ACC test:  0.5022222222222222\n",
      "\tEpoch 312: \tAverage Loss:  1.9383831787109376\t ACC train:  0.4875\t ACC test:  0.4911111111111111\n",
      "\tEpoch 313: \tAverage Loss:  1.93763232421875\t ACC train:  0.485\t ACC test:  0.4888888888888889\n",
      "\tEpoch 314: \tAverage Loss:  1.9372210693359375\t ACC train:  0.465\t ACC test:  0.4888888888888889\n",
      "\tEpoch 315: \tAverage Loss:  1.9370537109375\t ACC train:  0.46\t ACC test:  0.4866666666666667\n",
      "\tEpoch 316: \tAverage Loss:  1.936535888671875\t ACC train:  0.455\t ACC test:  0.48444444444444446\n",
      "\tEpoch 317: \tAverage Loss:  1.935801025390625\t ACC train:  0.46\t ACC test:  0.4866666666666667\n",
      "\tEpoch 318: \tAverage Loss:  1.9352318115234375\t ACC train:  0.4625\t ACC test:  0.47555555555555556\n",
      "\tEpoch 319: \tAverage Loss:  1.93514697265625\t ACC train:  0.4575\t ACC test:  0.4822222222222222\n",
      "\tEpoch 320: \tAverage Loss:  1.934179443359375\t ACC train:  0.46\t ACC test:  0.4822222222222222\n",
      "\tEpoch 321: \tAverage Loss:  1.9342242431640626\t ACC train:  0.4525\t ACC test:  0.4888888888888889\n",
      "\tEpoch 322: \tAverage Loss:  1.93333447265625\t ACC train:  0.4575\t ACC test:  0.4888888888888889\n",
      "\tEpoch 323: \tAverage Loss:  1.9331563720703124\t ACC train:  0.455\t ACC test:  0.4866666666666667\n",
      "\tEpoch 324: \tAverage Loss:  1.9325762939453126\t ACC train:  0.46\t ACC test:  0.4866666666666667\n",
      "\tEpoch 325: \tAverage Loss:  1.93268212890625\t ACC train:  0.4525\t ACC test:  0.4888888888888889\n",
      "\tEpoch 326: \tAverage Loss:  1.931820068359375\t ACC train:  0.455\t ACC test:  0.4888888888888889\n",
      "\tEpoch 327: \tAverage Loss:  1.9309578857421874\t ACC train:  0.4575\t ACC test:  0.4888888888888889\n",
      "\tEpoch 328: \tAverage Loss:  1.93106689453125\t ACC train:  0.4575\t ACC test:  0.4911111111111111\n",
      "\tEpoch 329: \tAverage Loss:  1.930286376953125\t ACC train:  0.4625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 330: \tAverage Loss:  1.930119873046875\t ACC train:  0.4625\t ACC test:  0.48444444444444446\n",
      "\tEpoch 331: \tAverage Loss:  1.929318359375\t ACC train:  0.465\t ACC test:  0.48\n",
      "\tEpoch 332: \tAverage Loss:  1.929290283203125\t ACC train:  0.455\t ACC test:  0.48444444444444446\n",
      "\tEpoch 333: \tAverage Loss:  1.928812255859375\t ACC train:  0.4675\t ACC test:  0.48444444444444446\n",
      "\tEpoch 334: \tAverage Loss:  1.92835205078125\t ACC train:  0.4575\t ACC test:  0.4822222222222222\n",
      "\tEpoch 335: \tAverage Loss:  1.9280933837890626\t ACC train:  0.46\t ACC test:  0.48\n",
      "\tEpoch 336: \tAverage Loss:  1.9279688720703125\t ACC train:  0.46\t ACC test:  0.4911111111111111\n",
      "\tEpoch 337: \tAverage Loss:  1.926826904296875\t ACC train:  0.4575\t ACC test:  0.48444444444444446\n",
      "\tEpoch 338: \tAverage Loss:  1.9270186767578126\t ACC train:  0.46\t ACC test:  0.4822222222222222\n",
      "\tEpoch 339: \tAverage Loss:  1.9264637451171875\t ACC train:  0.4525\t ACC test:  0.48444444444444446\n",
      "\tEpoch 340: \tAverage Loss:  1.9257547607421874\t ACC train:  0.4575\t ACC test:  0.48444444444444446\n",
      "\tEpoch 341: \tAverage Loss:  1.9257177734375\t ACC train:  0.46\t ACC test:  0.4911111111111111\n",
      "\tEpoch 342: \tAverage Loss:  1.925235595703125\t ACC train:  0.455\t ACC test:  0.48444444444444446\n",
      "\tEpoch 343: \tAverage Loss:  1.924651123046875\t ACC train:  0.455\t ACC test:  0.4822222222222222\n",
      "\tEpoch 344: \tAverage Loss:  1.9247210693359376\t ACC train:  0.4575\t ACC test:  0.48444444444444446\n",
      "\tEpoch 345: \tAverage Loss:  1.9247003173828126\t ACC train:  0.455\t ACC test:  0.4822222222222222\n",
      "\tEpoch 346: \tAverage Loss:  1.9239071044921876\t ACC train:  0.4475\t ACC test:  0.47555555555555556\n",
      "\tEpoch 347: \tAverage Loss:  1.9233367919921875\t ACC train:  0.45\t ACC test:  0.4777777777777778\n",
      "\tEpoch 348: \tAverage Loss:  1.9233345947265625\t ACC train:  0.46\t ACC test:  0.48\n",
      "\tEpoch 349: \tAverage Loss:  1.922958251953125\t ACC train:  0.455\t ACC test:  0.48444444444444446\n",
      "\tEpoch 350: \tAverage Loss:  1.9220068359375\t ACC train:  0.455\t ACC test:  0.48444444444444446\n",
      "\tEpoch 351: \tAverage Loss:  1.9216109619140624\t ACC train:  0.465\t ACC test:  0.48444444444444446\n",
      "\tEpoch 352: \tAverage Loss:  1.9223045654296875\t ACC train:  0.4575\t ACC test:  0.48444444444444446\n",
      "\tEpoch 353: \tAverage Loss:  1.9209967041015625\t ACC train:  0.455\t ACC test:  0.48444444444444446\n",
      "\tEpoch 354: \tAverage Loss:  1.9208634033203125\t ACC train:  0.465\t ACC test:  0.4822222222222222\n",
      "\tEpoch 355: \tAverage Loss:  1.919955078125\t ACC train:  0.4625\t ACC test:  0.4888888888888889\n",
      "\tEpoch 356: \tAverage Loss:  1.920654296875\t ACC train:  0.4525\t ACC test:  0.4888888888888889\n",
      "\tEpoch 357: \tAverage Loss:  1.9206776123046876\t ACC train:  0.4575\t ACC test:  0.47555555555555556\n",
      "\tEpoch 358: \tAverage Loss:  1.919166015625\t ACC train:  0.45\t ACC test:  0.47555555555555556\n",
      "\tEpoch 359: \tAverage Loss:  1.9188509521484376\t ACC train:  0.4625\t ACC test:  0.4822222222222222\n",
      "\tEpoch 360: \tAverage Loss:  1.918136474609375\t ACC train:  0.45\t ACC test:  0.4822222222222222\n",
      "\tEpoch 361: \tAverage Loss:  1.9182996826171874\t ACC train:  0.45\t ACC test:  0.48444444444444446\n",
      "\tEpoch 362: \tAverage Loss:  1.91783984375\t ACC train:  0.455\t ACC test:  0.4866666666666667\n",
      "\tEpoch 363: \tAverage Loss:  1.9176566162109374\t ACC train:  0.46\t ACC test:  0.48\n",
      "\tEpoch 364: \tAverage Loss:  1.9172518310546875\t ACC train:  0.46\t ACC test:  0.4866666666666667\n",
      "\tEpoch 365: \tAverage Loss:  1.9171182861328124\t ACC train:  0.455\t ACC test:  0.4822222222222222\n",
      "\tEpoch 366: \tAverage Loss:  1.9163302001953124\t ACC train:  0.455\t ACC test:  0.48444444444444446\n",
      "\tEpoch 367: \tAverage Loss:  1.9164893798828124\t ACC train:  0.4525\t ACC test:  0.48\n",
      "\tEpoch 368: \tAverage Loss:  1.9166461181640626\t ACC train:  0.4525\t ACC test:  0.48\n",
      "\tEpoch 369: \tAverage Loss:  1.9157083740234375\t ACC train:  0.455\t ACC test:  0.48\n",
      "\tEpoch 370: \tAverage Loss:  1.914974609375\t ACC train:  0.4575\t ACC test:  0.4866666666666667\n",
      "\tEpoch 371: \tAverage Loss:  1.914800537109375\t ACC train:  0.465\t ACC test:  0.48\n",
      "\tEpoch 372: \tAverage Loss:  1.9154166259765626\t ACC train:  0.455\t ACC test:  0.4822222222222222\n",
      "\tEpoch 373: \tAverage Loss:  1.914625244140625\t ACC train:  0.4575\t ACC test:  0.48444444444444446\n",
      "\tEpoch 374: \tAverage Loss:  1.9142685546875\t ACC train:  0.4525\t ACC test:  0.47555555555555556\n",
      "\tEpoch 375: \tAverage Loss:  1.914148681640625\t ACC train:  0.4525\t ACC test:  0.4777777777777778\n",
      "\tEpoch 376: \tAverage Loss:  1.9137838134765626\t ACC train:  0.455\t ACC test:  0.4822222222222222\n",
      "\tEpoch 377: \tAverage Loss:  1.9132122802734375\t ACC train:  0.455\t ACC test:  0.48\n",
      "\tEpoch 378: \tAverage Loss:  1.913234130859375\t ACC train:  0.455\t ACC test:  0.4866666666666667\n",
      "\tEpoch 379: \tAverage Loss:  1.9130289306640624\t ACC train:  0.455\t ACC test:  0.48444444444444446\n",
      "\tEpoch 380: \tAverage Loss:  1.9124886474609375\t ACC train:  0.4625\t ACC test:  0.4911111111111111\n",
      "\tEpoch 381: \tAverage Loss:  1.9125174560546876\t ACC train:  0.455\t ACC test:  0.4888888888888889\n",
      "\tEpoch 382: \tAverage Loss:  1.91164892578125\t ACC train:  0.4575\t ACC test:  0.4822222222222222\n",
      "\tEpoch 383: \tAverage Loss:  1.9111788330078125\t ACC train:  0.4625\t ACC test:  0.4866666666666667\n",
      "\tEpoch 384: \tAverage Loss:  1.9106031494140625\t ACC train:  0.465\t ACC test:  0.4866666666666667\n",
      "\tEpoch 385: \tAverage Loss:  1.91011767578125\t ACC train:  0.47\t ACC test:  0.4888888888888889\n",
      "\tEpoch 386: \tAverage Loss:  1.9096732177734375\t ACC train:  0.4575\t ACC test:  0.4911111111111111\n",
      "\tEpoch 387: \tAverage Loss:  1.909752685546875\t ACC train:  0.4725\t ACC test:  0.4911111111111111\n",
      "\tEpoch 388: \tAverage Loss:  1.9093392333984376\t ACC train:  0.465\t ACC test:  0.4911111111111111\n",
      "\tEpoch 389: \tAverage Loss:  1.90876708984375\t ACC train:  0.4675\t ACC test:  0.4955555555555556\n",
      "\tEpoch 390: \tAverage Loss:  1.9083914794921875\t ACC train:  0.465\t ACC test:  0.4911111111111111\n",
      "\tEpoch 391: \tAverage Loss:  1.9081153564453126\t ACC train:  0.4675\t ACC test:  0.4911111111111111\n",
      "\tEpoch 392: \tAverage Loss:  1.9069537353515624\t ACC train:  0.49\t ACC test:  0.4911111111111111\n",
      "\tEpoch 393: \tAverage Loss:  1.90711669921875\t ACC train:  0.4925\t ACC test:  0.5022222222222222\n",
      "\tEpoch 394: \tAverage Loss:  1.90668701171875\t ACC train:  0.495\t ACC test:  0.49333333333333335\n",
      "\tEpoch 395: \tAverage Loss:  1.90643603515625\t ACC train:  0.505\t ACC test:  0.5022222222222222\n",
      "\tEpoch 396: \tAverage Loss:  1.9041119384765626\t ACC train:  0.5225\t ACC test:  0.5133333333333333\n",
      "\tEpoch 397: \tAverage Loss:  1.9045849609375\t ACC train:  0.5275\t ACC test:  0.5155555555555555\n",
      "\tEpoch 398: \tAverage Loss:  1.9043271484375\t ACC train:  0.555\t ACC test:  0.52\n",
      "\tEpoch 399: \tAverage Loss:  1.9037911376953125\t ACC train:  0.55\t ACC test:  0.5355555555555556\n",
      "\tEpoch 400: \tAverage Loss:  1.902357421875\t ACC train:  0.57\t ACC test:  0.5311111111111111\n",
      "\tEpoch 401: \tAverage Loss:  1.9019940185546875\t ACC train:  0.575\t ACC test:  0.5511111111111111\n",
      "\tEpoch 402: \tAverage Loss:  1.9008057861328125\t ACC train:  0.5875\t ACC test:  0.5466666666666666\n",
      "\tEpoch 403: \tAverage Loss:  1.900610107421875\t ACC train:  0.59\t ACC test:  0.5555555555555556\n",
      "\tEpoch 404: \tAverage Loss:  1.9001488037109375\t ACC train:  0.5925\t ACC test:  0.5533333333333333\n",
      "\tEpoch 405: \tAverage Loss:  1.89996728515625\t ACC train:  0.5975\t ACC test:  0.5533333333333333\n",
      "\tEpoch 406: \tAverage Loss:  1.898200927734375\t ACC train:  0.605\t ACC test:  0.5622222222222222\n",
      "\tEpoch 407: \tAverage Loss:  1.898114501953125\t ACC train:  0.6025\t ACC test:  0.5666666666666667\n",
      "\tEpoch 408: \tAverage Loss:  1.8973360595703126\t ACC train:  0.605\t ACC test:  0.5666666666666667\n",
      "\tEpoch 409: \tAverage Loss:  1.896501220703125\t ACC train:  0.61\t ACC test:  0.5733333333333334\n",
      "\tEpoch 410: \tAverage Loss:  1.8955565185546874\t ACC train:  0.6175\t ACC test:  0.5733333333333334\n",
      "\tEpoch 411: \tAverage Loss:  1.896503173828125\t ACC train:  0.605\t ACC test:  0.5733333333333334\n",
      "\tEpoch 412: \tAverage Loss:  1.895908935546875\t ACC train:  0.6125\t ACC test:  0.5755555555555556\n",
      "\tEpoch 413: \tAverage Loss:  1.8933240966796876\t ACC train:  0.61\t ACC test:  0.5844444444444444\n",
      "\tEpoch 414: \tAverage Loss:  1.893489990234375\t ACC train:  0.615\t ACC test:  0.5777777777777777\n",
      "\tEpoch 415: \tAverage Loss:  1.893212890625\t ACC train:  0.615\t ACC test:  0.58\n",
      "\tEpoch 416: \tAverage Loss:  1.8935108642578125\t ACC train:  0.62\t ACC test:  0.5844444444444444\n",
      "\tEpoch 417: \tAverage Loss:  1.8918223876953124\t ACC train:  0.6225\t ACC test:  0.5888888888888889\n",
      "\tEpoch 418: \tAverage Loss:  1.891759521484375\t ACC train:  0.625\t ACC test:  0.5888888888888889\n",
      "\tEpoch 419: \tAverage Loss:  1.890605224609375\t ACC train:  0.6225\t ACC test:  0.6\n",
      "\tEpoch 420: \tAverage Loss:  1.8910133056640626\t ACC train:  0.63\t ACC test:  0.5977777777777777\n",
      "\tEpoch 421: \tAverage Loss:  1.8899564208984374\t ACC train:  0.625\t ACC test:  0.5933333333333334\n",
      "\tEpoch 422: \tAverage Loss:  1.88916845703125\t ACC train:  0.6275\t ACC test:  0.6066666666666667\n",
      "\tEpoch 423: \tAverage Loss:  1.889176513671875\t ACC train:  0.635\t ACC test:  0.6155555555555555\n",
      "\tEpoch 424: \tAverage Loss:  1.88713330078125\t ACC train:  0.64\t ACC test:  0.6222222222222222\n",
      "\tEpoch 425: \tAverage Loss:  1.8887010498046874\t ACC train:  0.645\t ACC test:  0.6244444444444445\n",
      "\tEpoch 426: \tAverage Loss:  1.88866064453125\t ACC train:  0.645\t ACC test:  0.6155555555555555\n",
      "\tEpoch 427: \tAverage Loss:  1.8867401123046874\t ACC train:  0.645\t ACC test:  0.6288888888888889\n",
      "\tEpoch 428: \tAverage Loss:  1.88762353515625\t ACC train:  0.645\t ACC test:  0.6288888888888889\n",
      "\tEpoch 429: \tAverage Loss:  1.88704296875\t ACC train:  0.6475\t ACC test:  0.6333333333333333\n",
      "\tEpoch 430: \tAverage Loss:  1.8852916259765624\t ACC train:  0.6475\t ACC test:  0.6266666666666667\n",
      "\tEpoch 431: \tAverage Loss:  1.8840128173828126\t ACC train:  0.6525\t ACC test:  0.6266666666666667\n",
      "\tEpoch 432: \tAverage Loss:  1.884798828125\t ACC train:  0.6525\t ACC test:  0.6266666666666667\n",
      "\tEpoch 433: \tAverage Loss:  1.88285009765625\t ACC train:  0.655\t ACC test:  0.6266666666666667\n",
      "\tEpoch 434: \tAverage Loss:  1.8828831787109375\t ACC train:  0.6575\t ACC test:  0.6355555555555555\n",
      "\tEpoch 435: \tAverage Loss:  1.8825235595703125\t ACC train:  0.6425\t ACC test:  0.6288888888888889\n",
      "\tEpoch 436: \tAverage Loss:  1.8825394287109376\t ACC train:  0.6475\t ACC test:  0.6266666666666667\n",
      "\tEpoch 437: \tAverage Loss:  1.88195166015625\t ACC train:  0.65\t ACC test:  0.6311111111111111\n",
      "\tEpoch 438: \tAverage Loss:  1.8804095458984376\t ACC train:  0.65\t ACC test:  0.6311111111111111\n",
      "\tEpoch 439: \tAverage Loss:  1.879720458984375\t ACC train:  0.66\t ACC test:  0.64\n",
      "\tEpoch 440: \tAverage Loss:  1.88112939453125\t ACC train:  0.66\t ACC test:  0.6355555555555555\n",
      "\tEpoch 441: \tAverage Loss:  1.8783304443359374\t ACC train:  0.6525\t ACC test:  0.6377777777777778\n",
      "\tEpoch 442: \tAverage Loss:  1.879335693359375\t ACC train:  0.6525\t ACC test:  0.64\n",
      "\tEpoch 443: \tAverage Loss:  1.8783623046875\t ACC train:  0.6525\t ACC test:  0.6355555555555555\n",
      "\tEpoch 444: \tAverage Loss:  1.8783990478515624\t ACC train:  0.66\t ACC test:  0.64\n",
      "\tEpoch 445: \tAverage Loss:  1.8782957763671875\t ACC train:  0.6525\t ACC test:  0.6422222222222222\n",
      "\tEpoch 446: \tAverage Loss:  1.879174072265625\t ACC train:  0.6625\t ACC test:  0.64\n",
      "\tEpoch 447: \tAverage Loss:  1.8775926513671874\t ACC train:  0.665\t ACC test:  0.6422222222222222\n",
      "\tEpoch 448: \tAverage Loss:  1.877904296875\t ACC train:  0.6575\t ACC test:  0.6266666666666667\n",
      "\tEpoch 449: \tAverage Loss:  1.87702490234375\t ACC train:  0.655\t ACC test:  0.6422222222222222\n",
      "\tEpoch 450: \tAverage Loss:  1.876572021484375\t ACC train:  0.6625\t ACC test:  0.6333333333333333\n",
      "\tEpoch 451: \tAverage Loss:  1.87590869140625\t ACC train:  0.6575\t ACC test:  0.6355555555555555\n",
      "\tEpoch 452: \tAverage Loss:  1.8750494384765626\t ACC train:  0.665\t ACC test:  0.64\n",
      "\tEpoch 453: \tAverage Loss:  1.875402587890625\t ACC train:  0.66\t ACC test:  0.6422222222222222\n",
      "\tEpoch 454: \tAverage Loss:  1.87582275390625\t ACC train:  0.6675\t ACC test:  0.6444444444444445\n",
      "\tEpoch 455: \tAverage Loss:  1.8754580078125\t ACC train:  0.6675\t ACC test:  0.6377777777777778\n",
      "\tEpoch 456: \tAverage Loss:  1.8736214599609375\t ACC train:  0.6625\t ACC test:  0.6488888888888888\n",
      "\tEpoch 457: \tAverage Loss:  1.8731650390625\t ACC train:  0.6625\t ACC test:  0.6377777777777778\n",
      "\tEpoch 458: \tAverage Loss:  1.8740294189453126\t ACC train:  0.6675\t ACC test:  0.6333333333333333\n",
      "\tEpoch 459: \tAverage Loss:  1.8733177490234374\t ACC train:  0.66\t ACC test:  0.6422222222222222\n",
      "\tEpoch 460: \tAverage Loss:  1.873906494140625\t ACC train:  0.6675\t ACC test:  0.64\n",
      "\tEpoch 461: \tAverage Loss:  1.873278564453125\t ACC train:  0.665\t ACC test:  0.6444444444444445\n",
      "\tEpoch 462: \tAverage Loss:  1.8730870361328125\t ACC train:  0.665\t ACC test:  0.6422222222222222\n",
      "\tEpoch 463: \tAverage Loss:  1.8723359375\t ACC train:  0.6625\t ACC test:  0.6422222222222222\n",
      "\tEpoch 464: \tAverage Loss:  1.8704169921875\t ACC train:  0.665\t ACC test:  0.6444444444444445\n",
      "\tEpoch 465: \tAverage Loss:  1.8711304931640624\t ACC train:  0.6675\t ACC test:  0.6444444444444445\n",
      "\tEpoch 466: \tAverage Loss:  1.871419677734375\t ACC train:  0.6775\t ACC test:  0.6444444444444445\n",
      "\tEpoch 467: \tAverage Loss:  1.8706961669921875\t ACC train:  0.6675\t ACC test:  0.6466666666666666\n",
      "\tEpoch 468: \tAverage Loss:  1.8701270751953125\t ACC train:  0.6675\t ACC test:  0.6377777777777778\n",
      "\tEpoch 469: \tAverage Loss:  1.8701719970703126\t ACC train:  0.67\t ACC test:  0.6466666666666666\n",
      "\tEpoch 470: \tAverage Loss:  1.8710537109375\t ACC train:  0.6675\t ACC test:  0.64\n",
      "\tEpoch 471: \tAverage Loss:  1.8698409423828124\t ACC train:  0.67\t ACC test:  0.6444444444444445\n",
      "\tEpoch 472: \tAverage Loss:  1.8683267822265626\t ACC train:  0.6675\t ACC test:  0.6422222222222222\n",
      "\tEpoch 473: \tAverage Loss:  1.8690341796875\t ACC train:  0.6775\t ACC test:  0.6488888888888888\n",
      "\tEpoch 474: \tAverage Loss:  1.8674736328125\t ACC train:  0.6675\t ACC test:  0.6444444444444445\n",
      "\tEpoch 475: \tAverage Loss:  1.8682794189453125\t ACC train:  0.675\t ACC test:  0.64\n",
      "\tEpoch 476: \tAverage Loss:  1.86660986328125\t ACC train:  0.67\t ACC test:  0.6488888888888888\n",
      "\tEpoch 477: \tAverage Loss:  1.86689794921875\t ACC train:  0.675\t ACC test:  0.6355555555555555\n",
      "\tEpoch 478: \tAverage Loss:  1.868039306640625\t ACC train:  0.675\t ACC test:  0.6488888888888888\n",
      "\tEpoch 479: \tAverage Loss:  1.865726806640625\t ACC train:  0.6725\t ACC test:  0.6444444444444445\n",
      "\tEpoch 480: \tAverage Loss:  1.8667896728515625\t ACC train:  0.6675\t ACC test:  0.6444444444444445\n",
      "\tEpoch 481: \tAverage Loss:  1.8659290771484376\t ACC train:  0.67\t ACC test:  0.64\n",
      "\tEpoch 482: \tAverage Loss:  1.86551171875\t ACC train:  0.6775\t ACC test:  0.6488888888888888\n",
      "\tEpoch 483: \tAverage Loss:  1.865119873046875\t ACC train:  0.675\t ACC test:  0.6422222222222222\n",
      "\tEpoch 484: \tAverage Loss:  1.865178955078125\t ACC train:  0.6775\t ACC test:  0.6466666666666666\n",
      "\tEpoch 485: \tAverage Loss:  1.864657958984375\t ACC train:  0.67\t ACC test:  0.6444444444444445\n",
      "\tEpoch 486: \tAverage Loss:  1.8636488037109376\t ACC train:  0.67\t ACC test:  0.6466666666666666\n",
      "\tEpoch 487: \tAverage Loss:  1.8633167724609374\t ACC train:  0.675\t ACC test:  0.6444444444444445\n",
      "\tEpoch 488: \tAverage Loss:  1.8638194580078125\t ACC train:  0.6775\t ACC test:  0.6422222222222222\n",
      "\tEpoch 489: \tAverage Loss:  1.864153076171875\t ACC train:  0.675\t ACC test:  0.6444444444444445\n",
      "\tEpoch 490: \tAverage Loss:  1.8635238037109374\t ACC train:  0.6725\t ACC test:  0.6466666666666666\n",
      "\tEpoch 491: \tAverage Loss:  1.8623712158203125\t ACC train:  0.675\t ACC test:  0.64\n",
      "\tEpoch 492: \tAverage Loss:  1.8623609619140624\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 493: \tAverage Loss:  1.8644207763671874\t ACC train:  0.67\t ACC test:  0.6444444444444445\n",
      "\tEpoch 494: \tAverage Loss:  1.86306005859375\t ACC train:  0.6775\t ACC test:  0.6488888888888888\n",
      "\tEpoch 495: \tAverage Loss:  1.862193603515625\t ACC train:  0.6775\t ACC test:  0.6466666666666666\n",
      "\tEpoch 496: \tAverage Loss:  1.86239013671875\t ACC train:  0.6725\t ACC test:  0.6488888888888888\n",
      "\tEpoch 497: \tAverage Loss:  1.8621368408203125\t ACC train:  0.68\t ACC test:  0.6444444444444445\n",
      "\tEpoch 498: \tAverage Loss:  1.8611124267578125\t ACC train:  0.6775\t ACC test:  0.6422222222222222\n",
      "\tEpoch 499: \tAverage Loss:  1.860301025390625\t ACC train:  0.675\t ACC test:  0.6466666666666666\n",
      "\tEpoch 500: \tAverage Loss:  1.8610567626953125\t ACC train:  0.6775\t ACC test:  0.6466666666666666\n",
      "\tEpoch 501: \tAverage Loss:  1.8608331298828125\t ACC train:  0.6775\t ACC test:  0.6444444444444445\n",
      "\tEpoch 502: \tAverage Loss:  1.859969970703125\t ACC train:  0.6725\t ACC test:  0.6444444444444445\n",
      "\tEpoch 503: \tAverage Loss:  1.860782470703125\t ACC train:  0.6775\t ACC test:  0.6533333333333333\n",
      "\tEpoch 504: \tAverage Loss:  1.8599031982421874\t ACC train:  0.6775\t ACC test:  0.6466666666666666\n",
      "\tEpoch 505: \tAverage Loss:  1.859145751953125\t ACC train:  0.6775\t ACC test:  0.6422222222222222\n",
      "\tEpoch 506: \tAverage Loss:  1.8593565673828125\t ACC train:  0.68\t ACC test:  0.6466666666666666\n",
      "\tEpoch 507: \tAverage Loss:  1.859001220703125\t ACC train:  0.68\t ACC test:  0.6422222222222222\n",
      "\tEpoch 508: \tAverage Loss:  1.858750244140625\t ACC train:  0.6775\t ACC test:  0.6444444444444445\n",
      "\tEpoch 509: \tAverage Loss:  1.8585086669921875\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 510: \tAverage Loss:  1.856998291015625\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 511: \tAverage Loss:  1.8579310302734375\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 512: \tAverage Loss:  1.85672021484375\t ACC train:  0.68\t ACC test:  0.6444444444444445\n",
      "\tEpoch 513: \tAverage Loss:  1.8572510986328126\t ACC train:  0.68\t ACC test:  0.6444444444444445\n",
      "\tEpoch 514: \tAverage Loss:  1.8556075439453126\t ACC train:  0.68\t ACC test:  0.6466666666666666\n",
      "\tEpoch 515: \tAverage Loss:  1.855373291015625\t ACC train:  0.6775\t ACC test:  0.6444444444444445\n",
      "\tEpoch 516: \tAverage Loss:  1.85587451171875\t ACC train:  0.68\t ACC test:  0.6533333333333333\n",
      "\tEpoch 517: \tAverage Loss:  1.855656005859375\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 518: \tAverage Loss:  1.8558646240234375\t ACC train:  0.6775\t ACC test:  0.6466666666666666\n",
      "\tEpoch 519: \tAverage Loss:  1.8548587646484376\t ACC train:  0.68\t ACC test:  0.6444444444444445\n",
      "\tEpoch 520: \tAverage Loss:  1.8552066650390624\t ACC train:  0.6775\t ACC test:  0.6422222222222222\n",
      "\tEpoch 521: \tAverage Loss:  1.855177978515625\t ACC train:  0.675\t ACC test:  0.6444444444444445\n",
      "\tEpoch 522: \tAverage Loss:  1.854266357421875\t ACC train:  0.68\t ACC test:  0.6466666666666666\n",
      "\tEpoch 523: \tAverage Loss:  1.853790283203125\t ACC train:  0.68\t ACC test:  0.6466666666666666\n",
      "\tEpoch 524: \tAverage Loss:  1.8550255126953126\t ACC train:  0.6775\t ACC test:  0.6444444444444445\n",
      "\tEpoch 525: \tAverage Loss:  1.8540736083984375\t ACC train:  0.68\t ACC test:  0.6444444444444445\n",
      "\tEpoch 526: \tAverage Loss:  1.8536727294921875\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 527: \tAverage Loss:  1.8527938232421874\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 528: \tAverage Loss:  1.8519764404296875\t ACC train:  0.6825\t ACC test:  0.6422222222222222\n",
      "\tEpoch 529: \tAverage Loss:  1.852329833984375\t ACC train:  0.68\t ACC test:  0.6466666666666666\n",
      "\tEpoch 530: \tAverage Loss:  1.8527689208984375\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 531: \tAverage Loss:  1.8524210205078124\t ACC train:  0.68\t ACC test:  0.6422222222222222\n",
      "\tEpoch 532: \tAverage Loss:  1.8517996826171874\t ACC train:  0.6775\t ACC test:  0.6444444444444445\n",
      "\tEpoch 533: \tAverage Loss:  1.851615478515625\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 534: \tAverage Loss:  1.8511873779296875\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 535: \tAverage Loss:  1.8523863525390625\t ACC train:  0.6825\t ACC test:  0.6511111111111111\n",
      "\tEpoch 536: \tAverage Loss:  1.8514464111328126\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 537: \tAverage Loss:  1.8509842529296876\t ACC train:  0.6825\t ACC test:  0.6488888888888888\n",
      "\tEpoch 538: \tAverage Loss:  1.85184326171875\t ACC train:  0.68\t ACC test:  0.64\n",
      "\tEpoch 539: \tAverage Loss:  1.8507183837890624\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 540: \tAverage Loss:  1.850892822265625\t ACC train:  0.6825\t ACC test:  0.6488888888888888\n",
      "\tEpoch 541: \tAverage Loss:  1.8495732421875\t ACC train:  0.6825\t ACC test:  0.6488888888888888\n",
      "\tEpoch 542: \tAverage Loss:  1.8498438720703125\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 543: \tAverage Loss:  1.8497161865234375\t ACC train:  0.68\t ACC test:  0.6444444444444445\n",
      "\tEpoch 544: \tAverage Loss:  1.8492794189453126\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 545: \tAverage Loss:  1.8490018310546874\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 546: \tAverage Loss:  1.847933837890625\t ACC train:  0.6775\t ACC test:  0.6444444444444445\n",
      "\tEpoch 547: \tAverage Loss:  1.8483323974609376\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 548: \tAverage Loss:  1.8482335205078124\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 549: \tAverage Loss:  1.8485643310546875\t ACC train:  0.68\t ACC test:  0.6511111111111111\n",
      "\tEpoch 550: \tAverage Loss:  1.847029052734375\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 551: \tAverage Loss:  1.84800390625\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 552: \tAverage Loss:  1.8476075439453126\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 553: \tAverage Loss:  1.84742578125\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 554: \tAverage Loss:  1.84688720703125\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 555: \tAverage Loss:  1.8463687744140624\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 556: \tAverage Loss:  1.8469844970703124\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 557: \tAverage Loss:  1.846634521484375\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 558: \tAverage Loss:  1.8462945556640624\t ACC train:  0.6825\t ACC test:  0.6511111111111111\n",
      "\tEpoch 559: \tAverage Loss:  1.8455738525390626\t ACC train:  0.68\t ACC test:  0.6444444444444445\n",
      "\tEpoch 560: \tAverage Loss:  1.8463026123046875\t ACC train:  0.6825\t ACC test:  0.6422222222222222\n",
      "\tEpoch 561: \tAverage Loss:  1.8453778076171874\t ACC train:  0.6825\t ACC test:  0.6511111111111111\n",
      "\tEpoch 562: \tAverage Loss:  1.8456619873046876\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 563: \tAverage Loss:  1.845147216796875\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 564: \tAverage Loss:  1.8448765869140624\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 565: \tAverage Loss:  1.8452415771484374\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 566: \tAverage Loss:  1.84474560546875\t ACC train:  0.6825\t ACC test:  0.6422222222222222\n",
      "\tEpoch 567: \tAverage Loss:  1.844380126953125\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 568: \tAverage Loss:  1.8447763671875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 569: \tAverage Loss:  1.84396728515625\t ACC train:  0.6825\t ACC test:  0.6511111111111111\n",
      "\tEpoch 570: \tAverage Loss:  1.8440985107421874\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 571: \tAverage Loss:  1.8435517578125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 572: \tAverage Loss:  1.84366357421875\t ACC train:  0.68\t ACC test:  0.6422222222222222\n",
      "\tEpoch 573: \tAverage Loss:  1.843325927734375\t ACC train:  0.6825\t ACC test:  0.6511111111111111\n",
      "\tEpoch 574: \tAverage Loss:  1.8430147705078126\t ACC train:  0.68\t ACC test:  0.6466666666666666\n",
      "\tEpoch 575: \tAverage Loss:  1.842927490234375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 576: \tAverage Loss:  1.84228759765625\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 577: \tAverage Loss:  1.84211962890625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 578: \tAverage Loss:  1.8419959716796874\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 579: \tAverage Loss:  1.8417830810546876\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 580: \tAverage Loss:  1.841768798828125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 581: \tAverage Loss:  1.8408973388671874\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 582: \tAverage Loss:  1.8408211669921875\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 583: \tAverage Loss:  1.841217041015625\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 584: \tAverage Loss:  1.8407305908203124\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 585: \tAverage Loss:  1.8406583251953126\t ACC train:  0.6825\t ACC test:  0.6422222222222222\n",
      "\tEpoch 586: \tAverage Loss:  1.839703369140625\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 587: \tAverage Loss:  1.8395064697265624\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 588: \tAverage Loss:  1.8396229248046876\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 589: \tAverage Loss:  1.839243896484375\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 590: \tAverage Loss:  1.839453857421875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 591: \tAverage Loss:  1.838575439453125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 592: \tAverage Loss:  1.8396063232421875\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 593: \tAverage Loss:  1.839151123046875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 594: \tAverage Loss:  1.8388372802734374\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 595: \tAverage Loss:  1.838479736328125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 596: \tAverage Loss:  1.8385849609375\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 597: \tAverage Loss:  1.837981689453125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 598: \tAverage Loss:  1.8386820068359375\t ACC train:  0.6825\t ACC test:  0.6488888888888888\n",
      "\tEpoch 599: \tAverage Loss:  1.837868896484375\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 600: \tAverage Loss:  1.8368983154296874\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 601: \tAverage Loss:  1.8376448974609374\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 602: \tAverage Loss:  1.83778515625\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 603: \tAverage Loss:  1.8370108642578125\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 604: \tAverage Loss:  1.8369268798828124\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 605: \tAverage Loss:  1.836673583984375\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 606: \tAverage Loss:  1.836301025390625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 607: \tAverage Loss:  1.83611572265625\t ACC train:  0.68\t ACC test:  0.6444444444444445\n",
      "\tEpoch 608: \tAverage Loss:  1.836190673828125\t ACC train:  0.6825\t ACC test:  0.6444444444444445\n",
      "\tEpoch 609: \tAverage Loss:  1.8354940185546875\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 610: \tAverage Loss:  1.8360126953125\t ACC train:  0.685\t ACC test:  0.6422222222222222\n",
      "\tEpoch 611: \tAverage Loss:  1.8348223876953125\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 612: \tAverage Loss:  1.83509130859375\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 613: \tAverage Loss:  1.83538916015625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 614: \tAverage Loss:  1.8354119873046875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 615: \tAverage Loss:  1.834931396484375\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 616: \tAverage Loss:  1.8341746826171874\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 617: \tAverage Loss:  1.835405517578125\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 618: \tAverage Loss:  1.8346934814453124\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 619: \tAverage Loss:  1.8341722412109376\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 620: \tAverage Loss:  1.833430419921875\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 621: \tAverage Loss:  1.8338621826171875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 622: \tAverage Loss:  1.8326217041015624\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 623: \tAverage Loss:  1.833049560546875\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 624: \tAverage Loss:  1.833369140625\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 625: \tAverage Loss:  1.832921875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 626: \tAverage Loss:  1.832877685546875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 627: \tAverage Loss:  1.8324134521484374\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 628: \tAverage Loss:  1.8317308349609376\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 629: \tAverage Loss:  1.832007080078125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 630: \tAverage Loss:  1.8322752685546875\t ACC train:  0.6825\t ACC test:  0.6466666666666666\n",
      "\tEpoch 631: \tAverage Loss:  1.831623291015625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 632: \tAverage Loss:  1.831382080078125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 633: \tAverage Loss:  1.8315521240234376\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 634: \tAverage Loss:  1.8305877685546874\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 635: \tAverage Loss:  1.8303380126953126\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 636: \tAverage Loss:  1.830722900390625\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 637: \tAverage Loss:  1.8306468505859375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 638: \tAverage Loss:  1.8299849853515624\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 639: \tAverage Loss:  1.829967529296875\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 640: \tAverage Loss:  1.8298267822265626\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 641: \tAverage Loss:  1.8297745361328126\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 642: \tAverage Loss:  1.8293397216796874\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 643: \tAverage Loss:  1.8287464599609375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 644: \tAverage Loss:  1.8288406982421874\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 645: \tAverage Loss:  1.8293201904296874\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 646: \tAverage Loss:  1.8291676025390624\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 647: \tAverage Loss:  1.8288359375\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 648: \tAverage Loss:  1.8280965576171875\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 649: \tAverage Loss:  1.8288114013671875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 650: \tAverage Loss:  1.8279422607421876\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 651: \tAverage Loss:  1.8282691650390626\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 652: \tAverage Loss:  1.8275325927734376\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 653: \tAverage Loss:  1.8278828125\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 654: \tAverage Loss:  1.827332763671875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 655: \tAverage Loss:  1.8271641845703126\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 656: \tAverage Loss:  1.82624462890625\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 657: \tAverage Loss:  1.827380615234375\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 658: \tAverage Loss:  1.826615234375\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 659: \tAverage Loss:  1.8265325927734375\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 660: \tAverage Loss:  1.8263775634765624\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 661: \tAverage Loss:  1.826455078125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 662: \tAverage Loss:  1.8256959228515626\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 663: \tAverage Loss:  1.82638525390625\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 664: \tAverage Loss:  1.8259088134765624\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 665: \tAverage Loss:  1.8250849609375\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 666: \tAverage Loss:  1.8255391845703124\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 667: \tAverage Loss:  1.8247862548828124\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 668: \tAverage Loss:  1.825076904296875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 669: \tAverage Loss:  1.8250960693359375\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 670: \tAverage Loss:  1.8245299072265626\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 671: \tAverage Loss:  1.824330322265625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 672: \tAverage Loss:  1.824288330078125\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 673: \tAverage Loss:  1.823959716796875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 674: \tAverage Loss:  1.8239407958984375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 675: \tAverage Loss:  1.8236636962890624\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 676: \tAverage Loss:  1.8232890625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 677: \tAverage Loss:  1.823088623046875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 678: \tAverage Loss:  1.82274658203125\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 679: \tAverage Loss:  1.8225010986328125\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 680: \tAverage Loss:  1.8229833984375\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 681: \tAverage Loss:  1.8226624755859375\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 682: \tAverage Loss:  1.8225322265625\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 683: \tAverage Loss:  1.8218968505859374\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 684: \tAverage Loss:  1.8218017578125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 685: \tAverage Loss:  1.821956298828125\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 686: \tAverage Loss:  1.8217215576171875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 687: \tAverage Loss:  1.82160791015625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 688: \tAverage Loss:  1.82141650390625\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 689: \tAverage Loss:  1.8210655517578125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 690: \tAverage Loss:  1.8208045654296876\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 691: \tAverage Loss:  1.820848388671875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 692: \tAverage Loss:  1.8204786376953126\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 693: \tAverage Loss:  1.8207899169921875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 694: \tAverage Loss:  1.8203934326171876\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 695: \tAverage Loss:  1.820121337890625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 696: \tAverage Loss:  1.8199381103515626\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 697: \tAverage Loss:  1.8197135009765626\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 698: \tAverage Loss:  1.8195506591796875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 699: \tAverage Loss:  1.819387451171875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 700: \tAverage Loss:  1.8193643798828125\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 701: \tAverage Loss:  1.81888916015625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 702: \tAverage Loss:  1.81909716796875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 703: \tAverage Loss:  1.8188902587890625\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 704: \tAverage Loss:  1.8184639892578125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 705: \tAverage Loss:  1.81847021484375\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 706: \tAverage Loss:  1.8182156982421875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 707: \tAverage Loss:  1.818455810546875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 708: \tAverage Loss:  1.817906494140625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 709: \tAverage Loss:  1.81768994140625\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 710: \tAverage Loss:  1.8175531005859376\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 711: \tAverage Loss:  1.8174456787109374\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 712: \tAverage Loss:  1.81707275390625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 713: \tAverage Loss:  1.8170595703125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 714: \tAverage Loss:  1.816884033203125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 715: \tAverage Loss:  1.8168465576171875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 716: \tAverage Loss:  1.81638232421875\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 717: \tAverage Loss:  1.8165009765625\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 718: \tAverage Loss:  1.8161947021484375\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 719: \tAverage Loss:  1.816059814453125\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 720: \tAverage Loss:  1.8157103271484376\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 721: \tAverage Loss:  1.815964111328125\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 722: \tAverage Loss:  1.8157608642578125\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 723: \tAverage Loss:  1.81521826171875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 724: \tAverage Loss:  1.81507275390625\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 725: \tAverage Loss:  1.81506298828125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 726: \tAverage Loss:  1.815076171875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 727: \tAverage Loss:  1.8147884521484374\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 728: \tAverage Loss:  1.8147100830078124\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 729: \tAverage Loss:  1.8141845703125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 730: \tAverage Loss:  1.81373779296875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 731: \tAverage Loss:  1.8140225830078125\t ACC train:  0.685\t ACC test:  0.6444444444444445\n",
      "\tEpoch 732: \tAverage Loss:  1.81395556640625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 733: \tAverage Loss:  1.8138748779296876\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 734: \tAverage Loss:  1.813771728515625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 735: \tAverage Loss:  1.8133804931640625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 736: \tAverage Loss:  1.8136484375\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 737: \tAverage Loss:  1.8132073974609375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 738: \tAverage Loss:  1.81331201171875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 739: \tAverage Loss:  1.8130279541015626\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 740: \tAverage Loss:  1.8132490234375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 741: \tAverage Loss:  1.81257421875\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 742: \tAverage Loss:  1.81259423828125\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 743: \tAverage Loss:  1.8120556640625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 744: \tAverage Loss:  1.8122408447265625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 745: \tAverage Loss:  1.8123175048828124\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 746: \tAverage Loss:  1.8116163330078126\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 747: \tAverage Loss:  1.81150244140625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 748: \tAverage Loss:  1.8112662353515625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 749: \tAverage Loss:  1.810900634765625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 750: \tAverage Loss:  1.8113507080078124\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 751: \tAverage Loss:  1.81105126953125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 752: \tAverage Loss:  1.8107579345703124\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 753: \tAverage Loss:  1.8105609130859375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 754: \tAverage Loss:  1.8104146728515624\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 755: \tAverage Loss:  1.81015576171875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 756: \tAverage Loss:  1.810088134765625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 757: \tAverage Loss:  1.810273193359375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 758: \tAverage Loss:  1.80949609375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 759: \tAverage Loss:  1.8098011474609375\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 760: \tAverage Loss:  1.8098837890625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 761: \tAverage Loss:  1.8094210205078125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 762: \tAverage Loss:  1.809206787109375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 763: \tAverage Loss:  1.809018798828125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 764: \tAverage Loss:  1.8089241943359375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 765: \tAverage Loss:  1.808724853515625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 766: \tAverage Loss:  1.80833740234375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 767: \tAverage Loss:  1.808580078125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 768: \tAverage Loss:  1.8084447021484376\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 769: \tAverage Loss:  1.8078619384765624\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 770: \tAverage Loss:  1.8078426513671875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 771: \tAverage Loss:  1.80803759765625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 772: \tAverage Loss:  1.8079356689453125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 773: \tAverage Loss:  1.8075389404296875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 774: \tAverage Loss:  1.8072052001953125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 775: \tAverage Loss:  1.8071492919921874\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 776: \tAverage Loss:  1.80709765625\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 777: \tAverage Loss:  1.806798583984375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 778: \tAverage Loss:  1.8069520263671874\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 779: \tAverage Loss:  1.8074322509765626\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 780: \tAverage Loss:  1.806560302734375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 781: \tAverage Loss:  1.80625341796875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 782: \tAverage Loss:  1.8065361328125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 783: \tAverage Loss:  1.8063272705078126\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 784: \tAverage Loss:  1.8059569091796874\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 785: \tAverage Loss:  1.805705810546875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 786: \tAverage Loss:  1.805677978515625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 787: \tAverage Loss:  1.8055286865234375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 788: \tAverage Loss:  1.8052528076171874\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 789: \tAverage Loss:  1.8050072021484376\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 790: \tAverage Loss:  1.8051673583984376\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 791: \tAverage Loss:  1.8045482177734375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 792: \tAverage Loss:  1.8044881591796875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 793: \tAverage Loss:  1.8044598388671875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 794: \tAverage Loss:  1.8045042724609375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 795: \tAverage Loss:  1.8043087158203126\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 796: \tAverage Loss:  1.8040281982421875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 797: \tAverage Loss:  1.803711669921875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 798: \tAverage Loss:  1.8039190673828125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 799: \tAverage Loss:  1.8035162353515626\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 800: \tAverage Loss:  1.803424560546875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 801: \tAverage Loss:  1.8033785400390625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 802: \tAverage Loss:  1.803542236328125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 803: \tAverage Loss:  1.8033721923828125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 804: \tAverage Loss:  1.802963623046875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 805: \tAverage Loss:  1.8026534423828124\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 806: \tAverage Loss:  1.802587158203125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 807: \tAverage Loss:  1.8022587890625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 808: \tAverage Loss:  1.802174072265625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 809: \tAverage Loss:  1.8021334228515624\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 810: \tAverage Loss:  1.8018297119140625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 811: \tAverage Loss:  1.801875244140625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 812: \tAverage Loss:  1.8014971923828125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 813: \tAverage Loss:  1.801632568359375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 814: \tAverage Loss:  1.8010782470703126\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 815: \tAverage Loss:  1.8012518310546874\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 816: \tAverage Loss:  1.8010482177734375\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 817: \tAverage Loss:  1.8012286376953126\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 818: \tAverage Loss:  1.8007034912109374\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 819: \tAverage Loss:  1.8006663818359374\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 820: \tAverage Loss:  1.8006207275390624\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 821: \tAverage Loss:  1.800482421875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 822: \tAverage Loss:  1.8003145751953125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 823: \tAverage Loss:  1.8002430419921875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 824: \tAverage Loss:  1.799861572265625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 825: \tAverage Loss:  1.80013330078125\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 826: \tAverage Loss:  1.799876220703125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 827: \tAverage Loss:  1.7999432373046875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 828: \tAverage Loss:  1.7994056396484375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 829: \tAverage Loss:  1.7991407470703125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 830: \tAverage Loss:  1.7992200927734374\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 831: \tAverage Loss:  1.79897509765625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 832: \tAverage Loss:  1.7989776611328125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 833: \tAverage Loss:  1.79877099609375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 834: \tAverage Loss:  1.798519775390625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 835: \tAverage Loss:  1.798373779296875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 836: \tAverage Loss:  1.7984410400390625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 837: \tAverage Loss:  1.798268310546875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 838: \tAverage Loss:  1.7982906494140625\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 839: \tAverage Loss:  1.7981746826171876\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 840: \tAverage Loss:  1.798006591796875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 841: \tAverage Loss:  1.797613525390625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 842: \tAverage Loss:  1.7975546875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 843: \tAverage Loss:  1.7974520263671876\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 844: \tAverage Loss:  1.7973531494140624\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 845: \tAverage Loss:  1.7972147216796874\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 846: \tAverage Loss:  1.7970926513671874\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 847: \tAverage Loss:  1.797103515625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 848: \tAverage Loss:  1.79679443359375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 849: \tAverage Loss:  1.7967510986328126\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 850: \tAverage Loss:  1.796452392578125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 851: \tAverage Loss:  1.7964854736328124\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 852: \tAverage Loss:  1.7964110107421876\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 853: \tAverage Loss:  1.796069580078125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 854: \tAverage Loss:  1.7959853515625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 855: \tAverage Loss:  1.796031494140625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 856: \tAverage Loss:  1.7956962890625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 857: \tAverage Loss:  1.7956500244140625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 858: \tAverage Loss:  1.7955283203125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 859: \tAverage Loss:  1.795281982421875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 860: \tAverage Loss:  1.79517919921875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 861: \tAverage Loss:  1.7950860595703124\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 862: \tAverage Loss:  1.7949967041015624\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 863: \tAverage Loss:  1.7949569091796875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 864: \tAverage Loss:  1.794693359375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 865: \tAverage Loss:  1.7947532958984376\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 866: \tAverage Loss:  1.7945850830078125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 867: \tAverage Loss:  1.794360107421875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 868: \tAverage Loss:  1.794414306640625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 869: \tAverage Loss:  1.7941063232421874\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 870: \tAverage Loss:  1.7941005859375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 871: \tAverage Loss:  1.793868896484375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 872: \tAverage Loss:  1.793828369140625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 873: \tAverage Loss:  1.7936654052734375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 874: \tAverage Loss:  1.7934798583984375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 875: \tAverage Loss:  1.79334130859375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 876: \tAverage Loss:  1.793251708984375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 877: \tAverage Loss:  1.7931229248046876\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 878: \tAverage Loss:  1.79294775390625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 879: \tAverage Loss:  1.7928060302734374\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 880: \tAverage Loss:  1.792764404296875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 881: \tAverage Loss:  1.79263427734375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 882: \tAverage Loss:  1.7924169921875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 883: \tAverage Loss:  1.7923978271484375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 884: \tAverage Loss:  1.79228369140625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 885: \tAverage Loss:  1.79216845703125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 886: \tAverage Loss:  1.7920081787109374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 887: \tAverage Loss:  1.7919293212890626\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 888: \tAverage Loss:  1.79176708984375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 889: \tAverage Loss:  1.7916846923828125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 890: \tAverage Loss:  1.7915286865234374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 891: \tAverage Loss:  1.79132861328125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 892: \tAverage Loss:  1.7913465576171874\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 893: \tAverage Loss:  1.791176025390625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 894: \tAverage Loss:  1.7910555419921874\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 895: \tAverage Loss:  1.790875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 896: \tAverage Loss:  1.7908946533203125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 897: \tAverage Loss:  1.7907076416015626\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 898: \tAverage Loss:  1.79057861328125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 899: \tAverage Loss:  1.790488037109375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 900: \tAverage Loss:  1.7903624267578124\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 901: \tAverage Loss:  1.7902086181640624\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 902: \tAverage Loss:  1.790164794921875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 903: \tAverage Loss:  1.790067138671875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 904: \tAverage Loss:  1.7898778076171875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 905: \tAverage Loss:  1.789766845703125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 906: \tAverage Loss:  1.789647216796875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 907: \tAverage Loss:  1.789591796875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 908: \tAverage Loss:  1.7894583740234375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 909: \tAverage Loss:  1.78932421875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 910: \tAverage Loss:  1.7891468505859376\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 911: \tAverage Loss:  1.7890982666015625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 912: \tAverage Loss:  1.7889034423828125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 913: \tAverage Loss:  1.7888616943359374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 914: \tAverage Loss:  1.7886595458984376\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 915: \tAverage Loss:  1.7885748291015624\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 916: \tAverage Loss:  1.7884599609375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 917: \tAverage Loss:  1.7883890380859375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 918: \tAverage Loss:  1.788227294921875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 919: \tAverage Loss:  1.7881256103515626\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 920: \tAverage Loss:  1.788053466796875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 921: \tAverage Loss:  1.7879515380859374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 922: \tAverage Loss:  1.7877880859375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 923: \tAverage Loss:  1.7876920166015624\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 924: \tAverage Loss:  1.7876207275390625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 925: \tAverage Loss:  1.787428466796875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 926: \tAverage Loss:  1.7873900146484376\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 927: \tAverage Loss:  1.7872852783203126\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 928: \tAverage Loss:  1.787166748046875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 929: \tAverage Loss:  1.7869803466796874\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 930: \tAverage Loss:  1.786853271484375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 931: \tAverage Loss:  1.7868419189453124\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 932: \tAverage Loss:  1.786780517578125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 933: \tAverage Loss:  1.7865789794921876\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 934: \tAverage Loss:  1.786447998046875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 935: \tAverage Loss:  1.786357666015625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 936: \tAverage Loss:  1.78621875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 937: \tAverage Loss:  1.7861138916015624\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 938: \tAverage Loss:  1.7859827880859376\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 939: \tAverage Loss:  1.7858941650390625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 940: \tAverage Loss:  1.7857720947265625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 941: \tAverage Loss:  1.7856346435546875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 942: \tAverage Loss:  1.7855296630859374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 943: \tAverage Loss:  1.7854144287109375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 944: \tAverage Loss:  1.7852900390625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 945: \tAverage Loss:  1.7852479248046875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 946: \tAverage Loss:  1.7850947265625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 947: \tAverage Loss:  1.7850450439453125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 948: \tAverage Loss:  1.7848709716796876\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 949: \tAverage Loss:  1.7847530517578125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 950: \tAverage Loss:  1.7846326904296874\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 951: \tAverage Loss:  1.7845391845703125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 952: \tAverage Loss:  1.784410400390625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 953: \tAverage Loss:  1.7843359375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 954: \tAverage Loss:  1.7841875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 955: \tAverage Loss:  1.784111572265625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 956: \tAverage Loss:  1.7840247802734375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 957: \tAverage Loss:  1.783921875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 958: \tAverage Loss:  1.7837652587890624\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 959: \tAverage Loss:  1.7836669921875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 960: \tAverage Loss:  1.7836199951171876\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 961: \tAverage Loss:  1.7835341796875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 962: \tAverage Loss:  1.78337158203125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 963: \tAverage Loss:  1.783199462890625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 964: \tAverage Loss:  1.7831046142578124\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 965: \tAverage Loss:  1.7829964599609376\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 966: \tAverage Loss:  1.7829034423828125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 967: \tAverage Loss:  1.782790771484375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 968: \tAverage Loss:  1.7827021484375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 969: \tAverage Loss:  1.782604248046875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 970: \tAverage Loss:  1.782480712890625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 971: \tAverage Loss:  1.782382568359375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 972: \tAverage Loss:  1.7822713623046875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 973: \tAverage Loss:  1.7821214599609374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 974: \tAverage Loss:  1.7820423583984375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 975: \tAverage Loss:  1.7819222412109375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 976: \tAverage Loss:  1.781798583984375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 977: \tAverage Loss:  1.78168017578125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 978: \tAverage Loss:  1.7815931396484375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 979: \tAverage Loss:  1.781501220703125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 980: \tAverage Loss:  1.7814754638671875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 981: \tAverage Loss:  1.7813714599609376\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 982: \tAverage Loss:  1.781254150390625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 983: \tAverage Loss:  1.781060791015625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 984: \tAverage Loss:  1.780991455078125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 985: \tAverage Loss:  1.7809693603515624\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 986: \tAverage Loss:  1.7808382568359375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 987: \tAverage Loss:  1.780712646484375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 988: \tAverage Loss:  1.7807806396484376\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 989: \tAverage Loss:  1.7805135498046876\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 990: \tAverage Loss:  1.780333984375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 991: \tAverage Loss:  1.7803892822265626\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 992: \tAverage Loss:  1.7801866455078126\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 993: \tAverage Loss:  1.780002685546875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 994: \tAverage Loss:  1.779926513671875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 995: \tAverage Loss:  1.77981494140625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 996: \tAverage Loss:  1.779693603515625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 997: \tAverage Loss:  1.7795570068359374\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 998: \tAverage Loss:  1.7795081787109375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 999: \tAverage Loss:  1.779406982421875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1000: \tAverage Loss:  1.7792408447265624\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1001: \tAverage Loss:  1.7791220703125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1002: \tAverage Loss:  1.77903955078125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1003: \tAverage Loss:  1.77894384765625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1004: \tAverage Loss:  1.7788865966796874\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1005: \tAverage Loss:  1.778718994140625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1006: \tAverage Loss:  1.7785999755859374\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1007: \tAverage Loss:  1.7785604248046876\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1008: \tAverage Loss:  1.7784554443359375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1009: \tAverage Loss:  1.7783277587890625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1010: \tAverage Loss:  1.77816064453125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1011: \tAverage Loss:  1.7781419677734376\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1012: \tAverage Loss:  1.7781373291015625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1013: \tAverage Loss:  1.7779185791015626\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1014: \tAverage Loss:  1.7777579345703125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1015: \tAverage Loss:  1.7778104248046875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1016: \tAverage Loss:  1.77764111328125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1017: \tAverage Loss:  1.777484375\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1018: \tAverage Loss:  1.777416015625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1019: \tAverage Loss:  1.7773277587890626\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1020: \tAverage Loss:  1.7771478271484376\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 1021: \tAverage Loss:  1.777026123046875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1022: \tAverage Loss:  1.7769625244140625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1023: \tAverage Loss:  1.7768428955078126\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1024: \tAverage Loss:  1.7767266845703125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1025: \tAverage Loss:  1.7766280517578126\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1026: \tAverage Loss:  1.7764825439453125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1027: \tAverage Loss:  1.776361083984375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1028: \tAverage Loss:  1.776287109375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1029: \tAverage Loss:  1.77618408203125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1030: \tAverage Loss:  1.7760751953125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1031: \tAverage Loss:  1.7759532470703125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1032: \tAverage Loss:  1.77584033203125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1033: \tAverage Loss:  1.77577490234375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1034: \tAverage Loss:  1.7756602783203126\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1035: \tAverage Loss:  1.7755341796875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1036: \tAverage Loss:  1.775421142578125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1037: \tAverage Loss:  1.775301513671875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1038: \tAverage Loss:  1.77519091796875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1039: \tAverage Loss:  1.77511181640625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1040: \tAverage Loss:  1.775049072265625\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1041: \tAverage Loss:  1.774877197265625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1042: \tAverage Loss:  1.774788330078125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1043: \tAverage Loss:  1.77474462890625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1044: \tAverage Loss:  1.774750732421875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1045: \tAverage Loss:  1.7745260009765624\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1046: \tAverage Loss:  1.77439892578125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1047: \tAverage Loss:  1.7744075927734375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1048: \tAverage Loss:  1.7741702880859376\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1049: \tAverage Loss:  1.7740472412109376\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1050: \tAverage Loss:  1.7739420166015625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1051: \tAverage Loss:  1.7738621826171874\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1052: \tAverage Loss:  1.7736395263671876\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1053: \tAverage Loss:  1.7735267333984375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1054: \tAverage Loss:  1.7734554443359376\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1055: \tAverage Loss:  1.7732720947265626\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1056: \tAverage Loss:  1.7731083984375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1057: \tAverage Loss:  1.7731368408203125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1058: \tAverage Loss:  1.77307421875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1059: \tAverage Loss:  1.7728123779296876\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1060: \tAverage Loss:  1.77280029296875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1061: \tAverage Loss:  1.772859375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1062: \tAverage Loss:  1.772513427734375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1063: \tAverage Loss:  1.7726104736328125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1064: \tAverage Loss:  1.7727073974609375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1065: \tAverage Loss:  1.772189208984375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1066: \tAverage Loss:  1.77233544921875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1067: \tAverage Loss:  1.7722330322265625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1068: \tAverage Loss:  1.7718326416015624\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1069: \tAverage Loss:  1.771951171875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1070: \tAverage Loss:  1.7717508544921876\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1071: \tAverage Loss:  1.771531982421875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1072: \tAverage Loss:  1.7715989990234375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1073: \tAverage Loss:  1.7713134765625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1074: \tAverage Loss:  1.771225341796875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1075: \tAverage Loss:  1.771177001953125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1076: \tAverage Loss:  1.770919677734375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1077: \tAverage Loss:  1.7708487548828125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1078: \tAverage Loss:  1.7707991943359376\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1079: \tAverage Loss:  1.7705345458984374\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1080: \tAverage Loss:  1.770418212890625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1081: \tAverage Loss:  1.77040234375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1082: \tAverage Loss:  1.770229736328125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1083: \tAverage Loss:  1.7701263427734375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1084: \tAverage Loss:  1.7700660400390624\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1085: \tAverage Loss:  1.7699071044921875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1086: \tAverage Loss:  1.7697611083984375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1087: \tAverage Loss:  1.7696632080078125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1088: \tAverage Loss:  1.76957275390625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1089: \tAverage Loss:  1.7694197998046874\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1090: \tAverage Loss:  1.76937353515625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1091: \tAverage Loss:  1.7692322998046874\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1092: \tAverage Loss:  1.769056396484375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1093: \tAverage Loss:  1.7689681396484376\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1094: \tAverage Loss:  1.7689385986328126\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1095: \tAverage Loss:  1.768724609375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1096: \tAverage Loss:  1.768668701171875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1097: \tAverage Loss:  1.7685751953125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1098: \tAverage Loss:  1.7683477783203125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1099: \tAverage Loss:  1.7682532958984376\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1100: \tAverage Loss:  1.7681826171875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1101: \tAverage Loss:  1.76799462890625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1102: \tAverage Loss:  1.7678848876953126\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1103: \tAverage Loss:  1.7677479248046875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1104: \tAverage Loss:  1.767609619140625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1105: \tAverage Loss:  1.7675369873046876\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1106: \tAverage Loss:  1.767434814453125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1107: \tAverage Loss:  1.7672822265625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1108: \tAverage Loss:  1.76720703125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1109: \tAverage Loss:  1.76711767578125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1110: \tAverage Loss:  1.766923583984375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1111: \tAverage Loss:  1.7668900146484374\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1112: \tAverage Loss:  1.76668896484375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1113: \tAverage Loss:  1.7666051025390626\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1114: \tAverage Loss:  1.766475341796875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1115: \tAverage Loss:  1.7663369140625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1116: \tAverage Loss:  1.766169677734375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1117: \tAverage Loss:  1.7660545654296875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1118: \tAverage Loss:  1.76592529296875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1119: \tAverage Loss:  1.76585693359375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1120: \tAverage Loss:  1.7657071533203126\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1121: \tAverage Loss:  1.765680419921875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1122: \tAverage Loss:  1.7654644775390624\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1123: \tAverage Loss:  1.76534814453125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1124: \tAverage Loss:  1.765224365234375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1125: \tAverage Loss:  1.765077392578125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1126: \tAverage Loss:  1.7649364013671875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1127: \tAverage Loss:  1.764890869140625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1128: \tAverage Loss:  1.764744140625\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1129: \tAverage Loss:  1.7646085205078126\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1130: \tAverage Loss:  1.764486328125\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1131: \tAverage Loss:  1.7643809814453124\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1132: \tAverage Loss:  1.7642113037109375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1133: \tAverage Loss:  1.7640870361328125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1134: \tAverage Loss:  1.76403662109375\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 1135: \tAverage Loss:  1.7638431396484375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1136: \tAverage Loss:  1.7636751708984375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1137: \tAverage Loss:  1.76358935546875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1138: \tAverage Loss:  1.7634620361328126\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1139: \tAverage Loss:  1.7633359375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1140: \tAverage Loss:  1.76315966796875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1141: \tAverage Loss:  1.7631258544921875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1142: \tAverage Loss:  1.7630467529296876\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1143: \tAverage Loss:  1.7628115234375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1144: \tAverage Loss:  1.76270458984375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1145: \tAverage Loss:  1.76257958984375\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1146: \tAverage Loss:  1.762445556640625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1147: \tAverage Loss:  1.762311279296875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1148: \tAverage Loss:  1.76211962890625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1149: \tAverage Loss:  1.76203515625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1150: \tAverage Loss:  1.7619046630859374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1151: \tAverage Loss:  1.7617821044921875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1152: \tAverage Loss:  1.7616136474609374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1153: \tAverage Loss:  1.7614869384765626\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1154: \tAverage Loss:  1.76138427734375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1155: \tAverage Loss:  1.761250244140625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1156: \tAverage Loss:  1.761101318359375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1157: \tAverage Loss:  1.7609432373046876\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1158: \tAverage Loss:  1.7607979736328125\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1159: \tAverage Loss:  1.7606898193359375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1160: \tAverage Loss:  1.7605556640625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1161: \tAverage Loss:  1.7603734130859374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1162: \tAverage Loss:  1.760258544921875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1163: \tAverage Loss:  1.760082763671875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1164: \tAverage Loss:  1.75992236328125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1165: \tAverage Loss:  1.7598609619140626\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1166: \tAverage Loss:  1.7596507568359374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1167: \tAverage Loss:  1.7594591064453124\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1168: \tAverage Loss:  1.7593046875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1169: \tAverage Loss:  1.7591766357421874\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1170: \tAverage Loss:  1.759056884765625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1171: \tAverage Loss:  1.7588514404296876\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1172: \tAverage Loss:  1.758660888671875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1173: \tAverage Loss:  1.7585159912109376\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1174: \tAverage Loss:  1.758324951171875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1175: \tAverage Loss:  1.7581583251953126\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1176: \tAverage Loss:  1.7580501708984375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1177: \tAverage Loss:  1.7578907470703125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1178: \tAverage Loss:  1.7576695556640625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1179: \tAverage Loss:  1.7574998779296875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1180: \tAverage Loss:  1.7573909912109376\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1181: \tAverage Loss:  1.757158447265625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1182: \tAverage Loss:  1.756994873046875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1183: \tAverage Loss:  1.756838623046875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1184: \tAverage Loss:  1.7566209716796874\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1185: \tAverage Loss:  1.7564356689453124\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1186: \tAverage Loss:  1.756310791015625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1187: \tAverage Loss:  1.75609375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1188: \tAverage Loss:  1.7558861083984374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1189: \tAverage Loss:  1.7557867431640626\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1190: \tAverage Loss:  1.7555504150390624\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1191: \tAverage Loss:  1.7553895263671875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1192: \tAverage Loss:  1.7551734619140624\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1193: \tAverage Loss:  1.75494384765625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1194: \tAverage Loss:  1.754759033203125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1195: \tAverage Loss:  1.7545533447265624\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1196: \tAverage Loss:  1.7543673095703125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1197: \tAverage Loss:  1.7541348876953125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1198: \tAverage Loss:  1.75394775390625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1199: \tAverage Loss:  1.753712158203125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1200: \tAverage Loss:  1.7534876708984375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1201: \tAverage Loss:  1.75325048828125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1202: \tAverage Loss:  1.752993896484375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1203: \tAverage Loss:  1.752759521484375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1204: \tAverage Loss:  1.752488037109375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1205: \tAverage Loss:  1.7522113037109375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1206: \tAverage Loss:  1.7519111328125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1207: \tAverage Loss:  1.7516014404296876\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1208: \tAverage Loss:  1.7513211669921875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1209: \tAverage Loss:  1.750951904296875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1210: \tAverage Loss:  1.75071826171875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1211: \tAverage Loss:  1.750363525390625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1212: \tAverage Loss:  1.750016845703125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1213: \tAverage Loss:  1.7496962890625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1214: \tAverage Loss:  1.7493519287109376\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1215: \tAverage Loss:  1.7490208740234374\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1216: \tAverage Loss:  1.7486600341796874\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1217: \tAverage Loss:  1.7483011474609376\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1218: \tAverage Loss:  1.747969482421875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1219: \tAverage Loss:  1.7476597900390625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1220: \tAverage Loss:  1.7473070068359375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1221: \tAverage Loss:  1.7470050048828125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 1222: \tAverage Loss:  1.74668994140625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1223: \tAverage Loss:  1.7463048095703124\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1224: \tAverage Loss:  1.7459859619140625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1225: \tAverage Loss:  1.7455888671875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1226: \tAverage Loss:  1.745250732421875\t ACC train:  0.6825\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1227: \tAverage Loss:  1.7447825927734375\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 1228: \tAverage Loss:  1.7443250732421876\t ACC train:  0.6775\t ACC test:  0.6377777777777778\n",
      "\tEpoch 1229: \tAverage Loss:  1.7438702392578125\t ACC train:  0.665\t ACC test:  0.6288888888888889\n",
      "\tEpoch 1230: \tAverage Loss:  1.7433360595703125\t ACC train:  0.66\t ACC test:  0.6177777777777778\n",
      "\tEpoch 1231: \tAverage Loss:  1.7427803955078125\t ACC train:  0.655\t ACC test:  0.6066666666666667\n",
      "\tEpoch 1232: \tAverage Loss:  1.742234619140625\t ACC train:  0.6525\t ACC test:  0.6022222222222222\n",
      "\tEpoch 1233: \tAverage Loss:  1.7415841064453126\t ACC train:  0.63\t ACC test:  0.5955555555555555\n",
      "\tEpoch 1234: \tAverage Loss:  1.74098779296875\t ACC train:  0.6275\t ACC test:  0.5911111111111111\n",
      "\tEpoch 1235: \tAverage Loss:  1.7403203125\t ACC train:  0.62\t ACC test:  0.5844444444444444\n",
      "\tEpoch 1236: \tAverage Loss:  1.739624755859375\t ACC train:  0.6175\t ACC test:  0.5755555555555556\n",
      "\tEpoch 1237: \tAverage Loss:  1.7388394775390625\t ACC train:  0.6175\t ACC test:  0.5777777777777777\n",
      "\tEpoch 1238: \tAverage Loss:  1.73804052734375\t ACC train:  0.625\t ACC test:  0.5844444444444444\n",
      "\tEpoch 1239: \tAverage Loss:  1.7372587890625\t ACC train:  0.625\t ACC test:  0.5911111111111111\n",
      "\tEpoch 1240: \tAverage Loss:  1.736347412109375\t ACC train:  0.6725\t ACC test:  0.6177777777777778\n",
      "\tEpoch 1241: \tAverage Loss:  1.7354727783203125\t ACC train:  0.6775\t ACC test:  0.6222222222222222\n",
      "\tEpoch 1242: \tAverage Loss:  1.7344989013671874\t ACC train:  0.69\t ACC test:  0.6333333333333333\n",
      "\tEpoch 1243: \tAverage Loss:  1.7334505615234375\t ACC train:  0.705\t ACC test:  0.6355555555555555\n",
      "\tEpoch 1244: \tAverage Loss:  1.732431640625\t ACC train:  0.7175\t ACC test:  0.6533333333333333\n",
      "\tEpoch 1245: \tAverage Loss:  1.7314620361328126\t ACC train:  0.7175\t ACC test:  0.6577777777777778\n",
      "\tEpoch 1246: \tAverage Loss:  1.73043896484375\t ACC train:  0.74\t ACC test:  0.6711111111111111\n",
      "\tEpoch 1247: \tAverage Loss:  1.72949365234375\t ACC train:  0.7375\t ACC test:  0.6822222222222222\n",
      "\tEpoch 1248: \tAverage Loss:  1.7286119384765626\t ACC train:  0.745\t ACC test:  0.6866666666666666\n",
      "\tEpoch 1249: \tAverage Loss:  1.727649658203125\t ACC train:  0.7575\t ACC test:  0.6955555555555556\n",
      "\tEpoch 1250: \tAverage Loss:  1.7268704833984374\t ACC train:  0.76\t ACC test:  0.6955555555555556\n",
      "\tEpoch 1251: \tAverage Loss:  1.7258001708984374\t ACC train:  0.7675\t ACC test:  0.7066666666666667\n",
      "\tEpoch 1252: \tAverage Loss:  1.7250443115234375\t ACC train:  0.7625\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1253: \tAverage Loss:  1.724218505859375\t ACC train:  0.7625\t ACC test:  0.7177777777777777\n",
      "\tEpoch 1254: \tAverage Loss:  1.7233843994140625\t ACC train:  0.76\t ACC test:  0.72\n",
      "\tEpoch 1255: \tAverage Loss:  1.7226146240234375\t ACC train:  0.765\t ACC test:  0.7244444444444444\n",
      "\tEpoch 1256: \tAverage Loss:  1.721973388671875\t ACC train:  0.765\t ACC test:  0.7222222222222222\n",
      "\tEpoch 1257: \tAverage Loss:  1.7211337890625\t ACC train:  0.77\t ACC test:  0.7288888888888889\n",
      "\tEpoch 1258: \tAverage Loss:  1.7203140869140625\t ACC train:  0.77\t ACC test:  0.7311111111111112\n",
      "\tEpoch 1259: \tAverage Loss:  1.7196043701171875\t ACC train:  0.77\t ACC test:  0.7333333333333333\n",
      "\tEpoch 1260: \tAverage Loss:  1.7189630126953126\t ACC train:  0.7725\t ACC test:  0.7377777777777778\n",
      "\tEpoch 1261: \tAverage Loss:  1.7181717529296876\t ACC train:  0.7775\t ACC test:  0.7355555555555555\n",
      "\tEpoch 1262: \tAverage Loss:  1.717671142578125\t ACC train:  0.7775\t ACC test:  0.7333333333333333\n",
      "\tEpoch 1263: \tAverage Loss:  1.716993896484375\t ACC train:  0.7775\t ACC test:  0.7377777777777778\n",
      "\tEpoch 1264: \tAverage Loss:  1.7163597412109375\t ACC train:  0.7825\t ACC test:  0.74\n",
      "\tEpoch 1265: \tAverage Loss:  1.7156776123046875\t ACC train:  0.7825\t ACC test:  0.74\n",
      "\tEpoch 1266: \tAverage Loss:  1.7152545166015625\t ACC train:  0.7775\t ACC test:  0.7422222222222222\n",
      "\tEpoch 1267: \tAverage Loss:  1.714579833984375\t ACC train:  0.7775\t ACC test:  0.74\n",
      "\tEpoch 1268: \tAverage Loss:  1.71407080078125\t ACC train:  0.7775\t ACC test:  0.7422222222222222\n",
      "\tEpoch 1269: \tAverage Loss:  1.713592041015625\t ACC train:  0.7775\t ACC test:  0.74\n",
      "\tEpoch 1270: \tAverage Loss:  1.7131397705078124\t ACC train:  0.775\t ACC test:  0.7377777777777778\n",
      "\tEpoch 1271: \tAverage Loss:  1.712524658203125\t ACC train:  0.7775\t ACC test:  0.7377777777777778\n",
      "\tEpoch 1272: \tAverage Loss:  1.7120369873046875\t ACC train:  0.7825\t ACC test:  0.74\n",
      "\tEpoch 1273: \tAverage Loss:  1.7114886474609374\t ACC train:  0.7875\t ACC test:  0.7422222222222222\n",
      "\tEpoch 1274: \tAverage Loss:  1.7110452880859375\t ACC train:  0.785\t ACC test:  0.7444444444444445\n",
      "\tEpoch 1275: \tAverage Loss:  1.7105474853515625\t ACC train:  0.7875\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1276: \tAverage Loss:  1.7099825439453125\t ACC train:  0.785\t ACC test:  0.7444444444444445\n",
      "\tEpoch 1277: \tAverage Loss:  1.7096409912109376\t ACC train:  0.785\t ACC test:  0.7444444444444445\n",
      "\tEpoch 1278: \tAverage Loss:  1.7092315673828125\t ACC train:  0.7875\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1279: \tAverage Loss:  1.708618408203125\t ACC train:  0.785\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1280: \tAverage Loss:  1.70823779296875\t ACC train:  0.785\t ACC test:  0.7444444444444445\n",
      "\tEpoch 1281: \tAverage Loss:  1.7080029296875\t ACC train:  0.79\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1282: \tAverage Loss:  1.7078262939453126\t ACC train:  0.7925\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1283: \tAverage Loss:  1.7071727294921875\t ACC train:  0.79\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1284: \tAverage Loss:  1.706492919921875\t ACC train:  0.79\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1285: \tAverage Loss:  1.70631591796875\t ACC train:  0.795\t ACC test:  0.7444444444444445\n",
      "\tEpoch 1286: \tAverage Loss:  1.705869384765625\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1287: \tAverage Loss:  1.7056826171875\t ACC train:  0.7925\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1288: \tAverage Loss:  1.705004638671875\t ACC train:  0.7925\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1289: \tAverage Loss:  1.704666259765625\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1290: \tAverage Loss:  1.7043516845703126\t ACC train:  0.7925\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1291: \tAverage Loss:  1.7041610107421874\t ACC train:  0.7975\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1292: \tAverage Loss:  1.7038350830078124\t ACC train:  0.7925\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1293: \tAverage Loss:  1.7034874267578124\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1294: \tAverage Loss:  1.70317431640625\t ACC train:  0.795\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1295: \tAverage Loss:  1.702806396484375\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1296: \tAverage Loss:  1.7024742431640625\t ACC train:  0.795\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1297: \tAverage Loss:  1.7021416015625\t ACC train:  0.795\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1298: \tAverage Loss:  1.7018218994140626\t ACC train:  0.795\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1299: \tAverage Loss:  1.701500732421875\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1300: \tAverage Loss:  1.701349365234375\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1301: \tAverage Loss:  1.70107275390625\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1302: \tAverage Loss:  1.70076513671875\t ACC train:  0.795\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1303: \tAverage Loss:  1.7004571533203126\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1304: \tAverage Loss:  1.7000687255859375\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1305: \tAverage Loss:  1.6997198486328124\t ACC train:  0.795\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1306: \tAverage Loss:  1.6994700927734374\t ACC train:  0.795\t ACC test:  0.7466666666666667\n",
      "\tEpoch 1307: \tAverage Loss:  1.699180908203125\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1308: \tAverage Loss:  1.69887841796875\t ACC train:  0.795\t ACC test:  0.7488888888888889\n",
      "\tEpoch 1309: \tAverage Loss:  1.6986534423828126\t ACC train:  0.795\t ACC test:  0.7511111111111111\n",
      "\tEpoch 1310: \tAverage Loss:  1.698393798828125\t ACC train:  0.8\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1311: \tAverage Loss:  1.69830078125\t ACC train:  0.7925\t ACC test:  0.7511111111111111\n",
      "\tEpoch 1312: \tAverage Loss:  1.6981973876953125\t ACC train:  0.8025\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1313: \tAverage Loss:  1.6983328857421875\t ACC train:  0.7925\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1314: \tAverage Loss:  1.6979676513671875\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1315: \tAverage Loss:  1.6977581787109375\t ACC train:  0.7975\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1316: \tAverage Loss:  1.697509521484375\t ACC train:  0.7975\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1317: \tAverage Loss:  1.697002197265625\t ACC train:  0.8\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1318: \tAverage Loss:  1.69695361328125\t ACC train:  0.7925\t ACC test:  0.7511111111111111\n",
      "\tEpoch 1319: \tAverage Loss:  1.6968758544921876\t ACC train:  0.805\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1320: \tAverage Loss:  1.6968326416015624\t ACC train:  0.8\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1321: \tAverage Loss:  1.696172119140625\t ACC train:  0.8\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1322: \tAverage Loss:  1.6958861083984376\t ACC train:  0.8025\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1323: \tAverage Loss:  1.6959154052734375\t ACC train:  0.7975\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1324: \tAverage Loss:  1.6957943115234375\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1325: \tAverage Loss:  1.6955482177734376\t ACC train:  0.8025\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1326: \tAverage Loss:  1.695099365234375\t ACC train:  0.7975\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1327: \tAverage Loss:  1.69490087890625\t ACC train:  0.8025\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1328: \tAverage Loss:  1.695314697265625\t ACC train:  0.7975\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1329: \tAverage Loss:  1.6949884033203124\t ACC train:  0.8\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1330: \tAverage Loss:  1.6943753662109375\t ACC train:  0.8\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1331: \tAverage Loss:  1.6941865234375\t ACC train:  0.7975\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1332: \tAverage Loss:  1.6942879638671875\t ACC train:  0.8025\t ACC test:  0.76\n",
      "\tEpoch 1333: \tAverage Loss:  1.6942174072265626\t ACC train:  0.7975\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1334: \tAverage Loss:  1.693578857421875\t ACC train:  0.8\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1335: \tAverage Loss:  1.6933740234375\t ACC train:  0.805\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1336: \tAverage Loss:  1.69350732421875\t ACC train:  0.7975\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1337: \tAverage Loss:  1.693126953125\t ACC train:  0.8\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1338: \tAverage Loss:  1.6931568603515625\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1339: \tAverage Loss:  1.692681396484375\t ACC train:  0.8\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1340: \tAverage Loss:  1.6925045166015624\t ACC train:  0.8\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1341: \tAverage Loss:  1.6921614990234375\t ACC train:  0.8\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1342: \tAverage Loss:  1.691944580078125\t ACC train:  0.8025\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1343: \tAverage Loss:  1.6920296630859375\t ACC train:  0.8025\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1344: \tAverage Loss:  1.6919334716796874\t ACC train:  0.8025\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1345: \tAverage Loss:  1.6914312744140625\t ACC train:  0.8\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1346: \tAverage Loss:  1.6915986328125\t ACC train:  0.8\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1347: \tAverage Loss:  1.691219970703125\t ACC train:  0.8\t ACC test:  0.7511111111111111\n",
      "\tEpoch 1348: \tAverage Loss:  1.6911153564453125\t ACC train:  0.8\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1349: \tAverage Loss:  1.690872802734375\t ACC train:  0.8025\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1350: \tAverage Loss:  1.690599609375\t ACC train:  0.8025\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1351: \tAverage Loss:  1.6906806640625\t ACC train:  0.805\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1352: \tAverage Loss:  1.6905350341796874\t ACC train:  0.8075\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1353: \tAverage Loss:  1.690295166015625\t ACC train:  0.8025\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1354: \tAverage Loss:  1.690028564453125\t ACC train:  0.8\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1355: \tAverage Loss:  1.689809326171875\t ACC train:  0.805\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1356: \tAverage Loss:  1.6895672607421874\t ACC train:  0.8025\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1357: \tAverage Loss:  1.6893157958984375\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1358: \tAverage Loss:  1.6893072509765625\t ACC train:  0.8075\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1359: \tAverage Loss:  1.6889219970703124\t ACC train:  0.8025\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1360: \tAverage Loss:  1.688879150390625\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1361: \tAverage Loss:  1.6887476806640624\t ACC train:  0.805\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1362: \tAverage Loss:  1.68843359375\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1363: \tAverage Loss:  1.688148681640625\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1364: \tAverage Loss:  1.688080810546875\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1365: \tAverage Loss:  1.6877125244140625\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1366: \tAverage Loss:  1.6875726318359374\t ACC train:  0.8075\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1367: \tAverage Loss:  1.687387451171875\t ACC train:  0.805\t ACC test:  0.7533333333333333\n",
      "\tEpoch 1368: \tAverage Loss:  1.6873614501953125\t ACC train:  0.8075\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1369: \tAverage Loss:  1.687318603515625\t ACC train:  0.8075\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1370: \tAverage Loss:  1.6867403564453125\t ACC train:  0.805\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1371: \tAverage Loss:  1.68629541015625\t ACC train:  0.805\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1372: \tAverage Loss:  1.6861568603515624\t ACC train:  0.805\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1373: \tAverage Loss:  1.6858519287109375\t ACC train:  0.8075\t ACC test:  0.7555555555555555\n",
      "\tEpoch 1374: \tAverage Loss:  1.685782958984375\t ACC train:  0.8075\t ACC test:  0.76\n",
      "\tEpoch 1375: \tAverage Loss:  1.685584228515625\t ACC train:  0.8075\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1376: \tAverage Loss:  1.6852154541015625\t ACC train:  0.8075\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1377: \tAverage Loss:  1.68456689453125\t ACC train:  0.81\t ACC test:  0.76\n",
      "\tEpoch 1378: \tAverage Loss:  1.6843271484375\t ACC train:  0.8075\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1379: \tAverage Loss:  1.6844127197265626\t ACC train:  0.81\t ACC test:  0.76\n",
      "\tEpoch 1380: \tAverage Loss:  1.684384765625\t ACC train:  0.81\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1381: \tAverage Loss:  1.6834761962890625\t ACC train:  0.81\t ACC test:  0.76\n",
      "\tEpoch 1382: \tAverage Loss:  1.6828966064453126\t ACC train:  0.8075\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1383: \tAverage Loss:  1.683044189453125\t ACC train:  0.81\t ACC test:  0.7622222222222222\n",
      "\tEpoch 1384: \tAverage Loss:  1.683024169921875\t ACC train:  0.8075\t ACC test:  0.76\n",
      "\tEpoch 1385: \tAverage Loss:  1.6827813720703124\t ACC train:  0.8125\t ACC test:  0.76\n",
      "\tEpoch 1386: \tAverage Loss:  1.681810546875\t ACC train:  0.81\t ACC test:  0.7622222222222222\n",
      "\tEpoch 1387: \tAverage Loss:  1.6815888671875\t ACC train:  0.8075\t ACC test:  0.7577777777777778\n",
      "\tEpoch 1388: \tAverage Loss:  1.6818587646484375\t ACC train:  0.81\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1389: \tAverage Loss:  1.68137646484375\t ACC train:  0.8125\t ACC test:  0.7622222222222222\n",
      "\tEpoch 1390: \tAverage Loss:  1.680448486328125\t ACC train:  0.8125\t ACC test:  0.7622222222222222\n",
      "\tEpoch 1391: \tAverage Loss:  1.6802760009765625\t ACC train:  0.815\t ACC test:  0.7622222222222222\n",
      "\tEpoch 1392: \tAverage Loss:  1.680587158203125\t ACC train:  0.8125\t ACC test:  0.76\n",
      "\tEpoch 1393: \tAverage Loss:  1.680002197265625\t ACC train:  0.8125\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1394: \tAverage Loss:  1.679118408203125\t ACC train:  0.815\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1395: \tAverage Loss:  1.6789969482421876\t ACC train:  0.81\t ACC test:  0.7622222222222222\n",
      "\tEpoch 1396: \tAverage Loss:  1.6792059326171875\t ACC train:  0.8175\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1397: \tAverage Loss:  1.6782637939453124\t ACC train:  0.8175\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1398: \tAverage Loss:  1.6778531494140625\t ACC train:  0.815\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1399: \tAverage Loss:  1.6777713623046875\t ACC train:  0.82\t ACC test:  0.7622222222222222\n",
      "\tEpoch 1400: \tAverage Loss:  1.6771661376953124\t ACC train:  0.82\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1401: \tAverage Loss:  1.6767298583984376\t ACC train:  0.8175\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1402: \tAverage Loss:  1.6765859375\t ACC train:  0.825\t ACC test:  0.7622222222222222\n",
      "\tEpoch 1403: \tAverage Loss:  1.676379150390625\t ACC train:  0.82\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1404: \tAverage Loss:  1.6758826904296875\t ACC train:  0.825\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1405: \tAverage Loss:  1.675279541015625\t ACC train:  0.825\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1406: \tAverage Loss:  1.6750438232421876\t ACC train:  0.82\t ACC test:  0.7666666666666667\n",
      "\tEpoch 1407: \tAverage Loss:  1.674741455078125\t ACC train:  0.825\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1408: \tAverage Loss:  1.6742386474609374\t ACC train:  0.825\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1409: \tAverage Loss:  1.673876220703125\t ACC train:  0.825\t ACC test:  0.7666666666666667\n",
      "\tEpoch 1410: \tAverage Loss:  1.6735982666015625\t ACC train:  0.8275\t ACC test:  0.7644444444444445\n",
      "\tEpoch 1411: \tAverage Loss:  1.6729324951171876\t ACC train:  0.8275\t ACC test:  0.7622222222222222\n",
      "\tEpoch 1412: \tAverage Loss:  1.672635009765625\t ACC train:  0.83\t ACC test:  0.7755555555555556\n",
      "\tEpoch 1413: \tAverage Loss:  1.672302490234375\t ACC train:  0.8325\t ACC test:  0.7711111111111111\n",
      "\tEpoch 1414: \tAverage Loss:  1.671822998046875\t ACC train:  0.83\t ACC test:  0.7733333333333333\n",
      "\tEpoch 1415: \tAverage Loss:  1.67125537109375\t ACC train:  0.83\t ACC test:  0.7777777777777778\n",
      "\tEpoch 1416: \tAverage Loss:  1.670779296875\t ACC train:  0.83\t ACC test:  0.7755555555555556\n",
      "\tEpoch 1417: \tAverage Loss:  1.6703592529296876\t ACC train:  0.8325\t ACC test:  0.7822222222222223\n",
      "\tEpoch 1418: \tAverage Loss:  1.6698431396484374\t ACC train:  0.8325\t ACC test:  0.7733333333333333\n",
      "\tEpoch 1419: \tAverage Loss:  1.66946923828125\t ACC train:  0.845\t ACC test:  0.7866666666666666\n",
      "\tEpoch 1420: \tAverage Loss:  1.6688734130859375\t ACC train:  0.8425\t ACC test:  0.7866666666666666\n",
      "\tEpoch 1421: \tAverage Loss:  1.6683487548828124\t ACC train:  0.845\t ACC test:  0.7911111111111111\n",
      "\tEpoch 1422: \tAverage Loss:  1.6676639404296876\t ACC train:  0.845\t ACC test:  0.7977777777777778\n",
      "\tEpoch 1423: \tAverage Loss:  1.6675125732421876\t ACC train:  0.855\t ACC test:  0.8022222222222222\n",
      "\tEpoch 1424: \tAverage Loss:  1.6669522705078126\t ACC train:  0.85\t ACC test:  0.8\n",
      "\tEpoch 1425: \tAverage Loss:  1.6661513671875\t ACC train:  0.855\t ACC test:  0.8044444444444444\n",
      "\tEpoch 1426: \tAverage Loss:  1.6657081298828125\t ACC train:  0.8575\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1427: \tAverage Loss:  1.6650299072265624\t ACC train:  0.8575\t ACC test:  0.82\n",
      "\tEpoch 1428: \tAverage Loss:  1.6645047607421875\t ACC train:  0.8575\t ACC test:  0.8133333333333334\n",
      "\tEpoch 1429: \tAverage Loss:  1.664013427734375\t ACC train:  0.86\t ACC test:  0.82\n",
      "\tEpoch 1430: \tAverage Loss:  1.6634183349609375\t ACC train:  0.8625\t ACC test:  0.82\n",
      "\tEpoch 1431: \tAverage Loss:  1.6626822509765624\t ACC train:  0.8625\t ACC test:  0.8222222222222222\n",
      "\tEpoch 1432: \tAverage Loss:  1.6620050048828126\t ACC train:  0.875\t ACC test:  0.8244444444444444\n",
      "\tEpoch 1433: \tAverage Loss:  1.6616168212890625\t ACC train:  0.8775\t ACC test:  0.8244444444444444\n",
      "\tEpoch 1434: \tAverage Loss:  1.66073388671875\t ACC train:  0.88\t ACC test:  0.8266666666666667\n",
      "\tEpoch 1435: \tAverage Loss:  1.660222412109375\t ACC train:  0.88\t ACC test:  0.8288888888888889\n",
      "\tEpoch 1436: \tAverage Loss:  1.6593995361328124\t ACC train:  0.8825\t ACC test:  0.8266666666666667\n",
      "\tEpoch 1437: \tAverage Loss:  1.6588536376953125\t ACC train:  0.88\t ACC test:  0.8266666666666667\n",
      "\tEpoch 1438: \tAverage Loss:  1.6581060791015625\t ACC train:  0.8825\t ACC test:  0.8266666666666667\n",
      "\tEpoch 1439: \tAverage Loss:  1.65753515625\t ACC train:  0.8825\t ACC test:  0.8288888888888889\n",
      "\tEpoch 1440: \tAverage Loss:  1.6568358154296876\t ACC train:  0.88\t ACC test:  0.8311111111111111\n",
      "\tEpoch 1441: \tAverage Loss:  1.656223388671875\t ACC train:  0.8825\t ACC test:  0.8288888888888889\n",
      "\tEpoch 1442: \tAverage Loss:  1.655654541015625\t ACC train:  0.8825\t ACC test:  0.8288888888888889\n",
      "\tEpoch 1443: \tAverage Loss:  1.6550921630859374\t ACC train:  0.8825\t ACC test:  0.8266666666666667\n",
      "\tEpoch 1444: \tAverage Loss:  1.654333740234375\t ACC train:  0.8825\t ACC test:  0.8311111111111111\n",
      "\tEpoch 1445: \tAverage Loss:  1.6538470458984376\t ACC train:  0.8825\t ACC test:  0.8288888888888889\n",
      "\tEpoch 1446: \tAverage Loss:  1.6530328369140626\t ACC train:  0.885\t ACC test:  0.8355555555555556\n",
      "\tEpoch 1447: \tAverage Loss:  1.652477783203125\t ACC train:  0.8875\t ACC test:  0.8355555555555556\n",
      "\tEpoch 1448: \tAverage Loss:  1.6517001953125\t ACC train:  0.8875\t ACC test:  0.8333333333333334\n",
      "\tEpoch 1449: \tAverage Loss:  1.651241943359375\t ACC train:  0.8825\t ACC test:  0.8422222222222222\n",
      "\tEpoch 1450: \tAverage Loss:  1.65065771484375\t ACC train:  0.89\t ACC test:  0.8355555555555556\n",
      "\tEpoch 1451: \tAverage Loss:  1.650070556640625\t ACC train:  0.8825\t ACC test:  0.8422222222222222\n",
      "\tEpoch 1452: \tAverage Loss:  1.6494002685546876\t ACC train:  0.89\t ACC test:  0.8422222222222222\n",
      "\tEpoch 1453: \tAverage Loss:  1.6487701416015625\t ACC train:  0.8825\t ACC test:  0.84\n",
      "\tEpoch 1454: \tAverage Loss:  1.647912841796875\t ACC train:  0.88\t ACC test:  0.8488888888888889\n",
      "\tEpoch 1455: \tAverage Loss:  1.6473671875\t ACC train:  0.89\t ACC test:  0.8377777777777777\n",
      "\tEpoch 1456: \tAverage Loss:  1.647341064453125\t ACC train:  0.88\t ACC test:  0.8555555555555555\n",
      "\tEpoch 1457: \tAverage Loss:  1.64709716796875\t ACC train:  0.8925\t ACC test:  0.8422222222222222\n",
      "\tEpoch 1458: \tAverage Loss:  1.6466458740234375\t ACC train:  0.8775\t ACC test:  0.8555555555555555\n",
      "\tEpoch 1459: \tAverage Loss:  1.6452421875\t ACC train:  0.88\t ACC test:  0.8488888888888889\n",
      "\tEpoch 1460: \tAverage Loss:  1.6443853759765625\t ACC train:  0.8825\t ACC test:  0.8488888888888889\n",
      "\tEpoch 1461: \tAverage Loss:  1.6439393310546875\t ACC train:  0.8825\t ACC test:  0.8577777777777778\n",
      "\tEpoch 1462: \tAverage Loss:  1.6442462158203126\t ACC train:  0.8875\t ACC test:  0.8555555555555555\n",
      "\tEpoch 1463: \tAverage Loss:  1.6434832763671876\t ACC train:  0.8825\t ACC test:  0.86\n",
      "\tEpoch 1464: \tAverage Loss:  1.6425838623046876\t ACC train:  0.8775\t ACC test:  0.86\n",
      "\tEpoch 1465: \tAverage Loss:  1.6415245361328126\t ACC train:  0.8825\t ACC test:  0.8577777777777778\n",
      "\tEpoch 1466: \tAverage Loss:  1.6415966796875\t ACC train:  0.89\t ACC test:  0.8622222222222222\n",
      "\tEpoch 1467: \tAverage Loss:  1.641038818359375\t ACC train:  0.88\t ACC test:  0.86\n",
      "\tEpoch 1468: \tAverage Loss:  1.640282958984375\t ACC train:  0.8875\t ACC test:  0.8577777777777778\n",
      "\tEpoch 1469: \tAverage Loss:  1.6395648193359376\t ACC train:  0.89\t ACC test:  0.86\n",
      "\tEpoch 1470: \tAverage Loss:  1.639402587890625\t ACC train:  0.8875\t ACC test:  0.86\n",
      "\tEpoch 1471: \tAverage Loss:  1.6387337646484375\t ACC train:  0.89\t ACC test:  0.8577777777777778\n",
      "\tEpoch 1472: \tAverage Loss:  1.6381939697265624\t ACC train:  0.885\t ACC test:  0.8577777777777778\n",
      "\tEpoch 1473: \tAverage Loss:  1.6375477294921874\t ACC train:  0.89\t ACC test:  0.8622222222222222\n",
      "\tEpoch 1474: \tAverage Loss:  1.6369520263671875\t ACC train:  0.8925\t ACC test:  0.8577777777777778\n",
      "\tEpoch 1475: \tAverage Loss:  1.636464599609375\t ACC train:  0.89\t ACC test:  0.86\n",
      "\tEpoch 1476: \tAverage Loss:  1.6360672607421876\t ACC train:  0.89\t ACC test:  0.8555555555555555\n",
      "\tEpoch 1477: \tAverage Loss:  1.635286865234375\t ACC train:  0.89\t ACC test:  0.86\n",
      "\tEpoch 1478: \tAverage Loss:  1.635108642578125\t ACC train:  0.89\t ACC test:  0.8622222222222222\n",
      "\tEpoch 1479: \tAverage Loss:  1.6346417236328126\t ACC train:  0.895\t ACC test:  0.86\n",
      "\tEpoch 1480: \tAverage Loss:  1.634232177734375\t ACC train:  0.895\t ACC test:  0.8688888888888889\n",
      "\tEpoch 1481: \tAverage Loss:  1.633379638671875\t ACC train:  0.8925\t ACC test:  0.8622222222222222\n",
      "\tEpoch 1482: \tAverage Loss:  1.632912109375\t ACC train:  0.8925\t ACC test:  0.8644444444444445\n",
      "\tEpoch 1483: \tAverage Loss:  1.6324310302734375\t ACC train:  0.895\t ACC test:  0.8666666666666667\n",
      "\tEpoch 1484: \tAverage Loss:  1.6320185546875\t ACC train:  0.8925\t ACC test:  0.8644444444444445\n",
      "\tEpoch 1485: \tAverage Loss:  1.6316746826171875\t ACC train:  0.895\t ACC test:  0.8688888888888889\n",
      "\tEpoch 1486: \tAverage Loss:  1.6307225341796876\t ACC train:  0.8925\t ACC test:  0.8688888888888889\n",
      "\tEpoch 1487: \tAverage Loss:  1.630768798828125\t ACC train:  0.8925\t ACC test:  0.8688888888888889\n",
      "\tEpoch 1488: \tAverage Loss:  1.6302198486328126\t ACC train:  0.8925\t ACC test:  0.8666666666666667\n",
      "\tEpoch 1489: \tAverage Loss:  1.629979736328125\t ACC train:  0.895\t ACC test:  0.8711111111111111\n",
      "\tEpoch 1490: \tAverage Loss:  1.6293857421875\t ACC train:  0.895\t ACC test:  0.8711111111111111\n",
      "\tEpoch 1491: \tAverage Loss:  1.6290399169921874\t ACC train:  0.895\t ACC test:  0.8711111111111111\n",
      "\tEpoch 1492: \tAverage Loss:  1.628454345703125\t ACC train:  0.8975\t ACC test:  0.8711111111111111\n",
      "\tEpoch 1493: \tAverage Loss:  1.6277464599609375\t ACC train:  0.8975\t ACC test:  0.8733333333333333\n",
      "\tEpoch 1494: \tAverage Loss:  1.6272166748046875\t ACC train:  0.9\t ACC test:  0.8711111111111111\n",
      "\tEpoch 1495: \tAverage Loss:  1.62726611328125\t ACC train:  0.9025\t ACC test:  0.88\n",
      "\tEpoch 1496: \tAverage Loss:  1.62624658203125\t ACC train:  0.905\t ACC test:  0.88\n",
      "\tEpoch 1497: \tAverage Loss:  1.625711181640625\t ACC train:  0.905\t ACC test:  0.8755555555555555\n",
      "\tEpoch 1498: \tAverage Loss:  1.625991943359375\t ACC train:  0.905\t ACC test:  0.8866666666666667\n",
      "\tEpoch 1499: \tAverage Loss:  1.624667724609375\t ACC train:  0.91\t ACC test:  0.8888888888888888\n",
      "\tEpoch 1500: \tAverage Loss:  1.62412548828125\t ACC train:  0.905\t ACC test:  0.8822222222222222\n",
      "\tEpoch 1501: \tAverage Loss:  1.6235909423828125\t ACC train:  0.905\t ACC test:  0.8911111111111111\n",
      "\tEpoch 1502: \tAverage Loss:  1.6231717529296874\t ACC train:  0.9075\t ACC test:  0.8888888888888888\n",
      "\tEpoch 1503: \tAverage Loss:  1.622550048828125\t ACC train:  0.9075\t ACC test:  0.8888888888888888\n",
      "\tEpoch 1504: \tAverage Loss:  1.6218389892578124\t ACC train:  0.91\t ACC test:  0.8911111111111111\n",
      "\tEpoch 1505: \tAverage Loss:  1.6215146484375\t ACC train:  0.915\t ACC test:  0.8888888888888888\n",
      "\tEpoch 1506: \tAverage Loss:  1.6211602783203125\t ACC train:  0.915\t ACC test:  0.8933333333333333\n",
      "\tEpoch 1507: \tAverage Loss:  1.6204979248046876\t ACC train:  0.915\t ACC test:  0.8911111111111111\n",
      "\tEpoch 1508: \tAverage Loss:  1.6198919677734376\t ACC train:  0.9125\t ACC test:  0.8955555555555555\n",
      "\tEpoch 1509: \tAverage Loss:  1.6192159423828125\t ACC train:  0.915\t ACC test:  0.9\n",
      "\tEpoch 1510: \tAverage Loss:  1.6186885986328126\t ACC train:  0.915\t ACC test:  0.8955555555555555\n",
      "\tEpoch 1511: \tAverage Loss:  1.618273681640625\t ACC train:  0.92\t ACC test:  0.9\n",
      "\tEpoch 1512: \tAverage Loss:  1.617478515625\t ACC train:  0.9175\t ACC test:  0.8977777777777778\n",
      "\tEpoch 1513: \tAverage Loss:  1.616919921875\t ACC train:  0.915\t ACC test:  0.8977777777777778\n",
      "\tEpoch 1514: \tAverage Loss:  1.6168892822265626\t ACC train:  0.9175\t ACC test:  0.8955555555555555\n",
      "\tEpoch 1515: \tAverage Loss:  1.616213134765625\t ACC train:  0.9175\t ACC test:  0.8977777777777778\n",
      "\tEpoch 1516: \tAverage Loss:  1.615517822265625\t ACC train:  0.92\t ACC test:  0.9\n",
      "\tEpoch 1517: \tAverage Loss:  1.6149830322265626\t ACC train:  0.9225\t ACC test:  0.9\n",
      "\tEpoch 1518: \tAverage Loss:  1.6142587890625\t ACC train:  0.925\t ACC test:  0.9\n",
      "\tEpoch 1519: \tAverage Loss:  1.61385791015625\t ACC train:  0.92\t ACC test:  0.8977777777777778\n",
      "\tEpoch 1520: \tAverage Loss:  1.613385009765625\t ACC train:  0.9275\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1521: \tAverage Loss:  1.6130250244140625\t ACC train:  0.92\t ACC test:  0.9\n",
      "\tEpoch 1522: \tAverage Loss:  1.6121976318359375\t ACC train:  0.92\t ACC test:  0.9\n",
      "\tEpoch 1523: \tAverage Loss:  1.6118228759765625\t ACC train:  0.925\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1524: \tAverage Loss:  1.6114266357421876\t ACC train:  0.9275\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1525: \tAverage Loss:  1.6106348876953125\t ACC train:  0.9325\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1526: \tAverage Loss:  1.6101044921875\t ACC train:  0.9275\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1527: \tAverage Loss:  1.6097086181640625\t ACC train:  0.9325\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1528: \tAverage Loss:  1.6092847900390626\t ACC train:  0.93\t ACC test:  0.9\n",
      "\tEpoch 1529: \tAverage Loss:  1.60866357421875\t ACC train:  0.93\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1530: \tAverage Loss:  1.6082686767578125\t ACC train:  0.9325\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1531: \tAverage Loss:  1.60778662109375\t ACC train:  0.935\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1532: \tAverage Loss:  1.60730517578125\t ACC train:  0.935\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1533: \tAverage Loss:  1.6067745361328125\t ACC train:  0.9325\t ACC test:  0.9022222222222223\n",
      "\tEpoch 1534: \tAverage Loss:  1.6062916259765625\t ACC train:  0.935\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1535: \tAverage Loss:  1.6057623291015626\t ACC train:  0.9325\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1536: \tAverage Loss:  1.6052359619140626\t ACC train:  0.9375\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1537: \tAverage Loss:  1.6048221435546874\t ACC train:  0.935\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1538: \tAverage Loss:  1.6041524658203126\t ACC train:  0.935\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1539: \tAverage Loss:  1.6036556396484376\t ACC train:  0.935\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1540: \tAverage Loss:  1.603162109375\t ACC train:  0.935\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1541: \tAverage Loss:  1.602754150390625\t ACC train:  0.9325\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1542: \tAverage Loss:  1.6023973388671875\t ACC train:  0.935\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1543: \tAverage Loss:  1.602171142578125\t ACC train:  0.935\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1544: \tAverage Loss:  1.6018936767578125\t ACC train:  0.9375\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1545: \tAverage Loss:  1.6012200927734375\t ACC train:  0.9375\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1546: \tAverage Loss:  1.6007301025390626\t ACC train:  0.9375\t ACC test:  0.9044444444444445\n",
      "\tEpoch 1547: \tAverage Loss:  1.600333251953125\t ACC train:  0.9425\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1548: \tAverage Loss:  1.5995360107421874\t ACC train:  0.9375\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1549: \tAverage Loss:  1.5994161376953124\t ACC train:  0.94\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1550: \tAverage Loss:  1.5988336181640626\t ACC train:  0.935\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1551: \tAverage Loss:  1.598990234375\t ACC train:  0.94\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1552: \tAverage Loss:  1.5984185791015626\t ACC train:  0.94\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1553: \tAverage Loss:  1.5975892333984374\t ACC train:  0.94\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1554: \tAverage Loss:  1.5973240966796876\t ACC train:  0.9425\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1555: \tAverage Loss:  1.5965018310546875\t ACC train:  0.9425\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1556: \tAverage Loss:  1.597021240234375\t ACC train:  0.9425\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1557: \tAverage Loss:  1.596377685546875\t ACC train:  0.9425\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1558: \tAverage Loss:  1.5955797119140624\t ACC train:  0.945\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1559: \tAverage Loss:  1.594613525390625\t ACC train:  0.9425\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1560: \tAverage Loss:  1.5943974609375\t ACC train:  0.945\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1561: \tAverage Loss:  1.5939031982421874\t ACC train:  0.9425\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1562: \tAverage Loss:  1.59342724609375\t ACC train:  0.9475\t ACC test:  0.9066666666666666\n",
      "\tEpoch 1563: \tAverage Loss:  1.5930838623046875\t ACC train:  0.95\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1564: \tAverage Loss:  1.5927894287109374\t ACC train:  0.9475\t ACC test:  0.9088888888888889\n",
      "\tEpoch 1565: \tAverage Loss:  1.5920753173828126\t ACC train:  0.95\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1566: \tAverage Loss:  1.5918035888671875\t ACC train:  0.95\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1567: \tAverage Loss:  1.5913214111328124\t ACC train:  0.95\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1568: \tAverage Loss:  1.59085791015625\t ACC train:  0.95\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1569: \tAverage Loss:  1.590550537109375\t ACC train:  0.9475\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1570: \tAverage Loss:  1.590189453125\t ACC train:  0.95\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1571: \tAverage Loss:  1.5893048095703124\t ACC train:  0.95\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1572: \tAverage Loss:  1.58897119140625\t ACC train:  0.9475\t ACC test:  0.9133333333333333\n",
      "\tEpoch 1573: \tAverage Loss:  1.588833740234375\t ACC train:  0.95\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1574: \tAverage Loss:  1.5884625244140624\t ACC train:  0.9475\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1575: \tAverage Loss:  1.588136962890625\t ACC train:  0.95\t ACC test:  0.9111111111111111\n",
      "\tEpoch 1576: \tAverage Loss:  1.588230224609375\t ACC train:  0.95\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1577: \tAverage Loss:  1.5883697509765624\t ACC train:  0.95\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1578: \tAverage Loss:  1.587468505859375\t ACC train:  0.95\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1579: \tAverage Loss:  1.5862529296875\t ACC train:  0.9525\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1580: \tAverage Loss:  1.58580615234375\t ACC train:  0.95\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1581: \tAverage Loss:  1.585863525390625\t ACC train:  0.9525\t ACC test:  0.9155555555555556\n",
      "\tEpoch 1582: \tAverage Loss:  1.585875244140625\t ACC train:  0.9475\t ACC test:  0.92\n",
      "\tEpoch 1583: \tAverage Loss:  1.5849881591796875\t ACC train:  0.9475\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1584: \tAverage Loss:  1.5843531494140626\t ACC train:  0.9525\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1585: \tAverage Loss:  1.58420263671875\t ACC train:  0.9525\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1586: \tAverage Loss:  1.5839964599609375\t ACC train:  0.955\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1587: \tAverage Loss:  1.5835079345703125\t ACC train:  0.9525\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1588: \tAverage Loss:  1.58274609375\t ACC train:  0.9525\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1589: \tAverage Loss:  1.582505859375\t ACC train:  0.955\t ACC test:  0.92\n",
      "\tEpoch 1590: \tAverage Loss:  1.5822547607421875\t ACC train:  0.9525\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1591: \tAverage Loss:  1.5820455322265625\t ACC train:  0.9575\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1592: \tAverage Loss:  1.581199951171875\t ACC train:  0.955\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1593: \tAverage Loss:  1.580663818359375\t ACC train:  0.9525\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1594: \tAverage Loss:  1.5804945068359375\t ACC train:  0.955\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1595: \tAverage Loss:  1.5802120361328125\t ACC train:  0.955\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1596: \tAverage Loss:  1.5795364990234375\t ACC train:  0.955\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1597: \tAverage Loss:  1.579036376953125\t ACC train:  0.9575\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1598: \tAverage Loss:  1.5786497802734376\t ACC train:  0.955\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1599: \tAverage Loss:  1.578416748046875\t ACC train:  0.9575\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1600: \tAverage Loss:  1.5783447265625\t ACC train:  0.955\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1601: \tAverage Loss:  1.5772947998046876\t ACC train:  0.955\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1602: \tAverage Loss:  1.576532470703125\t ACC train:  0.9575\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1603: \tAverage Loss:  1.5760667724609374\t ACC train:  0.955\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1604: \tAverage Loss:  1.5759140625\t ACC train:  0.965\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1605: \tAverage Loss:  1.5755101318359375\t ACC train:  0.955\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1606: \tAverage Loss:  1.574908203125\t ACC train:  0.965\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1607: \tAverage Loss:  1.574319580078125\t ACC train:  0.9675\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1608: \tAverage Loss:  1.5733006591796874\t ACC train:  0.9625\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1609: \tAverage Loss:  1.5732711181640624\t ACC train:  0.965\t ACC test:  0.92\n",
      "\tEpoch 1610: \tAverage Loss:  1.5725018310546874\t ACC train:  0.9625\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1611: \tAverage Loss:  1.572212890625\t ACC train:  0.97\t ACC test:  0.92\n",
      "\tEpoch 1612: \tAverage Loss:  1.571869873046875\t ACC train:  0.965\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1613: \tAverage Loss:  1.57141455078125\t ACC train:  0.9725\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1614: \tAverage Loss:  1.570438720703125\t ACC train:  0.9725\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1615: \tAverage Loss:  1.569995849609375\t ACC train:  0.9725\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1616: \tAverage Loss:  1.5693115234375\t ACC train:  0.9725\t ACC test:  0.92\n",
      "\tEpoch 1617: \tAverage Loss:  1.5689267578125\t ACC train:  0.97\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1618: \tAverage Loss:  1.56898974609375\t ACC train:  0.975\t ACC test:  0.92\n",
      "\tEpoch 1619: \tAverage Loss:  1.5685458984375\t ACC train:  0.97\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1620: \tAverage Loss:  1.56806640625\t ACC train:  0.9775\t ACC test:  0.92\n",
      "\tEpoch 1621: \tAverage Loss:  1.5671514892578124\t ACC train:  0.9725\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1622: \tAverage Loss:  1.56666943359375\t ACC train:  0.9775\t ACC test:  0.92\n",
      "\tEpoch 1623: \tAverage Loss:  1.5661435546875\t ACC train:  0.975\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1624: \tAverage Loss:  1.565607421875\t ACC train:  0.9725\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1625: \tAverage Loss:  1.565284912109375\t ACC train:  0.975\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1626: \tAverage Loss:  1.5648798828125\t ACC train:  0.975\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1627: \tAverage Loss:  1.5647767333984375\t ACC train:  0.9775\t ACC test:  0.92\n",
      "\tEpoch 1628: \tAverage Loss:  1.564985595703125\t ACC train:  0.97\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1629: \tAverage Loss:  1.5656888427734375\t ACC train:  0.975\t ACC test:  0.92\n",
      "\tEpoch 1630: \tAverage Loss:  1.56553515625\t ACC train:  0.97\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1631: \tAverage Loss:  1.564207275390625\t ACC train:  0.98\t ACC test:  0.92\n",
      "\tEpoch 1632: \tAverage Loss:  1.5625423583984375\t ACC train:  0.9775\t ACC test:  0.92\n",
      "\tEpoch 1633: \tAverage Loss:  1.5621546630859375\t ACC train:  0.9725\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1634: \tAverage Loss:  1.5631986083984375\t ACC train:  0.9775\t ACC test:  0.9177777777777778\n",
      "\tEpoch 1635: \tAverage Loss:  1.56279296875\t ACC train:  0.975\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1636: \tAverage Loss:  1.561546142578125\t ACC train:  0.9775\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1637: \tAverage Loss:  1.560544677734375\t ACC train:  0.9775\t ACC test:  0.92\n",
      "\tEpoch 1638: \tAverage Loss:  1.56209814453125\t ACC train:  0.9775\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1639: \tAverage Loss:  1.5635616455078125\t ACC train:  0.975\t ACC test:  0.92\n",
      "\tEpoch 1640: \tAverage Loss:  1.5620831298828124\t ACC train:  0.9775\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1641: \tAverage Loss:  1.558907958984375\t ACC train:  0.9725\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1642: \tAverage Loss:  1.562601806640625\t ACC train:  0.975\t ACC test:  0.92\n",
      "\tEpoch 1643: \tAverage Loss:  1.5613448486328125\t ACC train:  0.98\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1644: \tAverage Loss:  1.5577381591796875\t ACC train:  0.98\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1645: \tAverage Loss:  1.5607071533203125\t ACC train:  0.9775\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1646: \tAverage Loss:  1.5607572021484375\t ACC train:  0.9825\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1647: \tAverage Loss:  1.5570433349609376\t ACC train:  0.985\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1648: \tAverage Loss:  1.55864453125\t ACC train:  0.98\t ACC test:  0.92\n",
      "\tEpoch 1649: \tAverage Loss:  1.55801318359375\t ACC train:  0.9825\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1650: \tAverage Loss:  1.5554287109375\t ACC train:  0.98\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1651: \tAverage Loss:  1.557668212890625\t ACC train:  0.985\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1652: \tAverage Loss:  1.556695068359375\t ACC train:  0.9825\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1653: \tAverage Loss:  1.5544283447265625\t ACC train:  0.9875\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1654: \tAverage Loss:  1.5572691650390624\t ACC train:  0.9825\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1655: \tAverage Loss:  1.555118408203125\t ACC train:  0.985\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1656: \tAverage Loss:  1.553186767578125\t ACC train:  0.9875\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1657: \tAverage Loss:  1.554593505859375\t ACC train:  0.98\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1658: \tAverage Loss:  1.5544661865234375\t ACC train:  0.9875\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1659: \tAverage Loss:  1.55190087890625\t ACC train:  0.9875\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1660: \tAverage Loss:  1.554476806640625\t ACC train:  0.9775\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1661: \tAverage Loss:  1.5536566162109375\t ACC train:  0.9875\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1662: \tAverage Loss:  1.551283447265625\t ACC train:  0.9875\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1663: \tAverage Loss:  1.5543118896484376\t ACC train:  0.985\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1664: \tAverage Loss:  1.551930908203125\t ACC train:  0.9825\t ACC test:  0.9222222222222223\n",
      "\tEpoch 1665: \tAverage Loss:  1.550857421875\t ACC train:  0.9875\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1666: \tAverage Loss:  1.55145166015625\t ACC train:  0.9875\t ACC test:  0.92\n",
      "\tEpoch 1667: \tAverage Loss:  1.5498055419921875\t ACC train:  0.985\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1668: \tAverage Loss:  1.5496468505859375\t ACC train:  0.9875\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1669: \tAverage Loss:  1.5500146484375\t ACC train:  0.99\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1670: \tAverage Loss:  1.5476392822265626\t ACC train:  0.9875\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1671: \tAverage Loss:  1.5486279296875\t ACC train:  0.9875\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1672: \tAverage Loss:  1.547941650390625\t ACC train:  0.99\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1673: \tAverage Loss:  1.547083984375\t ACC train:  0.9925\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1674: \tAverage Loss:  1.5465858154296874\t ACC train:  0.99\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1675: \tAverage Loss:  1.54736962890625\t ACC train:  0.985\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1676: \tAverage Loss:  1.5466068115234375\t ACC train:  0.99\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1677: \tAverage Loss:  1.545625244140625\t ACC train:  0.9925\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1678: \tAverage Loss:  1.5446995849609375\t ACC train:  0.9925\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1679: \tAverage Loss:  1.5448060302734374\t ACC train:  0.99\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1680: \tAverage Loss:  1.5448857421875\t ACC train:  0.985\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1681: \tAverage Loss:  1.5448238525390625\t ACC train:  0.9925\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1682: \tAverage Loss:  1.5441031494140625\t ACC train:  0.9925\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1683: \tAverage Loss:  1.5430794677734374\t ACC train:  0.9925\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1684: \tAverage Loss:  1.5431650390625\t ACC train:  0.9925\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1685: \tAverage Loss:  1.5434671630859376\t ACC train:  0.9925\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1686: \tAverage Loss:  1.5432010498046875\t ACC train:  0.9925\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1687: \tAverage Loss:  1.541981689453125\t ACC train:  0.9925\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1688: \tAverage Loss:  1.541513916015625\t ACC train:  0.9925\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1689: \tAverage Loss:  1.5416915283203125\t ACC train:  0.9925\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1690: \tAverage Loss:  1.5420526123046876\t ACC train:  0.985\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1691: \tAverage Loss:  1.54329736328125\t ACC train:  0.9925\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1692: \tAverage Loss:  1.541412353515625\t ACC train:  0.9925\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1693: \tAverage Loss:  1.5400120849609376\t ACC train:  0.9925\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1694: \tAverage Loss:  1.540386962890625\t ACC train:  0.9925\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1695: \tAverage Loss:  1.5410479736328124\t ACC train:  0.9875\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1696: \tAverage Loss:  1.541715576171875\t ACC train:  0.9925\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1697: \tAverage Loss:  1.539359619140625\t ACC train:  0.9925\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1698: \tAverage Loss:  1.538182861328125\t ACC train:  0.995\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1699: \tAverage Loss:  1.538573486328125\t ACC train:  0.9925\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1700: \tAverage Loss:  1.5391956787109375\t ACC train:  0.995\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1701: \tAverage Loss:  1.53805712890625\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1702: \tAverage Loss:  1.5372662353515625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1703: \tAverage Loss:  1.5370140380859374\t ACC train:  0.9925\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1704: \tAverage Loss:  1.537643798828125\t ACC train:  0.9925\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1705: \tAverage Loss:  1.537154052734375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1706: \tAverage Loss:  1.53671484375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1707: \tAverage Loss:  1.535926025390625\t ACC train:  0.9925\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1708: \tAverage Loss:  1.5353763427734375\t ACC train:  0.995\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1709: \tAverage Loss:  1.5356400146484375\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1710: \tAverage Loss:  1.5353226318359374\t ACC train:  0.99\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1711: \tAverage Loss:  1.5354296875\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1712: \tAverage Loss:  1.5347462158203125\t ACC train:  0.995\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1713: \tAverage Loss:  1.53423486328125\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1714: \tAverage Loss:  1.53383740234375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1715: \tAverage Loss:  1.5333892822265625\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1716: \tAverage Loss:  1.5329501953125\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1717: \tAverage Loss:  1.53275439453125\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1718: \tAverage Loss:  1.5325799560546876\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1719: \tAverage Loss:  1.5323143310546874\t ACC train:  0.995\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1720: \tAverage Loss:  1.5322589111328124\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1721: \tAverage Loss:  1.532246337890625\t ACC train:  0.995\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1722: \tAverage Loss:  1.532017333984375\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1723: \tAverage Loss:  1.5312620849609375\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1724: \tAverage Loss:  1.53070751953125\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1725: \tAverage Loss:  1.530589599609375\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1726: \tAverage Loss:  1.5303470458984374\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1727: \tAverage Loss:  1.53008056640625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1728: \tAverage Loss:  1.52987646484375\t ACC train:  0.995\t ACC test:  0.9244444444444444\n",
      "\tEpoch 1729: \tAverage Loss:  1.5294873046875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1730: \tAverage Loss:  1.52897412109375\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1731: \tAverage Loss:  1.52859228515625\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1732: \tAverage Loss:  1.5289388427734374\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1733: \tAverage Loss:  1.5296243896484376\t ACC train:  0.9875\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1734: \tAverage Loss:  1.530207275390625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1735: \tAverage Loss:  1.5294913330078126\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1736: \tAverage Loss:  1.5277120361328125\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1737: \tAverage Loss:  1.5273916015625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1738: \tAverage Loss:  1.5277098388671875\t ACC train:  0.9875\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1739: \tAverage Loss:  1.5282364501953125\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1740: \tAverage Loss:  1.52749462890625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1741: \tAverage Loss:  1.5261961669921875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1742: \tAverage Loss:  1.525812744140625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1743: \tAverage Loss:  1.526124755859375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1744: \tAverage Loss:  1.5266202392578125\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1745: \tAverage Loss:  1.52627734375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1746: \tAverage Loss:  1.524877685546875\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1747: \tAverage Loss:  1.524612060546875\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1748: \tAverage Loss:  1.5248160400390625\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1749: \tAverage Loss:  1.5247275390625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1750: \tAverage Loss:  1.5240570068359376\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1751: \tAverage Loss:  1.523343017578125\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1752: \tAverage Loss:  1.5231639404296875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1753: \tAverage Loss:  1.5229046630859375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1754: \tAverage Loss:  1.5228787841796876\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1755: \tAverage Loss:  1.522624755859375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1756: \tAverage Loss:  1.52209130859375\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1757: \tAverage Loss:  1.521641845703125\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1758: \tAverage Loss:  1.5213775634765625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1759: \tAverage Loss:  1.5212545166015625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1760: \tAverage Loss:  1.521135009765625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1761: \tAverage Loss:  1.5214232177734375\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1762: \tAverage Loss:  1.521165771484375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1763: \tAverage Loss:  1.5203558349609374\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1764: \tAverage Loss:  1.5198001708984374\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1765: \tAverage Loss:  1.519704833984375\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1766: \tAverage Loss:  1.5202086181640626\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1767: \tAverage Loss:  1.52076513671875\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1768: \tAverage Loss:  1.5194691162109375\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1769: \tAverage Loss:  1.5184541015625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1770: \tAverage Loss:  1.5183125\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1771: \tAverage Loss:  1.518574462890625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1772: \tAverage Loss:  1.5185943603515626\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1773: \tAverage Loss:  1.51773291015625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1774: \tAverage Loss:  1.5169578857421875\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1775: \tAverage Loss:  1.5172080078125\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1776: \tAverage Loss:  1.517505126953125\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1777: \tAverage Loss:  1.517614501953125\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1778: \tAverage Loss:  1.5163150634765625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1779: \tAverage Loss:  1.51598974609375\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1780: \tAverage Loss:  1.51708935546875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1781: \tAverage Loss:  1.516554931640625\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1782: \tAverage Loss:  1.5154024658203125\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1783: \tAverage Loss:  1.514735595703125\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1784: \tAverage Loss:  1.5154705810546876\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1785: \tAverage Loss:  1.51636865234375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1786: \tAverage Loss:  1.514449462890625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1787: \tAverage Loss:  1.5136937255859375\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1788: \tAverage Loss:  1.5140694580078125\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1789: \tAverage Loss:  1.513906494140625\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1790: \tAverage Loss:  1.5132271728515625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1791: \tAverage Loss:  1.5125570068359375\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1792: \tAverage Loss:  1.51272216796875\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1793: \tAverage Loss:  1.51312158203125\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1794: \tAverage Loss:  1.5121859130859374\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1795: \tAverage Loss:  1.5116246337890624\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1796: \tAverage Loss:  1.5119771728515625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1797: \tAverage Loss:  1.511826171875\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1798: \tAverage Loss:  1.51127001953125\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1799: \tAverage Loss:  1.5104798583984376\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1800: \tAverage Loss:  1.5105137939453126\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1801: \tAverage Loss:  1.510629638671875\t ACC train:  0.995\t ACC test:  0.9266666666666666\n",
      "\tEpoch 1802: \tAverage Loss:  1.509992431640625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1803: \tAverage Loss:  1.50948388671875\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1804: \tAverage Loss:  1.5092301025390624\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1805: \tAverage Loss:  1.5090321044921875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1806: \tAverage Loss:  1.50874853515625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1807: \tAverage Loss:  1.508541748046875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1808: \tAverage Loss:  1.50816796875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1809: \tAverage Loss:  1.507857421875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1810: \tAverage Loss:  1.5076072998046874\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1811: \tAverage Loss:  1.507489013671875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1812: \tAverage Loss:  1.5071700439453124\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1813: \tAverage Loss:  1.5070592041015625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1814: \tAverage Loss:  1.506773681640625\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1815: \tAverage Loss:  1.5063404541015626\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1816: \tAverage Loss:  1.506014892578125\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1817: \tAverage Loss:  1.5057435302734374\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1818: \tAverage Loss:  1.5055994873046874\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1819: \tAverage Loss:  1.50547509765625\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1820: \tAverage Loss:  1.5053221435546875\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1821: \tAverage Loss:  1.504775390625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1822: \tAverage Loss:  1.5045177001953125\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1823: \tAverage Loss:  1.504139404296875\t ACC train:  0.995\t ACC test:  0.9288888888888889\n",
      "\tEpoch 1824: \tAverage Loss:  1.503995849609375\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1825: \tAverage Loss:  1.5037349853515625\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1826: \tAverage Loss:  1.503687255859375\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1827: \tAverage Loss:  1.5034598388671876\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1828: \tAverage Loss:  1.5033759765625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1829: \tAverage Loss:  1.5026441650390625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1830: \tAverage Loss:  1.50230712890625\t ACC train:  0.995\t ACC test:  0.9311111111111111\n",
      "\tEpoch 1831: \tAverage Loss:  1.502030517578125\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1832: \tAverage Loss:  1.5018726806640625\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1833: \tAverage Loss:  1.50203125\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1834: \tAverage Loss:  1.5016162109375\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1835: \tAverage Loss:  1.5011573486328125\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1836: \tAverage Loss:  1.5007529296875\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1837: \tAverage Loss:  1.500613525390625\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1838: \tAverage Loss:  1.5004298095703126\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1839: \tAverage Loss:  1.500214599609375\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1840: \tAverage Loss:  1.499897705078125\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1841: \tAverage Loss:  1.499583251953125\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1842: \tAverage Loss:  1.4993125\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1843: \tAverage Loss:  1.498982177734375\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1844: \tAverage Loss:  1.4988529052734374\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1845: \tAverage Loss:  1.4984951171875\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1846: \tAverage Loss:  1.4983448486328126\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1847: \tAverage Loss:  1.4980316162109375\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1848: \tAverage Loss:  1.4979691162109374\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1849: \tAverage Loss:  1.4974852294921874\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1850: \tAverage Loss:  1.49720263671875\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1851: \tAverage Loss:  1.49677880859375\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1852: \tAverage Loss:  1.4964541015625\t ACC train:  0.995\t ACC test:  0.9333333333333333\n",
      "\tEpoch 1853: \tAverage Loss:  1.496621826171875\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1854: \tAverage Loss:  1.49645556640625\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1855: \tAverage Loss:  1.4966661376953125\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1856: \tAverage Loss:  1.4959716796875\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1857: \tAverage Loss:  1.4954444580078126\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1858: \tAverage Loss:  1.49499853515625\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1859: \tAverage Loss:  1.494859619140625\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1860: \tAverage Loss:  1.495343505859375\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1861: \tAverage Loss:  1.494859619140625\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1862: \tAverage Loss:  1.4943018798828125\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1863: \tAverage Loss:  1.493627197265625\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1864: \tAverage Loss:  1.4936641845703125\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1865: \tAverage Loss:  1.4938587646484376\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1866: \tAverage Loss:  1.49340380859375\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1867: \tAverage Loss:  1.493004638671875\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1868: \tAverage Loss:  1.4922689208984374\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1869: \tAverage Loss:  1.4922569580078124\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1870: \tAverage Loss:  1.4928624267578126\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1871: \tAverage Loss:  1.492080078125\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1872: \tAverage Loss:  1.4914639892578125\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1873: \tAverage Loss:  1.490932373046875\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1874: \tAverage Loss:  1.4910540771484375\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1875: \tAverage Loss:  1.4914757080078125\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1876: \tAverage Loss:  1.4905504150390625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1877: \tAverage Loss:  1.4903267822265625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1878: \tAverage Loss:  1.4897791748046876\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1879: \tAverage Loss:  1.489916748046875\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1880: \tAverage Loss:  1.4897083740234376\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1881: \tAverage Loss:  1.4889710693359375\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1882: \tAverage Loss:  1.4885286865234375\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1883: \tAverage Loss:  1.48837353515625\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1884: \tAverage Loss:  1.48839453125\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1885: \tAverage Loss:  1.4880048828125\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1886: \tAverage Loss:  1.4876343994140624\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1887: \tAverage Loss:  1.4871419677734374\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1888: \tAverage Loss:  1.48714208984375\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1889: \tAverage Loss:  1.4867955322265625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1890: \tAverage Loss:  1.486444580078125\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1891: \tAverage Loss:  1.486129150390625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1892: \tAverage Loss:  1.485888916015625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1893: \tAverage Loss:  1.48573779296875\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1894: \tAverage Loss:  1.485705322265625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1895: \tAverage Loss:  1.4856619873046875\t ACC train:  0.995\t ACC test:  0.9355555555555556\n",
      "\tEpoch 1896: \tAverage Loss:  1.484997802734375\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1897: \tAverage Loss:  1.484518798828125\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1898: \tAverage Loss:  1.4842625732421875\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1899: \tAverage Loss:  1.4842049560546875\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1900: \tAverage Loss:  1.48406201171875\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1901: \tAverage Loss:  1.4836097412109375\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1902: \tAverage Loss:  1.48330908203125\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1903: \tAverage Loss:  1.4829173583984374\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1904: \tAverage Loss:  1.4826719970703126\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1905: \tAverage Loss:  1.482409423828125\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1906: \tAverage Loss:  1.48220849609375\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1907: \tAverage Loss:  1.481934326171875\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1908: \tAverage Loss:  1.4816502685546875\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1909: \tAverage Loss:  1.481234375\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1910: \tAverage Loss:  1.481068603515625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1911: \tAverage Loss:  1.4807176513671876\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1912: \tAverage Loss:  1.480593505859375\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1913: \tAverage Loss:  1.480305908203125\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1914: \tAverage Loss:  1.4802408447265625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1915: \tAverage Loss:  1.4799364013671874\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1916: \tAverage Loss:  1.479431884765625\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1917: \tAverage Loss:  1.4790823974609375\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1918: \tAverage Loss:  1.4789266357421875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1919: \tAverage Loss:  1.4789166259765625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1920: \tAverage Loss:  1.4786199951171874\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1921: \tAverage Loss:  1.4786025390625\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1922: \tAverage Loss:  1.4780606689453124\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1923: \tAverage Loss:  1.47748779296875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1924: \tAverage Loss:  1.4773001708984375\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1925: \tAverage Loss:  1.4773116455078126\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1926: \tAverage Loss:  1.4777384033203125\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1927: \tAverage Loss:  1.4771285400390626\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1928: \tAverage Loss:  1.4770205078125\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1929: \tAverage Loss:  1.4760166015625\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1930: \tAverage Loss:  1.47569677734375\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1931: \tAverage Loss:  1.47610107421875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1932: \tAverage Loss:  1.4761231689453125\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1933: \tAverage Loss:  1.4763260498046875\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1934: \tAverage Loss:  1.4748079833984375\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1935: \tAverage Loss:  1.4741827392578124\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1936: \tAverage Loss:  1.4744639892578124\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1937: \tAverage Loss:  1.4740267333984376\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1938: \tAverage Loss:  1.4736856689453126\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1939: \tAverage Loss:  1.473274169921875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1940: \tAverage Loss:  1.4728770751953124\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1941: \tAverage Loss:  1.4725828857421874\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1942: \tAverage Loss:  1.47228955078125\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1943: \tAverage Loss:  1.4720184326171875\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1944: \tAverage Loss:  1.4719166259765626\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1945: \tAverage Loss:  1.4719365234375\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1946: \tAverage Loss:  1.47163818359375\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1947: \tAverage Loss:  1.4711273193359375\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1948: \tAverage Loss:  1.470593017578125\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1949: \tAverage Loss:  1.4703338623046875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1950: \tAverage Loss:  1.4699608154296875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1951: \tAverage Loss:  1.4697379150390626\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1952: \tAverage Loss:  1.469683837890625\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1953: \tAverage Loss:  1.4694464111328125\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1954: \tAverage Loss:  1.4694510498046875\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1955: \tAverage Loss:  1.4690159912109375\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1956: \tAverage Loss:  1.46842431640625\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1957: \tAverage Loss:  1.468072998046875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1958: \tAverage Loss:  1.4678021240234376\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1959: \tAverage Loss:  1.46754052734375\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1960: \tAverage Loss:  1.467221435546875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1961: \tAverage Loss:  1.46684326171875\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1962: \tAverage Loss:  1.466572998046875\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1963: \tAverage Loss:  1.4662510986328126\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1964: \tAverage Loss:  1.4660830078125\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1965: \tAverage Loss:  1.466390625\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1966: \tAverage Loss:  1.4661070556640625\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1967: \tAverage Loss:  1.466568359375\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1968: \tAverage Loss:  1.465796142578125\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1969: \tAverage Loss:  1.465575439453125\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1970: \tAverage Loss:  1.4646092529296875\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1971: \tAverage Loss:  1.464150390625\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1972: \tAverage Loss:  1.4641968994140624\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1973: \tAverage Loss:  1.4640445556640624\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1974: \tAverage Loss:  1.4643865966796874\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1975: \tAverage Loss:  1.4637613525390625\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1976: \tAverage Loss:  1.46336083984375\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1977: \tAverage Loss:  1.4623944091796874\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1978: \tAverage Loss:  1.462081787109375\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1979: \tAverage Loss:  1.4620098876953125\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1980: \tAverage Loss:  1.4618680419921875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1981: \tAverage Loss:  1.461891357421875\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1982: \tAverage Loss:  1.4613671875\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1983: \tAverage Loss:  1.46089013671875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1984: \tAverage Loss:  1.46026953125\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1985: \tAverage Loss:  1.4602330322265624\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1986: \tAverage Loss:  1.4602606201171875\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1987: \tAverage Loss:  1.4602091064453124\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1988: \tAverage Loss:  1.460736328125\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1989: \tAverage Loss:  1.459372802734375\t ACC train:  0.995\t ACC test:  0.9444444444444444\n",
      "\tEpoch 1990: \tAverage Loss:  1.458750732421875\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "\tEpoch 1991: \tAverage Loss:  1.4586318359375\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1992: \tAverage Loss:  1.4587742919921876\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1993: \tAverage Loss:  1.4588372802734375\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1994: \tAverage Loss:  1.4579466552734375\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1995: \tAverage Loss:  1.4572841796875\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 1996: \tAverage Loss:  1.4568568115234375\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1997: \tAverage Loss:  1.4569471435546875\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1998: \tAverage Loss:  1.4573809814453125\t ACC train:  0.995\t ACC test:  0.9422222222222222\n",
      "\tEpoch 1999: \tAverage Loss:  1.456331298828125\t ACC train:  0.995\t ACC test:  0.94\n",
      "\tEpoch 2000: \tAverage Loss:  1.455569091796875\t ACC train:  0.995\t ACC test:  0.9377777777777778\n",
      "Training for sample size: 500\n",
      "\tEpoch 1: \tAverage Loss:  4.61896533203125\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 2: \tAverage Loss:  4.6021201171875\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 3: \tAverage Loss:  4.58007177734375\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 4: \tAverage Loss:  4.56759228515625\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 5: \tAverage Loss:  4.5467099609375\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 6: \tAverage Loss:  4.5299677734375\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 7: \tAverage Loss:  4.513654296875\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 8: \tAverage Loss:  4.4992978515625\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 9: \tAverage Loss:  4.4860078125\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 10: \tAverage Loss:  4.4674892578125\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  4.4561142578125\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  4.445337890625\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  4.43153759765625\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  4.42127197265625\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  4.408501953125\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  4.39377001953125\t ACC train:  0.508\t ACC test:  0.48444444444444446\n",
      "\tEpoch 17: \tAverage Loss:  4.386330078125\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  4.36953564453125\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  4.36166943359375\t ACC train:  0.508\t ACC test:  0.48444444444444446\n",
      "\tEpoch 20: \tAverage Loss:  4.3505888671875\t ACC train:  0.508\t ACC test:  0.48444444444444446\n",
      "\tEpoch 21: \tAverage Loss:  4.34082421875\t ACC train:  0.508\t ACC test:  0.4888888888888889\n",
      "\tEpoch 22: \tAverage Loss:  4.3319111328125\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  4.32159716796875\t ACC train:  0.506\t ACC test:  0.4888888888888889\n",
      "\tEpoch 24: \tAverage Loss:  4.313330078125\t ACC train:  0.506\t ACC test:  0.4822222222222222\n",
      "\tEpoch 25: \tAverage Loss:  4.298697265625\t ACC train:  0.508\t ACC test:  0.48444444444444446\n",
      "\tEpoch 26: \tAverage Loss:  4.29633984375\t ACC train:  0.51\t ACC test:  0.49777777777777776\n",
      "\tEpoch 27: \tAverage Loss:  4.2797685546875\t ACC train:  0.506\t ACC test:  0.5244444444444445\n",
      "\tEpoch 28: \tAverage Loss:  4.2791904296875\t ACC train:  0.516\t ACC test:  0.47555555555555556\n",
      "\tEpoch 29: \tAverage Loss:  4.26790185546875\t ACC train:  0.504\t ACC test:  0.5222222222222223\n",
      "\tEpoch 30: \tAverage Loss:  4.2626044921875\t ACC train:  0.522\t ACC test:  0.49777777777777776\n",
      "\tEpoch 31: \tAverage Loss:  4.25308935546875\t ACC train:  0.518\t ACC test:  0.5177777777777778\n",
      "\tEpoch 32: \tAverage Loss:  4.24679833984375\t ACC train:  0.518\t ACC test:  0.5\n",
      "\tEpoch 33: \tAverage Loss:  4.24025439453125\t ACC train:  0.5\t ACC test:  0.5066666666666667\n",
      "\tEpoch 34: \tAverage Loss:  4.23163720703125\t ACC train:  0.528\t ACC test:  0.4888888888888889\n",
      "\tEpoch 35: \tAverage Loss:  4.2255537109375\t ACC train:  0.494\t ACC test:  0.5155555555555555\n",
      "\tEpoch 36: \tAverage Loss:  4.21966552734375\t ACC train:  0.514\t ACC test:  0.5177777777777778\n",
      "\tEpoch 37: \tAverage Loss:  4.20935986328125\t ACC train:  0.488\t ACC test:  0.5155555555555555\n",
      "\tEpoch 38: \tAverage Loss:  4.20337939453125\t ACC train:  0.54\t ACC test:  0.5177777777777778\n",
      "\tEpoch 39: \tAverage Loss:  4.1988876953125\t ACC train:  0.556\t ACC test:  0.5333333333333333\n",
      "\tEpoch 40: \tAverage Loss:  4.1865986328125\t ACC train:  0.506\t ACC test:  0.5044444444444445\n",
      "\tEpoch 41: \tAverage Loss:  4.186578125\t ACC train:  0.512\t ACC test:  0.49777777777777776\n",
      "\tEpoch 42: \tAverage Loss:  4.17694384765625\t ACC train:  0.52\t ACC test:  0.4955555555555556\n",
      "\tEpoch 43: \tAverage Loss:  4.17132373046875\t ACC train:  0.532\t ACC test:  0.46\n",
      "\tEpoch 44: \tAverage Loss:  4.1652861328125\t ACC train:  0.548\t ACC test:  0.4888888888888889\n",
      "\tEpoch 45: \tAverage Loss:  4.15674462890625\t ACC train:  0.53\t ACC test:  0.5288888888888889\n",
      "\tEpoch 46: \tAverage Loss:  4.15730712890625\t ACC train:  0.548\t ACC test:  0.5311111111111111\n",
      "\tEpoch 47: \tAverage Loss:  4.14817578125\t ACC train:  0.55\t ACC test:  0.4911111111111111\n",
      "\tEpoch 48: \tAverage Loss:  4.14323583984375\t ACC train:  0.492\t ACC test:  0.5155555555555555\n",
      "\tEpoch 49: \tAverage Loss:  4.134650390625\t ACC train:  0.504\t ACC test:  0.5222222222222223\n",
      "\tEpoch 50: \tAverage Loss:  4.12474560546875\t ACC train:  0.548\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  4.1238056640625\t ACC train:  0.532\t ACC test:  0.5288888888888889\n",
      "\tEpoch 52: \tAverage Loss:  4.118712890625\t ACC train:  0.524\t ACC test:  0.5022222222222222\n",
      "\tEpoch 53: \tAverage Loss:  4.1157392578125\t ACC train:  0.54\t ACC test:  0.4822222222222222\n",
      "\tEpoch 54: \tAverage Loss:  4.11011376953125\t ACC train:  0.492\t ACC test:  0.4888888888888889\n",
      "\tEpoch 55: \tAverage Loss:  4.1022548828125\t ACC train:  0.516\t ACC test:  0.5311111111111111\n",
      "\tEpoch 56: \tAverage Loss:  4.098986328125\t ACC train:  0.52\t ACC test:  0.49333333333333335\n",
      "\tEpoch 57: \tAverage Loss:  4.095654541015625\t ACC train:  0.522\t ACC test:  0.5222222222222223\n",
      "\tEpoch 58: \tAverage Loss:  4.0903154296875\t ACC train:  0.524\t ACC test:  0.5088888888888888\n",
      "\tEpoch 59: \tAverage Loss:  4.081634765625\t ACC train:  0.522\t ACC test:  0.5511111111111111\n",
      "\tEpoch 60: \tAverage Loss:  4.0822041015625\t ACC train:  0.542\t ACC test:  0.5244444444444445\n",
      "\tEpoch 61: \tAverage Loss:  4.073416015625\t ACC train:  0.506\t ACC test:  0.4955555555555556\n",
      "\tEpoch 62: \tAverage Loss:  4.0701162109375\t ACC train:  0.514\t ACC test:  0.5533333333333333\n",
      "\tEpoch 63: \tAverage Loss:  4.067791015625\t ACC train:  0.528\t ACC test:  0.5155555555555555\n",
      "\tEpoch 64: \tAverage Loss:  4.06125537109375\t ACC train:  0.528\t ACC test:  0.5377777777777778\n",
      "\tEpoch 65: \tAverage Loss:  4.056544921875\t ACC train:  0.54\t ACC test:  0.5355555555555556\n",
      "\tEpoch 66: \tAverage Loss:  4.0527763671875\t ACC train:  0.522\t ACC test:  0.5733333333333334\n",
      "\tEpoch 67: \tAverage Loss:  4.0490146484375\t ACC train:  0.526\t ACC test:  0.5377777777777778\n",
      "\tEpoch 68: \tAverage Loss:  4.042718017578125\t ACC train:  0.502\t ACC test:  0.5511111111111111\n",
      "\tEpoch 69: \tAverage Loss:  4.03872998046875\t ACC train:  0.598\t ACC test:  0.5666666666666667\n",
      "\tEpoch 70: \tAverage Loss:  4.03332470703125\t ACC train:  0.578\t ACC test:  0.5222222222222223\n",
      "\tEpoch 71: \tAverage Loss:  4.0287880859375\t ACC train:  0.526\t ACC test:  0.5133333333333333\n",
      "\tEpoch 72: \tAverage Loss:  4.03024169921875\t ACC train:  0.542\t ACC test:  0.56\n",
      "\tEpoch 73: \tAverage Loss:  4.0272109375\t ACC train:  0.546\t ACC test:  0.5511111111111111\n",
      "\tEpoch 74: \tAverage Loss:  4.0230224609375\t ACC train:  0.544\t ACC test:  0.5288888888888889\n",
      "\tEpoch 75: \tAverage Loss:  4.013780517578125\t ACC train:  0.536\t ACC test:  0.5177777777777778\n",
      "\tEpoch 76: \tAverage Loss:  4.00943310546875\t ACC train:  0.552\t ACC test:  0.5022222222222222\n",
      "\tEpoch 77: \tAverage Loss:  4.00967724609375\t ACC train:  0.542\t ACC test:  0.5244444444444445\n",
      "\tEpoch 78: \tAverage Loss:  4.008830078125\t ACC train:  0.568\t ACC test:  0.5311111111111111\n",
      "\tEpoch 79: \tAverage Loss:  3.996578125\t ACC train:  0.564\t ACC test:  0.5688888888888889\n",
      "\tEpoch 80: \tAverage Loss:  3.996806396484375\t ACC train:  0.586\t ACC test:  0.5622222222222222\n",
      "\tEpoch 81: \tAverage Loss:  3.989115234375\t ACC train:  0.57\t ACC test:  0.5644444444444444\n",
      "\tEpoch 82: \tAverage Loss:  3.9857802734375\t ACC train:  0.55\t ACC test:  0.52\n",
      "\tEpoch 83: \tAverage Loss:  3.9878984375\t ACC train:  0.542\t ACC test:  0.5822222222222222\n",
      "\tEpoch 84: \tAverage Loss:  3.979749267578125\t ACC train:  0.562\t ACC test:  0.5466666666666666\n",
      "\tEpoch 85: \tAverage Loss:  3.97525048828125\t ACC train:  0.588\t ACC test:  0.5088888888888888\n",
      "\tEpoch 86: \tAverage Loss:  3.9771220703125\t ACC train:  0.61\t ACC test:  0.5511111111111111\n",
      "\tEpoch 87: \tAverage Loss:  3.967824951171875\t ACC train:  0.572\t ACC test:  0.5488888888888889\n",
      "\tEpoch 88: \tAverage Loss:  3.967597900390625\t ACC train:  0.55\t ACC test:  0.5622222222222222\n",
      "\tEpoch 89: \tAverage Loss:  3.961398193359375\t ACC train:  0.59\t ACC test:  0.5377777777777778\n",
      "\tEpoch 90: \tAverage Loss:  3.95960107421875\t ACC train:  0.626\t ACC test:  0.5933333333333334\n",
      "\tEpoch 91: \tAverage Loss:  3.948509033203125\t ACC train:  0.564\t ACC test:  0.5755555555555556\n",
      "\tEpoch 92: \tAverage Loss:  3.96051904296875\t ACC train:  0.592\t ACC test:  0.5666666666666667\n",
      "\tEpoch 93: \tAverage Loss:  3.944440673828125\t ACC train:  0.602\t ACC test:  0.5488888888888889\n",
      "\tEpoch 94: \tAverage Loss:  3.93365869140625\t ACC train:  0.626\t ACC test:  0.5888888888888889\n",
      "\tEpoch 95: \tAverage Loss:  3.933037841796875\t ACC train:  0.596\t ACC test:  0.6088888888888889\n",
      "\tEpoch 96: \tAverage Loss:  3.939066162109375\t ACC train:  0.592\t ACC test:  0.5733333333333334\n",
      "\tEpoch 97: \tAverage Loss:  3.9249873046875\t ACC train:  0.57\t ACC test:  0.5933333333333334\n",
      "\tEpoch 98: \tAverage Loss:  3.91662939453125\t ACC train:  0.59\t ACC test:  0.5933333333333334\n",
      "\tEpoch 99: \tAverage Loss:  3.915178955078125\t ACC train:  0.61\t ACC test:  0.6\n",
      "\tEpoch 100: \tAverage Loss:  3.90824365234375\t ACC train:  0.594\t ACC test:  0.5866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  3.9134970703125\t ACC train:  0.592\t ACC test:  0.5688888888888889\n",
      "\tEpoch 102: \tAverage Loss:  3.9134013671875\t ACC train:  0.586\t ACC test:  0.5755555555555556\n",
      "\tEpoch 103: \tAverage Loss:  3.9017939453125\t ACC train:  0.598\t ACC test:  0.6288888888888889\n",
      "\tEpoch 104: \tAverage Loss:  3.89677880859375\t ACC train:  0.588\t ACC test:  0.5688888888888889\n",
      "\tEpoch 105: \tAverage Loss:  3.87697216796875\t ACC train:  0.62\t ACC test:  0.6244444444444445\n",
      "\tEpoch 106: \tAverage Loss:  3.880484375\t ACC train:  0.588\t ACC test:  0.5644444444444444\n",
      "\tEpoch 107: \tAverage Loss:  3.868669189453125\t ACC train:  0.634\t ACC test:  0.5733333333333334\n",
      "\tEpoch 108: \tAverage Loss:  3.86851611328125\t ACC train:  0.652\t ACC test:  0.5733333333333334\n",
      "\tEpoch 109: \tAverage Loss:  3.85864111328125\t ACC train:  0.624\t ACC test:  0.6\n",
      "\tEpoch 110: \tAverage Loss:  3.86225\t ACC train:  0.602\t ACC test:  0.5977777777777777\n",
      "\tEpoch 111: \tAverage Loss:  3.855671875\t ACC train:  0.608\t ACC test:  0.5911111111111111\n",
      "\tEpoch 112: \tAverage Loss:  3.837277099609375\t ACC train:  0.616\t ACC test:  0.6266666666666667\n",
      "\tEpoch 113: \tAverage Loss:  3.8560478515625\t ACC train:  0.656\t ACC test:  0.6022222222222222\n",
      "\tEpoch 114: \tAverage Loss:  3.831566162109375\t ACC train:  0.608\t ACC test:  0.5866666666666667\n",
      "\tEpoch 115: \tAverage Loss:  3.832495849609375\t ACC train:  0.63\t ACC test:  0.6111111111111112\n",
      "\tEpoch 116: \tAverage Loss:  3.817985595703125\t ACC train:  0.644\t ACC test:  0.5955555555555555\n",
      "\tEpoch 117: \tAverage Loss:  3.801212646484375\t ACC train:  0.604\t ACC test:  0.58\n",
      "\tEpoch 118: \tAverage Loss:  3.801306640625\t ACC train:  0.63\t ACC test:  0.6111111111111112\n",
      "\tEpoch 119: \tAverage Loss:  3.784220703125\t ACC train:  0.638\t ACC test:  0.6111111111111112\n",
      "\tEpoch 120: \tAverage Loss:  3.77799267578125\t ACC train:  0.616\t ACC test:  0.6\n",
      "\tEpoch 121: \tAverage Loss:  3.75930078125\t ACC train:  0.638\t ACC test:  0.6022222222222222\n",
      "\tEpoch 122: \tAverage Loss:  3.756587890625\t ACC train:  0.632\t ACC test:  0.6133333333333333\n",
      "\tEpoch 123: \tAverage Loss:  3.75684716796875\t ACC train:  0.622\t ACC test:  0.5955555555555555\n",
      "\tEpoch 124: \tAverage Loss:  3.7356796875\t ACC train:  0.656\t ACC test:  0.5866666666666667\n",
      "\tEpoch 125: \tAverage Loss:  3.72776513671875\t ACC train:  0.638\t ACC test:  0.6155555555555555\n",
      "\tEpoch 126: \tAverage Loss:  3.69351171875\t ACC train:  0.588\t ACC test:  0.6333333333333333\n",
      "\tEpoch 127: \tAverage Loss:  3.713419921875\t ACC train:  0.614\t ACC test:  0.5955555555555555\n",
      "\tEpoch 128: \tAverage Loss:  3.694494873046875\t ACC train:  0.606\t ACC test:  0.6311111111111111\n",
      "\tEpoch 129: \tAverage Loss:  3.694901611328125\t ACC train:  0.652\t ACC test:  0.5911111111111111\n",
      "\tEpoch 130: \tAverage Loss:  3.66893798828125\t ACC train:  0.608\t ACC test:  0.5933333333333334\n",
      "\tEpoch 131: \tAverage Loss:  3.644832763671875\t ACC train:  0.622\t ACC test:  0.5644444444444444\n",
      "\tEpoch 132: \tAverage Loss:  3.6287578125\t ACC train:  0.608\t ACC test:  0.5866666666666667\n",
      "\tEpoch 133: \tAverage Loss:  3.640405517578125\t ACC train:  0.634\t ACC test:  0.5844444444444444\n",
      "\tEpoch 134: \tAverage Loss:  3.6514462890625\t ACC train:  0.616\t ACC test:  0.5755555555555556\n",
      "\tEpoch 135: \tAverage Loss:  3.615382568359375\t ACC train:  0.616\t ACC test:  0.6244444444444445\n",
      "\tEpoch 136: \tAverage Loss:  3.609231689453125\t ACC train:  0.634\t ACC test:  0.5844444444444444\n",
      "\tEpoch 137: \tAverage Loss:  3.58279150390625\t ACC train:  0.608\t ACC test:  0.5844444444444444\n",
      "\tEpoch 138: \tAverage Loss:  3.545282958984375\t ACC train:  0.642\t ACC test:  0.5644444444444444\n",
      "\tEpoch 139: \tAverage Loss:  3.563474365234375\t ACC train:  0.618\t ACC test:  0.6044444444444445\n",
      "\tEpoch 140: \tAverage Loss:  3.55296728515625\t ACC train:  0.594\t ACC test:  0.5711111111111111\n",
      "\tEpoch 141: \tAverage Loss:  3.5380771484375\t ACC train:  0.618\t ACC test:  0.5866666666666667\n",
      "\tEpoch 142: \tAverage Loss:  3.49329052734375\t ACC train:  0.602\t ACC test:  0.5911111111111111\n",
      "\tEpoch 143: \tAverage Loss:  3.47138916015625\t ACC train:  0.618\t ACC test:  0.5777777777777777\n",
      "\tEpoch 144: \tAverage Loss:  3.485500244140625\t ACC train:  0.616\t ACC test:  0.5555555555555556\n",
      "\tEpoch 145: \tAverage Loss:  3.45885009765625\t ACC train:  0.626\t ACC test:  0.5933333333333334\n",
      "\tEpoch 146: \tAverage Loss:  3.46543359375\t ACC train:  0.63\t ACC test:  0.5666666666666667\n",
      "\tEpoch 147: \tAverage Loss:  3.452690673828125\t ACC train:  0.612\t ACC test:  0.5822222222222222\n",
      "\tEpoch 148: \tAverage Loss:  3.41476611328125\t ACC train:  0.594\t ACC test:  0.6\n",
      "\tEpoch 149: \tAverage Loss:  3.40710693359375\t ACC train:  0.602\t ACC test:  0.5644444444444444\n",
      "\tEpoch 150: \tAverage Loss:  3.35543701171875\t ACC train:  0.614\t ACC test:  0.5777777777777777\n",
      "\tEpoch 151: \tAverage Loss:  3.39423828125\t ACC train:  0.612\t ACC test:  0.5777777777777777\n",
      "\tEpoch 152: \tAverage Loss:  3.384824462890625\t ACC train:  0.61\t ACC test:  0.5822222222222222\n",
      "\tEpoch 153: \tAverage Loss:  3.37075732421875\t ACC train:  0.606\t ACC test:  0.5866666666666667\n",
      "\tEpoch 154: \tAverage Loss:  3.3363583984375\t ACC train:  0.608\t ACC test:  0.5666666666666667\n",
      "\tEpoch 155: \tAverage Loss:  3.3412373046875\t ACC train:  0.606\t ACC test:  0.5777777777777777\n",
      "\tEpoch 156: \tAverage Loss:  3.311583740234375\t ACC train:  0.612\t ACC test:  0.5688888888888889\n",
      "\tEpoch 157: \tAverage Loss:  3.312721923828125\t ACC train:  0.618\t ACC test:  0.5866666666666667\n",
      "\tEpoch 158: \tAverage Loss:  3.31296044921875\t ACC train:  0.602\t ACC test:  0.5777777777777777\n",
      "\tEpoch 159: \tAverage Loss:  3.286376953125\t ACC train:  0.586\t ACC test:  0.5777777777777777\n",
      "\tEpoch 160: \tAverage Loss:  3.26969775390625\t ACC train:  0.616\t ACC test:  0.5755555555555556\n",
      "\tEpoch 161: \tAverage Loss:  3.275430419921875\t ACC train:  0.612\t ACC test:  0.5688888888888889\n",
      "\tEpoch 162: \tAverage Loss:  3.218795654296875\t ACC train:  0.618\t ACC test:  0.5777777777777777\n",
      "\tEpoch 163: \tAverage Loss:  3.25447509765625\t ACC train:  0.596\t ACC test:  0.5955555555555555\n",
      "\tEpoch 164: \tAverage Loss:  3.252197998046875\t ACC train:  0.598\t ACC test:  0.5511111111111111\n",
      "\tEpoch 165: \tAverage Loss:  3.245747314453125\t ACC train:  0.6\t ACC test:  0.5577777777777778\n",
      "\tEpoch 166: \tAverage Loss:  3.201886962890625\t ACC train:  0.616\t ACC test:  0.5911111111111111\n",
      "\tEpoch 167: \tAverage Loss:  3.16270458984375\t ACC train:  0.612\t ACC test:  0.58\n",
      "\tEpoch 168: \tAverage Loss:  3.1575283203125\t ACC train:  0.616\t ACC test:  0.5688888888888889\n",
      "\tEpoch 169: \tAverage Loss:  3.19322998046875\t ACC train:  0.618\t ACC test:  0.5555555555555556\n",
      "\tEpoch 170: \tAverage Loss:  3.1565205078125\t ACC train:  0.604\t ACC test:  0.5666666666666667\n",
      "\tEpoch 171: \tAverage Loss:  3.18042431640625\t ACC train:  0.61\t ACC test:  0.5777777777777777\n",
      "\tEpoch 172: \tAverage Loss:  3.13043603515625\t ACC train:  0.618\t ACC test:  0.5777777777777777\n",
      "\tEpoch 173: \tAverage Loss:  3.131943115234375\t ACC train:  0.588\t ACC test:  0.5911111111111111\n",
      "\tEpoch 174: \tAverage Loss:  3.13600830078125\t ACC train:  0.608\t ACC test:  0.5711111111111111\n",
      "\tEpoch 175: \tAverage Loss:  3.10595458984375\t ACC train:  0.616\t ACC test:  0.5688888888888889\n",
      "\tEpoch 176: \tAverage Loss:  3.112262939453125\t ACC train:  0.612\t ACC test:  0.5711111111111111\n",
      "\tEpoch 177: \tAverage Loss:  3.068505126953125\t ACC train:  0.612\t ACC test:  0.5666666666666667\n",
      "\tEpoch 178: \tAverage Loss:  3.0726708984375\t ACC train:  0.608\t ACC test:  0.58\n",
      "\tEpoch 179: \tAverage Loss:  3.074155517578125\t ACC train:  0.598\t ACC test:  0.5733333333333334\n",
      "\tEpoch 180: \tAverage Loss:  3.05231884765625\t ACC train:  0.62\t ACC test:  0.5822222222222222\n",
      "\tEpoch 181: \tAverage Loss:  3.0426484375\t ACC train:  0.612\t ACC test:  0.5777777777777777\n",
      "\tEpoch 182: \tAverage Loss:  3.03360400390625\t ACC train:  0.618\t ACC test:  0.5644444444444444\n",
      "\tEpoch 183: \tAverage Loss:  3.053023193359375\t ACC train:  0.59\t ACC test:  0.58\n",
      "\tEpoch 184: \tAverage Loss:  3.011041259765625\t ACC train:  0.608\t ACC test:  0.5844444444444444\n",
      "\tEpoch 185: \tAverage Loss:  3.00109033203125\t ACC train:  0.622\t ACC test:  0.5866666666666667\n",
      "\tEpoch 186: \tAverage Loss:  2.982046875\t ACC train:  0.614\t ACC test:  0.5866666666666667\n",
      "\tEpoch 187: \tAverage Loss:  2.94552587890625\t ACC train:  0.59\t ACC test:  0.5688888888888889\n",
      "\tEpoch 188: \tAverage Loss:  2.972998779296875\t ACC train:  0.61\t ACC test:  0.5866666666666667\n",
      "\tEpoch 189: \tAverage Loss:  2.95576416015625\t ACC train:  0.62\t ACC test:  0.5822222222222222\n",
      "\tEpoch 190: \tAverage Loss:  2.9722802734375\t ACC train:  0.608\t ACC test:  0.5866666666666667\n",
      "\tEpoch 191: \tAverage Loss:  2.945392578125\t ACC train:  0.606\t ACC test:  0.58\n",
      "\tEpoch 192: \tAverage Loss:  2.913048828125\t ACC train:  0.594\t ACC test:  0.5866666666666667\n",
      "\tEpoch 193: \tAverage Loss:  2.905716064453125\t ACC train:  0.598\t ACC test:  0.5933333333333334\n",
      "\tEpoch 194: \tAverage Loss:  2.907845703125\t ACC train:  0.602\t ACC test:  0.5866666666666667\n",
      "\tEpoch 195: \tAverage Loss:  2.917823974609375\t ACC train:  0.6\t ACC test:  0.5888888888888889\n",
      "\tEpoch 196: \tAverage Loss:  2.876828369140625\t ACC train:  0.594\t ACC test:  0.5755555555555556\n",
      "\tEpoch 197: \tAverage Loss:  2.90001806640625\t ACC train:  0.63\t ACC test:  0.5933333333333334\n",
      "\tEpoch 198: \tAverage Loss:  2.8577880859375\t ACC train:  0.62\t ACC test:  0.6022222222222222\n",
      "\tEpoch 199: \tAverage Loss:  2.86214208984375\t ACC train:  0.61\t ACC test:  0.6177777777777778\n",
      "\tEpoch 200: \tAverage Loss:  2.844751953125\t ACC train:  0.628\t ACC test:  0.5977777777777777\n",
      "\tEpoch 201: \tAverage Loss:  2.817724609375\t ACC train:  0.634\t ACC test:  0.6133333333333333\n",
      "\tEpoch 202: \tAverage Loss:  2.849805419921875\t ACC train:  0.658\t ACC test:  0.6244444444444445\n",
      "\tEpoch 203: \tAverage Loss:  2.824698486328125\t ACC train:  0.646\t ACC test:  0.6333333333333333\n",
      "\tEpoch 204: \tAverage Loss:  2.80189892578125\t ACC train:  0.668\t ACC test:  0.6377777777777778\n",
      "\tEpoch 205: \tAverage Loss:  2.80469091796875\t ACC train:  0.676\t ACC test:  0.6488888888888888\n",
      "\tEpoch 206: \tAverage Loss:  2.815468994140625\t ACC train:  0.652\t ACC test:  0.68\n",
      "\tEpoch 207: \tAverage Loss:  2.78649072265625\t ACC train:  0.65\t ACC test:  0.6755555555555556\n",
      "\tEpoch 208: \tAverage Loss:  2.77402197265625\t ACC train:  0.674\t ACC test:  0.6777777777777778\n",
      "\tEpoch 209: \tAverage Loss:  2.778455810546875\t ACC train:  0.708\t ACC test:  0.6844444444444444\n",
      "\tEpoch 210: \tAverage Loss:  2.76613720703125\t ACC train:  0.704\t ACC test:  0.6911111111111111\n",
      "\tEpoch 211: \tAverage Loss:  2.75887939453125\t ACC train:  0.728\t ACC test:  0.7155555555555555\n",
      "\tEpoch 212: \tAverage Loss:  2.74415576171875\t ACC train:  0.698\t ACC test:  0.7311111111111112\n",
      "\tEpoch 213: \tAverage Loss:  2.74525537109375\t ACC train:  0.706\t ACC test:  0.74\n",
      "\tEpoch 214: \tAverage Loss:  2.728979736328125\t ACC train:  0.742\t ACC test:  0.7088888888888889\n",
      "\tEpoch 215: \tAverage Loss:  2.74922216796875\t ACC train:  0.748\t ACC test:  0.7533333333333333\n",
      "\tEpoch 216: \tAverage Loss:  2.70849462890625\t ACC train:  0.758\t ACC test:  0.7577777777777778\n",
      "\tEpoch 217: \tAverage Loss:  2.69579736328125\t ACC train:  0.76\t ACC test:  0.7644444444444445\n",
      "\tEpoch 218: \tAverage Loss:  2.704919189453125\t ACC train:  0.78\t ACC test:  0.7577777777777778\n",
      "\tEpoch 219: \tAverage Loss:  2.694477783203125\t ACC train:  0.784\t ACC test:  0.7711111111111111\n",
      "\tEpoch 220: \tAverage Loss:  2.688261962890625\t ACC train:  0.792\t ACC test:  0.7955555555555556\n",
      "\tEpoch 221: \tAverage Loss:  2.67891845703125\t ACC train:  0.782\t ACC test:  0.78\n",
      "\tEpoch 222: \tAverage Loss:  2.683797607421875\t ACC train:  0.798\t ACC test:  0.7888888888888889\n",
      "\tEpoch 223: \tAverage Loss:  2.671621337890625\t ACC train:  0.806\t ACC test:  0.8088888888888889\n",
      "\tEpoch 224: \tAverage Loss:  2.668772216796875\t ACC train:  0.804\t ACC test:  0.8355555555555556\n",
      "\tEpoch 225: \tAverage Loss:  2.638069091796875\t ACC train:  0.818\t ACC test:  0.8222222222222222\n",
      "\tEpoch 226: \tAverage Loss:  2.640455810546875\t ACC train:  0.818\t ACC test:  0.8022222222222222\n",
      "\tEpoch 227: \tAverage Loss:  2.616732177734375\t ACC train:  0.804\t ACC test:  0.84\n",
      "\tEpoch 228: \tAverage Loss:  2.626419677734375\t ACC train:  0.838\t ACC test:  0.8511111111111112\n",
      "\tEpoch 229: \tAverage Loss:  2.629860595703125\t ACC train:  0.828\t ACC test:  0.8222222222222222\n",
      "\tEpoch 230: \tAverage Loss:  2.597953857421875\t ACC train:  0.832\t ACC test:  0.8111111111111111\n",
      "\tEpoch 231: \tAverage Loss:  2.60202978515625\t ACC train:  0.848\t ACC test:  0.8111111111111111\n",
      "\tEpoch 232: \tAverage Loss:  2.599399169921875\t ACC train:  0.816\t ACC test:  0.8533333333333334\n",
      "\tEpoch 233: \tAverage Loss:  2.597509765625\t ACC train:  0.824\t ACC test:  0.84\n",
      "\tEpoch 234: \tAverage Loss:  2.58171142578125\t ACC train:  0.822\t ACC test:  0.8488888888888889\n",
      "\tEpoch 235: \tAverage Loss:  2.58246240234375\t ACC train:  0.82\t ACC test:  0.8511111111111112\n",
      "\tEpoch 236: \tAverage Loss:  2.579862548828125\t ACC train:  0.834\t ACC test:  0.8155555555555556\n",
      "\tEpoch 237: \tAverage Loss:  2.5503544921875\t ACC train:  0.858\t ACC test:  0.8466666666666667\n",
      "\tEpoch 238: \tAverage Loss:  2.563602783203125\t ACC train:  0.858\t ACC test:  0.8444444444444444\n",
      "\tEpoch 239: \tAverage Loss:  2.558887451171875\t ACC train:  0.828\t ACC test:  0.8711111111111111\n",
      "\tEpoch 240: \tAverage Loss:  2.543156982421875\t ACC train:  0.86\t ACC test:  0.8555555555555555\n",
      "\tEpoch 241: \tAverage Loss:  2.543047607421875\t ACC train:  0.856\t ACC test:  0.8244444444444444\n",
      "\tEpoch 242: \tAverage Loss:  2.5449287109375\t ACC train:  0.868\t ACC test:  0.88\n",
      "\tEpoch 243: \tAverage Loss:  2.5355986328125\t ACC train:  0.856\t ACC test:  0.8688888888888889\n",
      "\tEpoch 244: \tAverage Loss:  2.538159912109375\t ACC train:  0.858\t ACC test:  0.8444444444444444\n",
      "\tEpoch 245: \tAverage Loss:  2.51620947265625\t ACC train:  0.842\t ACC test:  0.8555555555555555\n",
      "\tEpoch 246: \tAverage Loss:  2.5185048828125\t ACC train:  0.86\t ACC test:  0.88\n",
      "\tEpoch 247: \tAverage Loss:  2.511408447265625\t ACC train:  0.86\t ACC test:  0.8577777777777778\n",
      "\tEpoch 248: \tAverage Loss:  2.513066650390625\t ACC train:  0.878\t ACC test:  0.8755555555555555\n",
      "\tEpoch 249: \tAverage Loss:  2.49318212890625\t ACC train:  0.858\t ACC test:  0.8866666666666667\n",
      "\tEpoch 250: \tAverage Loss:  2.489900634765625\t ACC train:  0.876\t ACC test:  0.8755555555555555\n",
      "\tEpoch 251: \tAverage Loss:  2.49131982421875\t ACC train:  0.852\t ACC test:  0.8688888888888889\n",
      "\tEpoch 252: \tAverage Loss:  2.500989013671875\t ACC train:  0.844\t ACC test:  0.8866666666666667\n",
      "\tEpoch 253: \tAverage Loss:  2.483038818359375\t ACC train:  0.876\t ACC test:  0.8711111111111111\n",
      "\tEpoch 254: \tAverage Loss:  2.479175537109375\t ACC train:  0.858\t ACC test:  0.8844444444444445\n",
      "\tEpoch 255: \tAverage Loss:  2.461576171875\t ACC train:  0.862\t ACC test:  0.8844444444444445\n",
      "\tEpoch 256: \tAverage Loss:  2.473996826171875\t ACC train:  0.874\t ACC test:  0.8866666666666667\n",
      "\tEpoch 257: \tAverage Loss:  2.464603271484375\t ACC train:  0.866\t ACC test:  0.8711111111111111\n",
      "\tEpoch 258: \tAverage Loss:  2.45802978515625\t ACC train:  0.876\t ACC test:  0.8666666666666667\n",
      "\tEpoch 259: \tAverage Loss:  2.453951904296875\t ACC train:  0.884\t ACC test:  0.8844444444444445\n",
      "\tEpoch 260: \tAverage Loss:  2.446579345703125\t ACC train:  0.886\t ACC test:  0.9022222222222223\n",
      "\tEpoch 261: \tAverage Loss:  2.43250634765625\t ACC train:  0.876\t ACC test:  0.8866666666666667\n",
      "\tEpoch 262: \tAverage Loss:  2.447278076171875\t ACC train:  0.886\t ACC test:  0.9111111111111111\n",
      "\tEpoch 263: \tAverage Loss:  2.4464833984375\t ACC train:  0.898\t ACC test:  0.8933333333333333\n",
      "\tEpoch 264: \tAverage Loss:  2.419896240234375\t ACC train:  0.882\t ACC test:  0.9\n",
      "\tEpoch 265: \tAverage Loss:  2.435484130859375\t ACC train:  0.862\t ACC test:  0.8733333333333333\n",
      "\tEpoch 266: \tAverage Loss:  2.41300146484375\t ACC train:  0.908\t ACC test:  0.8866666666666667\n",
      "\tEpoch 267: \tAverage Loss:  2.412150634765625\t ACC train:  0.892\t ACC test:  0.88\n",
      "\tEpoch 268: \tAverage Loss:  2.413361572265625\t ACC train:  0.886\t ACC test:  0.8933333333333333\n",
      "\tEpoch 269: \tAverage Loss:  2.40153857421875\t ACC train:  0.906\t ACC test:  0.88\n",
      "\tEpoch 270: \tAverage Loss:  2.41293701171875\t ACC train:  0.902\t ACC test:  0.8822222222222222\n",
      "\tEpoch 271: \tAverage Loss:  2.401564697265625\t ACC train:  0.916\t ACC test:  0.9288888888888889\n",
      "\tEpoch 272: \tAverage Loss:  2.397946533203125\t ACC train:  0.896\t ACC test:  0.9133333333333333\n",
      "\tEpoch 273: \tAverage Loss:  2.400916259765625\t ACC train:  0.886\t ACC test:  0.9022222222222223\n",
      "\tEpoch 274: \tAverage Loss:  2.3964208984375\t ACC train:  0.908\t ACC test:  0.9066666666666666\n",
      "\tEpoch 275: \tAverage Loss:  2.38916259765625\t ACC train:  0.896\t ACC test:  0.8888888888888888\n",
      "\tEpoch 276: \tAverage Loss:  2.38097509765625\t ACC train:  0.918\t ACC test:  0.9044444444444445\n",
      "\tEpoch 277: \tAverage Loss:  2.38204296875\t ACC train:  0.902\t ACC test:  0.9111111111111111\n",
      "\tEpoch 278: \tAverage Loss:  2.3900029296875\t ACC train:  0.91\t ACC test:  0.8977777777777778\n",
      "\tEpoch 279: \tAverage Loss:  2.369893310546875\t ACC train:  0.902\t ACC test:  0.9133333333333333\n",
      "\tEpoch 280: \tAverage Loss:  2.351119384765625\t ACC train:  0.898\t ACC test:  0.9133333333333333\n",
      "\tEpoch 281: \tAverage Loss:  2.373219482421875\t ACC train:  0.898\t ACC test:  0.8977777777777778\n",
      "\tEpoch 282: \tAverage Loss:  2.365430419921875\t ACC train:  0.9\t ACC test:  0.9133333333333333\n",
      "\tEpoch 283: \tAverage Loss:  2.355153564453125\t ACC train:  0.924\t ACC test:  0.9133333333333333\n",
      "\tEpoch 284: \tAverage Loss:  2.36180322265625\t ACC train:  0.896\t ACC test:  0.9022222222222223\n",
      "\tEpoch 285: \tAverage Loss:  2.3561806640625\t ACC train:  0.9\t ACC test:  0.8955555555555555\n",
      "\tEpoch 286: \tAverage Loss:  2.34279541015625\t ACC train:  0.906\t ACC test:  0.9288888888888889\n",
      "\tEpoch 287: \tAverage Loss:  2.355005859375\t ACC train:  0.904\t ACC test:  0.9066666666666666\n",
      "\tEpoch 288: \tAverage Loss:  2.340754150390625\t ACC train:  0.918\t ACC test:  0.9177777777777778\n",
      "\tEpoch 289: \tAverage Loss:  2.333790771484375\t ACC train:  0.904\t ACC test:  0.9177777777777778\n",
      "\tEpoch 290: \tAverage Loss:  2.33500537109375\t ACC train:  0.916\t ACC test:  0.9266666666666666\n",
      "\tEpoch 291: \tAverage Loss:  2.32340966796875\t ACC train:  0.914\t ACC test:  0.9133333333333333\n",
      "\tEpoch 292: \tAverage Loss:  2.32644384765625\t ACC train:  0.928\t ACC test:  0.9177777777777778\n",
      "\tEpoch 293: \tAverage Loss:  2.330643798828125\t ACC train:  0.936\t ACC test:  0.9155555555555556\n",
      "\tEpoch 294: \tAverage Loss:  2.33296142578125\t ACC train:  0.902\t ACC test:  0.9088888888888889\n",
      "\tEpoch 295: \tAverage Loss:  2.31900341796875\t ACC train:  0.91\t ACC test:  0.9111111111111111\n",
      "\tEpoch 296: \tAverage Loss:  2.3196796875\t ACC train:  0.922\t ACC test:  0.9066666666666666\n",
      "\tEpoch 297: \tAverage Loss:  2.325406982421875\t ACC train:  0.926\t ACC test:  0.9266666666666666\n",
      "\tEpoch 298: \tAverage Loss:  2.309607177734375\t ACC train:  0.942\t ACC test:  0.9311111111111111\n",
      "\tEpoch 299: \tAverage Loss:  2.31072119140625\t ACC train:  0.928\t ACC test:  0.9133333333333333\n",
      "\tEpoch 300: \tAverage Loss:  2.306246337890625\t ACC train:  0.924\t ACC test:  0.9377777777777778\n",
      "\tEpoch 301: \tAverage Loss:  2.330501953125\t ACC train:  0.912\t ACC test:  0.9111111111111111\n",
      "\tEpoch 302: \tAverage Loss:  2.312655029296875\t ACC train:  0.93\t ACC test:  0.9333333333333333\n",
      "\tEpoch 303: \tAverage Loss:  2.3040673828125\t ACC train:  0.922\t ACC test:  0.9155555555555556\n",
      "\tEpoch 304: \tAverage Loss:  2.294502685546875\t ACC train:  0.936\t ACC test:  0.9266666666666666\n",
      "\tEpoch 305: \tAverage Loss:  2.290912353515625\t ACC train:  0.93\t ACC test:  0.9377777777777778\n",
      "\tEpoch 306: \tAverage Loss:  2.30840234375\t ACC train:  0.926\t ACC test:  0.9288888888888889\n",
      "\tEpoch 307: \tAverage Loss:  2.287213134765625\t ACC train:  0.912\t ACC test:  0.9133333333333333\n",
      "\tEpoch 308: \tAverage Loss:  2.28449755859375\t ACC train:  0.924\t ACC test:  0.9222222222222223\n",
      "\tEpoch 309: \tAverage Loss:  2.286417724609375\t ACC train:  0.918\t ACC test:  0.9333333333333333\n",
      "\tEpoch 310: \tAverage Loss:  2.28631787109375\t ACC train:  0.926\t ACC test:  0.9333333333333333\n",
      "\tEpoch 311: \tAverage Loss:  2.27449658203125\t ACC train:  0.936\t ACC test:  0.9355555555555556\n",
      "\tEpoch 312: \tAverage Loss:  2.278572021484375\t ACC train:  0.942\t ACC test:  0.9444444444444444\n",
      "\tEpoch 313: \tAverage Loss:  2.272416259765625\t ACC train:  0.94\t ACC test:  0.9222222222222223\n",
      "\tEpoch 314: \tAverage Loss:  2.27719775390625\t ACC train:  0.934\t ACC test:  0.9422222222222222\n",
      "\tEpoch 315: \tAverage Loss:  2.270682861328125\t ACC train:  0.94\t ACC test:  0.9333333333333333\n",
      "\tEpoch 316: \tAverage Loss:  2.276354736328125\t ACC train:  0.926\t ACC test:  0.9355555555555556\n",
      "\tEpoch 317: \tAverage Loss:  2.2594169921875\t ACC train:  0.926\t ACC test:  0.9422222222222222\n",
      "\tEpoch 318: \tAverage Loss:  2.2747373046875\t ACC train:  0.938\t ACC test:  0.9488888888888889\n",
      "\tEpoch 319: \tAverage Loss:  2.26935205078125\t ACC train:  0.926\t ACC test:  0.9355555555555556\n",
      "\tEpoch 320: \tAverage Loss:  2.25053759765625\t ACC train:  0.932\t ACC test:  0.94\n",
      "\tEpoch 321: \tAverage Loss:  2.26634033203125\t ACC train:  0.926\t ACC test:  0.9244444444444444\n",
      "\tEpoch 322: \tAverage Loss:  2.251769287109375\t ACC train:  0.932\t ACC test:  0.94\n",
      "\tEpoch 323: \tAverage Loss:  2.2547646484375\t ACC train:  0.932\t ACC test:  0.94\n",
      "\tEpoch 324: \tAverage Loss:  2.250321044921875\t ACC train:  0.958\t ACC test:  0.9466666666666667\n",
      "\tEpoch 325: \tAverage Loss:  2.256493896484375\t ACC train:  0.95\t ACC test:  0.9355555555555556\n",
      "\tEpoch 326: \tAverage Loss:  2.248856689453125\t ACC train:  0.94\t ACC test:  0.94\n",
      "\tEpoch 327: \tAverage Loss:  2.261914306640625\t ACC train:  0.94\t ACC test:  0.9466666666666667\n",
      "\tEpoch 328: \tAverage Loss:  2.259658447265625\t ACC train:  0.944\t ACC test:  0.9444444444444444\n",
      "\tEpoch 329: \tAverage Loss:  2.237696533203125\t ACC train:  0.94\t ACC test:  0.94\n",
      "\tEpoch 330: \tAverage Loss:  2.224076171875\t ACC train:  0.95\t ACC test:  0.94\n",
      "\tEpoch 331: \tAverage Loss:  2.235389892578125\t ACC train:  0.946\t ACC test:  0.9444444444444444\n",
      "\tEpoch 332: \tAverage Loss:  2.23078369140625\t ACC train:  0.948\t ACC test:  0.9311111111111111\n",
      "\tEpoch 333: \tAverage Loss:  2.22431298828125\t ACC train:  0.944\t ACC test:  0.9377777777777778\n",
      "\tEpoch 334: \tAverage Loss:  2.229718505859375\t ACC train:  0.924\t ACC test:  0.9511111111111111\n",
      "\tEpoch 335: \tAverage Loss:  2.229132080078125\t ACC train:  0.936\t ACC test:  0.9377777777777778\n",
      "\tEpoch 336: \tAverage Loss:  2.220346923828125\t ACC train:  0.95\t ACC test:  0.9555555555555556\n",
      "\tEpoch 337: \tAverage Loss:  2.20750341796875\t ACC train:  0.936\t ACC test:  0.9511111111111111\n",
      "\tEpoch 338: \tAverage Loss:  2.227705810546875\t ACC train:  0.928\t ACC test:  0.9511111111111111\n",
      "\tEpoch 339: \tAverage Loss:  2.215761474609375\t ACC train:  0.954\t ACC test:  0.9622222222222222\n",
      "\tEpoch 340: \tAverage Loss:  2.211098388671875\t ACC train:  0.95\t ACC test:  0.9555555555555556\n",
      "\tEpoch 341: \tAverage Loss:  2.21519580078125\t ACC train:  0.938\t ACC test:  0.9422222222222222\n",
      "\tEpoch 342: \tAverage Loss:  2.2090849609375\t ACC train:  0.948\t ACC test:  0.9444444444444444\n",
      "\tEpoch 343: \tAverage Loss:  2.21342626953125\t ACC train:  0.952\t ACC test:  0.9422222222222222\n",
      "\tEpoch 344: \tAverage Loss:  2.203833984375\t ACC train:  0.952\t ACC test:  0.9466666666666667\n",
      "\tEpoch 345: \tAverage Loss:  2.20833154296875\t ACC train:  0.938\t ACC test:  0.9466666666666667\n",
      "\tEpoch 346: \tAverage Loss:  2.20593212890625\t ACC train:  0.966\t ACC test:  0.9511111111111111\n",
      "\tEpoch 347: \tAverage Loss:  2.19730712890625\t ACC train:  0.946\t ACC test:  0.9577777777777777\n",
      "\tEpoch 348: \tAverage Loss:  2.19534716796875\t ACC train:  0.948\t ACC test:  0.96\n",
      "\tEpoch 349: \tAverage Loss:  2.1953935546875\t ACC train:  0.948\t ACC test:  0.9622222222222222\n",
      "\tEpoch 350: \tAverage Loss:  2.1841123046875\t ACC train:  0.952\t ACC test:  0.9555555555555556\n",
      "\tEpoch 351: \tAverage Loss:  2.1878935546875\t ACC train:  0.968\t ACC test:  0.9555555555555556\n",
      "\tEpoch 352: \tAverage Loss:  2.18389453125\t ACC train:  0.948\t ACC test:  0.9622222222222222\n",
      "\tEpoch 353: \tAverage Loss:  2.17163134765625\t ACC train:  0.944\t ACC test:  0.9466666666666667\n",
      "\tEpoch 354: \tAverage Loss:  2.1835087890625\t ACC train:  0.948\t ACC test:  0.9533333333333334\n",
      "\tEpoch 355: \tAverage Loss:  2.19055224609375\t ACC train:  0.956\t ACC test:  0.9555555555555556\n",
      "\tEpoch 356: \tAverage Loss:  2.180502197265625\t ACC train:  0.954\t ACC test:  0.9533333333333334\n",
      "\tEpoch 357: \tAverage Loss:  2.179628173828125\t ACC train:  0.946\t ACC test:  0.9533333333333334\n",
      "\tEpoch 358: \tAverage Loss:  2.163641357421875\t ACC train:  0.946\t ACC test:  0.96\n",
      "\tEpoch 359: \tAverage Loss:  2.165168701171875\t ACC train:  0.952\t ACC test:  0.9555555555555556\n",
      "\tEpoch 360: \tAverage Loss:  2.18269140625\t ACC train:  0.956\t ACC test:  0.9466666666666667\n",
      "\tEpoch 361: \tAverage Loss:  2.17113134765625\t ACC train:  0.958\t ACC test:  0.9555555555555556\n",
      "\tEpoch 362: \tAverage Loss:  2.1681005859375\t ACC train:  0.948\t ACC test:  0.96\n",
      "\tEpoch 363: \tAverage Loss:  2.168171875\t ACC train:  0.95\t ACC test:  0.96\n",
      "\tEpoch 364: \tAverage Loss:  2.161882568359375\t ACC train:  0.952\t ACC test:  0.9555555555555556\n",
      "\tEpoch 365: \tAverage Loss:  2.15853857421875\t ACC train:  0.954\t ACC test:  0.9466666666666667\n",
      "\tEpoch 366: \tAverage Loss:  2.156470947265625\t ACC train:  0.958\t ACC test:  0.9488888888888889\n",
      "\tEpoch 367: \tAverage Loss:  2.154790283203125\t ACC train:  0.952\t ACC test:  0.9577777777777777\n",
      "\tEpoch 368: \tAverage Loss:  2.1609013671875\t ACC train:  0.952\t ACC test:  0.96\n",
      "\tEpoch 369: \tAverage Loss:  2.14673193359375\t ACC train:  0.964\t ACC test:  0.9444444444444444\n",
      "\tEpoch 370: \tAverage Loss:  2.152935546875\t ACC train:  0.958\t ACC test:  0.9577777777777777\n",
      "\tEpoch 371: \tAverage Loss:  2.156678955078125\t ACC train:  0.952\t ACC test:  0.9533333333333334\n",
      "\tEpoch 372: \tAverage Loss:  2.150662841796875\t ACC train:  0.966\t ACC test:  0.9533333333333334\n",
      "\tEpoch 373: \tAverage Loss:  2.1480615234375\t ACC train:  0.96\t ACC test:  0.9511111111111111\n",
      "\tEpoch 374: \tAverage Loss:  2.138552490234375\t ACC train:  0.958\t ACC test:  0.9622222222222222\n",
      "\tEpoch 375: \tAverage Loss:  2.14149560546875\t ACC train:  0.958\t ACC test:  0.9444444444444444\n",
      "\tEpoch 376: \tAverage Loss:  2.129811279296875\t ACC train:  0.968\t ACC test:  0.9533333333333334\n",
      "\tEpoch 377: \tAverage Loss:  2.14951025390625\t ACC train:  0.962\t ACC test:  0.9511111111111111\n",
      "\tEpoch 378: \tAverage Loss:  2.132701416015625\t ACC train:  0.962\t ACC test:  0.9555555555555556\n",
      "\tEpoch 379: \tAverage Loss:  2.133289794921875\t ACC train:  0.97\t ACC test:  0.9555555555555556\n",
      "\tEpoch 380: \tAverage Loss:  2.14895166015625\t ACC train:  0.96\t ACC test:  0.9577777777777777\n",
      "\tEpoch 381: \tAverage Loss:  2.13222119140625\t ACC train:  0.968\t ACC test:  0.9577777777777777\n",
      "\tEpoch 382: \tAverage Loss:  2.121692138671875\t ACC train:  0.958\t ACC test:  0.96\n",
      "\tEpoch 383: \tAverage Loss:  2.12729248046875\t ACC train:  0.968\t ACC test:  0.9555555555555556\n",
      "\tEpoch 384: \tAverage Loss:  2.1310888671875\t ACC train:  0.95\t ACC test:  0.9577777777777777\n",
      "\tEpoch 385: \tAverage Loss:  2.11834375\t ACC train:  0.97\t ACC test:  0.9533333333333334\n",
      "\tEpoch 386: \tAverage Loss:  2.117720947265625\t ACC train:  0.958\t ACC test:  0.9555555555555556\n",
      "\tEpoch 387: \tAverage Loss:  2.1151708984375\t ACC train:  0.96\t ACC test:  0.9533333333333334\n",
      "\tEpoch 388: \tAverage Loss:  2.117371337890625\t ACC train:  0.956\t ACC test:  0.9488888888888889\n",
      "\tEpoch 389: \tAverage Loss:  2.12059912109375\t ACC train:  0.96\t ACC test:  0.9466666666666667\n",
      "\tEpoch 390: \tAverage Loss:  2.114208740234375\t ACC train:  0.966\t ACC test:  0.9488888888888889\n",
      "\tEpoch 391: \tAverage Loss:  2.11562109375\t ACC train:  0.956\t ACC test:  0.96\n",
      "\tEpoch 392: \tAverage Loss:  2.110757568359375\t ACC train:  0.958\t ACC test:  0.9555555555555556\n",
      "\tEpoch 393: \tAverage Loss:  2.104218994140625\t ACC train:  0.96\t ACC test:  0.96\n",
      "\tEpoch 394: \tAverage Loss:  2.099768798828125\t ACC train:  0.964\t ACC test:  0.96\n",
      "\tEpoch 395: \tAverage Loss:  2.1038515625\t ACC train:  0.97\t ACC test:  0.9466666666666667\n",
      "\tEpoch 396: \tAverage Loss:  2.107005859375\t ACC train:  0.968\t ACC test:  0.9511111111111111\n",
      "\tEpoch 397: \tAverage Loss:  2.110736083984375\t ACC train:  0.96\t ACC test:  0.96\n",
      "\tEpoch 398: \tAverage Loss:  2.0951103515625\t ACC train:  0.958\t ACC test:  0.9555555555555556\n",
      "\tEpoch 399: \tAverage Loss:  2.103990478515625\t ACC train:  0.964\t ACC test:  0.9533333333333334\n",
      "\tEpoch 400: \tAverage Loss:  2.102043212890625\t ACC train:  0.958\t ACC test:  0.9577777777777777\n",
      "\tEpoch 401: \tAverage Loss:  2.0884580078125\t ACC train:  0.966\t ACC test:  0.9688888888888889\n",
      "\tEpoch 402: \tAverage Loss:  2.093380615234375\t ACC train:  0.96\t ACC test:  0.9577777777777777\n",
      "\tEpoch 403: \tAverage Loss:  2.08711279296875\t ACC train:  0.966\t ACC test:  0.9577777777777777\n",
      "\tEpoch 404: \tAverage Loss:  2.10246875\t ACC train:  0.966\t ACC test:  0.9644444444444444\n",
      "\tEpoch 405: \tAverage Loss:  2.072337158203125\t ACC train:  0.954\t ACC test:  0.96\n",
      "\tEpoch 406: \tAverage Loss:  2.079749267578125\t ACC train:  0.964\t ACC test:  0.96\n",
      "\tEpoch 407: \tAverage Loss:  2.072999267578125\t ACC train:  0.958\t ACC test:  0.9533333333333334\n",
      "\tEpoch 408: \tAverage Loss:  2.0811318359375\t ACC train:  0.968\t ACC test:  0.9533333333333334\n",
      "\tEpoch 409: \tAverage Loss:  2.07005908203125\t ACC train:  0.964\t ACC test:  0.96\n",
      "\tEpoch 410: \tAverage Loss:  2.065855712890625\t ACC train:  0.956\t ACC test:  0.9577777777777777\n",
      "\tEpoch 411: \tAverage Loss:  2.07321337890625\t ACC train:  0.97\t ACC test:  0.9577777777777777\n",
      "\tEpoch 412: \tAverage Loss:  2.0700673828125\t ACC train:  0.958\t ACC test:  0.9711111111111111\n",
      "\tEpoch 413: \tAverage Loss:  2.075593994140625\t ACC train:  0.968\t ACC test:  0.9577777777777777\n",
      "\tEpoch 414: \tAverage Loss:  2.06587841796875\t ACC train:  0.966\t ACC test:  0.9577777777777777\n",
      "\tEpoch 415: \tAverage Loss:  2.066867431640625\t ACC train:  0.962\t ACC test:  0.96\n",
      "\tEpoch 416: \tAverage Loss:  2.05577734375\t ACC train:  0.964\t ACC test:  0.9711111111111111\n",
      "\tEpoch 417: \tAverage Loss:  2.058543212890625\t ACC train:  0.966\t ACC test:  0.96\n",
      "\tEpoch 418: \tAverage Loss:  2.057404541015625\t ACC train:  0.966\t ACC test:  0.9577777777777777\n",
      "\tEpoch 419: \tAverage Loss:  2.05556787109375\t ACC train:  0.956\t ACC test:  0.9577777777777777\n",
      "\tEpoch 420: \tAverage Loss:  2.056605712890625\t ACC train:  0.964\t ACC test:  0.96\n",
      "\tEpoch 421: \tAverage Loss:  2.04740234375\t ACC train:  0.968\t ACC test:  0.9577777777777777\n",
      "\tEpoch 422: \tAverage Loss:  2.04277685546875\t ACC train:  0.974\t ACC test:  0.9622222222222222\n",
      "\tEpoch 423: \tAverage Loss:  2.0447935791015626\t ACC train:  0.97\t ACC test:  0.9555555555555556\n",
      "\tEpoch 424: \tAverage Loss:  2.05393310546875\t ACC train:  0.97\t ACC test:  0.9644444444444444\n",
      "\tEpoch 425: \tAverage Loss:  2.03963427734375\t ACC train:  0.958\t ACC test:  0.9555555555555556\n",
      "\tEpoch 426: \tAverage Loss:  2.0435396728515625\t ACC train:  0.964\t ACC test:  0.9555555555555556\n",
      "\tEpoch 427: \tAverage Loss:  2.0395953369140627\t ACC train:  0.972\t ACC test:  0.9555555555555556\n",
      "\tEpoch 428: \tAverage Loss:  2.030343505859375\t ACC train:  0.958\t ACC test:  0.9555555555555556\n",
      "\tEpoch 429: \tAverage Loss:  2.03222802734375\t ACC train:  0.968\t ACC test:  0.9577777777777777\n",
      "\tEpoch 430: \tAverage Loss:  2.022111083984375\t ACC train:  0.97\t ACC test:  0.96\n",
      "\tEpoch 431: \tAverage Loss:  2.0289986572265626\t ACC train:  0.97\t ACC test:  0.9644444444444444\n",
      "\tEpoch 432: \tAverage Loss:  2.0280859375\t ACC train:  0.97\t ACC test:  0.9577777777777777\n",
      "\tEpoch 433: \tAverage Loss:  2.0227567138671874\t ACC train:  0.97\t ACC test:  0.96\n",
      "\tEpoch 434: \tAverage Loss:  2.029102783203125\t ACC train:  0.968\t ACC test:  0.9644444444444444\n",
      "\tEpoch 435: \tAverage Loss:  2.029197509765625\t ACC train:  0.956\t ACC test:  0.9533333333333334\n",
      "\tEpoch 436: \tAverage Loss:  2.022078369140625\t ACC train:  0.97\t ACC test:  0.9533333333333334\n",
      "\tEpoch 437: \tAverage Loss:  2.0153780517578124\t ACC train:  0.964\t ACC test:  0.9511111111111111\n",
      "\tEpoch 438: \tAverage Loss:  2.01058740234375\t ACC train:  0.976\t ACC test:  0.9555555555555556\n",
      "\tEpoch 439: \tAverage Loss:  2.008982666015625\t ACC train:  0.97\t ACC test:  0.9555555555555556\n",
      "\tEpoch 440: \tAverage Loss:  2.0077236328125\t ACC train:  0.968\t ACC test:  0.9577777777777777\n",
      "\tEpoch 441: \tAverage Loss:  2.00160205078125\t ACC train:  0.968\t ACC test:  0.96\n",
      "\tEpoch 442: \tAverage Loss:  2.006753173828125\t ACC train:  0.976\t ACC test:  0.96\n",
      "\tEpoch 443: \tAverage Loss:  2.0058424072265626\t ACC train:  0.972\t ACC test:  0.96\n",
      "\tEpoch 444: \tAverage Loss:  1.995860595703125\t ACC train:  0.972\t ACC test:  0.96\n",
      "\tEpoch 445: \tAverage Loss:  1.997759033203125\t ACC train:  0.972\t ACC test:  0.9577777777777777\n",
      "\tEpoch 446: \tAverage Loss:  1.991535888671875\t ACC train:  0.974\t ACC test:  0.9555555555555556\n",
      "\tEpoch 447: \tAverage Loss:  1.98969189453125\t ACC train:  0.966\t ACC test:  0.9555555555555556\n",
      "\tEpoch 448: \tAverage Loss:  1.995083740234375\t ACC train:  0.968\t ACC test:  0.9533333333333334\n",
      "\tEpoch 449: \tAverage Loss:  1.9987674560546875\t ACC train:  0.972\t ACC test:  0.9622222222222222\n",
      "\tEpoch 450: \tAverage Loss:  1.9953555908203124\t ACC train:  0.968\t ACC test:  0.96\n",
      "\tEpoch 451: \tAverage Loss:  1.988225830078125\t ACC train:  0.966\t ACC test:  0.9533333333333334\n",
      "\tEpoch 452: \tAverage Loss:  1.98019677734375\t ACC train:  0.968\t ACC test:  0.9577777777777777\n",
      "\tEpoch 453: \tAverage Loss:  1.9852247314453124\t ACC train:  0.972\t ACC test:  0.9577777777777777\n",
      "\tEpoch 454: \tAverage Loss:  1.9818818359375\t ACC train:  0.966\t ACC test:  0.9577777777777777\n",
      "\tEpoch 455: \tAverage Loss:  1.976069580078125\t ACC train:  0.972\t ACC test:  0.9644444444444444\n",
      "\tEpoch 456: \tAverage Loss:  1.976256103515625\t ACC train:  0.962\t ACC test:  0.9555555555555556\n",
      "\tEpoch 457: \tAverage Loss:  1.974079345703125\t ACC train:  0.97\t ACC test:  0.9622222222222222\n",
      "\tEpoch 458: \tAverage Loss:  1.9758062744140625\t ACC train:  0.968\t ACC test:  0.9644444444444444\n",
      "\tEpoch 459: \tAverage Loss:  1.9646287841796874\t ACC train:  0.966\t ACC test:  0.9555555555555556\n",
      "\tEpoch 460: \tAverage Loss:  1.967806884765625\t ACC train:  0.97\t ACC test:  0.9533333333333334\n",
      "\tEpoch 461: \tAverage Loss:  1.965845703125\t ACC train:  0.966\t ACC test:  0.9511111111111111\n",
      "\tEpoch 462: \tAverage Loss:  1.95692041015625\t ACC train:  0.97\t ACC test:  0.9622222222222222\n",
      "\tEpoch 463: \tAverage Loss:  1.948589111328125\t ACC train:  0.966\t ACC test:  0.9577777777777777\n",
      "\tEpoch 464: \tAverage Loss:  1.9549327392578124\t ACC train:  0.966\t ACC test:  0.9555555555555556\n",
      "\tEpoch 465: \tAverage Loss:  1.95801513671875\t ACC train:  0.962\t ACC test:  0.9577777777777777\n",
      "\tEpoch 466: \tAverage Loss:  1.95352001953125\t ACC train:  0.966\t ACC test:  0.96\n",
      "\tEpoch 467: \tAverage Loss:  1.9523560791015624\t ACC train:  0.96\t ACC test:  0.9622222222222222\n",
      "\tEpoch 468: \tAverage Loss:  1.940885498046875\t ACC train:  0.968\t ACC test:  0.96\n",
      "\tEpoch 469: \tAverage Loss:  1.9484019775390624\t ACC train:  0.974\t ACC test:  0.9533333333333334\n",
      "\tEpoch 470: \tAverage Loss:  1.9382518310546875\t ACC train:  0.968\t ACC test:  0.9577777777777777\n",
      "\tEpoch 471: \tAverage Loss:  1.948150390625\t ACC train:  0.974\t ACC test:  0.9488888888888889\n",
      "\tEpoch 472: \tAverage Loss:  1.9374224853515625\t ACC train:  0.962\t ACC test:  0.9555555555555556\n",
      "\tEpoch 473: \tAverage Loss:  1.937844970703125\t ACC train:  0.974\t ACC test:  0.9555555555555556\n",
      "\tEpoch 474: \tAverage Loss:  1.9347403564453125\t ACC train:  0.974\t ACC test:  0.9555555555555556\n",
      "\tEpoch 475: \tAverage Loss:  1.9270865478515624\t ACC train:  0.974\t ACC test:  0.9488888888888889\n",
      "\tEpoch 476: \tAverage Loss:  1.93235693359375\t ACC train:  0.974\t ACC test:  0.9555555555555556\n",
      "\tEpoch 477: \tAverage Loss:  1.929263427734375\t ACC train:  0.974\t ACC test:  0.96\n",
      "\tEpoch 478: \tAverage Loss:  1.921212646484375\t ACC train:  0.968\t ACC test:  0.9622222222222222\n",
      "\tEpoch 479: \tAverage Loss:  1.9293397216796875\t ACC train:  0.974\t ACC test:  0.9466666666666667\n",
      "\tEpoch 480: \tAverage Loss:  1.920603515625\t ACC train:  0.98\t ACC test:  0.9622222222222222\n",
      "\tEpoch 481: \tAverage Loss:  1.9180169677734376\t ACC train:  0.968\t ACC test:  0.9622222222222222\n",
      "\tEpoch 482: \tAverage Loss:  1.9244110107421875\t ACC train:  0.966\t ACC test:  0.96\n",
      "\tEpoch 483: \tAverage Loss:  1.9186314697265625\t ACC train:  0.974\t ACC test:  0.96\n",
      "\tEpoch 484: \tAverage Loss:  1.9072967529296876\t ACC train:  0.97\t ACC test:  0.9577777777777777\n",
      "\tEpoch 485: \tAverage Loss:  1.9182200927734374\t ACC train:  0.966\t ACC test:  0.9666666666666667\n",
      "\tEpoch 486: \tAverage Loss:  1.9088621826171874\t ACC train:  0.97\t ACC test:  0.96\n",
      "\tEpoch 487: \tAverage Loss:  1.907142333984375\t ACC train:  0.97\t ACC test:  0.9555555555555556\n",
      "\tEpoch 488: \tAverage Loss:  1.9099490966796875\t ACC train:  0.968\t ACC test:  0.9622222222222222\n",
      "\tEpoch 489: \tAverage Loss:  1.905904052734375\t ACC train:  0.98\t ACC test:  0.9577777777777777\n",
      "\tEpoch 490: \tAverage Loss:  1.90344970703125\t ACC train:  0.972\t ACC test:  0.9622222222222222\n",
      "\tEpoch 491: \tAverage Loss:  1.90313232421875\t ACC train:  0.978\t ACC test:  0.96\n",
      "\tEpoch 492: \tAverage Loss:  1.895816162109375\t ACC train:  0.97\t ACC test:  0.9555555555555556\n",
      "\tEpoch 493: \tAverage Loss:  1.893976806640625\t ACC train:  0.974\t ACC test:  0.96\n",
      "\tEpoch 494: \tAverage Loss:  1.9021064453125\t ACC train:  0.97\t ACC test:  0.9555555555555556\n",
      "\tEpoch 495: \tAverage Loss:  1.8984814453125\t ACC train:  0.972\t ACC test:  0.9577777777777777\n",
      "\tEpoch 496: \tAverage Loss:  1.8888702392578125\t ACC train:  0.974\t ACC test:  0.9644444444444444\n",
      "\tEpoch 497: \tAverage Loss:  1.8857984619140624\t ACC train:  0.972\t ACC test:  0.96\n",
      "\tEpoch 498: \tAverage Loss:  1.8859930419921875\t ACC train:  0.976\t ACC test:  0.9644444444444444\n",
      "\tEpoch 499: \tAverage Loss:  1.8879324951171874\t ACC train:  0.966\t ACC test:  0.9511111111111111\n",
      "\tEpoch 500: \tAverage Loss:  1.88587939453125\t ACC train:  0.976\t ACC test:  0.9533333333333334\n",
      "\tEpoch 501: \tAverage Loss:  1.8814248046875\t ACC train:  0.97\t ACC test:  0.9622222222222222\n",
      "\tEpoch 502: \tAverage Loss:  1.887427001953125\t ACC train:  0.976\t ACC test:  0.9577777777777777\n",
      "\tEpoch 503: \tAverage Loss:  1.890993408203125\t ACC train:  0.964\t ACC test:  0.9555555555555556\n",
      "\tEpoch 504: \tAverage Loss:  1.8787093505859376\t ACC train:  0.966\t ACC test:  0.96\n",
      "\tEpoch 505: \tAverage Loss:  1.8794735107421876\t ACC train:  0.972\t ACC test:  0.9622222222222222\n",
      "\tEpoch 506: \tAverage Loss:  1.8776866455078125\t ACC train:  0.97\t ACC test:  0.9622222222222222\n",
      "\tEpoch 507: \tAverage Loss:  1.87698779296875\t ACC train:  0.98\t ACC test:  0.9577777777777777\n",
      "\tEpoch 508: \tAverage Loss:  1.8789754638671874\t ACC train:  0.968\t ACC test:  0.9555555555555556\n",
      "\tEpoch 509: \tAverage Loss:  1.8688140869140626\t ACC train:  0.976\t ACC test:  0.9622222222222222\n",
      "\tEpoch 510: \tAverage Loss:  1.873087890625\t ACC train:  0.97\t ACC test:  0.9555555555555556\n",
      "\tEpoch 511: \tAverage Loss:  1.870228759765625\t ACC train:  0.976\t ACC test:  0.9622222222222222\n",
      "\tEpoch 512: \tAverage Loss:  1.8612449951171874\t ACC train:  0.976\t ACC test:  0.96\n",
      "\tEpoch 513: \tAverage Loss:  1.86077978515625\t ACC train:  0.972\t ACC test:  0.9555555555555556\n",
      "\tEpoch 514: \tAverage Loss:  1.862847900390625\t ACC train:  0.976\t ACC test:  0.9622222222222222\n",
      "\tEpoch 515: \tAverage Loss:  1.8675899658203126\t ACC train:  0.976\t ACC test:  0.9555555555555556\n",
      "\tEpoch 516: \tAverage Loss:  1.8656890869140625\t ACC train:  0.98\t ACC test:  0.9577777777777777\n",
      "\tEpoch 517: \tAverage Loss:  1.8613275146484376\t ACC train:  0.968\t ACC test:  0.9622222222222222\n",
      "\tEpoch 518: \tAverage Loss:  1.8664786376953124\t ACC train:  0.976\t ACC test:  0.9622222222222222\n",
      "\tEpoch 519: \tAverage Loss:  1.8625201416015624\t ACC train:  0.976\t ACC test:  0.96\n",
      "\tEpoch 520: \tAverage Loss:  1.85694580078125\t ACC train:  0.976\t ACC test:  0.9622222222222222\n",
      "\tEpoch 521: \tAverage Loss:  1.862095458984375\t ACC train:  0.972\t ACC test:  0.9577777777777777\n",
      "\tEpoch 522: \tAverage Loss:  1.85799609375\t ACC train:  0.974\t ACC test:  0.9622222222222222\n",
      "\tEpoch 523: \tAverage Loss:  1.8561375732421874\t ACC train:  0.978\t ACC test:  0.9622222222222222\n",
      "\tEpoch 524: \tAverage Loss:  1.8617752685546876\t ACC train:  0.978\t ACC test:  0.9533333333333334\n",
      "\tEpoch 525: \tAverage Loss:  1.8491708984375\t ACC train:  0.972\t ACC test:  0.9622222222222222\n",
      "\tEpoch 526: \tAverage Loss:  1.85635009765625\t ACC train:  0.978\t ACC test:  0.96\n",
      "\tEpoch 527: \tAverage Loss:  1.8477203369140625\t ACC train:  0.982\t ACC test:  0.9533333333333334\n",
      "\tEpoch 528: \tAverage Loss:  1.851796142578125\t ACC train:  0.972\t ACC test:  0.9644444444444444\n",
      "\tEpoch 529: \tAverage Loss:  1.848980712890625\t ACC train:  0.98\t ACC test:  0.9577777777777777\n",
      "\tEpoch 530: \tAverage Loss:  1.847759765625\t ACC train:  0.974\t ACC test:  0.9622222222222222\n",
      "\tEpoch 531: \tAverage Loss:  1.8345072021484374\t ACC train:  0.98\t ACC test:  0.9622222222222222\n",
      "\tEpoch 532: \tAverage Loss:  1.8382462158203126\t ACC train:  0.976\t ACC test:  0.9644444444444444\n",
      "\tEpoch 533: \tAverage Loss:  1.83588037109375\t ACC train:  0.98\t ACC test:  0.9622222222222222\n",
      "\tEpoch 534: \tAverage Loss:  1.8413349609375\t ACC train:  0.978\t ACC test:  0.9555555555555556\n",
      "\tEpoch 535: \tAverage Loss:  1.835417724609375\t ACC train:  0.986\t ACC test:  0.9622222222222222\n",
      "\tEpoch 536: \tAverage Loss:  1.8391590576171875\t ACC train:  0.982\t ACC test:  0.9644444444444444\n",
      "\tEpoch 537: \tAverage Loss:  1.84067578125\t ACC train:  0.976\t ACC test:  0.9555555555555556\n",
      "\tEpoch 538: \tAverage Loss:  1.8303536376953125\t ACC train:  0.98\t ACC test:  0.9644444444444444\n",
      "\tEpoch 539: \tAverage Loss:  1.8367706298828126\t ACC train:  0.984\t ACC test:  0.9622222222222222\n",
      "\tEpoch 540: \tAverage Loss:  1.82793896484375\t ACC train:  0.98\t ACC test:  0.9644444444444444\n",
      "\tEpoch 541: \tAverage Loss:  1.8277720947265625\t ACC train:  0.986\t ACC test:  0.9622222222222222\n",
      "\tEpoch 542: \tAverage Loss:  1.8312301025390625\t ACC train:  0.982\t ACC test:  0.9622222222222222\n",
      "\tEpoch 543: \tAverage Loss:  1.8330657958984375\t ACC train:  0.976\t ACC test:  0.9577777777777777\n",
      "\tEpoch 544: \tAverage Loss:  1.8308944091796875\t ACC train:  0.98\t ACC test:  0.9644444444444444\n",
      "\tEpoch 545: \tAverage Loss:  1.8315196533203124\t ACC train:  0.98\t ACC test:  0.9622222222222222\n",
      "\tEpoch 546: \tAverage Loss:  1.8245772705078125\t ACC train:  0.98\t ACC test:  0.96\n",
      "\tEpoch 547: \tAverage Loss:  1.8311005859375\t ACC train:  0.984\t ACC test:  0.9666666666666667\n",
      "\tEpoch 548: \tAverage Loss:  1.823080810546875\t ACC train:  0.982\t ACC test:  0.96\n",
      "\tEpoch 549: \tAverage Loss:  1.821362060546875\t ACC train:  0.978\t ACC test:  0.96\n",
      "\tEpoch 550: \tAverage Loss:  1.8255284423828124\t ACC train:  0.982\t ACC test:  0.96\n",
      "\tEpoch 551: \tAverage Loss:  1.8187945556640626\t ACC train:  0.978\t ACC test:  0.9622222222222222\n",
      "\tEpoch 552: \tAverage Loss:  1.815902587890625\t ACC train:  0.984\t ACC test:  0.9622222222222222\n",
      "\tEpoch 553: \tAverage Loss:  1.818586181640625\t ACC train:  0.986\t ACC test:  0.9577777777777777\n",
      "\tEpoch 554: \tAverage Loss:  1.8193868408203124\t ACC train:  0.98\t ACC test:  0.96\n",
      "\tEpoch 555: \tAverage Loss:  1.8153831787109376\t ACC train:  0.982\t ACC test:  0.9577777777777777\n",
      "\tEpoch 556: \tAverage Loss:  1.8110626220703125\t ACC train:  0.972\t ACC test:  0.9666666666666667\n",
      "\tEpoch 557: \tAverage Loss:  1.8199501953125\t ACC train:  0.982\t ACC test:  0.9622222222222222\n",
      "\tEpoch 558: \tAverage Loss:  1.815557373046875\t ACC train:  0.986\t ACC test:  0.9622222222222222\n",
      "\tEpoch 559: \tAverage Loss:  1.8175894775390624\t ACC train:  0.988\t ACC test:  0.9577777777777777\n",
      "\tEpoch 560: \tAverage Loss:  1.8169471435546876\t ACC train:  0.986\t ACC test:  0.96\n",
      "\tEpoch 561: \tAverage Loss:  1.811970947265625\t ACC train:  0.986\t ACC test:  0.9622222222222222\n",
      "\tEpoch 562: \tAverage Loss:  1.8175196533203124\t ACC train:  0.986\t ACC test:  0.9688888888888889\n",
      "\tEpoch 563: \tAverage Loss:  1.809326904296875\t ACC train:  0.986\t ACC test:  0.9644444444444444\n",
      "\tEpoch 564: \tAverage Loss:  1.8125692138671874\t ACC train:  0.982\t ACC test:  0.9622222222222222\n",
      "\tEpoch 565: \tAverage Loss:  1.8116080322265624\t ACC train:  0.984\t ACC test:  0.9577777777777777\n",
      "\tEpoch 566: \tAverage Loss:  1.805701171875\t ACC train:  0.98\t ACC test:  0.9622222222222222\n",
      "\tEpoch 567: \tAverage Loss:  1.8034781494140626\t ACC train:  0.98\t ACC test:  0.9577777777777777\n",
      "\tEpoch 568: \tAverage Loss:  1.8043394775390624\t ACC train:  0.976\t ACC test:  0.9622222222222222\n",
      "\tEpoch 569: \tAverage Loss:  1.8003385009765625\t ACC train:  0.976\t ACC test:  0.9555555555555556\n",
      "\tEpoch 570: \tAverage Loss:  1.8050557861328125\t ACC train:  0.988\t ACC test:  0.9577777777777777\n",
      "\tEpoch 571: \tAverage Loss:  1.8012255859375\t ACC train:  0.982\t ACC test:  0.9555555555555556\n",
      "\tEpoch 572: \tAverage Loss:  1.809326416015625\t ACC train:  0.982\t ACC test:  0.9622222222222222\n",
      "\tEpoch 573: \tAverage Loss:  1.80074462890625\t ACC train:  0.982\t ACC test:  0.9644444444444444\n",
      "\tEpoch 574: \tAverage Loss:  1.8045211181640626\t ACC train:  0.98\t ACC test:  0.9622222222222222\n",
      "\tEpoch 575: \tAverage Loss:  1.7963673095703125\t ACC train:  0.99\t ACC test:  0.9666666666666667\n",
      "\tEpoch 576: \tAverage Loss:  1.79742919921875\t ACC train:  0.986\t ACC test:  0.96\n",
      "\tEpoch 577: \tAverage Loss:  1.7985850830078125\t ACC train:  0.978\t ACC test:  0.9577777777777777\n",
      "\tEpoch 578: \tAverage Loss:  1.800981201171875\t ACC train:  0.986\t ACC test:  0.9688888888888889\n",
      "\tEpoch 579: \tAverage Loss:  1.7991185302734376\t ACC train:  0.986\t ACC test:  0.9577777777777777\n",
      "\tEpoch 580: \tAverage Loss:  1.7994722900390625\t ACC train:  0.982\t ACC test:  0.96\n",
      "\tEpoch 581: \tAverage Loss:  1.791320068359375\t ACC train:  0.986\t ACC test:  0.9622222222222222\n",
      "\tEpoch 582: \tAverage Loss:  1.794553955078125\t ACC train:  0.984\t ACC test:  0.9666666666666667\n",
      "\tEpoch 583: \tAverage Loss:  1.7925567626953125\t ACC train:  0.982\t ACC test:  0.9644444444444444\n",
      "\tEpoch 584: \tAverage Loss:  1.7900709228515626\t ACC train:  0.988\t ACC test:  0.9622222222222222\n",
      "\tEpoch 585: \tAverage Loss:  1.7854171142578126\t ACC train:  0.984\t ACC test:  0.9644444444444444\n",
      "\tEpoch 586: \tAverage Loss:  1.791286376953125\t ACC train:  0.984\t ACC test:  0.96\n",
      "\tEpoch 587: \tAverage Loss:  1.7952607421875\t ACC train:  0.984\t ACC test:  0.96\n",
      "\tEpoch 588: \tAverage Loss:  1.783511474609375\t ACC train:  0.99\t ACC test:  0.9577777777777777\n",
      "\tEpoch 589: \tAverage Loss:  1.79401123046875\t ACC train:  0.988\t ACC test:  0.9622222222222222\n",
      "\tEpoch 590: \tAverage Loss:  1.790646240234375\t ACC train:  0.986\t ACC test:  0.9666666666666667\n",
      "\tEpoch 591: \tAverage Loss:  1.7857783203125\t ACC train:  0.986\t ACC test:  0.9644444444444444\n",
      "\tEpoch 592: \tAverage Loss:  1.784107177734375\t ACC train:  0.982\t ACC test:  0.9644444444444444\n",
      "\tEpoch 593: \tAverage Loss:  1.7832877197265624\t ACC train:  0.99\t ACC test:  0.9666666666666667\n",
      "\tEpoch 594: \tAverage Loss:  1.783373291015625\t ACC train:  0.986\t ACC test:  0.96\n",
      "\tEpoch 595: \tAverage Loss:  1.7836190185546874\t ACC train:  0.986\t ACC test:  0.9577777777777777\n",
      "\tEpoch 596: \tAverage Loss:  1.7861944580078124\t ACC train:  0.99\t ACC test:  0.9666666666666667\n",
      "\tEpoch 597: \tAverage Loss:  1.7787158203125\t ACC train:  0.986\t ACC test:  0.9622222222222222\n",
      "\tEpoch 598: \tAverage Loss:  1.777595703125\t ACC train:  0.99\t ACC test:  0.9555555555555556\n",
      "\tEpoch 599: \tAverage Loss:  1.7801434326171874\t ACC train:  0.984\t ACC test:  0.9644444444444444\n",
      "\tEpoch 600: \tAverage Loss:  1.77978515625\t ACC train:  0.982\t ACC test:  0.9644444444444444\n",
      "\tEpoch 601: \tAverage Loss:  1.779029052734375\t ACC train:  0.986\t ACC test:  0.9622222222222222\n",
      "\tEpoch 602: \tAverage Loss:  1.7784554443359375\t ACC train:  0.984\t ACC test:  0.9711111111111111\n",
      "\tEpoch 603: \tAverage Loss:  1.777236083984375\t ACC train:  0.988\t ACC test:  0.96\n",
      "\tEpoch 604: \tAverage Loss:  1.7806153564453124\t ACC train:  0.982\t ACC test:  0.9666666666666667\n",
      "\tEpoch 605: \tAverage Loss:  1.7750792236328126\t ACC train:  0.99\t ACC test:  0.9622222222222222\n",
      "\tEpoch 606: \tAverage Loss:  1.7728411865234375\t ACC train:  0.992\t ACC test:  0.9577777777777777\n",
      "\tEpoch 607: \tAverage Loss:  1.770251953125\t ACC train:  0.988\t ACC test:  0.9644444444444444\n",
      "\tEpoch 608: \tAverage Loss:  1.7740439453125\t ACC train:  0.98\t ACC test:  0.9511111111111111\n",
      "\tEpoch 609: \tAverage Loss:  1.7734259033203126\t ACC train:  0.99\t ACC test:  0.9577777777777777\n",
      "\tEpoch 610: \tAverage Loss:  1.777982421875\t ACC train:  0.99\t ACC test:  0.9577777777777777\n",
      "\tEpoch 611: \tAverage Loss:  1.7734825439453126\t ACC train:  0.99\t ACC test:  0.9577777777777777\n",
      "\tEpoch 612: \tAverage Loss:  1.7715673828125\t ACC train:  0.99\t ACC test:  0.9644444444444444\n",
      "\tEpoch 613: \tAverage Loss:  1.76961376953125\t ACC train:  0.988\t ACC test:  0.9666666666666667\n",
      "\tEpoch 614: \tAverage Loss:  1.76241943359375\t ACC train:  0.988\t ACC test:  0.9644444444444444\n",
      "\tEpoch 615: \tAverage Loss:  1.76869580078125\t ACC train:  0.99\t ACC test:  0.9622222222222222\n",
      "\tEpoch 616: \tAverage Loss:  1.769077392578125\t ACC train:  0.994\t ACC test:  0.9622222222222222\n",
      "\tEpoch 617: \tAverage Loss:  1.7652706298828125\t ACC train:  0.992\t ACC test:  0.9622222222222222\n",
      "\tEpoch 618: \tAverage Loss:  1.769115478515625\t ACC train:  0.992\t ACC test:  0.9666666666666667\n",
      "\tEpoch 619: \tAverage Loss:  1.7659407958984374\t ACC train:  0.984\t ACC test:  0.9555555555555556\n",
      "\tEpoch 620: \tAverage Loss:  1.7648773193359375\t ACC train:  0.988\t ACC test:  0.9533333333333334\n",
      "\tEpoch 621: \tAverage Loss:  1.7638653564453124\t ACC train:  0.98\t ACC test:  0.9666666666666667\n",
      "\tEpoch 622: \tAverage Loss:  1.7716207275390625\t ACC train:  0.984\t ACC test:  0.9666666666666667\n",
      "\tEpoch 623: \tAverage Loss:  1.7638543701171876\t ACC train:  0.986\t ACC test:  0.9688888888888889\n",
      "\tEpoch 624: \tAverage Loss:  1.762715576171875\t ACC train:  0.99\t ACC test:  0.9666666666666667\n",
      "\tEpoch 625: \tAverage Loss:  1.7653082275390626\t ACC train:  0.988\t ACC test:  0.9622222222222222\n",
      "\tEpoch 626: \tAverage Loss:  1.7632333984375\t ACC train:  0.988\t ACC test:  0.9644444444444444\n",
      "\tEpoch 627: \tAverage Loss:  1.7601981201171875\t ACC train:  0.986\t ACC test:  0.96\n",
      "\tEpoch 628: \tAverage Loss:  1.7644166259765626\t ACC train:  0.992\t ACC test:  0.9622222222222222\n",
      "\tEpoch 629: \tAverage Loss:  1.763688720703125\t ACC train:  0.988\t ACC test:  0.9622222222222222\n",
      "\tEpoch 630: \tAverage Loss:  1.7578211669921875\t ACC train:  0.99\t ACC test:  0.96\n",
      "\tEpoch 631: \tAverage Loss:  1.755909423828125\t ACC train:  0.992\t ACC test:  0.9644444444444444\n",
      "\tEpoch 632: \tAverage Loss:  1.756286865234375\t ACC train:  0.986\t ACC test:  0.96\n",
      "\tEpoch 633: \tAverage Loss:  1.7575582275390624\t ACC train:  0.992\t ACC test:  0.9622222222222222\n",
      "\tEpoch 634: \tAverage Loss:  1.75650927734375\t ACC train:  0.992\t ACC test:  0.96\n",
      "\tEpoch 635: \tAverage Loss:  1.7582637939453125\t ACC train:  0.992\t ACC test:  0.9666666666666667\n",
      "\tEpoch 636: \tAverage Loss:  1.7590609130859376\t ACC train:  0.988\t ACC test:  0.9644444444444444\n",
      "\tEpoch 637: \tAverage Loss:  1.758517333984375\t ACC train:  0.99\t ACC test:  0.9644444444444444\n",
      "\tEpoch 638: \tAverage Loss:  1.76222119140625\t ACC train:  0.988\t ACC test:  0.9644444444444444\n",
      "\tEpoch 639: \tAverage Loss:  1.7539599609375\t ACC train:  0.988\t ACC test:  0.9688888888888889\n",
      "\tEpoch 640: \tAverage Loss:  1.7550574951171876\t ACC train:  0.99\t ACC test:  0.9644444444444444\n",
      "\tEpoch 641: \tAverage Loss:  1.7573182373046874\t ACC train:  0.988\t ACC test:  0.9622222222222222\n",
      "\tEpoch 642: \tAverage Loss:  1.755908447265625\t ACC train:  0.994\t ACC test:  0.9711111111111111\n",
      "\tEpoch 643: \tAverage Loss:  1.7550511474609376\t ACC train:  0.994\t ACC test:  0.96\n",
      "\tEpoch 644: \tAverage Loss:  1.750749267578125\t ACC train:  0.994\t ACC test:  0.9711111111111111\n",
      "\tEpoch 645: \tAverage Loss:  1.7545634765625\t ACC train:  0.99\t ACC test:  0.9711111111111111\n",
      "\tEpoch 646: \tAverage Loss:  1.7532054443359375\t ACC train:  0.992\t ACC test:  0.9666666666666667\n",
      "\tEpoch 647: \tAverage Loss:  1.7491239013671875\t ACC train:  0.992\t ACC test:  0.9644444444444444\n",
      "\tEpoch 648: \tAverage Loss:  1.7488206787109375\t ACC train:  0.99\t ACC test:  0.9533333333333334\n",
      "\tEpoch 649: \tAverage Loss:  1.748958251953125\t ACC train:  0.988\t ACC test:  0.9644444444444444\n",
      "\tEpoch 650: \tAverage Loss:  1.7486995849609375\t ACC train:  0.994\t ACC test:  0.9666666666666667\n",
      "\tEpoch 651: \tAverage Loss:  1.7492728271484375\t ACC train:  0.994\t ACC test:  0.96\n",
      "\tEpoch 652: \tAverage Loss:  1.747011474609375\t ACC train:  0.992\t ACC test:  0.9622222222222222\n",
      "\tEpoch 653: \tAverage Loss:  1.746602294921875\t ACC train:  0.992\t ACC test:  0.9644444444444444\n",
      "\tEpoch 654: \tAverage Loss:  1.7480628662109374\t ACC train:  0.992\t ACC test:  0.9666666666666667\n",
      "\tEpoch 655: \tAverage Loss:  1.7491546630859376\t ACC train:  0.992\t ACC test:  0.9555555555555556\n",
      "\tEpoch 656: \tAverage Loss:  1.74563330078125\t ACC train:  0.996\t ACC test:  0.9577777777777777\n",
      "\tEpoch 657: \tAverage Loss:  1.7450799560546875\t ACC train:  0.992\t ACC test:  0.9711111111111111\n",
      "\tEpoch 658: \tAverage Loss:  1.745851806640625\t ACC train:  0.99\t ACC test:  0.9644444444444444\n",
      "\tEpoch 659: \tAverage Loss:  1.74535498046875\t ACC train:  0.99\t ACC test:  0.9688888888888889\n",
      "\tEpoch 660: \tAverage Loss:  1.7458818359375\t ACC train:  0.992\t ACC test:  0.9711111111111111\n",
      "\tEpoch 661: \tAverage Loss:  1.7435982666015626\t ACC train:  0.992\t ACC test:  0.9711111111111111\n",
      "\tEpoch 662: \tAverage Loss:  1.743418212890625\t ACC train:  0.992\t ACC test:  0.9666666666666667\n",
      "\tEpoch 663: \tAverage Loss:  1.7430518798828125\t ACC train:  0.988\t ACC test:  0.9666666666666667\n",
      "\tEpoch 664: \tAverage Loss:  1.7408594970703124\t ACC train:  0.992\t ACC test:  0.9666666666666667\n",
      "\tEpoch 665: \tAverage Loss:  1.74433154296875\t ACC train:  0.992\t ACC test:  0.9666666666666667\n",
      "\tEpoch 666: \tAverage Loss:  1.7393641357421874\t ACC train:  0.992\t ACC test:  0.96\n",
      "\tEpoch 667: \tAverage Loss:  1.7378389892578125\t ACC train:  0.996\t ACC test:  0.9555555555555556\n",
      "\tEpoch 668: \tAverage Loss:  1.741156494140625\t ACC train:  0.994\t ACC test:  0.9644444444444444\n",
      "\tEpoch 669: \tAverage Loss:  1.7389189453125\t ACC train:  0.99\t ACC test:  0.9666666666666667\n",
      "\tEpoch 670: \tAverage Loss:  1.74487451171875\t ACC train:  0.988\t ACC test:  0.9666666666666667\n",
      "\tEpoch 671: \tAverage Loss:  1.7406962890625\t ACC train:  0.994\t ACC test:  0.96\n",
      "\tEpoch 672: \tAverage Loss:  1.7428197021484375\t ACC train:  0.994\t ACC test:  0.9644444444444444\n",
      "\tEpoch 673: \tAverage Loss:  1.740207275390625\t ACC train:  0.986\t ACC test:  0.9711111111111111\n",
      "\tEpoch 674: \tAverage Loss:  1.738401123046875\t ACC train:  0.994\t ACC test:  0.9666666666666667\n",
      "\tEpoch 675: \tAverage Loss:  1.73766796875\t ACC train:  0.996\t ACC test:  0.9666666666666667\n",
      "\tEpoch 676: \tAverage Loss:  1.7367799072265624\t ACC train:  0.996\t ACC test:  0.9711111111111111\n",
      "\tEpoch 677: \tAverage Loss:  1.7364169921875\t ACC train:  0.992\t ACC test:  0.9688888888888889\n",
      "\tEpoch 678: \tAverage Loss:  1.7351151123046875\t ACC train:  0.996\t ACC test:  0.9622222222222222\n",
      "\tEpoch 679: \tAverage Loss:  1.73470361328125\t ACC train:  0.994\t ACC test:  0.9688888888888889\n",
      "\tEpoch 680: \tAverage Loss:  1.7344305419921875\t ACC train:  0.99\t ACC test:  0.9711111111111111\n",
      "\tEpoch 681: \tAverage Loss:  1.73270849609375\t ACC train:  0.994\t ACC test:  0.9666666666666667\n",
      "\tEpoch 682: \tAverage Loss:  1.7352728271484374\t ACC train:  0.996\t ACC test:  0.9622222222222222\n",
      "\tEpoch 683: \tAverage Loss:  1.7352119140625\t ACC train:  0.996\t ACC test:  0.9711111111111111\n",
      "\tEpoch 684: \tAverage Loss:  1.7344478759765625\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 685: \tAverage Loss:  1.7360400390625\t ACC train:  0.998\t ACC test:  0.9644444444444444\n",
      "\tEpoch 686: \tAverage Loss:  1.7329873046875\t ACC train:  0.994\t ACC test:  0.9711111111111111\n",
      "\tEpoch 687: \tAverage Loss:  1.73183154296875\t ACC train:  0.994\t ACC test:  0.9688888888888889\n",
      "\tEpoch 688: \tAverage Loss:  1.7316793212890624\t ACC train:  1.0\t ACC test:  0.9644444444444444\n",
      "\tEpoch 689: \tAverage Loss:  1.7291319580078126\t ACC train:  0.998\t ACC test:  0.9666666666666667\n",
      "\tEpoch 690: \tAverage Loss:  1.733399658203125\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 691: \tAverage Loss:  1.72693408203125\t ACC train:  0.998\t ACC test:  0.9666666666666667\n",
      "\tEpoch 692: \tAverage Loss:  1.73112255859375\t ACC train:  0.996\t ACC test:  0.9666666666666667\n",
      "\tEpoch 693: \tAverage Loss:  1.728194580078125\t ACC train:  0.994\t ACC test:  0.9688888888888889\n",
      "\tEpoch 694: \tAverage Loss:  1.73096142578125\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 695: \tAverage Loss:  1.7286251220703126\t ACC train:  0.994\t ACC test:  0.9688888888888889\n",
      "\tEpoch 696: \tAverage Loss:  1.729798828125\t ACC train:  0.994\t ACC test:  0.9688888888888889\n",
      "\tEpoch 697: \tAverage Loss:  1.7295986328125\t ACC train:  0.998\t ACC test:  0.9688888888888889\n",
      "\tEpoch 698: \tAverage Loss:  1.7271923828125\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 699: \tAverage Loss:  1.7274263916015624\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 700: \tAverage Loss:  1.72760205078125\t ACC train:  0.998\t ACC test:  0.9688888888888889\n",
      "\tEpoch 701: \tAverage Loss:  1.727547607421875\t ACC train:  0.994\t ACC test:  0.9688888888888889\n",
      "\tEpoch 702: \tAverage Loss:  1.726548828125\t ACC train:  0.996\t ACC test:  0.9666666666666667\n",
      "\tEpoch 703: \tAverage Loss:  1.7269794921875\t ACC train:  0.996\t ACC test:  0.9666666666666667\n",
      "\tEpoch 704: \tAverage Loss:  1.72649462890625\t ACC train:  0.994\t ACC test:  0.9688888888888889\n",
      "\tEpoch 705: \tAverage Loss:  1.72479345703125\t ACC train:  1.0\t ACC test:  0.9688888888888889\n",
      "\tEpoch 706: \tAverage Loss:  1.7263006591796874\t ACC train:  0.992\t ACC test:  0.9688888888888889\n",
      "\tEpoch 707: \tAverage Loss:  1.723408203125\t ACC train:  0.996\t ACC test:  0.9711111111111111\n",
      "\tEpoch 708: \tAverage Loss:  1.72328759765625\t ACC train:  0.994\t ACC test:  0.9688888888888889\n",
      "\tEpoch 709: \tAverage Loss:  1.72314208984375\t ACC train:  0.996\t ACC test:  0.9733333333333334\n",
      "\tEpoch 710: \tAverage Loss:  1.72212744140625\t ACC train:  0.992\t ACC test:  0.9644444444444444\n",
      "\tEpoch 711: \tAverage Loss:  1.7225550537109375\t ACC train:  0.996\t ACC test:  0.9666666666666667\n",
      "\tEpoch 712: \tAverage Loss:  1.72215576171875\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 713: \tAverage Loss:  1.7231513671875\t ACC train:  0.994\t ACC test:  0.9666666666666667\n",
      "\tEpoch 714: \tAverage Loss:  1.7224849853515625\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 715: \tAverage Loss:  1.7194073486328125\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 716: \tAverage Loss:  1.71882763671875\t ACC train:  0.994\t ACC test:  0.9711111111111111\n",
      "\tEpoch 717: \tAverage Loss:  1.7182518310546875\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 718: \tAverage Loss:  1.719265869140625\t ACC train:  0.998\t ACC test:  0.9688888888888889\n",
      "\tEpoch 719: \tAverage Loss:  1.7193900146484375\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 720: \tAverage Loss:  1.71861572265625\t ACC train:  0.994\t ACC test:  0.9688888888888889\n",
      "\tEpoch 721: \tAverage Loss:  1.7191771240234375\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 722: \tAverage Loss:  1.721455810546875\t ACC train:  0.996\t ACC test:  0.9666666666666667\n",
      "\tEpoch 723: \tAverage Loss:  1.7185533447265624\t ACC train:  0.994\t ACC test:  0.9711111111111111\n",
      "\tEpoch 724: \tAverage Loss:  1.717211181640625\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 725: \tAverage Loss:  1.7172762451171875\t ACC train:  0.998\t ACC test:  0.9688888888888889\n",
      "\tEpoch 726: \tAverage Loss:  1.716067138671875\t ACC train:  0.996\t ACC test:  0.9755555555555555\n",
      "\tEpoch 727: \tAverage Loss:  1.717348876953125\t ACC train:  0.998\t ACC test:  0.9688888888888889\n",
      "\tEpoch 728: \tAverage Loss:  1.7180460205078125\t ACC train:  0.996\t ACC test:  0.9711111111111111\n",
      "\tEpoch 729: \tAverage Loss:  1.712763427734375\t ACC train:  0.998\t ACC test:  0.9666666666666667\n",
      "\tEpoch 730: \tAverage Loss:  1.7141602783203125\t ACC train:  0.998\t ACC test:  0.9622222222222222\n",
      "\tEpoch 731: \tAverage Loss:  1.716419189453125\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 732: \tAverage Loss:  1.7141671142578125\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 733: \tAverage Loss:  1.716052734375\t ACC train:  0.996\t ACC test:  0.9711111111111111\n",
      "\tEpoch 734: \tAverage Loss:  1.716385498046875\t ACC train:  0.996\t ACC test:  0.9622222222222222\n",
      "\tEpoch 735: \tAverage Loss:  1.7120145263671875\t ACC train:  0.998\t ACC test:  0.9644444444444444\n",
      "\tEpoch 736: \tAverage Loss:  1.7128402099609374\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 737: \tAverage Loss:  1.714314453125\t ACC train:  0.998\t ACC test:  0.9688888888888889\n",
      "\tEpoch 738: \tAverage Loss:  1.7148228759765625\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 739: \tAverage Loss:  1.712601806640625\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 740: \tAverage Loss:  1.7118385009765624\t ACC train:  0.998\t ACC test:  0.9688888888888889\n",
      "\tEpoch 741: \tAverage Loss:  1.7093929443359375\t ACC train:  0.996\t ACC test:  0.9711111111111111\n",
      "\tEpoch 742: \tAverage Loss:  1.7124591064453125\t ACC train:  1.0\t ACC test:  0.9688888888888889\n",
      "\tEpoch 743: \tAverage Loss:  1.7123367919921875\t ACC train:  1.0\t ACC test:  0.9688888888888889\n",
      "\tEpoch 744: \tAverage Loss:  1.7128291015625\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 745: \tAverage Loss:  1.7088321533203126\t ACC train:  0.998\t ACC test:  0.9666666666666667\n",
      "\tEpoch 746: \tAverage Loss:  1.709185791015625\t ACC train:  0.998\t ACC test:  0.9733333333333334\n",
      "\tEpoch 747: \tAverage Loss:  1.711278076171875\t ACC train:  0.996\t ACC test:  0.9666666666666667\n",
      "\tEpoch 748: \tAverage Loss:  1.7100357666015624\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 749: \tAverage Loss:  1.709744140625\t ACC train:  1.0\t ACC test:  0.9622222222222222\n",
      "\tEpoch 750: \tAverage Loss:  1.7098739013671875\t ACC train:  0.996\t ACC test:  0.9644444444444444\n",
      "\tEpoch 751: \tAverage Loss:  1.70745361328125\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 752: \tAverage Loss:  1.708204833984375\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 753: \tAverage Loss:  1.708357177734375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 754: \tAverage Loss:  1.709451904296875\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 755: \tAverage Loss:  1.7069276123046875\t ACC train:  1.0\t ACC test:  0.9644444444444444\n",
      "\tEpoch 756: \tAverage Loss:  1.7062669677734374\t ACC train:  0.998\t ACC test:  0.9644444444444444\n",
      "\tEpoch 757: \tAverage Loss:  1.7052652587890624\t ACC train:  0.998\t ACC test:  0.9666666666666667\n",
      "\tEpoch 758: \tAverage Loss:  1.7087198486328126\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 759: \tAverage Loss:  1.7084019775390624\t ACC train:  0.996\t ACC test:  0.9711111111111111\n",
      "\tEpoch 760: \tAverage Loss:  1.70716015625\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 761: \tAverage Loss:  1.7055667724609376\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 762: \tAverage Loss:  1.70452685546875\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 763: \tAverage Loss:  1.703869140625\t ACC train:  1.0\t ACC test:  0.9644444444444444\n",
      "\tEpoch 764: \tAverage Loss:  1.7034613037109374\t ACC train:  0.998\t ACC test:  0.9688888888888889\n",
      "\tEpoch 765: \tAverage Loss:  1.7055772705078125\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 766: \tAverage Loss:  1.705160888671875\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 767: \tAverage Loss:  1.7037310791015625\t ACC train:  0.996\t ACC test:  0.9711111111111111\n",
      "\tEpoch 768: \tAverage Loss:  1.70263623046875\t ACC train:  0.996\t ACC test:  0.9711111111111111\n",
      "\tEpoch 769: \tAverage Loss:  1.70254052734375\t ACC train:  0.998\t ACC test:  0.9688888888888889\n",
      "\tEpoch 770: \tAverage Loss:  1.703095703125\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 771: \tAverage Loss:  1.7042847900390625\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 772: \tAverage Loss:  1.704164794921875\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 773: \tAverage Loss:  1.7014996337890624\t ACC train:  0.998\t ACC test:  0.9755555555555555\n",
      "\tEpoch 774: \tAverage Loss:  1.70307666015625\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 775: \tAverage Loss:  1.7036627197265626\t ACC train:  0.998\t ACC test:  0.9733333333333334\n",
      "\tEpoch 776: \tAverage Loss:  1.69923974609375\t ACC train:  1.0\t ACC test:  0.9688888888888889\n",
      "\tEpoch 777: \tAverage Loss:  1.701200439453125\t ACC train:  0.994\t ACC test:  0.9666666666666667\n",
      "\tEpoch 778: \tAverage Loss:  1.700853271484375\t ACC train:  1.0\t ACC test:  0.9688888888888889\n",
      "\tEpoch 779: \tAverage Loss:  1.7009298095703125\t ACC train:  0.996\t ACC test:  0.9688888888888889\n",
      "\tEpoch 780: \tAverage Loss:  1.7011353759765624\t ACC train:  0.998\t ACC test:  0.9733333333333334\n",
      "\tEpoch 781: \tAverage Loss:  1.701115234375\t ACC train:  0.998\t ACC test:  0.9755555555555555\n",
      "\tEpoch 782: \tAverage Loss:  1.7002838134765625\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 783: \tAverage Loss:  1.6997109375\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 784: \tAverage Loss:  1.6998997802734375\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 785: \tAverage Loss:  1.6992705078125\t ACC train:  0.998\t ACC test:  0.9777777777777777\n",
      "\tEpoch 786: \tAverage Loss:  1.7010384521484374\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 787: \tAverage Loss:  1.69990625\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 788: \tAverage Loss:  1.69982763671875\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 789: \tAverage Loss:  1.698849853515625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 790: \tAverage Loss:  1.697250244140625\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 791: \tAverage Loss:  1.6972716064453126\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 792: \tAverage Loss:  1.6966959228515626\t ACC train:  0.996\t ACC test:  0.9755555555555555\n",
      "\tEpoch 793: \tAverage Loss:  1.6961300048828125\t ACC train:  0.998\t ACC test:  0.9755555555555555\n",
      "\tEpoch 794: \tAverage Loss:  1.69558984375\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 795: \tAverage Loss:  1.696979736328125\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 796: \tAverage Loss:  1.69652685546875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 797: \tAverage Loss:  1.69785546875\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 798: \tAverage Loss:  1.695401611328125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 799: \tAverage Loss:  1.694900634765625\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 800: \tAverage Loss:  1.69550927734375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 801: \tAverage Loss:  1.6942822265625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 802: \tAverage Loss:  1.6968193359375\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 803: \tAverage Loss:  1.6944449462890625\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 804: \tAverage Loss:  1.6955260009765625\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 805: \tAverage Loss:  1.69471630859375\t ACC train:  0.994\t ACC test:  0.9755555555555555\n",
      "\tEpoch 806: \tAverage Loss:  1.6944029541015626\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 807: \tAverage Loss:  1.693082763671875\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 808: \tAverage Loss:  1.6916732177734375\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 809: \tAverage Loss:  1.691631591796875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 810: \tAverage Loss:  1.6921947021484376\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 811: \tAverage Loss:  1.6921650390625\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 812: \tAverage Loss:  1.6933211669921875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 813: \tAverage Loss:  1.6907320556640626\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 814: \tAverage Loss:  1.691926513671875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 815: \tAverage Loss:  1.69261474609375\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 816: \tAverage Loss:  1.68973583984375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 817: \tAverage Loss:  1.690338623046875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 818: \tAverage Loss:  1.689970947265625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 819: \tAverage Loss:  1.6916497802734376\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 820: \tAverage Loss:  1.6894913330078125\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 821: \tAverage Loss:  1.690439697265625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 822: \tAverage Loss:  1.6892861328125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 823: \tAverage Loss:  1.689005859375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 824: \tAverage Loss:  1.689513427734375\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 825: \tAverage Loss:  1.6887257080078124\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 826: \tAverage Loss:  1.6903668212890626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 827: \tAverage Loss:  1.68886474609375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 828: \tAverage Loss:  1.6879141845703125\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 829: \tAverage Loss:  1.6893729248046876\t ACC train:  0.998\t ACC test:  0.9711111111111111\n",
      "\tEpoch 830: \tAverage Loss:  1.6875557861328125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 831: \tAverage Loss:  1.687751953125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 832: \tAverage Loss:  1.688850341796875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 833: \tAverage Loss:  1.6889801025390625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 834: \tAverage Loss:  1.6859307861328126\t ACC train:  1.0\t ACC test:  0.9711111111111111\n",
      "\tEpoch 835: \tAverage Loss:  1.68666455078125\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 836: \tAverage Loss:  1.6863118896484375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 837: \tAverage Loss:  1.68631494140625\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 838: \tAverage Loss:  1.68542626953125\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 839: \tAverage Loss:  1.687057373046875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 840: \tAverage Loss:  1.68673974609375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 841: \tAverage Loss:  1.68518359375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 842: \tAverage Loss:  1.6851746826171874\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 843: \tAverage Loss:  1.68644921875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 844: \tAverage Loss:  1.6845789794921875\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 845: \tAverage Loss:  1.6849346923828126\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 846: \tAverage Loss:  1.6844039306640626\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 847: \tAverage Loss:  1.684323974609375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 848: \tAverage Loss:  1.68532373046875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 849: \tAverage Loss:  1.6837508544921875\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 850: \tAverage Loss:  1.6848861083984374\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 851: \tAverage Loss:  1.6829305419921874\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 852: \tAverage Loss:  1.682973876953125\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 853: \tAverage Loss:  1.682495849609375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 854: \tAverage Loss:  1.682392822265625\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 855: \tAverage Loss:  1.683156982421875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 856: \tAverage Loss:  1.6827933349609374\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 857: \tAverage Loss:  1.681064208984375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 858: \tAverage Loss:  1.682742919921875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 859: \tAverage Loss:  1.6818218994140626\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 860: \tAverage Loss:  1.6822510986328125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 861: \tAverage Loss:  1.6797481689453124\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 862: \tAverage Loss:  1.680720703125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 863: \tAverage Loss:  1.68264208984375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 864: \tAverage Loss:  1.6814332275390624\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 865: \tAverage Loss:  1.680532958984375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 866: \tAverage Loss:  1.6795911865234374\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 867: \tAverage Loss:  1.680884521484375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 868: \tAverage Loss:  1.6801044921875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 869: \tAverage Loss:  1.6800003662109375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 870: \tAverage Loss:  1.6791522216796875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 871: \tAverage Loss:  1.679318603515625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 872: \tAverage Loss:  1.67904296875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 873: \tAverage Loss:  1.6787301025390624\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 874: \tAverage Loss:  1.68020263671875\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 875: \tAverage Loss:  1.6788082275390626\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 876: \tAverage Loss:  1.6785372314453124\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 877: \tAverage Loss:  1.678680908203125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 878: \tAverage Loss:  1.678400146484375\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 879: \tAverage Loss:  1.6783768310546876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 880: \tAverage Loss:  1.677871826171875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 881: \tAverage Loss:  1.6776119384765624\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 882: \tAverage Loss:  1.6774786376953126\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 883: \tAverage Loss:  1.67640283203125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 884: \tAverage Loss:  1.677455810546875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 885: \tAverage Loss:  1.677415283203125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 886: \tAverage Loss:  1.6777872314453126\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 887: \tAverage Loss:  1.67689697265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 888: \tAverage Loss:  1.677078857421875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 889: \tAverage Loss:  1.6761265869140625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 890: \tAverage Loss:  1.6767177734375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 891: \tAverage Loss:  1.67540380859375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 892: \tAverage Loss:  1.675428955078125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 893: \tAverage Loss:  1.674876953125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 894: \tAverage Loss:  1.6762955322265625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 895: \tAverage Loss:  1.6752498779296876\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 896: \tAverage Loss:  1.67541064453125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 897: \tAverage Loss:  1.6762366943359375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 898: \tAverage Loss:  1.67502099609375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 899: \tAverage Loss:  1.6746270751953125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 900: \tAverage Loss:  1.67417138671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 901: \tAverage Loss:  1.6743768310546876\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 902: \tAverage Loss:  1.6733974609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 903: \tAverage Loss:  1.6738636474609374\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 904: \tAverage Loss:  1.6734251708984376\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 905: \tAverage Loss:  1.6739517822265626\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 906: \tAverage Loss:  1.6741097412109376\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 907: \tAverage Loss:  1.67332080078125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 908: \tAverage Loss:  1.673591552734375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 909: \tAverage Loss:  1.6731435546875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 910: \tAverage Loss:  1.672978515625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 911: \tAverage Loss:  1.672864990234375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 912: \tAverage Loss:  1.672037841796875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 913: \tAverage Loss:  1.672189208984375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 914: \tAverage Loss:  1.6722657470703124\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 915: \tAverage Loss:  1.6721534423828126\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 916: \tAverage Loss:  1.6716181640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 917: \tAverage Loss:  1.6717296142578124\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 918: \tAverage Loss:  1.6716475830078126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 919: \tAverage Loss:  1.671431884765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 920: \tAverage Loss:  1.671431884765625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 921: \tAverage Loss:  1.670524658203125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 922: \tAverage Loss:  1.6710166015625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 923: \tAverage Loss:  1.670646240234375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 924: \tAverage Loss:  1.670342041015625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 925: \tAverage Loss:  1.6703111572265625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 926: \tAverage Loss:  1.6704656982421875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 927: \tAverage Loss:  1.669730712890625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 928: \tAverage Loss:  1.670259033203125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 929: \tAverage Loss:  1.6689915771484376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 930: \tAverage Loss:  1.669704345703125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 931: \tAverage Loss:  1.6696649169921876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 932: \tAverage Loss:  1.66928466796875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 933: \tAverage Loss:  1.6688316650390624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 934: \tAverage Loss:  1.669314453125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 935: \tAverage Loss:  1.6691148681640624\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 936: \tAverage Loss:  1.6684163818359374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 937: \tAverage Loss:  1.6687869873046874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 938: \tAverage Loss:  1.667393310546875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 939: \tAverage Loss:  1.668080322265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 940: \tAverage Loss:  1.6677908935546875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 941: \tAverage Loss:  1.6674852294921876\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 942: \tAverage Loss:  1.668256591796875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 943: \tAverage Loss:  1.6672159423828126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 944: \tAverage Loss:  1.6677808837890624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 945: \tAverage Loss:  1.6669669189453125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 946: \tAverage Loss:  1.66762548828125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 947: \tAverage Loss:  1.666523193359375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 948: \tAverage Loss:  1.666724609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 949: \tAverage Loss:  1.666564697265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 950: \tAverage Loss:  1.6665709228515626\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 951: \tAverage Loss:  1.6664444580078126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 952: \tAverage Loss:  1.665309326171875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 953: \tAverage Loss:  1.6659715576171874\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 954: \tAverage Loss:  1.66607470703125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 955: \tAverage Loss:  1.66616552734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 956: \tAverage Loss:  1.66595458984375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 957: \tAverage Loss:  1.66565234375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 958: \tAverage Loss:  1.6655263671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 959: \tAverage Loss:  1.6653133544921874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 960: \tAverage Loss:  1.66489892578125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 961: \tAverage Loss:  1.665159423828125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 962: \tAverage Loss:  1.66454638671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 963: \tAverage Loss:  1.6648819580078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 964: \tAverage Loss:  1.665299560546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 965: \tAverage Loss:  1.6645950927734374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 966: \tAverage Loss:  1.6642296142578126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 967: \tAverage Loss:  1.664387939453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 968: \tAverage Loss:  1.6641849365234376\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 969: \tAverage Loss:  1.663433837890625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 970: \tAverage Loss:  1.6637957763671876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 971: \tAverage Loss:  1.663068359375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 972: \tAverage Loss:  1.6638515625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 973: \tAverage Loss:  1.663593017578125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 974: \tAverage Loss:  1.6634554443359375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 975: \tAverage Loss:  1.66336474609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 976: \tAverage Loss:  1.662734130859375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 977: \tAverage Loss:  1.6627843017578126\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 978: \tAverage Loss:  1.662946533203125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 979: \tAverage Loss:  1.6623558349609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 980: \tAverage Loss:  1.662478759765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 981: \tAverage Loss:  1.6622225341796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 982: \tAverage Loss:  1.661942626953125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 983: \tAverage Loss:  1.66193994140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 984: \tAverage Loss:  1.66211279296875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 985: \tAverage Loss:  1.662056640625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 986: \tAverage Loss:  1.662010498046875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 987: \tAverage Loss:  1.661518798828125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 988: \tAverage Loss:  1.6613651123046875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 989: \tAverage Loss:  1.6613880615234375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 990: \tAverage Loss:  1.6615467529296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 991: \tAverage Loss:  1.6609718017578126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 992: \tAverage Loss:  1.6609166259765624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 993: \tAverage Loss:  1.661047607421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 994: \tAverage Loss:  1.6605404052734376\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 995: \tAverage Loss:  1.661109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 996: \tAverage Loss:  1.6607110595703125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 997: \tAverage Loss:  1.6600447998046874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 998: \tAverage Loss:  1.660493896484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 999: \tAverage Loss:  1.659821533203125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1000: \tAverage Loss:  1.6604693603515626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1001: \tAverage Loss:  1.659420654296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1002: \tAverage Loss:  1.659958251953125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1003: \tAverage Loss:  1.6597525634765624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1004: \tAverage Loss:  1.6595897216796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1005: \tAverage Loss:  1.6598048095703124\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1006: \tAverage Loss:  1.6596478271484374\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1007: \tAverage Loss:  1.6592247314453126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1008: \tAverage Loss:  1.6590501708984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1009: \tAverage Loss:  1.6588328857421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1010: \tAverage Loss:  1.658937255859375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1011: \tAverage Loss:  1.659370361328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1012: \tAverage Loss:  1.6589434814453126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1013: \tAverage Loss:  1.6584034423828125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1014: \tAverage Loss:  1.6584632568359374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1015: \tAverage Loss:  1.65842431640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1016: \tAverage Loss:  1.6583038330078126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1017: \tAverage Loss:  1.6577330322265624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1018: \tAverage Loss:  1.6577684326171875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1019: \tAverage Loss:  1.6573365478515625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1020: \tAverage Loss:  1.6578885498046876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1021: \tAverage Loss:  1.657751708984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1022: \tAverage Loss:  1.6574542236328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1023: \tAverage Loss:  1.6573040771484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1024: \tAverage Loss:  1.65687451171875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1025: \tAverage Loss:  1.6570533447265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1026: \tAverage Loss:  1.65687744140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1027: \tAverage Loss:  1.6569627685546875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1028: \tAverage Loss:  1.6566375732421874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1029: \tAverage Loss:  1.656674072265625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1030: \tAverage Loss:  1.656681884765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1031: \tAverage Loss:  1.6564200439453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1032: \tAverage Loss:  1.6563077392578125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1033: \tAverage Loss:  1.656732666015625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1034: \tAverage Loss:  1.6562122802734376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1035: \tAverage Loss:  1.6562642822265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1036: \tAverage Loss:  1.655910888671875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1037: \tAverage Loss:  1.655635498046875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1038: \tAverage Loss:  1.65547509765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1039: \tAverage Loss:  1.655566162109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1040: \tAverage Loss:  1.6555433349609374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1041: \tAverage Loss:  1.655505859375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1042: \tAverage Loss:  1.6551591796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1043: \tAverage Loss:  1.65498681640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1044: \tAverage Loss:  1.6548636474609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1045: \tAverage Loss:  1.6551429443359376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1046: \tAverage Loss:  1.65495751953125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1047: \tAverage Loss:  1.6545118408203126\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1048: \tAverage Loss:  1.65488671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1049: \tAverage Loss:  1.65439697265625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1050: \tAverage Loss:  1.6540963134765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1051: \tAverage Loss:  1.6543681640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1052: \tAverage Loss:  1.65420556640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1053: \tAverage Loss:  1.6541005859375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1054: \tAverage Loss:  1.6542315673828125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1055: \tAverage Loss:  1.6538404541015626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1056: \tAverage Loss:  1.6538931884765624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1057: \tAverage Loss:  1.65374169921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1058: \tAverage Loss:  1.653501708984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1059: \tAverage Loss:  1.65326953125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1060: \tAverage Loss:  1.65343994140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1061: \tAverage Loss:  1.653520751953125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1062: \tAverage Loss:  1.6531141357421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1063: \tAverage Loss:  1.6530423583984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1064: \tAverage Loss:  1.6530194091796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1065: \tAverage Loss:  1.6525213623046875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1066: \tAverage Loss:  1.652681396484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1067: \tAverage Loss:  1.6527841796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1068: \tAverage Loss:  1.652911376953125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1069: \tAverage Loss:  1.6524495849609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1070: \tAverage Loss:  1.652398193359375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1071: \tAverage Loss:  1.652301513671875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1072: \tAverage Loss:  1.6520928955078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1073: \tAverage Loss:  1.6522320556640624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1074: \tAverage Loss:  1.6519417724609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1075: \tAverage Loss:  1.651908447265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1076: \tAverage Loss:  1.652154296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1077: \tAverage Loss:  1.6519534912109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1078: \tAverage Loss:  1.651661865234375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1079: \tAverage Loss:  1.6516728515625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1080: \tAverage Loss:  1.65155859375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1081: \tAverage Loss:  1.6512628173828126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1082: \tAverage Loss:  1.651303466796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1083: \tAverage Loss:  1.65113916015625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1084: \tAverage Loss:  1.6509139404296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1085: \tAverage Loss:  1.650926513671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1086: \tAverage Loss:  1.651066162109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1087: \tAverage Loss:  1.6509835205078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1088: \tAverage Loss:  1.65059619140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1089: \tAverage Loss:  1.650706298828125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1090: \tAverage Loss:  1.6505687255859376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1091: \tAverage Loss:  1.6504385986328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1092: \tAverage Loss:  1.6502196044921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1093: \tAverage Loss:  1.650108154296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1094: \tAverage Loss:  1.6499976806640626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1095: \tAverage Loss:  1.650059814453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1096: \tAverage Loss:  1.64991064453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1097: \tAverage Loss:  1.6501175537109376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1098: \tAverage Loss:  1.649951171875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1099: \tAverage Loss:  1.6497646484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1100: \tAverage Loss:  1.6494161376953125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1101: \tAverage Loss:  1.64965380859375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1102: \tAverage Loss:  1.6495118408203124\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1103: \tAverage Loss:  1.649345947265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1104: \tAverage Loss:  1.649080078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1105: \tAverage Loss:  1.649230712890625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1106: \tAverage Loss:  1.649238525390625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1107: \tAverage Loss:  1.64893603515625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1108: \tAverage Loss:  1.649079345703125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1109: \tAverage Loss:  1.6489071044921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1110: \tAverage Loss:  1.6486376953125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1111: \tAverage Loss:  1.6485263671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1112: \tAverage Loss:  1.6486068115234376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1113: \tAverage Loss:  1.648404052734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1114: \tAverage Loss:  1.6484407958984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1115: \tAverage Loss:  1.648078857421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1116: \tAverage Loss:  1.6482606201171874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1117: \tAverage Loss:  1.6480634765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1118: \tAverage Loss:  1.64813427734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1119: \tAverage Loss:  1.6480616455078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1120: \tAverage Loss:  1.647701171875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1121: \tAverage Loss:  1.6476007080078126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1122: \tAverage Loss:  1.6477537841796874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1123: \tAverage Loss:  1.6477015380859374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1124: \tAverage Loss:  1.64748486328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1125: \tAverage Loss:  1.6475872802734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1126: \tAverage Loss:  1.6474140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1127: \tAverage Loss:  1.6474686279296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1128: \tAverage Loss:  1.64749658203125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1129: \tAverage Loss:  1.6471090087890625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1130: \tAverage Loss:  1.6471016845703126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1131: \tAverage Loss:  1.646734619140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1132: \tAverage Loss:  1.646855712890625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1133: \tAverage Loss:  1.646831787109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1134: \tAverage Loss:  1.646861328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1135: \tAverage Loss:  1.646660888671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1136: \tAverage Loss:  1.646560546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1137: \tAverage Loss:  1.6465364990234375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1138: \tAverage Loss:  1.6465345458984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1139: \tAverage Loss:  1.646327392578125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1140: \tAverage Loss:  1.6462952880859374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1141: \tAverage Loss:  1.6463355712890626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1142: \tAverage Loss:  1.6460091552734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1143: \tAverage Loss:  1.6459971923828125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1144: \tAverage Loss:  1.646083984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1145: \tAverage Loss:  1.6458509521484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1146: \tAverage Loss:  1.6457991943359376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1147: \tAverage Loss:  1.64581201171875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1148: \tAverage Loss:  1.6456937255859374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1149: \tAverage Loss:  1.6456529541015625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1150: \tAverage Loss:  1.645644287109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1151: \tAverage Loss:  1.645326171875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1152: \tAverage Loss:  1.6453193359375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1153: \tAverage Loss:  1.6452294921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1154: \tAverage Loss:  1.6451986083984376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1155: \tAverage Loss:  1.64505810546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1156: \tAverage Loss:  1.6449576416015625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1157: \tAverage Loss:  1.6450205078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1158: \tAverage Loss:  1.6449935302734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1159: \tAverage Loss:  1.6449237060546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1160: \tAverage Loss:  1.6446912841796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1161: \tAverage Loss:  1.6445098876953126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1162: \tAverage Loss:  1.6446551513671874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1163: \tAverage Loss:  1.6443909912109376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1164: \tAverage Loss:  1.6444029541015626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1165: \tAverage Loss:  1.6443280029296874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1166: \tAverage Loss:  1.644229736328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1167: \tAverage Loss:  1.6441844482421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1168: \tAverage Loss:  1.6441240234375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1169: \tAverage Loss:  1.6439654541015625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1170: \tAverage Loss:  1.64391552734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1171: \tAverage Loss:  1.6439425048828125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1172: \tAverage Loss:  1.6438350830078126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1173: \tAverage Loss:  1.6436849365234374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1174: \tAverage Loss:  1.6435228271484374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1175: \tAverage Loss:  1.643578369140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1176: \tAverage Loss:  1.6434521484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1177: \tAverage Loss:  1.6434422607421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1178: \tAverage Loss:  1.64327099609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1179: \tAverage Loss:  1.6432972412109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1180: \tAverage Loss:  1.643226806640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1181: \tAverage Loss:  1.6431485595703126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1182: \tAverage Loss:  1.6430452880859374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1183: \tAverage Loss:  1.6429642333984376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1184: \tAverage Loss:  1.6429764404296876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1185: \tAverage Loss:  1.6428570556640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1186: \tAverage Loss:  1.6428470458984374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1187: \tAverage Loss:  1.642739990234375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1188: \tAverage Loss:  1.642625244140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1189: \tAverage Loss:  1.642594970703125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1190: \tAverage Loss:  1.64245263671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1191: \tAverage Loss:  1.64241796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1192: \tAverage Loss:  1.642397705078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1193: \tAverage Loss:  1.6422235107421874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1194: \tAverage Loss:  1.642189208984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1195: \tAverage Loss:  1.6422152099609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1196: \tAverage Loss:  1.64215185546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1197: \tAverage Loss:  1.641957275390625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1198: \tAverage Loss:  1.6419910888671876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1199: \tAverage Loss:  1.641913818359375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1200: \tAverage Loss:  1.641799072265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1201: \tAverage Loss:  1.6417314453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1202: \tAverage Loss:  1.641666748046875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1203: \tAverage Loss:  1.6415626220703126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1204: \tAverage Loss:  1.6415159912109376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1205: \tAverage Loss:  1.641470947265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1206: \tAverage Loss:  1.641303955078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1207: \tAverage Loss:  1.6412242431640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1208: \tAverage Loss:  1.6411387939453126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1209: \tAverage Loss:  1.641094970703125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1210: \tAverage Loss:  1.641139404296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1211: \tAverage Loss:  1.64102783203125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1212: \tAverage Loss:  1.6409334716796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1213: \tAverage Loss:  1.6407574462890624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1214: \tAverage Loss:  1.640887451171875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1215: \tAverage Loss:  1.640703369140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1216: \tAverage Loss:  1.64065625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1217: \tAverage Loss:  1.6406170654296874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1218: \tAverage Loss:  1.6405135498046874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1219: \tAverage Loss:  1.640419921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1220: \tAverage Loss:  1.640356689453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1221: \tAverage Loss:  1.640328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1222: \tAverage Loss:  1.6402308349609376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1223: \tAverage Loss:  1.6402183837890625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1224: \tAverage Loss:  1.640091796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1225: \tAverage Loss:  1.640085205078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1226: \tAverage Loss:  1.6400030517578126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1227: \tAverage Loss:  1.639917236328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1228: \tAverage Loss:  1.639885498046875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1229: \tAverage Loss:  1.6397501220703126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1230: \tAverage Loss:  1.63971435546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1231: \tAverage Loss:  1.6396881103515626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1232: \tAverage Loss:  1.6395850830078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1233: \tAverage Loss:  1.63955126953125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1234: \tAverage Loss:  1.6393758544921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1235: \tAverage Loss:  1.63939453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1236: \tAverage Loss:  1.6393895263671876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1237: \tAverage Loss:  1.6392525634765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1238: \tAverage Loss:  1.6392086181640626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1239: \tAverage Loss:  1.6391322021484376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1240: \tAverage Loss:  1.6391112060546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1241: \tAverage Loss:  1.6389400634765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1242: \tAverage Loss:  1.6389312744140625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1243: \tAverage Loss:  1.6389075927734376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1244: \tAverage Loss:  1.6387769775390626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1245: \tAverage Loss:  1.638725341796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1246: \tAverage Loss:  1.6386673583984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1247: \tAverage Loss:  1.6386402587890625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1248: \tAverage Loss:  1.638635986328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1249: \tAverage Loss:  1.638485595703125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1250: \tAverage Loss:  1.6384307861328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1251: \tAverage Loss:  1.6383997802734376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1252: \tAverage Loss:  1.6383023681640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1253: \tAverage Loss:  1.6382294921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1254: \tAverage Loss:  1.6381837158203125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1255: \tAverage Loss:  1.6380743408203124\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1256: \tAverage Loss:  1.6379951171875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1257: \tAverage Loss:  1.6379537353515625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1258: \tAverage Loss:  1.637847900390625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1259: \tAverage Loss:  1.6377818603515626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1260: \tAverage Loss:  1.637796142578125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1261: \tAverage Loss:  1.6376600341796874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1262: \tAverage Loss:  1.63769287109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1263: \tAverage Loss:  1.6375810546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1264: \tAverage Loss:  1.637484619140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1265: \tAverage Loss:  1.6374993896484376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1266: \tAverage Loss:  1.63742333984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1267: \tAverage Loss:  1.6372857666015626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1268: \tAverage Loss:  1.6372747802734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1269: \tAverage Loss:  1.6371534423828125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1270: \tAverage Loss:  1.63716064453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1271: \tAverage Loss:  1.6371171875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1272: \tAverage Loss:  1.6370177001953126\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1273: \tAverage Loss:  1.6369404296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1274: \tAverage Loss:  1.6369053955078126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1275: \tAverage Loss:  1.63678125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1276: \tAverage Loss:  1.6367366943359376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1277: \tAverage Loss:  1.63663427734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1278: \tAverage Loss:  1.6365966796875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1279: \tAverage Loss:  1.63651025390625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1280: \tAverage Loss:  1.6364453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1281: \tAverage Loss:  1.6363641357421874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1282: \tAverage Loss:  1.6364022216796874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1283: \tAverage Loss:  1.6362926025390625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1284: \tAverage Loss:  1.636211669921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1285: \tAverage Loss:  1.636260009765625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1286: \tAverage Loss:  1.636099609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1287: \tAverage Loss:  1.636031005859375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1288: \tAverage Loss:  1.636017333984375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1289: \tAverage Loss:  1.6359344482421876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1290: \tAverage Loss:  1.6358232421875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1291: \tAverage Loss:  1.6358084716796875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1292: \tAverage Loss:  1.6357972412109374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1293: \tAverage Loss:  1.63566650390625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1294: \tAverage Loss:  1.635582763671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1295: \tAverage Loss:  1.6355440673828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1296: \tAverage Loss:  1.6354515380859376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1297: \tAverage Loss:  1.635385498046875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1298: \tAverage Loss:  1.635339111328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1299: \tAverage Loss:  1.6353070068359374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1300: \tAverage Loss:  1.635232177734375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1301: \tAverage Loss:  1.63512890625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1302: \tAverage Loss:  1.63510498046875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1303: \tAverage Loss:  1.63506201171875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1304: \tAverage Loss:  1.6349947509765625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1305: \tAverage Loss:  1.634935546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1306: \tAverage Loss:  1.6349093017578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1307: \tAverage Loss:  1.6348238525390626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1308: \tAverage Loss:  1.6347445068359374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1309: \tAverage Loss:  1.634682861328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1310: \tAverage Loss:  1.634624267578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1311: \tAverage Loss:  1.634560791015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1312: \tAverage Loss:  1.6344967041015626\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1313: \tAverage Loss:  1.634514404296875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1314: \tAverage Loss:  1.634478759765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1315: \tAverage Loss:  1.63456005859375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1316: \tAverage Loss:  1.6344603271484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1317: \tAverage Loss:  1.634453369140625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1318: \tAverage Loss:  1.6342685546875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1319: \tAverage Loss:  1.63413134765625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1320: \tAverage Loss:  1.6339766845703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1321: \tAverage Loss:  1.6339678955078125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1322: \tAverage Loss:  1.633931640625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1323: \tAverage Loss:  1.633949951171875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1324: \tAverage Loss:  1.63386865234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1325: \tAverage Loss:  1.633827392578125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1326: \tAverage Loss:  1.63377392578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1327: \tAverage Loss:  1.633671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1328: \tAverage Loss:  1.6335396728515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1329: \tAverage Loss:  1.6334635009765626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1330: \tAverage Loss:  1.63341064453125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1331: \tAverage Loss:  1.6333880615234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1332: \tAverage Loss:  1.633312255859375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1333: \tAverage Loss:  1.63326025390625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1334: \tAverage Loss:  1.6332276611328125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1335: \tAverage Loss:  1.633111328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1336: \tAverage Loss:  1.6330406494140626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1337: \tAverage Loss:  1.6330228271484375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1338: \tAverage Loss:  1.632876220703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1339: \tAverage Loss:  1.6328994140625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1340: \tAverage Loss:  1.6328040771484376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1341: \tAverage Loss:  1.6327506103515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1342: \tAverage Loss:  1.632702880859375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1343: \tAverage Loss:  1.632632568359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1344: \tAverage Loss:  1.6325791015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1345: \tAverage Loss:  1.6325306396484376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1346: \tAverage Loss:  1.632420166015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1347: \tAverage Loss:  1.6323717041015624\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1348: \tAverage Loss:  1.632308837890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1349: \tAverage Loss:  1.632252685546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1350: \tAverage Loss:  1.632216064453125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1351: \tAverage Loss:  1.6321705322265625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1352: \tAverage Loss:  1.6321353759765624\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1353: \tAverage Loss:  1.632117919921875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1354: \tAverage Loss:  1.6322042236328125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1355: \tAverage Loss:  1.63215576171875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1356: \tAverage Loss:  1.63226953125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1357: \tAverage Loss:  1.632283935546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1358: \tAverage Loss:  1.63245947265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1359: \tAverage Loss:  1.63234716796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1360: \tAverage Loss:  1.632124755859375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1361: \tAverage Loss:  1.6318712158203126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1362: \tAverage Loss:  1.631623046875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1363: \tAverage Loss:  1.6314334716796874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1364: \tAverage Loss:  1.63143212890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1365: \tAverage Loss:  1.63134765625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1366: \tAverage Loss:  1.6313055419921876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1367: \tAverage Loss:  1.6314368896484375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1368: \tAverage Loss:  1.6312060546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1369: \tAverage Loss:  1.631188232421875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1370: \tAverage Loss:  1.63104638671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1371: \tAverage Loss:  1.630988037109375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1372: \tAverage Loss:  1.6309696044921875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1373: \tAverage Loss:  1.63094873046875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1374: \tAverage Loss:  1.6309339599609376\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1375: \tAverage Loss:  1.63091943359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1376: \tAverage Loss:  1.6307872314453125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1377: \tAverage Loss:  1.6307125244140626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1378: \tAverage Loss:  1.630594970703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1379: \tAverage Loss:  1.6305093994140625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1380: \tAverage Loss:  1.6304642333984376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1381: \tAverage Loss:  1.630384033203125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1382: \tAverage Loss:  1.630364990234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1383: \tAverage Loss:  1.6303447265625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1384: \tAverage Loss:  1.630301025390625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1385: \tAverage Loss:  1.630197998046875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1386: \tAverage Loss:  1.6301519775390625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1387: \tAverage Loss:  1.6300806884765624\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1388: \tAverage Loss:  1.630074462890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1389: \tAverage Loss:  1.630025634765625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1390: \tAverage Loss:  1.630010009765625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1391: \tAverage Loss:  1.62995751953125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1392: \tAverage Loss:  1.62999365234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1393: \tAverage Loss:  1.629978515625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1394: \tAverage Loss:  1.630030029296875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1395: \tAverage Loss:  1.63010498046875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1396: \tAverage Loss:  1.6301151123046875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1397: \tAverage Loss:  1.6299254150390625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1398: \tAverage Loss:  1.6297010498046876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1399: \tAverage Loss:  1.6295814208984376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1400: \tAverage Loss:  1.629492431640625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1401: \tAverage Loss:  1.6293099365234376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1402: \tAverage Loss:  1.629206787109375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1403: \tAverage Loss:  1.6291630859375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1404: \tAverage Loss:  1.62912646484375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1405: \tAverage Loss:  1.629093017578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1406: \tAverage Loss:  1.6290751953125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1407: \tAverage Loss:  1.6290821533203126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1408: \tAverage Loss:  1.628987548828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1409: \tAverage Loss:  1.6289139404296875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1410: \tAverage Loss:  1.62886328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1411: \tAverage Loss:  1.62878466796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1412: \tAverage Loss:  1.628690673828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1413: \tAverage Loss:  1.628614013671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1414: \tAverage Loss:  1.6285426025390626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1415: \tAverage Loss:  1.628552978515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1416: \tAverage Loss:  1.6285718994140626\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1417: \tAverage Loss:  1.6284722900390625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1418: \tAverage Loss:  1.6283720703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1419: \tAverage Loss:  1.628328857421875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1420: \tAverage Loss:  1.62822802734375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1421: \tAverage Loss:  1.6282080078125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1422: \tAverage Loss:  1.6282113037109376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1423: \tAverage Loss:  1.6283037109375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1424: \tAverage Loss:  1.628228515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1425: \tAverage Loss:  1.628255859375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1426: \tAverage Loss:  1.6282608642578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1427: \tAverage Loss:  1.6282581787109376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1428: \tAverage Loss:  1.628185546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1429: \tAverage Loss:  1.62808203125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1430: \tAverage Loss:  1.6279482421875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1431: \tAverage Loss:  1.6277635498046874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1432: \tAverage Loss:  1.6276314697265626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1433: \tAverage Loss:  1.6274892578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1434: \tAverage Loss:  1.6274171142578124\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1435: \tAverage Loss:  1.6274317626953125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1436: \tAverage Loss:  1.6274422607421875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1437: \tAverage Loss:  1.6275167236328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1438: \tAverage Loss:  1.62762890625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1439: \tAverage Loss:  1.6276380615234376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1440: \tAverage Loss:  1.6276143798828124\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1441: \tAverage Loss:  1.6275164794921875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1442: \tAverage Loss:  1.627357666015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1443: \tAverage Loss:  1.6271588134765624\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1444: \tAverage Loss:  1.6269815673828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1445: \tAverage Loss:  1.6268472900390625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1446: \tAverage Loss:  1.6268751220703126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1447: \tAverage Loss:  1.626989013671875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1448: \tAverage Loss:  1.6270994873046876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1449: \tAverage Loss:  1.6270904541015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1450: \tAverage Loss:  1.62694091796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1451: \tAverage Loss:  1.6267576904296874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1452: \tAverage Loss:  1.6265518798828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1453: \tAverage Loss:  1.626475830078125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1454: \tAverage Loss:  1.6264088134765624\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1455: \tAverage Loss:  1.62645068359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1456: \tAverage Loss:  1.6265135498046874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1457: \tAverage Loss:  1.626515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1458: \tAverage Loss:  1.6263973388671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1459: \tAverage Loss:  1.6262564697265625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1460: \tAverage Loss:  1.6261353759765624\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1461: \tAverage Loss:  1.6260184326171876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1462: \tAverage Loss:  1.625936279296875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1463: \tAverage Loss:  1.625986083984375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1464: \tAverage Loss:  1.62590087890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1465: \tAverage Loss:  1.625897705078125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1466: \tAverage Loss:  1.6258310546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1467: \tAverage Loss:  1.6257791748046875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1468: \tAverage Loss:  1.625656982421875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1469: \tAverage Loss:  1.625626953125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1470: \tAverage Loss:  1.6255758056640626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1471: \tAverage Loss:  1.6255\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1472: \tAverage Loss:  1.6254678955078126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1473: \tAverage Loss:  1.6254197998046875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1474: \tAverage Loss:  1.625373779296875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1475: \tAverage Loss:  1.6253193359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1476: \tAverage Loss:  1.6252581787109375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1477: \tAverage Loss:  1.62518603515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1478: \tAverage Loss:  1.625104736328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1479: \tAverage Loss:  1.6250350341796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1480: \tAverage Loss:  1.6250029296875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1481: \tAverage Loss:  1.624930419921875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1482: \tAverage Loss:  1.624976318359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1483: \tAverage Loss:  1.624928466796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1484: \tAverage Loss:  1.6249144287109376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1485: \tAverage Loss:  1.62493212890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1486: \tAverage Loss:  1.62497705078125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1487: \tAverage Loss:  1.62495556640625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1488: \tAverage Loss:  1.6248712158203125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1489: \tAverage Loss:  1.624750244140625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1490: \tAverage Loss:  1.6246309814453126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1491: \tAverage Loss:  1.6244967041015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1492: \tAverage Loss:  1.62441357421875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1493: \tAverage Loss:  1.624310791015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1494: \tAverage Loss:  1.624261962890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1495: \tAverage Loss:  1.62421923828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1496: \tAverage Loss:  1.6242091064453126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1497: \tAverage Loss:  1.62415478515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1498: \tAverage Loss:  1.624140625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1499: \tAverage Loss:  1.6241397705078124\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1500: \tAverage Loss:  1.62417431640625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1501: \tAverage Loss:  1.6241402587890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1502: \tAverage Loss:  1.6241844482421874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1503: \tAverage Loss:  1.6242359619140625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1504: \tAverage Loss:  1.6242484130859376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1505: \tAverage Loss:  1.624256103515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1506: \tAverage Loss:  1.624162841796875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1507: \tAverage Loss:  1.6240150146484376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1508: \tAverage Loss:  1.623732177734375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1509: \tAverage Loss:  1.6235291748046874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1510: \tAverage Loss:  1.623436767578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1511: \tAverage Loss:  1.62346484375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1512: \tAverage Loss:  1.6234857177734374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1513: \tAverage Loss:  1.62351953125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1514: \tAverage Loss:  1.623531494140625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1515: \tAverage Loss:  1.6234139404296875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1516: \tAverage Loss:  1.62330615234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1517: \tAverage Loss:  1.623158935546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1518: \tAverage Loss:  1.6230482177734376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1519: \tAverage Loss:  1.622951416015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1520: \tAverage Loss:  1.622927490234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1521: \tAverage Loss:  1.6228804931640626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1522: \tAverage Loss:  1.62286962890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1523: \tAverage Loss:  1.6228408203125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1524: \tAverage Loss:  1.6227835693359376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1525: \tAverage Loss:  1.6227069091796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1526: \tAverage Loss:  1.6226688232421875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1527: \tAverage Loss:  1.622633544921875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1528: \tAverage Loss:  1.6225262451171876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1529: \tAverage Loss:  1.622453125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1530: \tAverage Loss:  1.6224044189453124\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1531: \tAverage Loss:  1.6223446044921874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1532: \tAverage Loss:  1.622267333984375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1533: \tAverage Loss:  1.6222279052734374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1534: \tAverage Loss:  1.622224365234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1535: \tAverage Loss:  1.6222139892578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1536: \tAverage Loss:  1.6222303466796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1537: \tAverage Loss:  1.622245361328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1538: \tAverage Loss:  1.6222852783203126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1539: \tAverage Loss:  1.6223314208984374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1540: \tAverage Loss:  1.622410888671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1541: \tAverage Loss:  1.6222515869140626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1542: \tAverage Loss:  1.622111083984375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1543: \tAverage Loss:  1.6219058837890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1544: \tAverage Loss:  1.62174853515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1545: \tAverage Loss:  1.6216396484375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1546: \tAverage Loss:  1.62158984375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1547: \tAverage Loss:  1.621600341796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1548: \tAverage Loss:  1.621570068359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1549: \tAverage Loss:  1.621534423828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1550: \tAverage Loss:  1.62150634765625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1551: \tAverage Loss:  1.621339599609375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1552: \tAverage Loss:  1.6213118896484375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1553: \tAverage Loss:  1.621226806640625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1554: \tAverage Loss:  1.6211473388671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1555: \tAverage Loss:  1.6211513671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1556: \tAverage Loss:  1.621137451171875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1557: \tAverage Loss:  1.621101318359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1558: \tAverage Loss:  1.6210252685546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1559: \tAverage Loss:  1.6210042724609375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1560: \tAverage Loss:  1.621016845703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1561: \tAverage Loss:  1.62099072265625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1562: \tAverage Loss:  1.621020263671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1563: \tAverage Loss:  1.621042724609375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1564: \tAverage Loss:  1.6210089111328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1565: \tAverage Loss:  1.6210523681640625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1566: \tAverage Loss:  1.6209892578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1567: \tAverage Loss:  1.620930908203125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1568: \tAverage Loss:  1.6208302001953125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1569: \tAverage Loss:  1.6207401123046874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1570: \tAverage Loss:  1.6206199951171876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1571: \tAverage Loss:  1.6205029296875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1572: \tAverage Loss:  1.6203453369140626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1573: \tAverage Loss:  1.6202672119140624\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1574: \tAverage Loss:  1.620166015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1575: \tAverage Loss:  1.6201898193359374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1576: \tAverage Loss:  1.620142578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1577: \tAverage Loss:  1.6201431884765625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1578: \tAverage Loss:  1.6202037353515626\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1579: \tAverage Loss:  1.6202310791015626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1580: \tAverage Loss:  1.6202154541015625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1581: \tAverage Loss:  1.6201585693359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1582: \tAverage Loss:  1.61998193359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1583: \tAverage Loss:  1.6199345703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1584: \tAverage Loss:  1.619771240234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1585: \tAverage Loss:  1.6196292724609376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1586: \tAverage Loss:  1.61956787109375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1587: \tAverage Loss:  1.6195653076171874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1588: \tAverage Loss:  1.6195560302734375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1589: \tAverage Loss:  1.6195863037109375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1590: \tAverage Loss:  1.619487548828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1591: \tAverage Loss:  1.6194415283203125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1592: \tAverage Loss:  1.6193653564453125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1593: \tAverage Loss:  1.6193033447265626\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1594: \tAverage Loss:  1.6191943359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1595: \tAverage Loss:  1.6192490234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1596: \tAverage Loss:  1.6192327880859374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1597: \tAverage Loss:  1.619131103515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1598: \tAverage Loss:  1.6190804443359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1599: \tAverage Loss:  1.6190169677734374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1600: \tAverage Loss:  1.618918212890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1601: \tAverage Loss:  1.6189111328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1602: \tAverage Loss:  1.6188880615234376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1603: \tAverage Loss:  1.6187406005859375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1604: \tAverage Loss:  1.618648193359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1605: \tAverage Loss:  1.618643310546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1606: \tAverage Loss:  1.618578857421875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1607: \tAverage Loss:  1.618573486328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1608: \tAverage Loss:  1.61852783203125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1609: \tAverage Loss:  1.618423095703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1610: \tAverage Loss:  1.618408935546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1611: \tAverage Loss:  1.61833642578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1612: \tAverage Loss:  1.6183109130859374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1613: \tAverage Loss:  1.61820166015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1614: \tAverage Loss:  1.6181708984375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1615: \tAverage Loss:  1.6181317138671876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1616: \tAverage Loss:  1.61806298828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1617: \tAverage Loss:  1.6180850830078124\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1618: \tAverage Loss:  1.61804638671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1619: \tAverage Loss:  1.6179417724609375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1620: \tAverage Loss:  1.617958740234375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1621: \tAverage Loss:  1.6179315185546874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1622: \tAverage Loss:  1.6180040283203125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1623: \tAverage Loss:  1.6180726318359375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1624: \tAverage Loss:  1.6181761474609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1625: \tAverage Loss:  1.618327392578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1626: \tAverage Loss:  1.6185047607421874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1627: \tAverage Loss:  1.61842578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1628: \tAverage Loss:  1.6183238525390624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1629: \tAverage Loss:  1.6180174560546876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1630: \tAverage Loss:  1.61768017578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1631: \tAverage Loss:  1.6173621826171876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1632: \tAverage Loss:  1.6172421875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1633: \tAverage Loss:  1.6172391357421876\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1634: \tAverage Loss:  1.6173427734375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1635: \tAverage Loss:  1.617397705078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1636: \tAverage Loss:  1.6173907470703126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1637: \tAverage Loss:  1.6172720947265624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1638: \tAverage Loss:  1.6170537109375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1639: \tAverage Loss:  1.616943603515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1640: \tAverage Loss:  1.616969482421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1641: \tAverage Loss:  1.6168048095703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1642: \tAverage Loss:  1.616804443359375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1643: \tAverage Loss:  1.616740234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1644: \tAverage Loss:  1.616694091796875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1645: \tAverage Loss:  1.616655029296875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1646: \tAverage Loss:  1.6166116943359374\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1647: \tAverage Loss:  1.61656591796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1648: \tAverage Loss:  1.616465087890625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1649: \tAverage Loss:  1.616386962890625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1650: \tAverage Loss:  1.616362060546875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1651: \tAverage Loss:  1.616290771484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1652: \tAverage Loss:  1.6162689208984375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1653: \tAverage Loss:  1.616259521484375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1654: \tAverage Loss:  1.6162091064453126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1655: \tAverage Loss:  1.6161275634765624\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1656: \tAverage Loss:  1.6160877685546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1657: \tAverage Loss:  1.6161173095703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1658: \tAverage Loss:  1.616196533203125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1659: \tAverage Loss:  1.616138916015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1660: \tAverage Loss:  1.61617431640625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1661: \tAverage Loss:  1.6160169677734375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1662: \tAverage Loss:  1.615921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1663: \tAverage Loss:  1.6157684326171875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1664: \tAverage Loss:  1.6157254638671874\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1665: \tAverage Loss:  1.615622802734375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1666: \tAverage Loss:  1.61555517578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1667: \tAverage Loss:  1.6155665283203124\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1668: \tAverage Loss:  1.6155887451171875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1669: \tAverage Loss:  1.61554296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1670: \tAverage Loss:  1.6155811767578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1671: \tAverage Loss:  1.615576904296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1672: \tAverage Loss:  1.6155506591796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1673: \tAverage Loss:  1.6154814453125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1674: \tAverage Loss:  1.61542041015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1675: \tAverage Loss:  1.6152838134765626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1676: \tAverage Loss:  1.61514794921875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1677: \tAverage Loss:  1.6151373291015625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1678: \tAverage Loss:  1.615059326171875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1679: \tAverage Loss:  1.615048828125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1680: \tAverage Loss:  1.6149573974609375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1681: \tAverage Loss:  1.6148541259765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1682: \tAverage Loss:  1.6148123779296875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1683: \tAverage Loss:  1.6147037353515625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1684: \tAverage Loss:  1.614669677734375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1685: \tAverage Loss:  1.61464453125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1686: \tAverage Loss:  1.614582275390625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1687: \tAverage Loss:  1.61460986328125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1688: \tAverage Loss:  1.6146473388671876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1689: \tAverage Loss:  1.61467919921875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1690: \tAverage Loss:  1.614776123046875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1691: \tAverage Loss:  1.6148681640625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1692: \tAverage Loss:  1.6148997802734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1693: \tAverage Loss:  1.6148309326171875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1694: \tAverage Loss:  1.6147835693359376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1695: \tAverage Loss:  1.61463427734375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1696: \tAverage Loss:  1.6144608154296876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1697: \tAverage Loss:  1.614186279296875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1698: \tAverage Loss:  1.6140411376953125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1699: \tAverage Loss:  1.6139332275390625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1700: \tAverage Loss:  1.61394970703125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1701: \tAverage Loss:  1.6140054931640626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1702: \tAverage Loss:  1.6140703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1703: \tAverage Loss:  1.6141580810546876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1704: \tAverage Loss:  1.6141793212890625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1705: \tAverage Loss:  1.6141357421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1706: \tAverage Loss:  1.61390625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1707: \tAverage Loss:  1.613710205078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1708: \tAverage Loss:  1.6136038818359375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1709: \tAverage Loss:  1.6134566650390625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1710: \tAverage Loss:  1.6134261474609375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1711: \tAverage Loss:  1.6133841552734376\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1712: \tAverage Loss:  1.6133922119140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1713: \tAverage Loss:  1.613355224609375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1714: \tAverage Loss:  1.6133563232421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1715: \tAverage Loss:  1.613356689453125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1716: \tAverage Loss:  1.6133385009765624\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1717: \tAverage Loss:  1.6133197021484376\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1718: \tAverage Loss:  1.613283935546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1719: \tAverage Loss:  1.613203369140625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1720: \tAverage Loss:  1.6131142578125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1721: \tAverage Loss:  1.6130269775390624\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1722: \tAverage Loss:  1.612943603515625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1723: \tAverage Loss:  1.61285009765625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1724: \tAverage Loss:  1.6128192138671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1725: \tAverage Loss:  1.6127401123046874\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1726: \tAverage Loss:  1.6126624755859376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1727: \tAverage Loss:  1.6126329345703125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1728: \tAverage Loss:  1.6125517578125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1729: \tAverage Loss:  1.6125369873046875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1730: \tAverage Loss:  1.61257080078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1731: \tAverage Loss:  1.61251953125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1732: \tAverage Loss:  1.61262890625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1733: \tAverage Loss:  1.6126290283203124\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1734: \tAverage Loss:  1.61278955078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1735: \tAverage Loss:  1.612769287109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1736: \tAverage Loss:  1.612817138671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1737: \tAverage Loss:  1.612735107421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1738: \tAverage Loss:  1.6125791015625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1739: \tAverage Loss:  1.6123807373046875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1740: \tAverage Loss:  1.6122188720703126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1741: \tAverage Loss:  1.6120361328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1742: \tAverage Loss:  1.611827880859375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1743: \tAverage Loss:  1.6118143310546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1744: \tAverage Loss:  1.6119776611328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1745: \tAverage Loss:  1.612135986328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1746: \tAverage Loss:  1.6122431640625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1747: \tAverage Loss:  1.6122884521484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1748: \tAverage Loss:  1.612187744140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1749: \tAverage Loss:  1.6119586181640626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1750: \tAverage Loss:  1.6116583251953125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1751: \tAverage Loss:  1.6114462890625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1752: \tAverage Loss:  1.6113741455078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1753: \tAverage Loss:  1.61137744140625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1754: \tAverage Loss:  1.6114295654296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1755: \tAverage Loss:  1.6114169921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1756: \tAverage Loss:  1.6114130859375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1757: \tAverage Loss:  1.6113096923828125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1758: \tAverage Loss:  1.6111488037109376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1759: \tAverage Loss:  1.6110286865234376\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1760: \tAverage Loss:  1.6110203857421874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1761: \tAverage Loss:  1.61096484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1762: \tAverage Loss:  1.6109786376953126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1763: \tAverage Loss:  1.611077392578125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1764: \tAverage Loss:  1.6109765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1765: \tAverage Loss:  1.6109368896484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1766: \tAverage Loss:  1.610927978515625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1767: \tAverage Loss:  1.6109110107421876\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1768: \tAverage Loss:  1.6107994384765625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1769: \tAverage Loss:  1.6107532958984374\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1770: \tAverage Loss:  1.610663330078125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1771: \tAverage Loss:  1.610560791015625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1772: \tAverage Loss:  1.6104560546875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1773: \tAverage Loss:  1.6103824462890626\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1774: \tAverage Loss:  1.610315673828125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1775: \tAverage Loss:  1.6102645263671875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1776: \tAverage Loss:  1.610240478515625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1777: \tAverage Loss:  1.6102215576171874\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1778: \tAverage Loss:  1.610162841796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1779: \tAverage Loss:  1.610130859375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1780: \tAverage Loss:  1.6100924072265625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1781: \tAverage Loss:  1.6100584716796875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1782: \tAverage Loss:  1.6100081787109375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1783: \tAverage Loss:  1.6099744873046875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1784: \tAverage Loss:  1.6099737548828126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1785: \tAverage Loss:  1.6100147705078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1786: \tAverage Loss:  1.6100711669921874\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1787: \tAverage Loss:  1.61025537109375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1788: \tAverage Loss:  1.610431396484375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1789: \tAverage Loss:  1.610447509765625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1790: \tAverage Loss:  1.6103701171875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1791: \tAverage Loss:  1.610263916015625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1792: \tAverage Loss:  1.61000732421875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1793: \tAverage Loss:  1.609614013671875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1794: \tAverage Loss:  1.609414794921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1795: \tAverage Loss:  1.6094219970703125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1796: \tAverage Loss:  1.6094991455078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1797: \tAverage Loss:  1.6094227294921875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1798: \tAverage Loss:  1.609396728515625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1799: \tAverage Loss:  1.6093651123046875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1800: \tAverage Loss:  1.60924072265625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1801: \tAverage Loss:  1.609163330078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1802: \tAverage Loss:  1.6090811767578126\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1803: \tAverage Loss:  1.609004150390625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1804: \tAverage Loss:  1.608926513671875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1805: \tAverage Loss:  1.6088739013671876\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1806: \tAverage Loss:  1.6088472900390625\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1807: \tAverage Loss:  1.6087802734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1808: \tAverage Loss:  1.608798583984375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1809: \tAverage Loss:  1.608701171875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1810: \tAverage Loss:  1.6086737060546874\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1811: \tAverage Loss:  1.60861474609375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1812: \tAverage Loss:  1.60855322265625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1813: \tAverage Loss:  1.6085255126953124\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1814: \tAverage Loss:  1.608469970703125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1815: \tAverage Loss:  1.6084031982421876\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1816: \tAverage Loss:  1.608390380859375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1817: \tAverage Loss:  1.6083095703125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1818: \tAverage Loss:  1.6082974853515626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1819: \tAverage Loss:  1.6082276611328126\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1820: \tAverage Loss:  1.6081866455078124\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1821: \tAverage Loss:  1.608139404296875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1822: \tAverage Loss:  1.6080784912109376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1823: \tAverage Loss:  1.608130859375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1824: \tAverage Loss:  1.6080997314453125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1825: \tAverage Loss:  1.6083756103515625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1826: \tAverage Loss:  1.608595458984375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1827: \tAverage Loss:  1.6089814453125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1828: \tAverage Loss:  1.609416259765625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1829: \tAverage Loss:  1.6093109130859375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1830: \tAverage Loss:  1.608919677734375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1831: \tAverage Loss:  1.60824951171875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1832: \tAverage Loss:  1.60773779296875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1833: \tAverage Loss:  1.6075758056640626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1834: \tAverage Loss:  1.6077220458984376\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1835: \tAverage Loss:  1.6079117431640626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1836: \tAverage Loss:  1.60801708984375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1837: \tAverage Loss:  1.607975830078125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1838: \tAverage Loss:  1.60767041015625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1839: \tAverage Loss:  1.60740966796875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1840: \tAverage Loss:  1.60726171875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1841: \tAverage Loss:  1.607215576171875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1842: \tAverage Loss:  1.6072467041015626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1843: \tAverage Loss:  1.6072891845703126\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1844: \tAverage Loss:  1.6072969970703126\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1845: \tAverage Loss:  1.607254638671875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1846: \tAverage Loss:  1.6071875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1847: \tAverage Loss:  1.607108154296875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1848: \tAverage Loss:  1.606981689453125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1849: \tAverage Loss:  1.606880859375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1850: \tAverage Loss:  1.6067896728515625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1851: \tAverage Loss:  1.6067623291015625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1852: \tAverage Loss:  1.6066842041015625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1853: \tAverage Loss:  1.606718994140625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1854: \tAverage Loss:  1.60675146484375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1855: \tAverage Loss:  1.6067779541015625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1856: \tAverage Loss:  1.6067886962890625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1857: \tAverage Loss:  1.606843017578125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1858: \tAverage Loss:  1.6067584228515626\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1859: \tAverage Loss:  1.606581298828125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1860: \tAverage Loss:  1.6064561767578125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1861: \tAverage Loss:  1.6064287109375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1862: \tAverage Loss:  1.606359375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1863: \tAverage Loss:  1.6063043212890624\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1864: \tAverage Loss:  1.606219482421875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1865: \tAverage Loss:  1.6061380615234375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1866: \tAverage Loss:  1.6061251220703125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1867: \tAverage Loss:  1.60606103515625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1868: \tAverage Loss:  1.6060228271484376\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1869: \tAverage Loss:  1.605957763671875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1870: \tAverage Loss:  1.6059146728515625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1871: \tAverage Loss:  1.605899658203125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1872: \tAverage Loss:  1.605869140625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1873: \tAverage Loss:  1.605821533203125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1874: \tAverage Loss:  1.6057874755859376\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1875: \tAverage Loss:  1.60588330078125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1876: \tAverage Loss:  1.6059605712890626\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1877: \tAverage Loss:  1.6060535888671874\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1878: \tAverage Loss:  1.6060089111328124\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1879: \tAverage Loss:  1.60603369140625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1880: \tAverage Loss:  1.6058197021484375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1881: \tAverage Loss:  1.6056434326171876\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1882: \tAverage Loss:  1.605472412109375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1883: \tAverage Loss:  1.605333740234375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1884: \tAverage Loss:  1.60524853515625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1885: \tAverage Loss:  1.6052601318359374\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1886: \tAverage Loss:  1.6053212890625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1887: \tAverage Loss:  1.6052734375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1888: \tAverage Loss:  1.6052669677734375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1889: \tAverage Loss:  1.605171142578125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1890: \tAverage Loss:  1.60512646484375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1891: \tAverage Loss:  1.605056640625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1892: \tAverage Loss:  1.6049725341796874\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1893: \tAverage Loss:  1.60492626953125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1894: \tAverage Loss:  1.604892333984375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1895: \tAverage Loss:  1.6048223876953125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1896: \tAverage Loss:  1.604786865234375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1897: \tAverage Loss:  1.604885498046875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1898: \tAverage Loss:  1.6048668212890624\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1899: \tAverage Loss:  1.6049007568359375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1900: \tAverage Loss:  1.60500634765625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1901: \tAverage Loss:  1.60504345703125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1902: \tAverage Loss:  1.6047938232421874\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1903: \tAverage Loss:  1.60466064453125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1904: \tAverage Loss:  1.604560791015625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1905: \tAverage Loss:  1.6044647216796875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1906: \tAverage Loss:  1.6044346923828126\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1907: \tAverage Loss:  1.604311279296875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1908: \tAverage Loss:  1.604263916015625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1909: \tAverage Loss:  1.6042081298828126\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1910: \tAverage Loss:  1.604127685546875\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1911: \tAverage Loss:  1.6040457763671876\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1912: \tAverage Loss:  1.6039906005859375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1913: \tAverage Loss:  1.6039906005859375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1914: \tAverage Loss:  1.603920654296875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1915: \tAverage Loss:  1.6038387451171876\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1916: \tAverage Loss:  1.6037940673828126\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1917: \tAverage Loss:  1.60375048828125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1918: \tAverage Loss:  1.6037039794921875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1919: \tAverage Loss:  1.6037794189453125\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1920: \tAverage Loss:  1.603589111328125\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1921: \tAverage Loss:  1.6036058349609374\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1922: \tAverage Loss:  1.6035172119140626\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1923: \tAverage Loss:  1.6034547119140625\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1924: \tAverage Loss:  1.603452880859375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1925: \tAverage Loss:  1.603368896484375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1926: \tAverage Loss:  1.603458740234375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1927: \tAverage Loss:  1.603349609375\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1928: \tAverage Loss:  1.6033072509765625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1929: \tAverage Loss:  1.6033111572265626\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1930: \tAverage Loss:  1.6034222412109376\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1931: \tAverage Loss:  1.603798095703125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1932: \tAverage Loss:  1.60403662109375\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1933: \tAverage Loss:  1.60439453125\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1934: \tAverage Loss:  1.60474951171875\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1935: \tAverage Loss:  1.604818603515625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1936: \tAverage Loss:  1.6041578369140626\t ACC train:  1.0\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1937: \tAverage Loss:  1.603453369140625\t ACC train:  1.0\t ACC test:  0.9755555555555555\n",
      "Stopping early at epoch 1937. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 600\n",
      "\tEpoch 1: \tAverage Loss:  2.6316613464355467\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 2: \tAverage Loss:  2.6132322692871095\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 3: \tAverage Loss:  2.5975687561035157\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 4: \tAverage Loss:  2.583505676269531\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 5: \tAverage Loss:  2.570206512451172\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 6: \tAverage Loss:  2.5577716064453124\t ACC train:  0.5066666666666667\t ACC test:  0.48444444444444446\n",
      "\tEpoch 7: \tAverage Loss:  2.5457403564453127\t ACC train:  0.5066666666666667\t ACC test:  0.48444444444444446\n",
      "\tEpoch 8: \tAverage Loss:  2.5345214538574217\t ACC train:  0.5033333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 9: \tAverage Loss:  2.5234548034667967\t ACC train:  0.5083333333333333\t ACC test:  0.4822222222222222\n",
      "\tEpoch 10: \tAverage Loss:  2.512731231689453\t ACC train:  0.5083333333333333\t ACC test:  0.4822222222222222\n",
      "\tEpoch 11: \tAverage Loss:  2.502365936279297\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  2.4927532958984373\t ACC train:  0.5083333333333333\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  2.4828582458496093\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  2.4731039428710937\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  2.463977020263672\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  2.4544903869628905\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  2.4458573303222657\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  2.4370394287109374\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  2.429042541503906\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  2.4207518310546874\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  2.4124788818359373\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  2.4047813720703126\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  2.396311767578125\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  2.3881707458496093\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  2.381308044433594\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  2.3729073486328125\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  2.3655896301269532\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  2.3570726318359374\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  2.3499607238769533\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  2.343975799560547\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  2.333079437255859\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  2.325235809326172\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  2.3168767700195314\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  2.3096401672363283\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  2.2982618408203126\t ACC train:  0.51\t ACC test:  0.4888888888888889\n",
      "\tEpoch 36: \tAverage Loss:  2.288133087158203\t ACC train:  0.515\t ACC test:  0.4888888888888889\n",
      "\tEpoch 37: \tAverage Loss:  2.28006884765625\t ACC train:  0.5283333333333333\t ACC test:  0.5\n",
      "\tEpoch 38: \tAverage Loss:  2.2720555725097658\t ACC train:  0.5483333333333333\t ACC test:  0.5288888888888889\n",
      "\tEpoch 39: \tAverage Loss:  2.262499755859375\t ACC train:  0.5583333333333333\t ACC test:  0.5311111111111111\n",
      "\tEpoch 40: \tAverage Loss:  2.248182678222656\t ACC train:  0.5716666666666667\t ACC test:  0.5511111111111111\n",
      "\tEpoch 41: \tAverage Loss:  2.238696960449219\t ACC train:  0.5783333333333334\t ACC test:  0.5577777777777778\n",
      "\tEpoch 42: \tAverage Loss:  2.2163487854003905\t ACC train:  0.595\t ACC test:  0.5733333333333334\n",
      "\tEpoch 43: \tAverage Loss:  2.211313720703125\t ACC train:  0.6033333333333334\t ACC test:  0.56\n",
      "\tEpoch 44: \tAverage Loss:  2.2000811157226563\t ACC train:  0.6133333333333333\t ACC test:  0.5555555555555556\n",
      "\tEpoch 45: \tAverage Loss:  2.179733551025391\t ACC train:  0.5816666666666667\t ACC test:  0.6022222222222222\n",
      "\tEpoch 46: \tAverage Loss:  2.1596839599609376\t ACC train:  0.59\t ACC test:  0.5844444444444444\n",
      "\tEpoch 47: \tAverage Loss:  2.1429660339355467\t ACC train:  0.595\t ACC test:  0.5933333333333334\n",
      "\tEpoch 48: \tAverage Loss:  2.1310337219238282\t ACC train:  0.5966666666666667\t ACC test:  0.5822222222222222\n",
      "\tEpoch 49: \tAverage Loss:  2.114129699707031\t ACC train:  0.61\t ACC test:  0.6044444444444445\n",
      "\tEpoch 50: \tAverage Loss:  2.1087725524902345\t ACC train:  0.595\t ACC test:  0.5866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  2.1047574768066406\t ACC train:  0.5983333333333334\t ACC test:  0.5955555555555555\n",
      "\tEpoch 52: \tAverage Loss:  2.0707657165527342\t ACC train:  0.6133333333333333\t ACC test:  0.6066666666666667\n",
      "\tEpoch 53: \tAverage Loss:  2.054348205566406\t ACC train:  0.5916666666666667\t ACC test:  0.58\n",
      "\tEpoch 54: \tAverage Loss:  2.0594226989746094\t ACC train:  0.5883333333333334\t ACC test:  0.6088888888888889\n",
      "\tEpoch 55: \tAverage Loss:  2.032904754638672\t ACC train:  0.595\t ACC test:  0.58\n",
      "\tEpoch 56: \tAverage Loss:  2.0253023986816405\t ACC train:  0.5816666666666667\t ACC test:  0.5822222222222222\n",
      "\tEpoch 57: \tAverage Loss:  1.9884085693359375\t ACC train:  0.585\t ACC test:  0.5688888888888889\n",
      "\tEpoch 58: \tAverage Loss:  1.9795825500488282\t ACC train:  0.5833333333333334\t ACC test:  0.58\n",
      "\tEpoch 59: \tAverage Loss:  1.9680869445800782\t ACC train:  0.5816666666666667\t ACC test:  0.5511111111111111\n",
      "\tEpoch 60: \tAverage Loss:  1.9556306457519532\t ACC train:  0.5533333333333333\t ACC test:  0.5555555555555556\n",
      "\tEpoch 61: \tAverage Loss:  1.9323759765625\t ACC train:  0.57\t ACC test:  0.5577777777777778\n",
      "\tEpoch 62: \tAverage Loss:  1.9145552673339843\t ACC train:  0.5483333333333333\t ACC test:  0.5666666666666667\n",
      "\tEpoch 63: \tAverage Loss:  1.9102325134277345\t ACC train:  0.5666666666666667\t ACC test:  0.5444444444444444\n",
      "\tEpoch 64: \tAverage Loss:  1.89763720703125\t ACC train:  0.5583333333333333\t ACC test:  0.5577777777777778\n",
      "\tEpoch 65: \tAverage Loss:  1.8852601318359374\t ACC train:  0.56\t ACC test:  0.5511111111111111\n",
      "\tEpoch 66: \tAverage Loss:  1.8670531616210937\t ACC train:  0.5583333333333333\t ACC test:  0.5511111111111111\n",
      "\tEpoch 67: \tAverage Loss:  1.8551046142578125\t ACC train:  0.5783333333333334\t ACC test:  0.5622222222222222\n",
      "\tEpoch 68: \tAverage Loss:  1.8429456176757812\t ACC train:  0.5866666666666667\t ACC test:  0.5688888888888889\n",
      "\tEpoch 69: \tAverage Loss:  1.8417042236328125\t ACC train:  0.5716666666666667\t ACC test:  0.5555555555555556\n",
      "\tEpoch 70: \tAverage Loss:  1.8252559509277344\t ACC train:  0.5683333333333334\t ACC test:  0.5555555555555556\n",
      "\tEpoch 71: \tAverage Loss:  1.8096192321777345\t ACC train:  0.5683333333333334\t ACC test:  0.5711111111111111\n",
      "\tEpoch 72: \tAverage Loss:  1.7992824096679687\t ACC train:  0.575\t ACC test:  0.5688888888888889\n",
      "\tEpoch 73: \tAverage Loss:  1.7917527770996093\t ACC train:  0.5683333333333334\t ACC test:  0.5711111111111111\n",
      "\tEpoch 74: \tAverage Loss:  1.779369140625\t ACC train:  0.5583333333333333\t ACC test:  0.5511111111111111\n",
      "\tEpoch 75: \tAverage Loss:  1.7751597900390625\t ACC train:  0.5733333333333334\t ACC test:  0.5577777777777778\n",
      "\tEpoch 76: \tAverage Loss:  1.7682059020996095\t ACC train:  0.57\t ACC test:  0.5666666666666667\n",
      "\tEpoch 77: \tAverage Loss:  1.7549408264160156\t ACC train:  0.5633333333333334\t ACC test:  0.5555555555555556\n",
      "\tEpoch 78: \tAverage Loss:  1.7452209167480468\t ACC train:  0.5716666666666667\t ACC test:  0.58\n",
      "\tEpoch 79: \tAverage Loss:  1.73880908203125\t ACC train:  0.58\t ACC test:  0.5688888888888889\n",
      "\tEpoch 80: \tAverage Loss:  1.7275001220703126\t ACC train:  0.5716666666666667\t ACC test:  0.5777777777777777\n",
      "\tEpoch 81: \tAverage Loss:  1.7176493530273438\t ACC train:  0.5883333333333334\t ACC test:  0.5711111111111111\n",
      "\tEpoch 82: \tAverage Loss:  1.707585662841797\t ACC train:  0.5683333333333334\t ACC test:  0.5755555555555556\n",
      "\tEpoch 83: \tAverage Loss:  1.7054357604980468\t ACC train:  0.58\t ACC test:  0.5733333333333334\n",
      "\tEpoch 84: \tAverage Loss:  1.697847900390625\t ACC train:  0.5816666666666667\t ACC test:  0.5844444444444444\n",
      "\tEpoch 85: \tAverage Loss:  1.6887009887695312\t ACC train:  0.5883333333333334\t ACC test:  0.5622222222222222\n",
      "\tEpoch 86: \tAverage Loss:  1.6762234497070312\t ACC train:  0.59\t ACC test:  0.5666666666666667\n",
      "\tEpoch 87: \tAverage Loss:  1.6739895629882813\t ACC train:  0.6033333333333334\t ACC test:  0.5844444444444444\n",
      "\tEpoch 88: \tAverage Loss:  1.6667454528808594\t ACC train:  0.59\t ACC test:  0.5622222222222222\n",
      "\tEpoch 89: \tAverage Loss:  1.6610408935546874\t ACC train:  0.6\t ACC test:  0.5666666666666667\n",
      "\tEpoch 90: \tAverage Loss:  1.6576600952148437\t ACC train:  0.595\t ACC test:  0.5622222222222222\n",
      "\tEpoch 91: \tAverage Loss:  1.650554229736328\t ACC train:  0.585\t ACC test:  0.5622222222222222\n",
      "\tEpoch 92: \tAverage Loss:  1.6473453674316407\t ACC train:  0.5916666666666667\t ACC test:  0.5755555555555556\n",
      "\tEpoch 93: \tAverage Loss:  1.6384013671875\t ACC train:  0.595\t ACC test:  0.58\n",
      "\tEpoch 94: \tAverage Loss:  1.6301009826660156\t ACC train:  0.61\t ACC test:  0.5844444444444444\n",
      "\tEpoch 95: \tAverage Loss:  1.6254227294921875\t ACC train:  0.595\t ACC test:  0.5755555555555556\n",
      "\tEpoch 96: \tAverage Loss:  1.6246139373779296\t ACC train:  0.5866666666666667\t ACC test:  0.5733333333333334\n",
      "\tEpoch 97: \tAverage Loss:  1.617251953125\t ACC train:  0.6066666666666667\t ACC test:  0.5644444444444444\n",
      "\tEpoch 98: \tAverage Loss:  1.6112440185546875\t ACC train:  0.6083333333333333\t ACC test:  0.5844444444444444\n",
      "\tEpoch 99: \tAverage Loss:  1.608037872314453\t ACC train:  0.61\t ACC test:  0.5755555555555556\n",
      "\tEpoch 100: \tAverage Loss:  1.6057793884277343\t ACC train:  0.6\t ACC test:  0.5777777777777777\n",
      "\tEpoch 101: \tAverage Loss:  1.6013343505859374\t ACC train:  0.605\t ACC test:  0.5644444444444444\n",
      "\tEpoch 102: \tAverage Loss:  1.596556915283203\t ACC train:  0.6166666666666667\t ACC test:  0.5777777777777777\n",
      "\tEpoch 103: \tAverage Loss:  1.5934927673339845\t ACC train:  0.6166666666666667\t ACC test:  0.58\n",
      "\tEpoch 104: \tAverage Loss:  1.587217987060547\t ACC train:  0.605\t ACC test:  0.5844444444444444\n",
      "\tEpoch 105: \tAverage Loss:  1.5835966796875\t ACC train:  0.6083333333333333\t ACC test:  0.5933333333333334\n",
      "\tEpoch 106: \tAverage Loss:  1.5807718811035156\t ACC train:  0.6183333333333333\t ACC test:  0.6\n",
      "\tEpoch 107: \tAverage Loss:  1.5760514221191406\t ACC train:  0.6233333333333333\t ACC test:  0.5866666666666667\n",
      "\tEpoch 108: \tAverage Loss:  1.5764852905273437\t ACC train:  0.6166666666666667\t ACC test:  0.5888888888888889\n",
      "\tEpoch 109: \tAverage Loss:  1.5704347839355468\t ACC train:  0.6216666666666667\t ACC test:  0.5888888888888889\n",
      "\tEpoch 110: \tAverage Loss:  1.568757049560547\t ACC train:  0.6216666666666667\t ACC test:  0.6066666666666667\n",
      "\tEpoch 111: \tAverage Loss:  1.5663524475097657\t ACC train:  0.6316666666666667\t ACC test:  0.6\n",
      "\tEpoch 112: \tAverage Loss:  1.5604554443359375\t ACC train:  0.6183333333333333\t ACC test:  0.5933333333333334\n",
      "\tEpoch 113: \tAverage Loss:  1.557541290283203\t ACC train:  0.6216666666666667\t ACC test:  0.5844444444444444\n",
      "\tEpoch 114: \tAverage Loss:  1.5550617065429688\t ACC train:  0.63\t ACC test:  0.6\n",
      "\tEpoch 115: \tAverage Loss:  1.5515021362304688\t ACC train:  0.6266666666666667\t ACC test:  0.6022222222222222\n",
      "\tEpoch 116: \tAverage Loss:  1.5501154174804688\t ACC train:  0.625\t ACC test:  0.5866666666666667\n",
      "\tEpoch 117: \tAverage Loss:  1.54605126953125\t ACC train:  0.6283333333333333\t ACC test:  0.6133333333333333\n",
      "\tEpoch 118: \tAverage Loss:  1.5443501586914063\t ACC train:  0.635\t ACC test:  0.6066666666666667\n",
      "\tEpoch 119: \tAverage Loss:  1.5410388793945313\t ACC train:  0.6333333333333333\t ACC test:  0.6066666666666667\n",
      "\tEpoch 120: \tAverage Loss:  1.5382855682373047\t ACC train:  0.625\t ACC test:  0.6\n",
      "\tEpoch 121: \tAverage Loss:  1.537652618408203\t ACC train:  0.6416666666666667\t ACC test:  0.6066666666666667\n",
      "\tEpoch 122: \tAverage Loss:  1.5357445373535157\t ACC train:  0.635\t ACC test:  0.5955555555555555\n",
      "\tEpoch 123: \tAverage Loss:  1.5317868957519531\t ACC train:  0.645\t ACC test:  0.6111111111111112\n",
      "\tEpoch 124: \tAverage Loss:  1.5284461059570313\t ACC train:  0.63\t ACC test:  0.6\n",
      "\tEpoch 125: \tAverage Loss:  1.5269542541503907\t ACC train:  0.6316666666666667\t ACC test:  0.6044444444444445\n",
      "\tEpoch 126: \tAverage Loss:  1.5240349578857422\t ACC train:  0.6416666666666667\t ACC test:  0.6066666666666667\n",
      "\tEpoch 127: \tAverage Loss:  1.5230486450195313\t ACC train:  0.65\t ACC test:  0.6266666666666667\n",
      "\tEpoch 128: \tAverage Loss:  1.5204506530761719\t ACC train:  0.64\t ACC test:  0.6111111111111112\n",
      "\tEpoch 129: \tAverage Loss:  1.5181623687744141\t ACC train:  0.65\t ACC test:  0.6177777777777778\n",
      "\tEpoch 130: \tAverage Loss:  1.516337188720703\t ACC train:  0.6516666666666666\t ACC test:  0.6244444444444445\n",
      "\tEpoch 131: \tAverage Loss:  1.5144613647460938\t ACC train:  0.645\t ACC test:  0.6111111111111112\n",
      "\tEpoch 132: \tAverage Loss:  1.5132813873291016\t ACC train:  0.655\t ACC test:  0.6066666666666667\n",
      "\tEpoch 133: \tAverage Loss:  1.511955093383789\t ACC train:  0.6466666666666666\t ACC test:  0.6177777777777778\n",
      "\tEpoch 134: \tAverage Loss:  1.5097808685302734\t ACC train:  0.6483333333333333\t ACC test:  0.6177777777777778\n",
      "\tEpoch 135: \tAverage Loss:  1.5068770751953124\t ACC train:  0.6433333333333333\t ACC test:  0.6088888888888889\n",
      "\tEpoch 136: \tAverage Loss:  1.5054275817871094\t ACC train:  0.655\t ACC test:  0.6155555555555555\n",
      "\tEpoch 137: \tAverage Loss:  1.5036184387207032\t ACC train:  0.6583333333333333\t ACC test:  0.6244444444444445\n",
      "\tEpoch 138: \tAverage Loss:  1.5031512451171876\t ACC train:  0.6483333333333333\t ACC test:  0.6222222222222222\n",
      "\tEpoch 139: \tAverage Loss:  1.4997698822021484\t ACC train:  0.6483333333333333\t ACC test:  0.62\n",
      "\tEpoch 140: \tAverage Loss:  1.4979653778076172\t ACC train:  0.6533333333333333\t ACC test:  0.6355555555555555\n",
      "\tEpoch 141: \tAverage Loss:  1.497653564453125\t ACC train:  0.66\t ACC test:  0.6311111111111111\n",
      "\tEpoch 142: \tAverage Loss:  1.4949476165771485\t ACC train:  0.6516666666666666\t ACC test:  0.6244444444444445\n",
      "\tEpoch 143: \tAverage Loss:  1.494685073852539\t ACC train:  0.6616666666666666\t ACC test:  0.6222222222222222\n",
      "\tEpoch 144: \tAverage Loss:  1.491635498046875\t ACC train:  0.6633333333333333\t ACC test:  0.6311111111111111\n",
      "\tEpoch 145: \tAverage Loss:  1.490688720703125\t ACC train:  0.6566666666666666\t ACC test:  0.6288888888888889\n",
      "\tEpoch 146: \tAverage Loss:  1.488285140991211\t ACC train:  0.6566666666666666\t ACC test:  0.62\n",
      "\tEpoch 147: \tAverage Loss:  1.4874256591796875\t ACC train:  0.66\t ACC test:  0.6288888888888889\n",
      "\tEpoch 148: \tAverage Loss:  1.485578872680664\t ACC train:  0.6566666666666666\t ACC test:  0.6222222222222222\n",
      "\tEpoch 149: \tAverage Loss:  1.4847078552246094\t ACC train:  0.6583333333333333\t ACC test:  0.6244444444444445\n",
      "\tEpoch 150: \tAverage Loss:  1.4830796966552735\t ACC train:  0.67\t ACC test:  0.64\n",
      "\tEpoch 151: \tAverage Loss:  1.481603042602539\t ACC train:  0.6516666666666666\t ACC test:  0.6355555555555555\n",
      "\tEpoch 152: \tAverage Loss:  1.4795716400146484\t ACC train:  0.6633333333333333\t ACC test:  0.6355555555555555\n",
      "\tEpoch 153: \tAverage Loss:  1.479064666748047\t ACC train:  0.6616666666666666\t ACC test:  0.6333333333333333\n",
      "\tEpoch 154: \tAverage Loss:  1.4785162353515624\t ACC train:  0.665\t ACC test:  0.6288888888888889\n",
      "\tEpoch 155: \tAverage Loss:  1.4761196594238282\t ACC train:  0.67\t ACC test:  0.6444444444444445\n",
      "\tEpoch 156: \tAverage Loss:  1.4764680786132813\t ACC train:  0.6683333333333333\t ACC test:  0.6377777777777778\n",
      "\tEpoch 157: \tAverage Loss:  1.473552749633789\t ACC train:  0.6633333333333333\t ACC test:  0.6488888888888888\n",
      "\tEpoch 158: \tAverage Loss:  1.4727786865234376\t ACC train:  0.6683333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 159: \tAverage Loss:  1.4727290649414062\t ACC train:  0.6683333333333333\t ACC test:  0.64\n",
      "\tEpoch 160: \tAverage Loss:  1.4711296081542968\t ACC train:  0.6616666666666666\t ACC test:  0.6422222222222222\n",
      "\tEpoch 161: \tAverage Loss:  1.468194564819336\t ACC train:  0.67\t ACC test:  0.6444444444444445\n",
      "\tEpoch 162: \tAverage Loss:  1.4683687896728517\t ACC train:  0.6666666666666666\t ACC test:  0.6444444444444445\n",
      "\tEpoch 163: \tAverage Loss:  1.4668312377929686\t ACC train:  0.67\t ACC test:  0.6488888888888888\n",
      "\tEpoch 164: \tAverage Loss:  1.4667722778320313\t ACC train:  0.6766666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 165: \tAverage Loss:  1.4650064697265626\t ACC train:  0.6733333333333333\t ACC test:  0.6488888888888888\n",
      "\tEpoch 166: \tAverage Loss:  1.4641092529296875\t ACC train:  0.675\t ACC test:  0.6466666666666666\n",
      "\tEpoch 167: \tAverage Loss:  1.4628582763671876\t ACC train:  0.6716666666666666\t ACC test:  0.6488888888888888\n",
      "\tEpoch 168: \tAverage Loss:  1.4618090362548828\t ACC train:  0.6683333333333333\t ACC test:  0.6422222222222222\n",
      "\tEpoch 169: \tAverage Loss:  1.461286605834961\t ACC train:  0.6716666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 170: \tAverage Loss:  1.4604185485839845\t ACC train:  0.675\t ACC test:  0.6488888888888888\n",
      "\tEpoch 171: \tAverage Loss:  1.4596312103271485\t ACC train:  0.6733333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 172: \tAverage Loss:  1.4590518188476562\t ACC train:  0.6716666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 173: \tAverage Loss:  1.4577725982666017\t ACC train:  0.6766666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 174: \tAverage Loss:  1.4564271850585937\t ACC train:  0.675\t ACC test:  0.6511111111111111\n",
      "\tEpoch 175: \tAverage Loss:  1.4552809753417968\t ACC train:  0.675\t ACC test:  0.6511111111111111\n",
      "\tEpoch 176: \tAverage Loss:  1.455321060180664\t ACC train:  0.6733333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 177: \tAverage Loss:  1.4539228057861329\t ACC train:  0.6766666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 178: \tAverage Loss:  1.451467086791992\t ACC train:  0.675\t ACC test:  0.6511111111111111\n",
      "\tEpoch 179: \tAverage Loss:  1.452825210571289\t ACC train:  0.675\t ACC test:  0.6488888888888888\n",
      "\tEpoch 180: \tAverage Loss:  1.451086944580078\t ACC train:  0.6733333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 181: \tAverage Loss:  1.4495699310302734\t ACC train:  0.6783333333333333\t ACC test:  0.6466666666666666\n",
      "\tEpoch 182: \tAverage Loss:  1.4496040954589844\t ACC train:  0.6766666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 183: \tAverage Loss:  1.4490962219238281\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 184: \tAverage Loss:  1.4485079040527344\t ACC train:  0.6716666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 185: \tAverage Loss:  1.448499542236328\t ACC train:  0.6766666666666666\t ACC test:  0.6488888888888888\n",
      "\tEpoch 186: \tAverage Loss:  1.4461107788085938\t ACC train:  0.6766666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 187: \tAverage Loss:  1.4455849609375\t ACC train:  0.6783333333333333\t ACC test:  0.6488888888888888\n",
      "\tEpoch 188: \tAverage Loss:  1.4447485961914062\t ACC train:  0.6766666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 189: \tAverage Loss:  1.4448596801757811\t ACC train:  0.6783333333333333\t ACC test:  0.6466666666666666\n",
      "\tEpoch 190: \tAverage Loss:  1.4433158874511718\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 191: \tAverage Loss:  1.442060073852539\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 192: \tAverage Loss:  1.4419707336425782\t ACC train:  0.6766666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 193: \tAverage Loss:  1.4414231262207031\t ACC train:  0.6783333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 194: \tAverage Loss:  1.4410846710205079\t ACC train:  0.6783333333333333\t ACC test:  0.6488888888888888\n",
      "\tEpoch 195: \tAverage Loss:  1.4397658538818359\t ACC train:  0.68\t ACC test:  0.6466666666666666\n",
      "\tEpoch 196: \tAverage Loss:  1.4394734497070312\t ACC train:  0.68\t ACC test:  0.6511111111111111\n",
      "\tEpoch 197: \tAverage Loss:  1.438743453979492\t ACC train:  0.68\t ACC test:  0.6488888888888888\n",
      "\tEpoch 198: \tAverage Loss:  1.4380395355224609\t ACC train:  0.6816666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 199: \tAverage Loss:  1.4365345458984375\t ACC train:  0.6783333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 200: \tAverage Loss:  1.4370117034912109\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 201: \tAverage Loss:  1.4359785614013671\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 202: \tAverage Loss:  1.435264846801758\t ACC train:  0.6816666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 203: \tAverage Loss:  1.435171157836914\t ACC train:  0.6816666666666666\t ACC test:  0.6533333333333333\n",
      "\tEpoch 204: \tAverage Loss:  1.4344271087646485\t ACC train:  0.6816666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 205: \tAverage Loss:  1.433269073486328\t ACC train:  0.6816666666666666\t ACC test:  0.6533333333333333\n",
      "\tEpoch 206: \tAverage Loss:  1.433085968017578\t ACC train:  0.6816666666666666\t ACC test:  0.6488888888888888\n",
      "\tEpoch 207: \tAverage Loss:  1.432505584716797\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 208: \tAverage Loss:  1.431470458984375\t ACC train:  0.6816666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 209: \tAverage Loss:  1.4315145111083984\t ACC train:  0.68\t ACC test:  0.6533333333333333\n",
      "\tEpoch 210: \tAverage Loss:  1.4311389770507812\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 211: \tAverage Loss:  1.4318011474609376\t ACC train:  0.6766666666666666\t ACC test:  0.6533333333333333\n",
      "\tEpoch 212: \tAverage Loss:  1.4311130981445312\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 213: \tAverage Loss:  1.4297005920410155\t ACC train:  0.6816666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 214: \tAverage Loss:  1.4289749450683593\t ACC train:  0.6816666666666666\t ACC test:  0.6533333333333333\n",
      "\tEpoch 215: \tAverage Loss:  1.4282215576171875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 216: \tAverage Loss:  1.4280314025878906\t ACC train:  0.6816666666666666\t ACC test:  0.6488888888888888\n",
      "\tEpoch 217: \tAverage Loss:  1.4281327514648436\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 218: \tAverage Loss:  1.428087677001953\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 219: \tAverage Loss:  1.4262234344482423\t ACC train:  0.6833333333333333\t ACC test:  0.6488888888888888\n",
      "\tEpoch 220: \tAverage Loss:  1.425511016845703\t ACC train:  0.68\t ACC test:  0.6533333333333333\n",
      "\tEpoch 221: \tAverage Loss:  1.4251494903564452\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 222: \tAverage Loss:  1.424555923461914\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 223: \tAverage Loss:  1.4242136535644532\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 224: \tAverage Loss:  1.4235775146484375\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 225: \tAverage Loss:  1.422738265991211\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 226: \tAverage Loss:  1.4221243896484375\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 227: \tAverage Loss:  1.4224751281738282\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 228: \tAverage Loss:  1.4220558624267579\t ACC train:  0.6833333333333333\t ACC test:  0.6555555555555556\n",
      "\tEpoch 229: \tAverage Loss:  1.4218553466796875\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 230: \tAverage Loss:  1.4208301544189452\t ACC train:  0.6816666666666666\t ACC test:  0.6555555555555556\n",
      "\tEpoch 231: \tAverage Loss:  1.4213968200683593\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 232: \tAverage Loss:  1.420091766357422\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 233: \tAverage Loss:  1.4193247222900391\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 234: \tAverage Loss:  1.4191858520507812\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 235: \tAverage Loss:  1.4194037628173828\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 236: \tAverage Loss:  1.418818344116211\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 237: \tAverage Loss:  1.4180819091796875\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 238: \tAverage Loss:  1.4171992492675782\t ACC train:  0.6816666666666666\t ACC test:  0.6533333333333333\n",
      "\tEpoch 239: \tAverage Loss:  1.4168941955566405\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 240: \tAverage Loss:  1.4168578338623048\t ACC train:  0.6833333333333333\t ACC test:  0.6488888888888888\n",
      "\tEpoch 241: \tAverage Loss:  1.4159967346191407\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 242: \tAverage Loss:  1.4158303680419921\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 243: \tAverage Loss:  1.4152926025390624\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 244: \tAverage Loss:  1.4155615692138672\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 245: \tAverage Loss:  1.4146869506835937\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 246: \tAverage Loss:  1.4141392059326172\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 247: \tAverage Loss:  1.4145641326904297\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 248: \tAverage Loss:  1.413900421142578\t ACC train:  0.685\t ACC test:  0.6488888888888888\n",
      "\tEpoch 249: \tAverage Loss:  1.4131505889892577\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 250: \tAverage Loss:  1.4129643249511719\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 251: \tAverage Loss:  1.4127086334228516\t ACC train:  0.6833333333333333\t ACC test:  0.6555555555555556\n",
      "\tEpoch 252: \tAverage Loss:  1.4120665130615235\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 253: \tAverage Loss:  1.412999282836914\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 254: \tAverage Loss:  1.4123149871826173\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 255: \tAverage Loss:  1.412444091796875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 256: \tAverage Loss:  1.4106775817871093\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 257: \tAverage Loss:  1.410647430419922\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 258: \tAverage Loss:  1.4095184478759766\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 259: \tAverage Loss:  1.4096959838867187\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 260: \tAverage Loss:  1.409958511352539\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 261: \tAverage Loss:  1.4084150695800781\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 262: \tAverage Loss:  1.4084608001708985\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 263: \tAverage Loss:  1.4082178497314453\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 264: \tAverage Loss:  1.4074232482910156\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 265: \tAverage Loss:  1.40700439453125\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 266: \tAverage Loss:  1.406794677734375\t ACC train:  0.685\t ACC test:  0.6466666666666666\n",
      "\tEpoch 267: \tAverage Loss:  1.4068358917236328\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 268: \tAverage Loss:  1.406241943359375\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 269: \tAverage Loss:  1.4060871887207032\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 270: \tAverage Loss:  1.4060323333740234\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 271: \tAverage Loss:  1.4059240875244141\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 272: \tAverage Loss:  1.4055111694335938\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 273: \tAverage Loss:  1.4051315307617187\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 274: \tAverage Loss:  1.4052654724121094\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 275: \tAverage Loss:  1.4045998382568359\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 276: \tAverage Loss:  1.4047965087890626\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 277: \tAverage Loss:  1.4036944732666015\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 278: \tAverage Loss:  1.4038184814453125\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 279: \tAverage Loss:  1.4031009521484374\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 280: \tAverage Loss:  1.4020750274658202\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 281: \tAverage Loss:  1.4032633819580078\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 282: \tAverage Loss:  1.4020192260742188\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 283: \tAverage Loss:  1.4017000122070313\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 284: \tAverage Loss:  1.4015218048095703\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 285: \tAverage Loss:  1.401289077758789\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 286: \tAverage Loss:  1.4012992553710937\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 287: \tAverage Loss:  1.4012517547607422\t ACC train:  0.6833333333333333\t ACC test:  0.6511111111111111\n",
      "\tEpoch 288: \tAverage Loss:  1.4010576324462891\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 289: \tAverage Loss:  1.4004825439453126\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 290: \tAverage Loss:  1.3995942993164063\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 291: \tAverage Loss:  1.3994947967529296\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 292: \tAverage Loss:  1.39921044921875\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 293: \tAverage Loss:  1.3995711059570313\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 294: \tAverage Loss:  1.3987017059326172\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 295: \tAverage Loss:  1.398748779296875\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 296: \tAverage Loss:  1.3980659332275391\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 297: \tAverage Loss:  1.3979260559082032\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 298: \tAverage Loss:  1.3974865264892578\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 299: \tAverage Loss:  1.3973202362060546\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 300: \tAverage Loss:  1.3976680603027343\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 301: \tAverage Loss:  1.397436065673828\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 302: \tAverage Loss:  1.3969493865966798\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 303: \tAverage Loss:  1.3966041717529296\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 304: \tAverage Loss:  1.395852554321289\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 305: \tAverage Loss:  1.3967203063964844\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 306: \tAverage Loss:  1.3969998321533204\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 307: \tAverage Loss:  1.3981373443603515\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 308: \tAverage Loss:  1.3968009338378906\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 309: \tAverage Loss:  1.395598419189453\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 310: \tAverage Loss:  1.3945626983642578\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 311: \tAverage Loss:  1.3943308715820313\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 312: \tAverage Loss:  1.3948006896972656\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 313: \tAverage Loss:  1.394123504638672\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 314: \tAverage Loss:  1.3932781982421876\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 315: \tAverage Loss:  1.3935460815429688\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 316: \tAverage Loss:  1.3937733306884765\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 317: \tAverage Loss:  1.3940434265136719\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 318: \tAverage Loss:  1.393372055053711\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 319: \tAverage Loss:  1.3927798919677734\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 320: \tAverage Loss:  1.3922701721191406\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 321: \tAverage Loss:  1.392093521118164\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 322: \tAverage Loss:  1.3926392822265625\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 323: \tAverage Loss:  1.3925914154052734\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 324: \tAverage Loss:  1.3921439666748048\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 325: \tAverage Loss:  1.3912254791259766\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 326: \tAverage Loss:  1.3909798736572265\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 327: \tAverage Loss:  1.390744369506836\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 328: \tAverage Loss:  1.3908307189941407\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 329: \tAverage Loss:  1.3903298950195313\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 330: \tAverage Loss:  1.3894448852539063\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 331: \tAverage Loss:  1.3891275329589843\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 332: \tAverage Loss:  1.3892492065429687\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 333: \tAverage Loss:  1.3891509704589844\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 334: \tAverage Loss:  1.3888778839111329\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 335: \tAverage Loss:  1.3890118865966796\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 336: \tAverage Loss:  1.3887576446533203\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 337: \tAverage Loss:  1.388141860961914\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 338: \tAverage Loss:  1.3884388732910156\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 339: \tAverage Loss:  1.387598388671875\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 340: \tAverage Loss:  1.3877509155273438\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 341: \tAverage Loss:  1.3869403381347656\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 342: \tAverage Loss:  1.3874653167724609\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 343: \tAverage Loss:  1.3868839263916015\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 344: \tAverage Loss:  1.3863678741455079\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 345: \tAverage Loss:  1.3862188262939452\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 346: \tAverage Loss:  1.3865599822998047\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 347: \tAverage Loss:  1.3866385498046876\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 348: \tAverage Loss:  1.3872980194091797\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 349: \tAverage Loss:  1.3886585235595703\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 350: \tAverage Loss:  1.3874066772460938\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 351: \tAverage Loss:  1.3861143951416015\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 352: \tAverage Loss:  1.3847161712646485\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 353: \tAverage Loss:  1.3846912536621094\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 354: \tAverage Loss:  1.3853050689697266\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 355: \tAverage Loss:  1.385294158935547\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 356: \tAverage Loss:  1.3854908447265626\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 357: \tAverage Loss:  1.3839850006103516\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 358: \tAverage Loss:  1.3838067474365234\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 359: \tAverage Loss:  1.383625015258789\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 360: \tAverage Loss:  1.3833316192626952\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 361: \tAverage Loss:  1.3832423858642577\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 362: \tAverage Loss:  1.3833482055664061\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 363: \tAverage Loss:  1.3827348937988282\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 364: \tAverage Loss:  1.3830020294189453\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 365: \tAverage Loss:  1.382268829345703\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 366: \tAverage Loss:  1.383029541015625\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 367: \tAverage Loss:  1.3822980346679687\t ACC train:  0.685\t ACC test:  0.6511111111111111\n",
      "\tEpoch 368: \tAverage Loss:  1.382061264038086\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 369: \tAverage Loss:  1.3815405120849609\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 370: \tAverage Loss:  1.3811688842773437\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 371: \tAverage Loss:  1.3813378753662109\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 372: \tAverage Loss:  1.380939956665039\t ACC train:  0.685\t ACC test:  0.6533333333333333\n",
      "\tEpoch 373: \tAverage Loss:  1.3813787384033203\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 374: \tAverage Loss:  1.3807678375244141\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 375: \tAverage Loss:  1.3803573760986327\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 376: \tAverage Loss:  1.3800526123046875\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 377: \tAverage Loss:  1.3800327606201173\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 378: \tAverage Loss:  1.3797047729492187\t ACC train:  0.685\t ACC test:  0.6644444444444444\n",
      "\tEpoch 379: \tAverage Loss:  1.3794517974853515\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 380: \tAverage Loss:  1.379185577392578\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 381: \tAverage Loss:  1.3794447479248046\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 382: \tAverage Loss:  1.3798076171875\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 383: \tAverage Loss:  1.3798516387939452\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 384: \tAverage Loss:  1.3796272888183594\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 385: \tAverage Loss:  1.3796172943115235\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 386: \tAverage Loss:  1.3792789154052734\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 387: \tAverage Loss:  1.3784472961425782\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 388: \tAverage Loss:  1.3777960205078126\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 389: \tAverage Loss:  1.3775122222900391\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 390: \tAverage Loss:  1.377107666015625\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 391: \tAverage Loss:  1.377246139526367\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 392: \tAverage Loss:  1.3771786956787109\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 393: \tAverage Loss:  1.3771441650390626\t ACC train:  0.685\t ACC test:  0.6644444444444444\n",
      "\tEpoch 394: \tAverage Loss:  1.3766971893310547\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 395: \tAverage Loss:  1.3763865661621093\t ACC train:  0.685\t ACC test:  0.6644444444444444\n",
      "\tEpoch 396: \tAverage Loss:  1.3761147308349608\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 397: \tAverage Loss:  1.3758981628417968\t ACC train:  0.685\t ACC test:  0.6644444444444444\n",
      "\tEpoch 398: \tAverage Loss:  1.3756139831542968\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 399: \tAverage Loss:  1.3756739044189452\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 400: \tAverage Loss:  1.375958709716797\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 401: \tAverage Loss:  1.3767269592285156\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 402: \tAverage Loss:  1.3759827575683594\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 403: \tAverage Loss:  1.3749237823486329\t ACC train:  0.685\t ACC test:  0.6555555555555556\n",
      "\tEpoch 404: \tAverage Loss:  1.3746153259277343\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 405: \tAverage Loss:  1.3750477142333983\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 406: \tAverage Loss:  1.3765418548583985\t ACC train:  0.685\t ACC test:  0.6644444444444444\n",
      "\tEpoch 407: \tAverage Loss:  1.3760753631591798\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 408: \tAverage Loss:  1.374154327392578\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 409: \tAverage Loss:  1.3733680419921874\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 410: \tAverage Loss:  1.373621109008789\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 411: \tAverage Loss:  1.3741791076660157\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 412: \tAverage Loss:  1.3737152404785156\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 413: \tAverage Loss:  1.373073471069336\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 414: \tAverage Loss:  1.3721394958496094\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 415: \tAverage Loss:  1.372913558959961\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 416: \tAverage Loss:  1.37244091796875\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 417: \tAverage Loss:  1.3714129638671875\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 418: \tAverage Loss:  1.3712286987304687\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 419: \tAverage Loss:  1.3706358032226562\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 420: \tAverage Loss:  1.3714264526367188\t ACC train:  0.685\t ACC test:  0.6577777777777778\n",
      "\tEpoch 421: \tAverage Loss:  1.3707724761962892\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 422: \tAverage Loss:  1.370404006958008\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 423: \tAverage Loss:  1.3705364532470703\t ACC train:  0.6866666666666666\t ACC test:  0.6577777777777778\n",
      "\tEpoch 424: \tAverage Loss:  1.370279769897461\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 425: \tAverage Loss:  1.369975570678711\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 426: \tAverage Loss:  1.3704699249267578\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 427: \tAverage Loss:  1.3705347595214843\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 428: \tAverage Loss:  1.3690870666503907\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 429: \tAverage Loss:  1.3688845672607421\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 430: \tAverage Loss:  1.3693787689208985\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 431: \tAverage Loss:  1.3687614135742188\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 432: \tAverage Loss:  1.3690792388916015\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 433: \tAverage Loss:  1.3684476165771484\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 434: \tAverage Loss:  1.369158935546875\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 435: \tAverage Loss:  1.3686528930664061\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 436: \tAverage Loss:  1.3696194610595702\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 437: \tAverage Loss:  1.3687781829833985\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 438: \tAverage Loss:  1.3676360321044922\t ACC train:  0.6866666666666666\t ACC test:  0.6577777777777778\n",
      "\tEpoch 439: \tAverage Loss:  1.3673977355957032\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 440: \tAverage Loss:  1.3668409881591796\t ACC train:  0.685\t ACC test:  0.6622222222222223\n",
      "\tEpoch 441: \tAverage Loss:  1.3673067626953126\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 442: \tAverage Loss:  1.367474624633789\t ACC train:  0.685\t ACC test:  0.66\n",
      "\tEpoch 443: \tAverage Loss:  1.3667156524658204\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 444: \tAverage Loss:  1.366785873413086\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 445: \tAverage Loss:  1.366688430786133\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 446: \tAverage Loss:  1.3665047607421874\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 447: \tAverage Loss:  1.3655130462646485\t ACC train:  0.685\t ACC test:  0.6666666666666666\n",
      "\tEpoch 448: \tAverage Loss:  1.3653699645996094\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 449: \tAverage Loss:  1.3653947143554688\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 450: \tAverage Loss:  1.3645010986328125\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 451: \tAverage Loss:  1.3650854187011718\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 452: \tAverage Loss:  1.3647062225341797\t ACC train:  0.6866666666666666\t ACC test:  0.6577777777777778\n",
      "\tEpoch 453: \tAverage Loss:  1.3653543395996093\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 454: \tAverage Loss:  1.3647326202392578\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 455: \tAverage Loss:  1.3644979400634765\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 456: \tAverage Loss:  1.3640257720947266\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 457: \tAverage Loss:  1.3633296661376952\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 458: \tAverage Loss:  1.3632313842773438\t ACC train:  0.685\t ACC test:  0.6666666666666666\n",
      "\tEpoch 459: \tAverage Loss:  1.3636614532470703\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 460: \tAverage Loss:  1.3622163696289062\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 461: \tAverage Loss:  1.3629309539794923\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 462: \tAverage Loss:  1.36218603515625\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 463: \tAverage Loss:  1.3623775482177733\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 464: \tAverage Loss:  1.3625900115966796\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 465: \tAverage Loss:  1.3628565368652343\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 466: \tAverage Loss:  1.3635247497558594\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 467: \tAverage Loss:  1.362342269897461\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 468: \tAverage Loss:  1.361611373901367\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 469: \tAverage Loss:  1.3605521697998046\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 470: \tAverage Loss:  1.3605334320068359\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 471: \tAverage Loss:  1.3601961669921876\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 472: \tAverage Loss:  1.3600404052734374\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 473: \tAverage Loss:  1.3600359649658202\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 474: \tAverage Loss:  1.3591036224365234\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 475: \tAverage Loss:  1.358592559814453\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 476: \tAverage Loss:  1.3586349334716796\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 477: \tAverage Loss:  1.3584756927490234\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 478: \tAverage Loss:  1.3587912292480469\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 479: \tAverage Loss:  1.358512466430664\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 480: \tAverage Loss:  1.3580990753173827\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 481: \tAverage Loss:  1.3576205749511718\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 482: \tAverage Loss:  1.3576787719726562\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 483: \tAverage Loss:  1.3574547729492188\t ACC train:  0.685\t ACC test:  0.6666666666666666\n",
      "\tEpoch 484: \tAverage Loss:  1.356813995361328\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 485: \tAverage Loss:  1.3578942260742188\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 486: \tAverage Loss:  1.3566625671386718\t ACC train:  0.6866666666666666\t ACC test:  0.6688888888888889\n",
      "\tEpoch 487: \tAverage Loss:  1.355860580444336\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 488: \tAverage Loss:  1.3561329803466797\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 489: \tAverage Loss:  1.3565206451416016\t ACC train:  0.6866666666666666\t ACC test:  0.6688888888888889\n",
      "\tEpoch 490: \tAverage Loss:  1.35751611328125\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 491: \tAverage Loss:  1.3558607940673828\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 492: \tAverage Loss:  1.3545332489013673\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 493: \tAverage Loss:  1.3536316833496094\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 494: \tAverage Loss:  1.3537745208740235\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 495: \tAverage Loss:  1.3552695770263672\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 496: \tAverage Loss:  1.3570374603271484\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 497: \tAverage Loss:  1.3554816436767578\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 498: \tAverage Loss:  1.3533124084472656\t ACC train:  0.6866666666666666\t ACC test:  0.6644444444444444\n",
      "\tEpoch 499: \tAverage Loss:  1.3524931488037109\t ACC train:  0.6866666666666666\t ACC test:  0.6711111111111111\n",
      "\tEpoch 500: \tAverage Loss:  1.3519687805175782\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 501: \tAverage Loss:  1.3524879455566405\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 502: \tAverage Loss:  1.3512781829833984\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 503: \tAverage Loss:  1.350956741333008\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 504: \tAverage Loss:  1.3515863494873046\t ACC train:  0.6883333333333334\t ACC test:  0.6666666666666666\n",
      "\tEpoch 505: \tAverage Loss:  1.350987335205078\t ACC train:  0.6866666666666666\t ACC test:  0.6711111111111111\n",
      "\tEpoch 506: \tAverage Loss:  1.349767059326172\t ACC train:  0.6866666666666666\t ACC test:  0.6666666666666666\n",
      "\tEpoch 507: \tAverage Loss:  1.3490248413085937\t ACC train:  0.6883333333333334\t ACC test:  0.6666666666666666\n",
      "\tEpoch 508: \tAverage Loss:  1.348645767211914\t ACC train:  0.6866666666666666\t ACC test:  0.6688888888888889\n",
      "\tEpoch 509: \tAverage Loss:  1.3490836486816407\t ACC train:  0.6883333333333334\t ACC test:  0.6711111111111111\n",
      "\tEpoch 510: \tAverage Loss:  1.3473780059814453\t ACC train:  0.6866666666666666\t ACC test:  0.6688888888888889\n",
      "\tEpoch 511: \tAverage Loss:  1.3468116607666016\t ACC train:  0.6866666666666666\t ACC test:  0.6711111111111111\n",
      "\tEpoch 512: \tAverage Loss:  1.3478599548339845\t ACC train:  0.69\t ACC test:  0.68\n",
      "\tEpoch 513: \tAverage Loss:  1.3463990936279298\t ACC train:  0.6883333333333334\t ACC test:  0.6711111111111111\n",
      "\tEpoch 514: \tAverage Loss:  1.3479195861816406\t ACC train:  0.69\t ACC test:  0.6777777777777778\n",
      "\tEpoch 515: \tAverage Loss:  1.3465695343017579\t ACC train:  0.6866666666666666\t ACC test:  0.6733333333333333\n",
      "\tEpoch 516: \tAverage Loss:  1.346164291381836\t ACC train:  0.6866666666666666\t ACC test:  0.6711111111111111\n",
      "\tEpoch 517: \tAverage Loss:  1.3436766052246094\t ACC train:  0.6883333333333334\t ACC test:  0.6777777777777778\n",
      "\tEpoch 518: \tAverage Loss:  1.3429998321533203\t ACC train:  0.6883333333333334\t ACC test:  0.6777777777777778\n",
      "\tEpoch 519: \tAverage Loss:  1.3434532470703124\t ACC train:  0.6866666666666666\t ACC test:  0.6733333333333333\n",
      "\tEpoch 520: \tAverage Loss:  1.3409696960449218\t ACC train:  0.69\t ACC test:  0.6777777777777778\n",
      "\tEpoch 521: \tAverage Loss:  1.340855484008789\t ACC train:  0.6883333333333334\t ACC test:  0.6777777777777778\n",
      "\tEpoch 522: \tAverage Loss:  1.3392220458984374\t ACC train:  0.69\t ACC test:  0.6777777777777778\n",
      "\tEpoch 523: \tAverage Loss:  1.338634262084961\t ACC train:  0.6966666666666667\t ACC test:  0.68\n",
      "\tEpoch 524: \tAverage Loss:  1.3394054412841796\t ACC train:  0.6933333333333334\t ACC test:  0.6733333333333333\n",
      "\tEpoch 525: \tAverage Loss:  1.3380198822021485\t ACC train:  0.6883333333333334\t ACC test:  0.6733333333333333\n",
      "\tEpoch 526: \tAverage Loss:  1.3356189422607423\t ACC train:  0.7066666666666667\t ACC test:  0.6777777777777778\n",
      "\tEpoch 527: \tAverage Loss:  1.337760787963867\t ACC train:  0.695\t ACC test:  0.6844444444444444\n",
      "\tEpoch 528: \tAverage Loss:  1.3354985046386718\t ACC train:  0.7033333333333334\t ACC test:  0.6866666666666666\n",
      "\tEpoch 529: \tAverage Loss:  1.334324935913086\t ACC train:  0.7016666666666667\t ACC test:  0.6911111111111111\n",
      "\tEpoch 530: \tAverage Loss:  1.3330035858154297\t ACC train:  0.7166666666666667\t ACC test:  0.6977777777777778\n",
      "\tEpoch 531: \tAverage Loss:  1.3314825744628906\t ACC train:  0.715\t ACC test:  0.6888888888888889\n",
      "\tEpoch 532: \tAverage Loss:  1.3317999267578124\t ACC train:  0.7216666666666667\t ACC test:  0.7044444444444444\n",
      "\tEpoch 533: \tAverage Loss:  1.3292769317626953\t ACC train:  0.7416666666666667\t ACC test:  0.7222222222222222\n",
      "\tEpoch 534: \tAverage Loss:  1.3286219635009766\t ACC train:  0.7266666666666667\t ACC test:  0.7177777777777777\n",
      "\tEpoch 535: \tAverage Loss:  1.3306292419433594\t ACC train:  0.7666666666666667\t ACC test:  0.7377777777777778\n",
      "\tEpoch 536: \tAverage Loss:  1.3286437835693359\t ACC train:  0.7683333333333333\t ACC test:  0.7577777777777778\n",
      "\tEpoch 537: \tAverage Loss:  1.3232245330810546\t ACC train:  0.7766666666666666\t ACC test:  0.7666666666666667\n",
      "\tEpoch 538: \tAverage Loss:  1.3232809143066406\t ACC train:  0.7966666666666666\t ACC test:  0.7577777777777778\n",
      "\tEpoch 539: \tAverage Loss:  1.3234640502929687\t ACC train:  0.78\t ACC test:  0.7822222222222223\n",
      "\tEpoch 540: \tAverage Loss:  1.3193512725830079\t ACC train:  0.7966666666666666\t ACC test:  0.7777777777777778\n",
      "\tEpoch 541: \tAverage Loss:  1.3161966247558594\t ACC train:  0.8166666666666667\t ACC test:  0.8\n",
      "\tEpoch 542: \tAverage Loss:  1.3160931091308594\t ACC train:  0.8283333333333334\t ACC test:  0.7955555555555556\n",
      "\tEpoch 543: \tAverage Loss:  1.314054397583008\t ACC train:  0.8433333333333334\t ACC test:  0.8355555555555556\n",
      "\tEpoch 544: \tAverage Loss:  1.3139429016113282\t ACC train:  0.8416666666666667\t ACC test:  0.8422222222222222\n",
      "\tEpoch 545: \tAverage Loss:  1.3096917724609376\t ACC train:  0.85\t ACC test:  0.8511111111111112\n",
      "\tEpoch 546: \tAverage Loss:  1.3072378692626954\t ACC train:  0.8733333333333333\t ACC test:  0.8555555555555555\n",
      "\tEpoch 547: \tAverage Loss:  1.3044978637695313\t ACC train:  0.8733333333333333\t ACC test:  0.8622222222222222\n",
      "\tEpoch 548: \tAverage Loss:  1.3026393890380858\t ACC train:  0.8866666666666667\t ACC test:  0.8533333333333334\n",
      "\tEpoch 549: \tAverage Loss:  1.3001328887939454\t ACC train:  0.875\t ACC test:  0.86\n",
      "\tEpoch 550: \tAverage Loss:  1.2993693237304687\t ACC train:  0.885\t ACC test:  0.8733333333333333\n",
      "\tEpoch 551: \tAverage Loss:  1.2953445587158203\t ACC train:  0.8983333333333333\t ACC test:  0.8711111111111111\n",
      "\tEpoch 552: \tAverage Loss:  1.2944984436035156\t ACC train:  0.8983333333333333\t ACC test:  0.8888888888888888\n",
      "\tEpoch 553: \tAverage Loss:  1.2905950927734375\t ACC train:  0.9083333333333333\t ACC test:  0.8866666666666667\n",
      "\tEpoch 554: \tAverage Loss:  1.2898394165039062\t ACC train:  0.915\t ACC test:  0.8888888888888888\n",
      "\tEpoch 555: \tAverage Loss:  1.284593246459961\t ACC train:  0.9116666666666666\t ACC test:  0.8955555555555555\n",
      "\tEpoch 556: \tAverage Loss:  1.2812128448486328\t ACC train:  0.9066666666666666\t ACC test:  0.8866666666666667\n",
      "\tEpoch 557: \tAverage Loss:  1.2806181640625\t ACC train:  0.9216666666666666\t ACC test:  0.8977777777777778\n",
      "\tEpoch 558: \tAverage Loss:  1.2764260711669921\t ACC train:  0.9216666666666666\t ACC test:  0.8977777777777778\n",
      "\tEpoch 559: \tAverage Loss:  1.274505645751953\t ACC train:  0.915\t ACC test:  0.88\n",
      "\tEpoch 560: \tAverage Loss:  1.271612045288086\t ACC train:  0.91\t ACC test:  0.8955555555555555\n",
      "\tEpoch 561: \tAverage Loss:  1.2696463928222657\t ACC train:  0.9116666666666666\t ACC test:  0.8933333333333333\n",
      "\tEpoch 562: \tAverage Loss:  1.2682012786865235\t ACC train:  0.9116666666666666\t ACC test:  0.8977777777777778\n",
      "\tEpoch 563: \tAverage Loss:  1.2626044158935548\t ACC train:  0.9083333333333333\t ACC test:  0.8933333333333333\n",
      "\tEpoch 564: \tAverage Loss:  1.260317138671875\t ACC train:  0.9183333333333333\t ACC test:  0.8933333333333333\n",
      "\tEpoch 565: \tAverage Loss:  1.260316146850586\t ACC train:  0.9183333333333333\t ACC test:  0.8866666666666667\n",
      "\tEpoch 566: \tAverage Loss:  1.2539469909667968\t ACC train:  0.915\t ACC test:  0.8866666666666667\n",
      "\tEpoch 567: \tAverage Loss:  1.2525394134521484\t ACC train:  0.9216666666666666\t ACC test:  0.9044444444444445\n",
      "\tEpoch 568: \tAverage Loss:  1.2483974609375\t ACC train:  0.925\t ACC test:  0.8933333333333333\n",
      "\tEpoch 569: \tAverage Loss:  1.2476145782470702\t ACC train:  0.925\t ACC test:  0.8977777777777778\n",
      "\tEpoch 570: \tAverage Loss:  1.2450867919921875\t ACC train:  0.915\t ACC test:  0.8977777777777778\n",
      "\tEpoch 571: \tAverage Loss:  1.2414758148193359\t ACC train:  0.9283333333333333\t ACC test:  0.8977777777777778\n",
      "\tEpoch 572: \tAverage Loss:  1.2383961791992188\t ACC train:  0.9283333333333333\t ACC test:  0.9066666666666666\n",
      "\tEpoch 573: \tAverage Loss:  1.2346011657714844\t ACC train:  0.925\t ACC test:  0.8955555555555555\n",
      "\tEpoch 574: \tAverage Loss:  1.2356616821289061\t ACC train:  0.9283333333333333\t ACC test:  0.8977777777777778\n",
      "\tEpoch 575: \tAverage Loss:  1.231983612060547\t ACC train:  0.9283333333333333\t ACC test:  0.9022222222222223\n",
      "\tEpoch 576: \tAverage Loss:  1.229836181640625\t ACC train:  0.92\t ACC test:  0.8977777777777778\n",
      "\tEpoch 577: \tAverage Loss:  1.226104507446289\t ACC train:  0.925\t ACC test:  0.8955555555555555\n",
      "\tEpoch 578: \tAverage Loss:  1.2252324523925782\t ACC train:  0.9283333333333333\t ACC test:  0.9\n",
      "\tEpoch 579: \tAverage Loss:  1.2222736968994141\t ACC train:  0.9283333333333333\t ACC test:  0.8955555555555555\n",
      "\tEpoch 580: \tAverage Loss:  1.2188978881835937\t ACC train:  0.935\t ACC test:  0.9044444444444445\n",
      "\tEpoch 581: \tAverage Loss:  1.2169498748779297\t ACC train:  0.9316666666666666\t ACC test:  0.9044444444444445\n",
      "\tEpoch 582: \tAverage Loss:  1.2147129821777343\t ACC train:  0.9366666666666666\t ACC test:  0.9044444444444445\n",
      "\tEpoch 583: \tAverage Loss:  1.2135992431640625\t ACC train:  0.93\t ACC test:  0.9022222222222223\n",
      "\tEpoch 584: \tAverage Loss:  1.2114835205078125\t ACC train:  0.9383333333333334\t ACC test:  0.9022222222222223\n",
      "\tEpoch 585: \tAverage Loss:  1.2081869354248047\t ACC train:  0.9283333333333333\t ACC test:  0.8977777777777778\n",
      "\tEpoch 586: \tAverage Loss:  1.205841796875\t ACC train:  0.935\t ACC test:  0.9\n",
      "\tEpoch 587: \tAverage Loss:  1.2025698699951173\t ACC train:  0.9316666666666666\t ACC test:  0.9088888888888889\n",
      "\tEpoch 588: \tAverage Loss:  1.1988243255615234\t ACC train:  0.9366666666666666\t ACC test:  0.9022222222222223\n",
      "\tEpoch 589: \tAverage Loss:  1.1969185485839844\t ACC train:  0.9366666666666666\t ACC test:  0.9022222222222223\n",
      "\tEpoch 590: \tAverage Loss:  1.194675750732422\t ACC train:  0.93\t ACC test:  0.9066666666666666\n",
      "\tEpoch 591: \tAverage Loss:  1.1923648071289064\t ACC train:  0.9383333333333334\t ACC test:  0.9111111111111111\n",
      "\tEpoch 592: \tAverage Loss:  1.190101837158203\t ACC train:  0.93\t ACC test:  0.9044444444444445\n",
      "\tEpoch 593: \tAverage Loss:  1.1868119201660157\t ACC train:  0.9366666666666666\t ACC test:  0.9111111111111111\n",
      "\tEpoch 594: \tAverage Loss:  1.183954818725586\t ACC train:  0.9383333333333334\t ACC test:  0.9155555555555556\n",
      "\tEpoch 595: \tAverage Loss:  1.1805956268310547\t ACC train:  0.9333333333333333\t ACC test:  0.9088888888888889\n",
      "\tEpoch 596: \tAverage Loss:  1.1777053985595702\t ACC train:  0.9433333333333334\t ACC test:  0.9111111111111111\n",
      "\tEpoch 597: \tAverage Loss:  1.1754900207519532\t ACC train:  0.9333333333333333\t ACC test:  0.9088888888888889\n",
      "\tEpoch 598: \tAverage Loss:  1.1731930847167968\t ACC train:  0.9416666666666667\t ACC test:  0.9111111111111111\n",
      "\tEpoch 599: \tAverage Loss:  1.1702694091796875\t ACC train:  0.9366666666666666\t ACC test:  0.9133333333333333\n",
      "\tEpoch 600: \tAverage Loss:  1.166408462524414\t ACC train:  0.9433333333333334\t ACC test:  0.9155555555555556\n",
      "\tEpoch 601: \tAverage Loss:  1.1633409423828125\t ACC train:  0.94\t ACC test:  0.92\n",
      "\tEpoch 602: \tAverage Loss:  1.160583984375\t ACC train:  0.9383333333333334\t ACC test:  0.9111111111111111\n",
      "\tEpoch 603: \tAverage Loss:  1.1585125122070312\t ACC train:  0.9366666666666666\t ACC test:  0.9133333333333333\n",
      "\tEpoch 604: \tAverage Loss:  1.1554225463867187\t ACC train:  0.94\t ACC test:  0.9155555555555556\n",
      "\tEpoch 605: \tAverage Loss:  1.1528739776611328\t ACC train:  0.9416666666666667\t ACC test:  0.9155555555555556\n",
      "\tEpoch 606: \tAverage Loss:  1.1487410430908203\t ACC train:  0.9366666666666666\t ACC test:  0.9111111111111111\n",
      "\tEpoch 607: \tAverage Loss:  1.146286911010742\t ACC train:  0.9433333333333334\t ACC test:  0.9155555555555556\n",
      "\tEpoch 608: \tAverage Loss:  1.1445446014404297\t ACC train:  0.94\t ACC test:  0.9177777777777778\n",
      "\tEpoch 609: \tAverage Loss:  1.1429328918457031\t ACC train:  0.9383333333333334\t ACC test:  0.9177777777777778\n",
      "\tEpoch 610: \tAverage Loss:  1.1390355224609374\t ACC train:  0.94\t ACC test:  0.92\n",
      "\tEpoch 611: \tAverage Loss:  1.1353740844726563\t ACC train:  0.9383333333333334\t ACC test:  0.9133333333333333\n",
      "\tEpoch 612: \tAverage Loss:  1.1315403900146483\t ACC train:  0.94\t ACC test:  0.9133333333333333\n",
      "\tEpoch 613: \tAverage Loss:  1.129098617553711\t ACC train:  0.9333333333333333\t ACC test:  0.9177777777777778\n",
      "\tEpoch 614: \tAverage Loss:  1.1270934143066407\t ACC train:  0.9383333333333334\t ACC test:  0.9177777777777778\n",
      "\tEpoch 615: \tAverage Loss:  1.1246714935302735\t ACC train:  0.9366666666666666\t ACC test:  0.9155555555555556\n",
      "\tEpoch 616: \tAverage Loss:  1.1212098083496094\t ACC train:  0.9383333333333334\t ACC test:  0.9133333333333333\n",
      "\tEpoch 617: \tAverage Loss:  1.1175568084716796\t ACC train:  0.935\t ACC test:  0.9177777777777778\n",
      "\tEpoch 618: \tAverage Loss:  1.11488525390625\t ACC train:  0.935\t ACC test:  0.9155555555555556\n",
      "\tEpoch 619: \tAverage Loss:  1.1131047515869141\t ACC train:  0.935\t ACC test:  0.9177777777777778\n",
      "\tEpoch 620: \tAverage Loss:  1.1107381286621094\t ACC train:  0.9366666666666666\t ACC test:  0.92\n",
      "\tEpoch 621: \tAverage Loss:  1.1077854614257812\t ACC train:  0.9366666666666666\t ACC test:  0.9177777777777778\n",
      "\tEpoch 622: \tAverage Loss:  1.1044112243652344\t ACC train:  0.9333333333333333\t ACC test:  0.92\n",
      "\tEpoch 623: \tAverage Loss:  1.1020968017578125\t ACC train:  0.935\t ACC test:  0.9222222222222223\n",
      "\tEpoch 624: \tAverage Loss:  1.1003525238037108\t ACC train:  0.935\t ACC test:  0.92\n",
      "\tEpoch 625: \tAverage Loss:  1.0984983825683594\t ACC train:  0.9366666666666666\t ACC test:  0.9177777777777778\n",
      "\tEpoch 626: \tAverage Loss:  1.0962290954589844\t ACC train:  0.935\t ACC test:  0.9222222222222223\n",
      "\tEpoch 627: \tAverage Loss:  1.093724609375\t ACC train:  0.935\t ACC test:  0.9222222222222223\n",
      "\tEpoch 628: \tAverage Loss:  1.0918773040771483\t ACC train:  0.935\t ACC test:  0.9177777777777778\n",
      "\tEpoch 629: \tAverage Loss:  1.0900890350341796\t ACC train:  0.935\t ACC test:  0.92\n",
      "\tEpoch 630: \tAverage Loss:  1.0882523040771483\t ACC train:  0.935\t ACC test:  0.9244444444444444\n",
      "\tEpoch 631: \tAverage Loss:  1.0867135314941405\t ACC train:  0.9333333333333333\t ACC test:  0.92\n",
      "\tEpoch 632: \tAverage Loss:  1.084851806640625\t ACC train:  0.935\t ACC test:  0.92\n",
      "\tEpoch 633: \tAverage Loss:  1.0831674041748047\t ACC train:  0.935\t ACC test:  0.92\n",
      "\tEpoch 634: \tAverage Loss:  1.0817357025146483\t ACC train:  0.9383333333333334\t ACC test:  0.9177777777777778\n",
      "\tEpoch 635: \tAverage Loss:  1.080159683227539\t ACC train:  0.9383333333333334\t ACC test:  0.9222222222222223\n",
      "\tEpoch 636: \tAverage Loss:  1.0787254180908203\t ACC train:  0.9366666666666666\t ACC test:  0.92\n",
      "\tEpoch 637: \tAverage Loss:  1.0775428924560546\t ACC train:  0.935\t ACC test:  0.9177777777777778\n",
      "\tEpoch 638: \tAverage Loss:  1.0761846466064453\t ACC train:  0.935\t ACC test:  0.92\n",
      "\tEpoch 639: \tAverage Loss:  1.07498193359375\t ACC train:  0.9366666666666666\t ACC test:  0.9222222222222223\n",
      "\tEpoch 640: \tAverage Loss:  1.0735823669433593\t ACC train:  0.9366666666666666\t ACC test:  0.9222222222222223\n",
      "\tEpoch 641: \tAverage Loss:  1.0724720458984376\t ACC train:  0.9383333333333334\t ACC test:  0.9244444444444444\n",
      "\tEpoch 642: \tAverage Loss:  1.0712096862792968\t ACC train:  0.94\t ACC test:  0.9244444444444444\n",
      "\tEpoch 643: \tAverage Loss:  1.0702355651855469\t ACC train:  0.9416666666666667\t ACC test:  0.9244444444444444\n",
      "\tEpoch 644: \tAverage Loss:  1.0691522827148439\t ACC train:  0.9383333333333334\t ACC test:  0.9222222222222223\n",
      "\tEpoch 645: \tAverage Loss:  1.0680673980712891\t ACC train:  0.9383333333333334\t ACC test:  0.92\n",
      "\tEpoch 646: \tAverage Loss:  1.0672657623291015\t ACC train:  0.9366666666666666\t ACC test:  0.9222222222222223\n",
      "\tEpoch 647: \tAverage Loss:  1.0661942443847656\t ACC train:  0.94\t ACC test:  0.9266666666666666\n",
      "\tEpoch 648: \tAverage Loss:  1.0653316040039063\t ACC train:  0.9366666666666666\t ACC test:  0.9222222222222223\n",
      "\tEpoch 649: \tAverage Loss:  1.0645628967285157\t ACC train:  0.94\t ACC test:  0.9222222222222223\n",
      "\tEpoch 650: \tAverage Loss:  1.0636034698486327\t ACC train:  0.935\t ACC test:  0.9244444444444444\n",
      "\tEpoch 651: \tAverage Loss:  1.0626976013183593\t ACC train:  0.9383333333333334\t ACC test:  0.9222222222222223\n",
      "\tEpoch 652: \tAverage Loss:  1.061854507446289\t ACC train:  0.9366666666666666\t ACC test:  0.9244444444444444\n",
      "\tEpoch 653: \tAverage Loss:  1.0611045684814453\t ACC train:  0.9383333333333334\t ACC test:  0.9222222222222223\n",
      "\tEpoch 654: \tAverage Loss:  1.0603986511230468\t ACC train:  0.935\t ACC test:  0.9288888888888889\n",
      "\tEpoch 655: \tAverage Loss:  1.0593495635986327\t ACC train:  0.935\t ACC test:  0.9244444444444444\n",
      "\tEpoch 656: \tAverage Loss:  1.0588099670410156\t ACC train:  0.935\t ACC test:  0.9244444444444444\n",
      "\tEpoch 657: \tAverage Loss:  1.0580778198242187\t ACC train:  0.9383333333333334\t ACC test:  0.9244444444444444\n",
      "\tEpoch 658: \tAverage Loss:  1.0573200225830077\t ACC train:  0.94\t ACC test:  0.9266666666666666\n",
      "\tEpoch 659: \tAverage Loss:  1.0568045196533202\t ACC train:  0.9383333333333334\t ACC test:  0.9266666666666666\n",
      "\tEpoch 660: \tAverage Loss:  1.0559366607666016\t ACC train:  0.935\t ACC test:  0.9266666666666666\n",
      "\tEpoch 661: \tAverage Loss:  1.0553183898925782\t ACC train:  0.9383333333333334\t ACC test:  0.9288888888888889\n",
      "\tEpoch 662: \tAverage Loss:  1.0547514953613282\t ACC train:  0.9383333333333334\t ACC test:  0.9288888888888889\n",
      "\tEpoch 663: \tAverage Loss:  1.0541420288085936\t ACC train:  0.9383333333333334\t ACC test:  0.9288888888888889\n",
      "\tEpoch 664: \tAverage Loss:  1.0535030670166015\t ACC train:  0.94\t ACC test:  0.9222222222222223\n",
      "\tEpoch 665: \tAverage Loss:  1.0531904754638672\t ACC train:  0.94\t ACC test:  0.9288888888888889\n",
      "\tEpoch 666: \tAverage Loss:  1.0527895965576173\t ACC train:  0.9416666666666667\t ACC test:  0.9222222222222223\n",
      "\tEpoch 667: \tAverage Loss:  1.0518594665527343\t ACC train:  0.9383333333333334\t ACC test:  0.9288888888888889\n",
      "\tEpoch 668: \tAverage Loss:  1.0510417327880859\t ACC train:  0.94\t ACC test:  0.9288888888888889\n",
      "\tEpoch 669: \tAverage Loss:  1.0505768280029297\t ACC train:  0.9383333333333334\t ACC test:  0.9288888888888889\n",
      "\tEpoch 670: \tAverage Loss:  1.050196762084961\t ACC train:  0.94\t ACC test:  0.9266666666666666\n",
      "\tEpoch 671: \tAverage Loss:  1.0496143951416015\t ACC train:  0.94\t ACC test:  0.9311111111111111\n",
      "\tEpoch 672: \tAverage Loss:  1.0489912719726562\t ACC train:  0.94\t ACC test:  0.9311111111111111\n",
      "\tEpoch 673: \tAverage Loss:  1.048480194091797\t ACC train:  0.94\t ACC test:  0.9311111111111111\n",
      "\tEpoch 674: \tAverage Loss:  1.0479209289550782\t ACC train:  0.9416666666666667\t ACC test:  0.9288888888888889\n",
      "\tEpoch 675: \tAverage Loss:  1.047432861328125\t ACC train:  0.9416666666666667\t ACC test:  0.9288888888888889\n",
      "\tEpoch 676: \tAverage Loss:  1.046990005493164\t ACC train:  0.9416666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 677: \tAverage Loss:  1.0465086975097657\t ACC train:  0.9416666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 678: \tAverage Loss:  1.046101318359375\t ACC train:  0.9416666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 679: \tAverage Loss:  1.0456055297851563\t ACC train:  0.9416666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 680: \tAverage Loss:  1.04531396484375\t ACC train:  0.9433333333333334\t ACC test:  0.9311111111111111\n",
      "\tEpoch 681: \tAverage Loss:  1.044760726928711\t ACC train:  0.9433333333333334\t ACC test:  0.9288888888888889\n",
      "\tEpoch 682: \tAverage Loss:  1.0443697509765626\t ACC train:  0.9416666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 683: \tAverage Loss:  1.044026153564453\t ACC train:  0.9433333333333334\t ACC test:  0.9311111111111111\n",
      "\tEpoch 684: \tAverage Loss:  1.0435825347900392\t ACC train:  0.9433333333333334\t ACC test:  0.9311111111111111\n",
      "\tEpoch 685: \tAverage Loss:  1.0432072143554687\t ACC train:  0.9433333333333334\t ACC test:  0.9311111111111111\n",
      "\tEpoch 686: \tAverage Loss:  1.0428140716552734\t ACC train:  0.9416666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 687: \tAverage Loss:  1.042546371459961\t ACC train:  0.9466666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 688: \tAverage Loss:  1.0421935882568358\t ACC train:  0.9466666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 689: \tAverage Loss:  1.0417938537597655\t ACC train:  0.9466666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 690: \tAverage Loss:  1.0413261260986328\t ACC train:  0.9466666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 691: \tAverage Loss:  1.0410481872558595\t ACC train:  0.9483333333333334\t ACC test:  0.9311111111111111\n",
      "\tEpoch 692: \tAverage Loss:  1.040775161743164\t ACC train:  0.9483333333333334\t ACC test:  0.9311111111111111\n",
      "\tEpoch 693: \tAverage Loss:  1.0404549560546874\t ACC train:  0.9483333333333334\t ACC test:  0.9311111111111111\n",
      "\tEpoch 694: \tAverage Loss:  1.0400767517089844\t ACC train:  0.9466666666666667\t ACC test:  0.9311111111111111\n",
      "\tEpoch 695: \tAverage Loss:  1.0398458557128907\t ACC train:  0.95\t ACC test:  0.9311111111111111\n",
      "\tEpoch 696: \tAverage Loss:  1.0393352813720702\t ACC train:  0.95\t ACC test:  0.9311111111111111\n",
      "\tEpoch 697: \tAverage Loss:  1.039038101196289\t ACC train:  0.95\t ACC test:  0.9333333333333333\n",
      "\tEpoch 698: \tAverage Loss:  1.038706771850586\t ACC train:  0.9483333333333334\t ACC test:  0.9333333333333333\n",
      "\tEpoch 699: \tAverage Loss:  1.0384441528320312\t ACC train:  0.9516666666666667\t ACC test:  0.9355555555555556\n",
      "\tEpoch 700: \tAverage Loss:  1.0382039184570313\t ACC train:  0.9516666666666667\t ACC test:  0.9333333333333333\n",
      "\tEpoch 701: \tAverage Loss:  1.0378786926269532\t ACC train:  0.95\t ACC test:  0.9355555555555556\n",
      "\tEpoch 702: \tAverage Loss:  1.0375283203125\t ACC train:  0.9516666666666667\t ACC test:  0.9333333333333333\n",
      "\tEpoch 703: \tAverage Loss:  1.0373878021240235\t ACC train:  0.9516666666666667\t ACC test:  0.9355555555555556\n",
      "\tEpoch 704: \tAverage Loss:  1.03711376953125\t ACC train:  0.95\t ACC test:  0.9355555555555556\n",
      "\tEpoch 705: \tAverage Loss:  1.0367989196777343\t ACC train:  0.9516666666666667\t ACC test:  0.9333333333333333\n",
      "\tEpoch 706: \tAverage Loss:  1.036449203491211\t ACC train:  0.9516666666666667\t ACC test:  0.9333333333333333\n",
      "\tEpoch 707: \tAverage Loss:  1.0362418670654296\t ACC train:  0.95\t ACC test:  0.9355555555555556\n",
      "\tEpoch 708: \tAverage Loss:  1.0358694458007813\t ACC train:  0.9533333333333334\t ACC test:  0.9311111111111111\n",
      "\tEpoch 709: \tAverage Loss:  1.0356031341552734\t ACC train:  0.9516666666666667\t ACC test:  0.9355555555555556\n",
      "\tEpoch 710: \tAverage Loss:  1.035359161376953\t ACC train:  0.9516666666666667\t ACC test:  0.9333333333333333\n",
      "\tEpoch 711: \tAverage Loss:  1.0350499114990235\t ACC train:  0.9533333333333334\t ACC test:  0.9355555555555556\n",
      "\tEpoch 712: \tAverage Loss:  1.0347616119384766\t ACC train:  0.955\t ACC test:  0.9333333333333333\n",
      "\tEpoch 713: \tAverage Loss:  1.0344939880371093\t ACC train:  0.9533333333333334\t ACC test:  0.9355555555555556\n",
      "\tEpoch 714: \tAverage Loss:  1.0344276275634765\t ACC train:  0.9533333333333334\t ACC test:  0.9355555555555556\n",
      "\tEpoch 715: \tAverage Loss:  1.0343392639160156\t ACC train:  0.95\t ACC test:  0.9333333333333333\n",
      "\tEpoch 716: \tAverage Loss:  1.0347201538085937\t ACC train:  0.955\t ACC test:  0.9355555555555556\n",
      "\tEpoch 717: \tAverage Loss:  1.036521453857422\t ACC train:  0.9466666666666667\t ACC test:  0.9333333333333333\n",
      "\tEpoch 718: \tAverage Loss:  1.0378435974121094\t ACC train:  0.9533333333333334\t ACC test:  0.9333333333333333\n",
      "\tEpoch 719: \tAverage Loss:  1.0402662048339844\t ACC train:  0.9416666666666667\t ACC test:  0.9244444444444444\n",
      "\tEpoch 720: \tAverage Loss:  1.043902557373047\t ACC train:  0.955\t ACC test:  0.9355555555555556\n",
      "\tEpoch 721: \tAverage Loss:  1.0381838226318358\t ACC train:  0.9516666666666667\t ACC test:  0.9355555555555556\n",
      "\tEpoch 722: \tAverage Loss:  1.0336447448730468\t ACC train:  0.955\t ACC test:  0.9333333333333333\n",
      "\tEpoch 723: \tAverage Loss:  1.0327207641601563\t ACC train:  0.9566666666666667\t ACC test:  0.9333333333333333\n",
      "\tEpoch 724: \tAverage Loss:  1.035137924194336\t ACC train:  0.95\t ACC test:  0.9333333333333333\n",
      "\tEpoch 725: \tAverage Loss:  1.0370988311767577\t ACC train:  0.9583333333333334\t ACC test:  0.9333333333333333\n",
      "\tEpoch 726: \tAverage Loss:  1.0337846069335936\t ACC train:  0.9516666666666667\t ACC test:  0.9333333333333333\n",
      "\tEpoch 727: \tAverage Loss:  1.0316434326171875\t ACC train:  0.9533333333333334\t ACC test:  0.9355555555555556\n",
      "\tEpoch 728: \tAverage Loss:  1.0314590606689453\t ACC train:  0.9583333333333334\t ACC test:  0.9355555555555556\n",
      "\tEpoch 729: \tAverage Loss:  1.0324422454833984\t ACC train:  0.9516666666666667\t ACC test:  0.9355555555555556\n",
      "\tEpoch 730: \tAverage Loss:  1.0325185852050782\t ACC train:  0.9583333333333334\t ACC test:  0.94\n",
      "\tEpoch 731: \tAverage Loss:  1.0316617431640625\t ACC train:  0.9533333333333334\t ACC test:  0.9355555555555556\n",
      "\tEpoch 732: \tAverage Loss:  1.0303083038330079\t ACC train:  0.9533333333333334\t ACC test:  0.9355555555555556\n",
      "\tEpoch 733: \tAverage Loss:  1.0300745086669922\t ACC train:  0.955\t ACC test:  0.9355555555555556\n",
      "\tEpoch 734: \tAverage Loss:  1.0301173858642578\t ACC train:  0.955\t ACC test:  0.9355555555555556\n",
      "\tEpoch 735: \tAverage Loss:  1.029962387084961\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 736: \tAverage Loss:  1.029480178833008\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 737: \tAverage Loss:  1.0292519836425782\t ACC train:  0.955\t ACC test:  0.9377777777777778\n",
      "\tEpoch 738: \tAverage Loss:  1.0290668029785157\t ACC train:  0.9566666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 739: \tAverage Loss:  1.0290054779052735\t ACC train:  0.9566666666666667\t ACC test:  0.9355555555555556\n",
      "\tEpoch 740: \tAverage Loss:  1.028670196533203\t ACC train:  0.9583333333333334\t ACC test:  0.9355555555555556\n",
      "\tEpoch 741: \tAverage Loss:  1.0283758850097657\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 742: \tAverage Loss:  1.0281551361083985\t ACC train:  0.9566666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 743: \tAverage Loss:  1.0279219665527344\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 744: \tAverage Loss:  1.0277503662109375\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 745: \tAverage Loss:  1.0275313110351563\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 746: \tAverage Loss:  1.027347442626953\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 747: \tAverage Loss:  1.027245834350586\t ACC train:  0.9566666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 748: \tAverage Loss:  1.0270824737548827\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 749: \tAverage Loss:  1.0268616027832032\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 750: \tAverage Loss:  1.0266183776855469\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 751: \tAverage Loss:  1.026435592651367\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 752: \tAverage Loss:  1.0263042144775392\t ACC train:  0.9583333333333334\t ACC test:  0.9377777777777778\n",
      "\tEpoch 753: \tAverage Loss:  1.026255126953125\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 754: \tAverage Loss:  1.025927780151367\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 755: \tAverage Loss:  1.0256504974365235\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 756: \tAverage Loss:  1.0255435943603515\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 757: \tAverage Loss:  1.0254117126464843\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 758: \tAverage Loss:  1.0252069091796876\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 759: \tAverage Loss:  1.0250347442626953\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 760: \tAverage Loss:  1.0249057159423829\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 761: \tAverage Loss:  1.024686752319336\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 762: \tAverage Loss:  1.0244878234863282\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 763: \tAverage Loss:  1.0244253997802735\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 764: \tAverage Loss:  1.024229034423828\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 765: \tAverage Loss:  1.024037063598633\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 766: \tAverage Loss:  1.0238734741210938\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 767: \tAverage Loss:  1.023624801635742\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 768: \tAverage Loss:  1.0235047607421874\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 769: \tAverage Loss:  1.0233487548828124\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 770: \tAverage Loss:  1.023154754638672\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 771: \tAverage Loss:  1.0230028076171875\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 772: \tAverage Loss:  1.0229017333984376\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 773: \tAverage Loss:  1.0226817169189453\t ACC train:  0.9616666666666667\t ACC test:  0.94\n",
      "\tEpoch 774: \tAverage Loss:  1.0225465850830078\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 775: \tAverage Loss:  1.0223834381103516\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 776: \tAverage Loss:  1.022187744140625\t ACC train:  0.9616666666666667\t ACC test:  0.94\n",
      "\tEpoch 777: \tAverage Loss:  1.0220420684814453\t ACC train:  0.96\t ACC test:  0.94\n",
      "\tEpoch 778: \tAverage Loss:  1.0221021118164062\t ACC train:  0.9633333333333334\t ACC test:  0.9377777777777778\n",
      "\tEpoch 779: \tAverage Loss:  1.0220005950927735\t ACC train:  0.9616666666666667\t ACC test:  0.94\n",
      "\tEpoch 780: \tAverage Loss:  1.0217410278320314\t ACC train:  0.965\t ACC test:  0.94\n",
      "\tEpoch 781: \tAverage Loss:  1.021567657470703\t ACC train:  0.9633333333333334\t ACC test:  0.94\n",
      "\tEpoch 782: \tAverage Loss:  1.0213851470947266\t ACC train:  0.9616666666666667\t ACC test:  0.9377777777777778\n",
      "\tEpoch 783: \tAverage Loss:  1.0212947082519532\t ACC train:  0.9616666666666667\t ACC test:  0.94\n",
      "\tEpoch 784: \tAverage Loss:  1.021103302001953\t ACC train:  0.965\t ACC test:  0.9422222222222222\n",
      "\tEpoch 785: \tAverage Loss:  1.021000717163086\t ACC train:  0.965\t ACC test:  0.9422222222222222\n",
      "\tEpoch 786: \tAverage Loss:  1.0209778289794922\t ACC train:  0.965\t ACC test:  0.9422222222222222\n",
      "\tEpoch 787: \tAverage Loss:  1.0208072662353516\t ACC train:  0.9633333333333334\t ACC test:  0.94\n",
      "\tEpoch 788: \tAverage Loss:  1.0207117462158204\t ACC train:  0.965\t ACC test:  0.9422222222222222\n",
      "\tEpoch 789: \tAverage Loss:  1.020515396118164\t ACC train:  0.9633333333333334\t ACC test:  0.9422222222222222\n",
      "\tEpoch 790: \tAverage Loss:  1.0203301849365234\t ACC train:  0.965\t ACC test:  0.9422222222222222\n",
      "\tEpoch 791: \tAverage Loss:  1.0200894165039063\t ACC train:  0.965\t ACC test:  0.9444444444444444\n",
      "\tEpoch 792: \tAverage Loss:  1.0198112640380859\t ACC train:  0.965\t ACC test:  0.9488888888888889\n",
      "\tEpoch 793: \tAverage Loss:  1.0195897827148437\t ACC train:  0.965\t ACC test:  0.9444444444444444\n",
      "\tEpoch 794: \tAverage Loss:  1.0195174407958985\t ACC train:  0.965\t ACC test:  0.9422222222222222\n",
      "\tEpoch 795: \tAverage Loss:  1.019429443359375\t ACC train:  0.9666666666666667\t ACC test:  0.9466666666666667\n",
      "\tEpoch 796: \tAverage Loss:  1.0193297729492188\t ACC train:  0.965\t ACC test:  0.9422222222222222\n",
      "\tEpoch 797: \tAverage Loss:  1.0192193145751953\t ACC train:  0.965\t ACC test:  0.9511111111111111\n",
      "\tEpoch 798: \tAverage Loss:  1.0193237609863282\t ACC train:  0.965\t ACC test:  0.9422222222222222\n",
      "\tEpoch 799: \tAverage Loss:  1.0194254455566407\t ACC train:  0.965\t ACC test:  0.9488888888888889\n",
      "\tEpoch 800: \tAverage Loss:  1.019327163696289\t ACC train:  0.9633333333333334\t ACC test:  0.9422222222222222\n",
      "\tEpoch 801: \tAverage Loss:  1.0195582885742187\t ACC train:  0.9633333333333334\t ACC test:  0.9488888888888889\n",
      "\tEpoch 802: \tAverage Loss:  1.0206670989990234\t ACC train:  0.9616666666666667\t ACC test:  0.9444444444444444\n",
      "\tEpoch 803: \tAverage Loss:  1.0220283203125\t ACC train:  0.9633333333333334\t ACC test:  0.9488888888888889\n",
      "\tEpoch 804: \tAverage Loss:  1.0250899810791017\t ACC train:  0.9616666666666667\t ACC test:  0.9444444444444444\n",
      "\tEpoch 805: \tAverage Loss:  1.023026840209961\t ACC train:  0.9633333333333334\t ACC test:  0.9488888888888889\n",
      "\tEpoch 806: \tAverage Loss:  1.0211918487548828\t ACC train:  0.965\t ACC test:  0.9422222222222222\n",
      "\tEpoch 807: \tAverage Loss:  1.0187479248046876\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 808: \tAverage Loss:  1.0176073760986328\t ACC train:  0.965\t ACC test:  0.9511111111111111\n",
      "\tEpoch 809: \tAverage Loss:  1.0176761322021484\t ACC train:  0.9666666666666667\t ACC test:  0.9466666666666667\n",
      "\tEpoch 810: \tAverage Loss:  1.0182570190429687\t ACC train:  0.965\t ACC test:  0.9488888888888889\n",
      "\tEpoch 811: \tAverage Loss:  1.0185250854492187\t ACC train:  0.9666666666666667\t ACC test:  0.9488888888888889\n",
      "\tEpoch 812: \tAverage Loss:  1.0177588806152345\t ACC train:  0.965\t ACC test:  0.9511111111111111\n",
      "\tEpoch 813: \tAverage Loss:  1.0170875701904296\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 814: \tAverage Loss:  1.016637222290039\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 815: \tAverage Loss:  1.016761444091797\t ACC train:  0.965\t ACC test:  0.9511111111111111\n",
      "\tEpoch 816: \tAverage Loss:  1.0169398040771485\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 817: \tAverage Loss:  1.0168670501708985\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 818: \tAverage Loss:  1.0166036224365234\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 819: \tAverage Loss:  1.0161622161865234\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 820: \tAverage Loss:  1.0159236297607421\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 821: \tAverage Loss:  1.0158102569580079\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 822: \tAverage Loss:  1.0160275115966797\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 823: \tAverage Loss:  1.0159863891601562\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 824: \tAverage Loss:  1.0156437377929688\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 825: \tAverage Loss:  1.015261016845703\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 826: \tAverage Loss:  1.015092742919922\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 827: \tAverage Loss:  1.0152007751464844\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 828: \tAverage Loss:  1.015228469848633\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 829: \tAverage Loss:  1.0150484008789062\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 830: \tAverage Loss:  1.014793960571289\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 831: \tAverage Loss:  1.0145871124267578\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 832: \tAverage Loss:  1.0143188934326173\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 833: \tAverage Loss:  1.014147918701172\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 834: \tAverage Loss:  1.0141351776123047\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 835: \tAverage Loss:  1.0141271514892578\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 836: \tAverage Loss:  1.014119155883789\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 837: \tAverage Loss:  1.0139988708496093\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 838: \tAverage Loss:  1.0137486267089844\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 839: \tAverage Loss:  1.0135560913085937\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 840: \tAverage Loss:  1.0133204956054687\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 841: \tAverage Loss:  1.0131127166748046\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 842: \tAverage Loss:  1.013147216796875\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 843: \tAverage Loss:  1.0130482025146483\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 844: \tAverage Loss:  1.012896484375\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 845: \tAverage Loss:  1.0126788635253907\t ACC train:  0.9666666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 846: \tAverage Loss:  1.0126228637695311\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 847: \tAverage Loss:  1.0124276580810547\t ACC train:  0.9666666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 848: \tAverage Loss:  1.0122921600341797\t ACC train:  0.9666666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 849: \tAverage Loss:  1.0122946319580077\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 850: \tAverage Loss:  1.0122850036621094\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 851: \tAverage Loss:  1.0121577758789062\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 852: \tAverage Loss:  1.0119727020263671\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 853: \tAverage Loss:  1.0117991485595703\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 854: \tAverage Loss:  1.0116691284179689\t ACC train:  0.9666666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 855: \tAverage Loss:  1.011452911376953\t ACC train:  0.9666666666666667\t ACC test:  0.96\n",
      "\tEpoch 856: \tAverage Loss:  1.0113577728271483\t ACC train:  0.9666666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 857: \tAverage Loss:  1.0112006225585937\t ACC train:  0.9666666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 858: \tAverage Loss:  1.01112939453125\t ACC train:  0.9666666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 859: \tAverage Loss:  1.0109514770507813\t ACC train:  0.9666666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 860: \tAverage Loss:  1.0109498291015624\t ACC train:  0.9683333333333334\t ACC test:  0.96\n",
      "\tEpoch 861: \tAverage Loss:  1.010884735107422\t ACC train:  0.9666666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 862: \tAverage Loss:  1.0107461395263673\t ACC train:  0.9683333333333334\t ACC test:  0.9555555555555556\n",
      "\tEpoch 863: \tAverage Loss:  1.0106730194091798\t ACC train:  0.9683333333333334\t ACC test:  0.96\n",
      "\tEpoch 864: \tAverage Loss:  1.0104311981201173\t ACC train:  0.9683333333333334\t ACC test:  0.96\n",
      "\tEpoch 865: \tAverage Loss:  1.0101928100585937\t ACC train:  0.9683333333333334\t ACC test:  0.96\n",
      "\tEpoch 866: \tAverage Loss:  1.0101190795898438\t ACC train:  0.9666666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 867: \tAverage Loss:  1.010194351196289\t ACC train:  0.9683333333333334\t ACC test:  0.9555555555555556\n",
      "\tEpoch 868: \tAverage Loss:  1.0100365753173828\t ACC train:  0.97\t ACC test:  0.9577777777777777\n",
      "\tEpoch 869: \tAverage Loss:  1.0100787658691406\t ACC train:  0.9683333333333334\t ACC test:  0.9577777777777777\n",
      "\tEpoch 870: \tAverage Loss:  1.0099900207519532\t ACC train:  0.9666666666666667\t ACC test:  0.96\n",
      "\tEpoch 871: \tAverage Loss:  1.0098966522216797\t ACC train:  0.9683333333333334\t ACC test:  0.96\n",
      "\tEpoch 872: \tAverage Loss:  1.0098356323242188\t ACC train:  0.9683333333333334\t ACC test:  0.9577777777777777\n",
      "\tEpoch 873: \tAverage Loss:  1.0097496337890626\t ACC train:  0.9683333333333334\t ACC test:  0.9555555555555556\n",
      "\tEpoch 874: \tAverage Loss:  1.0097928314208984\t ACC train:  0.9666666666666667\t ACC test:  0.96\n",
      "\tEpoch 875: \tAverage Loss:  1.0098734588623046\t ACC train:  0.9683333333333334\t ACC test:  0.9577777777777777\n",
      "\tEpoch 876: \tAverage Loss:  1.0100752716064454\t ACC train:  0.97\t ACC test:  0.9577777777777777\n",
      "\tEpoch 877: \tAverage Loss:  1.010120132446289\t ACC train:  0.9683333333333334\t ACC test:  0.9622222222222222\n",
      "\tEpoch 878: \tAverage Loss:  1.0102090759277345\t ACC train:  0.97\t ACC test:  0.9577777777777777\n",
      "\tEpoch 879: \tAverage Loss:  1.0095794067382813\t ACC train:  0.97\t ACC test:  0.96\n",
      "\tEpoch 880: \tAverage Loss:  1.009253616333008\t ACC train:  0.9683333333333334\t ACC test:  0.96\n",
      "\tEpoch 881: \tAverage Loss:  1.0088392944335938\t ACC train:  0.9683333333333334\t ACC test:  0.9622222222222222\n",
      "\tEpoch 882: \tAverage Loss:  1.0085793151855469\t ACC train:  0.9683333333333334\t ACC test:  0.96\n",
      "\tEpoch 883: \tAverage Loss:  1.0083065185546876\t ACC train:  0.9683333333333334\t ACC test:  0.96\n",
      "\tEpoch 884: \tAverage Loss:  1.0082388916015625\t ACC train:  0.97\t ACC test:  0.9644444444444444\n",
      "\tEpoch 885: \tAverage Loss:  1.008170196533203\t ACC train:  0.9683333333333334\t ACC test:  0.96\n",
      "\tEpoch 886: \tAverage Loss:  1.0082216186523438\t ACC train:  0.9716666666666667\t ACC test:  0.9644444444444444\n",
      "\tEpoch 887: \tAverage Loss:  1.0083206939697265\t ACC train:  0.9716666666666667\t ACC test:  0.9577777777777777\n",
      "\tEpoch 888: \tAverage Loss:  1.008490249633789\t ACC train:  0.9733333333333334\t ACC test:  0.9644444444444444\n",
      "\tEpoch 889: \tAverage Loss:  1.0083150329589843\t ACC train:  0.9716666666666667\t ACC test:  0.96\n",
      "\tEpoch 890: \tAverage Loss:  1.0081681365966797\t ACC train:  0.975\t ACC test:  0.9666666666666667\n",
      "\tEpoch 891: \tAverage Loss:  1.0078975219726563\t ACC train:  0.97\t ACC test:  0.96\n",
      "\tEpoch 892: \tAverage Loss:  1.0077247924804686\t ACC train:  0.9733333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 893: \tAverage Loss:  1.0075574951171875\t ACC train:  0.97\t ACC test:  0.9622222222222222\n",
      "\tEpoch 894: \tAverage Loss:  1.0074251861572265\t ACC train:  0.975\t ACC test:  0.9666666666666667\n",
      "\tEpoch 895: \tAverage Loss:  1.007428436279297\t ACC train:  0.9733333333333334\t ACC test:  0.9622222222222222\n",
      "\tEpoch 896: \tAverage Loss:  1.0073333587646485\t ACC train:  0.975\t ACC test:  0.9666666666666667\n",
      "\tEpoch 897: \tAverage Loss:  1.0073426666259766\t ACC train:  0.9733333333333334\t ACC test:  0.96\n",
      "\tEpoch 898: \tAverage Loss:  1.0071759338378907\t ACC train:  0.975\t ACC test:  0.9666666666666667\n",
      "\tEpoch 899: \tAverage Loss:  1.007211654663086\t ACC train:  0.975\t ACC test:  0.9622222222222222\n",
      "\tEpoch 900: \tAverage Loss:  1.0071666412353515\t ACC train:  0.9766666666666667\t ACC test:  0.9666666666666667\n",
      "\tEpoch 901: \tAverage Loss:  1.0068620452880859\t ACC train:  0.9733333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 902: \tAverage Loss:  1.0064985046386719\t ACC train:  0.975\t ACC test:  0.9666666666666667\n",
      "\tEpoch 903: \tAverage Loss:  1.0063081970214844\t ACC train:  0.9766666666666667\t ACC test:  0.9666666666666667\n",
      "\tEpoch 904: \tAverage Loss:  1.0060254974365235\t ACC train:  0.9733333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 905: \tAverage Loss:  1.005887939453125\t ACC train:  0.975\t ACC test:  0.9666666666666667\n",
      "\tEpoch 906: \tAverage Loss:  1.0057149505615235\t ACC train:  0.975\t ACC test:  0.9666666666666667\n",
      "\tEpoch 907: \tAverage Loss:  1.005582717895508\t ACC train:  0.9766666666666667\t ACC test:  0.9666666666666667\n",
      "\tEpoch 908: \tAverage Loss:  1.0055169982910157\t ACC train:  0.9766666666666667\t ACC test:  0.9666666666666667\n",
      "\tEpoch 909: \tAverage Loss:  1.0054425506591798\t ACC train:  0.9766666666666667\t ACC test:  0.9666666666666667\n",
      "\tEpoch 910: \tAverage Loss:  1.005418670654297\t ACC train:  0.9766666666666667\t ACC test:  0.9666666666666667\n",
      "\tEpoch 911: \tAverage Loss:  1.0054862518310548\t ACC train:  0.975\t ACC test:  0.9666666666666667\n",
      "\tEpoch 912: \tAverage Loss:  1.0054715270996093\t ACC train:  0.9783333333333334\t ACC test:  0.9688888888888889\n",
      "\tEpoch 913: \tAverage Loss:  1.0055537414550781\t ACC train:  0.9766666666666667\t ACC test:  0.9666666666666667\n",
      "\tEpoch 914: \tAverage Loss:  1.0055648193359374\t ACC train:  0.9783333333333334\t ACC test:  0.9688888888888889\n",
      "\tEpoch 915: \tAverage Loss:  1.0056527557373047\t ACC train:  0.9783333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 916: \tAverage Loss:  1.005678970336914\t ACC train:  0.9783333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 917: \tAverage Loss:  1.005802963256836\t ACC train:  0.9783333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 918: \tAverage Loss:  1.0055640563964843\t ACC train:  0.9783333333333334\t ACC test:  0.9688888888888889\n",
      "\tEpoch 919: \tAverage Loss:  1.005412399291992\t ACC train:  0.9766666666666667\t ACC test:  0.9666666666666667\n",
      "\tEpoch 920: \tAverage Loss:  1.0048477325439453\t ACC train:  0.9783333333333334\t ACC test:  0.9688888888888889\n",
      "\tEpoch 921: \tAverage Loss:  1.0045597534179687\t ACC train:  0.9783333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 922: \tAverage Loss:  1.0042857360839843\t ACC train:  0.9783333333333334\t ACC test:  0.9688888888888889\n",
      "\tEpoch 923: \tAverage Loss:  1.0041290588378906\t ACC train:  0.9783333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 924: \tAverage Loss:  1.0039974822998048\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 925: \tAverage Loss:  1.0038968353271485\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 926: \tAverage Loss:  1.0038190460205079\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 927: \tAverage Loss:  1.0036987915039062\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 928: \tAverage Loss:  1.0036087799072266\t ACC train:  0.9783333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 929: \tAverage Loss:  1.0035652465820313\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 930: \tAverage Loss:  1.0034185180664061\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 931: \tAverage Loss:  1.0033072052001952\t ACC train:  0.9783333333333334\t ACC test:  0.9688888888888889\n",
      "\tEpoch 932: \tAverage Loss:  1.003262680053711\t ACC train:  0.9783333333333334\t ACC test:  0.9688888888888889\n",
      "\tEpoch 933: \tAverage Loss:  1.0032437438964843\t ACC train:  0.98\t ACC test:  0.9666666666666667\n",
      "\tEpoch 934: \tAverage Loss:  1.0031150817871093\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 935: \tAverage Loss:  1.0031940002441406\t ACC train:  0.9816666666666667\t ACC test:  0.9666666666666667\n",
      "\tEpoch 936: \tAverage Loss:  1.0031234436035157\t ACC train:  0.9783333333333334\t ACC test:  0.9688888888888889\n",
      "\tEpoch 937: \tAverage Loss:  1.0031160583496095\t ACC train:  0.9783333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 938: \tAverage Loss:  1.0033705749511719\t ACC train:  0.9783333333333334\t ACC test:  0.9688888888888889\n",
      "\tEpoch 939: \tAverage Loss:  1.003727783203125\t ACC train:  0.98\t ACC test:  0.9666666666666667\n",
      "\tEpoch 940: \tAverage Loss:  1.0046771697998047\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 941: \tAverage Loss:  1.0066031341552735\t ACC train:  0.9733333333333334\t ACC test:  0.96\n",
      "\tEpoch 942: \tAverage Loss:  1.0105055541992187\t ACC train:  0.98\t ACC test:  0.9622222222222222\n",
      "\tEpoch 943: \tAverage Loss:  1.015158447265625\t ACC train:  0.975\t ACC test:  0.9622222222222222\n",
      "\tEpoch 944: \tAverage Loss:  1.0109218292236328\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 945: \tAverage Loss:  1.006266616821289\t ACC train:  0.98\t ACC test:  0.9666666666666667\n",
      "\tEpoch 946: \tAverage Loss:  1.0027097320556642\t ACC train:  0.98\t ACC test:  0.9666666666666667\n",
      "\tEpoch 947: \tAverage Loss:  1.0028789520263672\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 948: \tAverage Loss:  1.0045751190185548\t ACC train:  0.98\t ACC test:  0.9666666666666667\n",
      "\tEpoch 949: \tAverage Loss:  1.0043586120605468\t ACC train:  0.9816666666666667\t ACC test:  0.9711111111111111\n",
      "\tEpoch 950: \tAverage Loss:  1.0028904724121093\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 951: \tAverage Loss:  1.0018143615722657\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 952: \tAverage Loss:  1.002040771484375\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 953: \tAverage Loss:  1.0024774322509766\t ACC train:  0.9833333333333333\t ACC test:  0.9666666666666667\n",
      "\tEpoch 954: \tAverage Loss:  1.0021678771972655\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 955: \tAverage Loss:  1.001556198120117\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 956: \tAverage Loss:  1.0013607025146485\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 957: \tAverage Loss:  1.0014656982421875\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 958: \tAverage Loss:  1.0014833221435546\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 959: \tAverage Loss:  1.0013175354003907\t ACC train:  0.98\t ACC test:  0.9688888888888889\n",
      "\tEpoch 960: \tAverage Loss:  1.0010518798828125\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 961: \tAverage Loss:  1.0009137573242188\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 962: \tAverage Loss:  1.000877426147461\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 963: \tAverage Loss:  1.000797653198242\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 964: \tAverage Loss:  1.0006939239501953\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 965: \tAverage Loss:  1.0006186828613282\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 966: \tAverage Loss:  1.0005547790527343\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 967: \tAverage Loss:  1.0004767150878906\t ACC train:  0.9816666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 968: \tAverage Loss:  1.0005335693359374\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 969: \tAverage Loss:  1.000383316040039\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 970: \tAverage Loss:  1.0002614593505859\t ACC train:  0.985\t ACC test:  0.9688888888888889\n",
      "\tEpoch 971: \tAverage Loss:  1.0001261138916016\t ACC train:  0.985\t ACC test:  0.9688888888888889\n",
      "\tEpoch 972: \tAverage Loss:  1.0001296691894532\t ACC train:  0.9833333333333333\t ACC test:  0.9711111111111111\n",
      "\tEpoch 973: \tAverage Loss:  1.0000748291015624\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 974: \tAverage Loss:  1.0000770568847657\t ACC train:  0.9833333333333333\t ACC test:  0.9711111111111111\n",
      "\tEpoch 975: \tAverage Loss:  0.9999760589599609\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 976: \tAverage Loss:  0.9998634033203125\t ACC train:  0.985\t ACC test:  0.9688888888888889\n",
      "\tEpoch 977: \tAverage Loss:  0.999745346069336\t ACC train:  0.9833333333333333\t ACC test:  0.9711111111111111\n",
      "\tEpoch 978: \tAverage Loss:  0.9996138305664063\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 979: \tAverage Loss:  0.9996297454833984\t ACC train:  0.9816666666666667\t ACC test:  0.9711111111111111\n",
      "\tEpoch 980: \tAverage Loss:  0.9997132873535156\t ACC train:  0.9833333333333333\t ACC test:  0.9688888888888889\n",
      "\tEpoch 981: \tAverage Loss:  0.9996587066650391\t ACC train:  0.9816666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 982: \tAverage Loss:  0.9995503997802735\t ACC train:  0.985\t ACC test:  0.9688888888888889\n",
      "\tEpoch 983: \tAverage Loss:  0.9994725646972656\t ACC train:  0.9816666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 984: \tAverage Loss:  0.9992993011474609\t ACC train:  0.985\t ACC test:  0.9711111111111111\n",
      "\tEpoch 985: \tAverage Loss:  0.9991318054199219\t ACC train:  0.985\t ACC test:  0.9711111111111111\n",
      "\tEpoch 986: \tAverage Loss:  0.9989827880859375\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 987: \tAverage Loss:  0.9989390106201171\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 988: \tAverage Loss:  0.9988499603271485\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 989: \tAverage Loss:  0.9987795562744141\t ACC train:  0.985\t ACC test:  0.9711111111111111\n",
      "\tEpoch 990: \tAverage Loss:  0.9986826171875\t ACC train:  0.9833333333333333\t ACC test:  0.9711111111111111\n",
      "\tEpoch 991: \tAverage Loss:  0.9986405639648438\t ACC train:  0.9816666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 992: \tAverage Loss:  0.9986025390625\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 993: \tAverage Loss:  0.9986200714111328\t ACC train:  0.9816666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 994: \tAverage Loss:  0.9985730438232422\t ACC train:  0.985\t ACC test:  0.9688888888888889\n",
      "\tEpoch 995: \tAverage Loss:  0.9985137023925781\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 996: \tAverage Loss:  0.9985152282714844\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 997: \tAverage Loss:  0.9986059875488281\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 998: \tAverage Loss:  0.9989516296386719\t ACC train:  0.985\t ACC test:  0.9711111111111111\n",
      "\tEpoch 999: \tAverage Loss:  0.9989640045166016\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1000: \tAverage Loss:  0.9990090484619141\t ACC train:  0.985\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1001: \tAverage Loss:  0.9988034362792969\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1002: \tAverage Loss:  0.9984796447753906\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1003: \tAverage Loss:  0.997910400390625\t ACC train:  0.985\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1004: \tAverage Loss:  0.9977214660644531\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1005: \tAverage Loss:  0.9976873931884765\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1006: \tAverage Loss:  0.9978636627197266\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1007: \tAverage Loss:  0.997950454711914\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1008: \tAverage Loss:  0.9977876586914063\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1009: \tAverage Loss:  0.997793441772461\t ACC train:  0.9866666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1010: \tAverage Loss:  0.9974847412109376\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1011: \tAverage Loss:  0.9971694641113281\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1012: \tAverage Loss:  0.9970361175537109\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1013: \tAverage Loss:  0.9973152923583984\t ACC train:  0.9866666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1014: \tAverage Loss:  0.997067367553711\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1015: \tAverage Loss:  0.9970069274902343\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1016: \tAverage Loss:  0.996996078491211\t ACC train:  0.985\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1017: \tAverage Loss:  0.9970596466064453\t ACC train:  0.9833333333333333\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1018: \tAverage Loss:  0.9967368927001953\t ACC train:  0.985\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1019: \tAverage Loss:  0.9966427764892578\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1020: \tAverage Loss:  0.996602310180664\t ACC train:  0.9816666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1021: \tAverage Loss:  0.9965338592529297\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1022: \tAverage Loss:  0.9965540008544922\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1023: \tAverage Loss:  0.996364761352539\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1024: \tAverage Loss:  0.9964187316894532\t ACC train:  0.9833333333333333\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1025: \tAverage Loss:  0.9964309539794922\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1026: \tAverage Loss:  0.996408447265625\t ACC train:  0.985\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1027: \tAverage Loss:  0.9968088226318359\t ACC train:  0.9866666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1028: \tAverage Loss:  0.9973675079345703\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1029: \tAverage Loss:  0.9983395385742188\t ACC train:  0.985\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1030: \tAverage Loss:  0.9990503234863282\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1031: \tAverage Loss:  1.0006311492919922\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1032: \tAverage Loss:  1.0028321228027344\t ACC train:  0.9833333333333333\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1033: \tAverage Loss:  1.0045392303466796\t ACC train:  0.9866666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1034: \tAverage Loss:  1.0030462036132812\t ACC train:  0.9833333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1035: \tAverage Loss:  0.9996977081298828\t ACC train:  0.985\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1036: \tAverage Loss:  0.9960489959716797\t ACC train:  0.9883333333333333\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1037: \tAverage Loss:  0.9963412322998046\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1038: \tAverage Loss:  0.9985531005859375\t ACC train:  0.9866666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1039: \tAverage Loss:  1.0001351928710938\t ACC train:  0.985\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1040: \tAverage Loss:  0.999162353515625\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1041: \tAverage Loss:  0.9960753631591797\t ACC train:  0.9866666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1042: \tAverage Loss:  0.9953851318359375\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1043: \tAverage Loss:  0.9964087677001953\t ACC train:  0.9866666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1044: \tAverage Loss:  0.9970072326660157\t ACC train:  0.985\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1045: \tAverage Loss:  0.9964353332519531\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1046: \tAverage Loss:  0.9950767211914062\t ACC train:  0.9866666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1047: \tAverage Loss:  0.9949688262939453\t ACC train:  0.985\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1048: \tAverage Loss:  0.9956481018066407\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1049: \tAverage Loss:  0.9957213745117187\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1050: \tAverage Loss:  0.9952357940673828\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1051: \tAverage Loss:  0.9945971221923828\t ACC train:  0.9866666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1052: \tAverage Loss:  0.9946397399902344\t ACC train:  0.9866666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1053: \tAverage Loss:  0.9949009399414063\t ACC train:  0.9883333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1054: \tAverage Loss:  0.9950561218261719\t ACC train:  0.985\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1055: \tAverage Loss:  0.9946522674560547\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1056: \tAverage Loss:  0.9943075714111328\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1057: \tAverage Loss:  0.9941369323730469\t ACC train:  0.9866666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1058: \tAverage Loss:  0.9942728118896484\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1059: \tAverage Loss:  0.9942374114990234\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1060: \tAverage Loss:  0.9941317138671875\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1061: \tAverage Loss:  0.9939657897949219\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1062: \tAverage Loss:  0.9938935852050781\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1063: \tAverage Loss:  0.9938997344970704\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1064: \tAverage Loss:  0.993752685546875\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1065: \tAverage Loss:  0.9937482299804687\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1066: \tAverage Loss:  0.9936318817138672\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1067: \tAverage Loss:  0.9935340118408204\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1068: \tAverage Loss:  0.9934195556640625\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1069: \tAverage Loss:  0.9933398284912109\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1070: \tAverage Loss:  0.9933812103271484\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1071: \tAverage Loss:  0.9934753875732422\t ACC train:  0.985\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1072: \tAverage Loss:  0.9933000030517578\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1073: \tAverage Loss:  0.9932283477783204\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1074: \tAverage Loss:  0.9931673583984375\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1075: \tAverage Loss:  0.9930195617675781\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1076: \tAverage Loss:  0.9929328155517578\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1077: \tAverage Loss:  0.9928489990234375\t ACC train:  0.9866666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1078: \tAverage Loss:  0.9929117584228515\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1079: \tAverage Loss:  0.9927853240966796\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1080: \tAverage Loss:  0.9927565307617188\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1081: \tAverage Loss:  0.9926896057128907\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1082: \tAverage Loss:  0.9925478210449219\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1083: \tAverage Loss:  0.9924433898925781\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1084: \tAverage Loss:  0.9924658203125\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1085: \tAverage Loss:  0.9923782348632812\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1086: \tAverage Loss:  0.9923423156738281\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1087: \tAverage Loss:  0.992219467163086\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1088: \tAverage Loss:  0.9921735687255859\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1089: \tAverage Loss:  0.9921276397705078\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1090: \tAverage Loss:  0.9920728607177735\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1091: \tAverage Loss:  0.9920177612304687\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1092: \tAverage Loss:  0.9918878631591797\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1093: \tAverage Loss:  0.992010726928711\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1094: \tAverage Loss:  0.9918433532714844\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1095: \tAverage Loss:  0.9918119049072266\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1096: \tAverage Loss:  0.9916915588378906\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1097: \tAverage Loss:  0.9918211822509766\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1098: \tAverage Loss:  0.9916482849121093\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1099: \tAverage Loss:  0.9915669860839844\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1100: \tAverage Loss:  0.9915511932373047\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1101: \tAverage Loss:  0.9915765838623047\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1102: \tAverage Loss:  0.9914497375488281\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1103: \tAverage Loss:  0.991519546508789\t ACC train:  0.9883333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1104: \tAverage Loss:  0.991492202758789\t ACC train:  0.9883333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1105: \tAverage Loss:  0.9915988311767578\t ACC train:  0.9866666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1106: \tAverage Loss:  0.9916481018066406\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1107: \tAverage Loss:  0.9917424011230469\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1108: \tAverage Loss:  0.9917703552246093\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1109: \tAverage Loss:  0.9916221923828125\t ACC train:  0.9883333333333333\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1110: \tAverage Loss:  0.9916793823242187\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1111: \tAverage Loss:  0.9914590606689453\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1112: \tAverage Loss:  0.9913353881835938\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1113: \tAverage Loss:  0.9911270294189453\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1114: \tAverage Loss:  0.9908567810058594\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1115: \tAverage Loss:  0.9907537689208984\t ACC train:  0.9883333333333333\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1116: \tAverage Loss:  0.990716552734375\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1117: \tAverage Loss:  0.9905404510498047\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1118: \tAverage Loss:  0.9905863647460937\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1119: \tAverage Loss:  0.9905187683105469\t ACC train:  0.99\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1120: \tAverage Loss:  0.9904709014892578\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1121: \tAverage Loss:  0.9904651794433593\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1122: \tAverage Loss:  0.9905029296875\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1123: \tAverage Loss:  0.9905039367675781\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1124: \tAverage Loss:  0.9906358032226562\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1125: \tAverage Loss:  0.9908069152832031\t ACC train:  0.99\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1126: \tAverage Loss:  0.9913168029785157\t ACC train:  0.9883333333333333\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1127: \tAverage Loss:  0.9915021057128907\t ACC train:  0.99\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1128: \tAverage Loss:  0.9923063201904296\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1129: \tAverage Loss:  0.9930808410644532\t ACC train:  0.99\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1130: \tAverage Loss:  0.9941588134765625\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1131: \tAverage Loss:  0.9935794677734375\t ACC train:  0.99\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1132: \tAverage Loss:  0.9928175506591796\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1133: \tAverage Loss:  0.9925816040039063\t ACC train:  0.99\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1134: \tAverage Loss:  0.9921710510253906\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1135: \tAverage Loss:  0.9907852172851562\t ACC train:  0.9916666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1136: \tAverage Loss:  0.9898934020996094\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1137: \tAverage Loss:  0.9895001983642578\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1138: \tAverage Loss:  0.9897183074951171\t ACC train:  0.9916666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1139: \tAverage Loss:  0.9897801055908203\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1140: \tAverage Loss:  0.9898818969726563\t ACC train:  0.9933333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1141: \tAverage Loss:  0.9896261596679687\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1142: \tAverage Loss:  0.9892771759033203\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1143: \tAverage Loss:  0.9890522918701172\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1144: \tAverage Loss:  0.9890944671630859\t ACC train:  0.9916666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1145: \tAverage Loss:  0.9889786529541016\t ACC train:  0.9933333333333333\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1146: \tAverage Loss:  0.9889779968261718\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1147: \tAverage Loss:  0.9888565521240235\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1148: \tAverage Loss:  0.9888167114257812\t ACC train:  0.9916666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1149: \tAverage Loss:  0.9887145538330078\t ACC train:  0.9916666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1150: \tAverage Loss:  0.9887574005126953\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1151: \tAverage Loss:  0.9887041625976563\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1152: \tAverage Loss:  0.988890853881836\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1153: \tAverage Loss:  0.9888484497070312\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1154: \tAverage Loss:  0.9889856109619141\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1155: \tAverage Loss:  0.9891148529052735\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1156: \tAverage Loss:  0.9894896850585938\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1157: \tAverage Loss:  0.9893204193115235\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1158: \tAverage Loss:  0.9891643371582032\t ACC train:  0.995\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1159: \tAverage Loss:  0.9890072937011719\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1160: \tAverage Loss:  0.9888062591552734\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1161: \tAverage Loss:  0.9887540893554687\t ACC train:  0.9916666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1162: \tAverage Loss:  0.9884917602539063\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1163: \tAverage Loss:  0.9882215423583984\t ACC train:  0.9933333333333333\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1164: \tAverage Loss:  0.9882818908691406\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1165: \tAverage Loss:  0.988064697265625\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1166: \tAverage Loss:  0.9879193420410156\t ACC train:  0.9933333333333333\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1167: \tAverage Loss:  0.9881721801757812\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1168: \tAverage Loss:  0.987877197265625\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1169: \tAverage Loss:  0.987811767578125\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1170: \tAverage Loss:  0.9878027038574219\t ACC train:  0.9916666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1171: \tAverage Loss:  0.98780126953125\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1172: \tAverage Loss:  0.9878032836914062\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1173: \tAverage Loss:  0.98789111328125\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1174: \tAverage Loss:  0.9879676971435547\t ACC train:  0.995\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1175: \tAverage Loss:  0.9880825958251953\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1176: \tAverage Loss:  0.9881920623779297\t ACC train:  0.9916666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1177: \tAverage Loss:  0.9882877502441406\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1178: \tAverage Loss:  0.9886000823974609\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1179: \tAverage Loss:  0.988783218383789\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1180: \tAverage Loss:  0.9891683044433593\t ACC train:  0.99\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1181: \tAverage Loss:  0.9896636199951172\t ACC train:  0.995\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1182: \tAverage Loss:  0.9899754943847656\t ACC train:  0.99\t ACC test:  0.98\n",
      "\tEpoch 1183: \tAverage Loss:  0.9895291137695312\t ACC train:  0.9933333333333333\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1184: \tAverage Loss:  0.9897058410644531\t ACC train:  0.9933333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1185: \tAverage Loss:  0.9885971221923828\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1186: \tAverage Loss:  0.9877874908447266\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1187: \tAverage Loss:  0.9872268829345703\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1188: \tAverage Loss:  0.9869970703125\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1189: \tAverage Loss:  0.987063491821289\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1190: \tAverage Loss:  0.9872112426757812\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1191: \tAverage Loss:  0.9873882904052734\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1192: \tAverage Loss:  0.9873612823486329\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1193: \tAverage Loss:  0.9875496063232422\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1194: \tAverage Loss:  0.987386947631836\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1195: \tAverage Loss:  0.987404281616211\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1196: \tAverage Loss:  0.9872232208251953\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1197: \tAverage Loss:  0.987052505493164\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1198: \tAverage Loss:  0.9867610321044922\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1199: \tAverage Loss:  0.9866335144042969\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1200: \tAverage Loss:  0.9865020751953125\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1201: \tAverage Loss:  0.9864585876464844\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1202: \tAverage Loss:  0.9865628662109375\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1203: \tAverage Loss:  0.9865499267578125\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1204: \tAverage Loss:  0.9867224578857422\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1205: \tAverage Loss:  0.9867437133789062\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1206: \tAverage Loss:  0.9868886413574218\t ACC train:  0.9933333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1207: \tAverage Loss:  0.9871532897949219\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1208: \tAverage Loss:  0.9873074645996094\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1209: \tAverage Loss:  0.9874561462402344\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1210: \tAverage Loss:  0.9876502075195313\t ACC train:  0.9933333333333333\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1211: \tAverage Loss:  0.9877711029052735\t ACC train:  0.9966666666666667\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1212: \tAverage Loss:  0.9878506622314454\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1213: \tAverage Loss:  0.9874587707519531\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1214: \tAverage Loss:  0.986986801147461\t ACC train:  0.995\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1215: \tAverage Loss:  0.9862276763916016\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1216: \tAverage Loss:  0.9859752349853516\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1217: \tAverage Loss:  0.9858475341796875\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1218: \tAverage Loss:  0.9857956237792969\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1219: \tAverage Loss:  0.9860239410400391\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1220: \tAverage Loss:  0.9861664581298828\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1221: \tAverage Loss:  0.9864060974121094\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1222: \tAverage Loss:  0.9864696197509766\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1223: \tAverage Loss:  0.9864212036132812\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1224: \tAverage Loss:  0.98650390625\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1225: \tAverage Loss:  0.9867789764404297\t ACC train:  0.995\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1226: \tAverage Loss:  0.9868470611572265\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1227: \tAverage Loss:  0.9869633483886718\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1228: \tAverage Loss:  0.9867767639160157\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1229: \tAverage Loss:  0.986552963256836\t ACC train:  0.995\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1230: \tAverage Loss:  0.9860183258056641\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1231: \tAverage Loss:  0.9856416931152344\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1232: \tAverage Loss:  0.9853416442871094\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1233: \tAverage Loss:  0.9852126159667969\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1234: \tAverage Loss:  0.985220458984375\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1235: \tAverage Loss:  0.9853614349365234\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1236: \tAverage Loss:  0.9854730987548828\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1237: \tAverage Loss:  0.985586669921875\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1238: \tAverage Loss:  0.9856862335205078\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1239: \tAverage Loss:  0.9856908569335937\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1240: \tAverage Loss:  0.9856496887207031\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1241: \tAverage Loss:  0.9857395629882812\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1242: \tAverage Loss:  0.9859458770751953\t ACC train:  0.995\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1243: \tAverage Loss:  0.9861863861083985\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1244: \tAverage Loss:  0.9862185516357422\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1245: \tAverage Loss:  0.9863486022949218\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1246: \tAverage Loss:  0.9868862762451172\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1247: \tAverage Loss:  0.9865669860839844\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1248: \tAverage Loss:  0.9864014892578125\t ACC train:  0.995\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1249: \tAverage Loss:  0.9858968200683593\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1250: \tAverage Loss:  0.9854519805908203\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1251: \tAverage Loss:  0.9847812652587891\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1252: \tAverage Loss:  0.9845035705566406\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1253: \tAverage Loss:  0.9846579284667969\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1254: \tAverage Loss:  0.9848926086425781\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1255: \tAverage Loss:  0.985125228881836\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1256: \tAverage Loss:  0.9852512512207031\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1257: \tAverage Loss:  0.9852091522216797\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1258: \tAverage Loss:  0.9847879180908203\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1259: \tAverage Loss:  0.9844462890625\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1260: \tAverage Loss:  0.9842737731933594\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1261: \tAverage Loss:  0.9842404479980469\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1262: \tAverage Loss:  0.9841745910644532\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1263: \tAverage Loss:  0.9841602020263672\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1264: \tAverage Loss:  0.984117446899414\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1265: \tAverage Loss:  0.9840525512695313\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1266: \tAverage Loss:  0.984046142578125\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1267: \tAverage Loss:  0.984004867553711\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1268: \tAverage Loss:  0.9839535827636718\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1269: \tAverage Loss:  0.9839308471679687\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1270: \tAverage Loss:  0.9839150543212891\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1271: \tAverage Loss:  0.9839288482666015\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1272: \tAverage Loss:  0.9840367584228515\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1273: \tAverage Loss:  0.9843176727294922\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1274: \tAverage Loss:  0.9844288940429687\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1275: \tAverage Loss:  0.9847254943847656\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1276: \tAverage Loss:  0.9849865417480469\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1277: \tAverage Loss:  0.9852432250976563\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1278: \tAverage Loss:  0.985479248046875\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1279: \tAverage Loss:  0.9856201324462891\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1280: \tAverage Loss:  0.9855600891113281\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1281: \tAverage Loss:  0.9854117889404297\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1282: \tAverage Loss:  0.9847848358154296\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1283: \tAverage Loss:  0.9845124816894532\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1284: \tAverage Loss:  0.9838651885986328\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1285: \tAverage Loss:  0.9835438842773437\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1286: \tAverage Loss:  0.9833641052246094\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1287: \tAverage Loss:  0.9833058776855469\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1288: \tAverage Loss:  0.9833276672363281\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1289: \tAverage Loss:  0.9833905181884766\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1290: \tAverage Loss:  0.983463394165039\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1291: \tAverage Loss:  0.9835209045410156\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1292: \tAverage Loss:  0.9838338165283204\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1293: \tAverage Loss:  0.9839571838378907\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1294: \tAverage Loss:  0.9843822326660157\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1295: \tAverage Loss:  0.9845733032226562\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1296: \tAverage Loss:  0.9849659423828125\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1297: \tAverage Loss:  0.9848717651367187\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1298: \tAverage Loss:  0.9852228393554687\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1299: \tAverage Loss:  0.9851526794433594\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1300: \tAverage Loss:  0.9849341735839844\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1301: \tAverage Loss:  0.9840318908691407\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1302: \tAverage Loss:  0.9836471862792969\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1303: \tAverage Loss:  0.9831034088134766\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1304: \tAverage Loss:  0.9828558349609375\t ACC train:  0.9966666666666667\t ACC test:  0.98\n",
      "\tEpoch 1305: \tAverage Loss:  0.98276806640625\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1306: \tAverage Loss:  0.9827280731201172\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1307: \tAverage Loss:  0.982854476928711\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1308: \tAverage Loss:  0.9828759155273438\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1309: \tAverage Loss:  0.9827950897216797\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1310: \tAverage Loss:  0.9827178192138671\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1311: \tAverage Loss:  0.98262841796875\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1312: \tAverage Loss:  0.9825840148925781\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1313: \tAverage Loss:  0.9825599822998047\t ACC train:  0.9966666666666667\t ACC test:  0.98\n",
      "\tEpoch 1314: \tAverage Loss:  0.9825571594238282\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1315: \tAverage Loss:  0.982643798828125\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1316: \tAverage Loss:  0.9827781066894531\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1317: \tAverage Loss:  0.982788558959961\t ACC train:  0.9966666666666667\t ACC test:  0.98\n",
      "\tEpoch 1318: \tAverage Loss:  0.98287939453125\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1319: \tAverage Loss:  0.9827432861328125\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1320: \tAverage Loss:  0.9826901550292969\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1321: \tAverage Loss:  0.982640853881836\t ACC train:  0.9966666666666667\t ACC test:  0.98\n",
      "\tEpoch 1322: \tAverage Loss:  0.9825751953125\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1323: \tAverage Loss:  0.9824320373535156\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1324: \tAverage Loss:  0.98243896484375\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1325: \tAverage Loss:  0.9824023742675781\t ACC train:  0.9966666666666667\t ACC test:  0.98\n",
      "\tEpoch 1326: \tAverage Loss:  0.9826322479248046\t ACC train:  0.9966666666666667\t ACC test:  0.98\n",
      "\tEpoch 1327: \tAverage Loss:  0.9826397247314453\t ACC train:  0.9966666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1328: \tAverage Loss:  0.9828492736816407\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1329: \tAverage Loss:  0.9829221801757813\t ACC train:  0.9966666666666667\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1330: \tAverage Loss:  0.9834302978515626\t ACC train:  0.9966666666666667\t ACC test:  0.9777777777777777\n",
      "Stopping early at epoch 1330. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 700\n",
      "\tEpoch 1: \tAverage Loss:  3.161424499511719\t ACC train:  0.4942857142857143\t ACC test:  0.5044444444444445\n",
      "\tEpoch 2: \tAverage Loss:  3.130204345703125\t ACC train:  0.49714285714285716\t ACC test:  0.4688888888888889\n",
      "\tEpoch 3: \tAverage Loss:  3.10184521484375\t ACC train:  0.5028571428571429\t ACC test:  0.5155555555555555\n",
      "\tEpoch 4: \tAverage Loss:  3.0779903564453126\t ACC train:  0.53\t ACC test:  0.5022222222222222\n",
      "\tEpoch 5: \tAverage Loss:  3.0576602172851564\t ACC train:  0.5185714285714286\t ACC test:  0.5022222222222222\n",
      "\tEpoch 6: \tAverage Loss:  3.041011779785156\t ACC train:  0.5271428571428571\t ACC test:  0.4911111111111111\n",
      "\tEpoch 7: \tAverage Loss:  3.0224283447265625\t ACC train:  0.5214285714285715\t ACC test:  0.4911111111111111\n",
      "\tEpoch 8: \tAverage Loss:  3.0078478393554686\t ACC train:  0.5157142857142857\t ACC test:  0.4911111111111111\n",
      "\tEpoch 9: \tAverage Loss:  2.992442626953125\t ACC train:  0.5142857142857142\t ACC test:  0.4911111111111111\n",
      "\tEpoch 10: \tAverage Loss:  2.978540283203125\t ACC train:  0.5185714285714286\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  2.9642469482421876\t ACC train:  0.5185714285714286\t ACC test:  0.4911111111111111\n",
      "\tEpoch 12: \tAverage Loss:  2.950454833984375\t ACC train:  0.5185714285714286\t ACC test:  0.4888888888888889\n",
      "\tEpoch 13: \tAverage Loss:  2.9352324829101564\t ACC train:  0.5157142857142857\t ACC test:  0.4911111111111111\n",
      "\tEpoch 14: \tAverage Loss:  2.9263856201171876\t ACC train:  0.5171428571428571\t ACC test:  0.4888888888888889\n",
      "\tEpoch 15: \tAverage Loss:  2.913229187011719\t ACC train:  0.52\t ACC test:  0.49777777777777776\n",
      "\tEpoch 16: \tAverage Loss:  2.9010008544921875\t ACC train:  0.5185714285714286\t ACC test:  0.4888888888888889\n",
      "\tEpoch 17: \tAverage Loss:  2.8892666015625\t ACC train:  0.5285714285714286\t ACC test:  0.4911111111111111\n",
      "\tEpoch 18: \tAverage Loss:  2.8804039306640625\t ACC train:  0.5228571428571429\t ACC test:  0.5022222222222222\n",
      "\tEpoch 19: \tAverage Loss:  2.8691065673828127\t ACC train:  0.5285714285714286\t ACC test:  0.49333333333333335\n",
      "\tEpoch 20: \tAverage Loss:  2.8576756591796877\t ACC train:  0.5214285714285715\t ACC test:  0.5155555555555555\n",
      "\tEpoch 21: \tAverage Loss:  2.8488917236328124\t ACC train:  0.5257142857142857\t ACC test:  0.5066666666666667\n",
      "\tEpoch 22: \tAverage Loss:  2.8392687377929686\t ACC train:  0.5528571428571428\t ACC test:  0.5088888888888888\n",
      "\tEpoch 23: \tAverage Loss:  2.829148010253906\t ACC train:  0.5557142857142857\t ACC test:  0.5222222222222223\n",
      "\tEpoch 24: \tAverage Loss:  2.822741271972656\t ACC train:  0.5385714285714286\t ACC test:  0.5155555555555555\n",
      "\tEpoch 25: \tAverage Loss:  2.811059814453125\t ACC train:  0.5585714285714286\t ACC test:  0.5444444444444444\n",
      "\tEpoch 26: \tAverage Loss:  2.8000980224609373\t ACC train:  0.5414285714285715\t ACC test:  0.5333333333333333\n",
      "\tEpoch 27: \tAverage Loss:  2.7928446044921875\t ACC train:  0.5671428571428572\t ACC test:  0.5022222222222222\n",
      "\tEpoch 28: \tAverage Loss:  2.776759521484375\t ACC train:  0.5628571428571428\t ACC test:  0.5488888888888889\n",
      "\tEpoch 29: \tAverage Loss:  2.7753943481445313\t ACC train:  0.5542857142857143\t ACC test:  0.5422222222222223\n",
      "\tEpoch 30: \tAverage Loss:  2.768694885253906\t ACC train:  0.5571428571428572\t ACC test:  0.5488888888888889\n",
      "\tEpoch 31: \tAverage Loss:  2.7519586791992188\t ACC train:  0.5485714285714286\t ACC test:  0.5266666666666666\n",
      "\tEpoch 32: \tAverage Loss:  2.7389969482421876\t ACC train:  0.5514285714285714\t ACC test:  0.5244444444444445\n",
      "\tEpoch 33: \tAverage Loss:  2.7241715087890626\t ACC train:  0.5485714285714286\t ACC test:  0.5155555555555555\n",
      "\tEpoch 34: \tAverage Loss:  2.7256529541015624\t ACC train:  0.5542857142857143\t ACC test:  0.5377777777777778\n",
      "\tEpoch 35: \tAverage Loss:  2.6944307861328123\t ACC train:  0.5471428571428572\t ACC test:  0.5577777777777778\n",
      "\tEpoch 36: \tAverage Loss:  2.685278076171875\t ACC train:  0.5471428571428572\t ACC test:  0.5266666666666666\n",
      "\tEpoch 37: \tAverage Loss:  2.6871107177734377\t ACC train:  0.5442857142857143\t ACC test:  0.5444444444444444\n",
      "\tEpoch 38: \tAverage Loss:  2.661602294921875\t ACC train:  0.5571428571428572\t ACC test:  0.5311111111111111\n",
      "\tEpoch 39: \tAverage Loss:  2.649717590332031\t ACC train:  0.5414285714285715\t ACC test:  0.5511111111111111\n",
      "\tEpoch 40: \tAverage Loss:  2.6355553588867187\t ACC train:  0.5585714285714286\t ACC test:  0.5288888888888889\n",
      "\tEpoch 41: \tAverage Loss:  2.6138873291015625\t ACC train:  0.56\t ACC test:  0.5288888888888889\n",
      "\tEpoch 42: \tAverage Loss:  2.6063715209960936\t ACC train:  0.5557142857142857\t ACC test:  0.5244444444444445\n",
      "\tEpoch 43: \tAverage Loss:  2.5716493530273437\t ACC train:  0.5328571428571428\t ACC test:  0.5444444444444444\n",
      "\tEpoch 44: \tAverage Loss:  2.5898776245117188\t ACC train:  0.55\t ACC test:  0.5244444444444445\n",
      "\tEpoch 45: \tAverage Loss:  2.5464561157226564\t ACC train:  0.5528571428571428\t ACC test:  0.52\n",
      "\tEpoch 46: \tAverage Loss:  2.5436801147460937\t ACC train:  0.53\t ACC test:  0.5444444444444444\n",
      "\tEpoch 47: \tAverage Loss:  2.502104064941406\t ACC train:  0.5285714285714286\t ACC test:  0.5266666666666666\n",
      "\tEpoch 48: \tAverage Loss:  2.484181457519531\t ACC train:  0.5342857142857143\t ACC test:  0.5266666666666666\n",
      "\tEpoch 49: \tAverage Loss:  2.478990478515625\t ACC train:  0.5485714285714286\t ACC test:  0.5511111111111111\n",
      "\tEpoch 50: \tAverage Loss:  2.4199400634765627\t ACC train:  0.5442857142857143\t ACC test:  0.5288888888888889\n",
      "\tEpoch 51: \tAverage Loss:  2.452736328125\t ACC train:  0.5414285714285715\t ACC test:  0.5355555555555556\n",
      "\tEpoch 52: \tAverage Loss:  2.3991414184570314\t ACC train:  0.5585714285714286\t ACC test:  0.5222222222222223\n",
      "\tEpoch 53: \tAverage Loss:  2.3985192260742187\t ACC train:  0.5528571428571428\t ACC test:  0.5311111111111111\n",
      "\tEpoch 54: \tAverage Loss:  2.361156311035156\t ACC train:  0.5514285714285714\t ACC test:  0.5377777777777778\n",
      "\tEpoch 55: \tAverage Loss:  2.3600982666015624\t ACC train:  0.5685714285714286\t ACC test:  0.52\n",
      "\tEpoch 56: \tAverage Loss:  2.3350836791992187\t ACC train:  0.5457142857142857\t ACC test:  0.5422222222222223\n",
      "\tEpoch 57: \tAverage Loss:  2.3381697998046875\t ACC train:  0.5514285714285714\t ACC test:  0.5355555555555556\n",
      "\tEpoch 58: \tAverage Loss:  2.2952918090820313\t ACC train:  0.5642857142857143\t ACC test:  0.5466666666666666\n",
      "\tEpoch 59: \tAverage Loss:  2.262976318359375\t ACC train:  0.5657142857142857\t ACC test:  0.5533333333333333\n",
      "\tEpoch 60: \tAverage Loss:  2.253562255859375\t ACC train:  0.5642857142857143\t ACC test:  0.5533333333333333\n",
      "\tEpoch 61: \tAverage Loss:  2.233657958984375\t ACC train:  0.5885714285714285\t ACC test:  0.5333333333333333\n",
      "\tEpoch 62: \tAverage Loss:  2.213630615234375\t ACC train:  0.5657142857142857\t ACC test:  0.5355555555555556\n",
      "\tEpoch 63: \tAverage Loss:  2.205675598144531\t ACC train:  0.5728571428571428\t ACC test:  0.5377777777777778\n",
      "\tEpoch 64: \tAverage Loss:  2.1874762573242186\t ACC train:  0.5914285714285714\t ACC test:  0.54\n",
      "\tEpoch 65: \tAverage Loss:  2.161668151855469\t ACC train:  0.5914285714285714\t ACC test:  0.5555555555555556\n",
      "\tEpoch 66: \tAverage Loss:  2.154370788574219\t ACC train:  0.5928571428571429\t ACC test:  0.5466666666666666\n",
      "\tEpoch 67: \tAverage Loss:  2.115153259277344\t ACC train:  0.5742857142857143\t ACC test:  0.5577777777777778\n",
      "\tEpoch 68: \tAverage Loss:  2.109863220214844\t ACC train:  0.5871428571428572\t ACC test:  0.5644444444444444\n",
      "\tEpoch 69: \tAverage Loss:  2.104333068847656\t ACC train:  0.6\t ACC test:  0.5422222222222223\n",
      "\tEpoch 70: \tAverage Loss:  2.1043275756835937\t ACC train:  0.5914285714285714\t ACC test:  0.5755555555555556\n",
      "\tEpoch 71: \tAverage Loss:  2.0719703369140623\t ACC train:  0.5785714285714286\t ACC test:  0.54\n",
      "\tEpoch 72: \tAverage Loss:  2.059262939453125\t ACC train:  0.5914285714285714\t ACC test:  0.5577777777777778\n",
      "\tEpoch 73: \tAverage Loss:  2.0618311767578126\t ACC train:  0.5971428571428572\t ACC test:  0.5511111111111111\n",
      "\tEpoch 74: \tAverage Loss:  2.0462476806640626\t ACC train:  0.5914285714285714\t ACC test:  0.56\n",
      "\tEpoch 75: \tAverage Loss:  2.0329248046875\t ACC train:  0.5914285714285714\t ACC test:  0.5955555555555555\n",
      "\tEpoch 76: \tAverage Loss:  2.0145020141601564\t ACC train:  0.5828571428571429\t ACC test:  0.5533333333333333\n",
      "\tEpoch 77: \tAverage Loss:  2.000141357421875\t ACC train:  0.5871428571428572\t ACC test:  0.56\n",
      "\tEpoch 78: \tAverage Loss:  2.002890380859375\t ACC train:  0.5942857142857143\t ACC test:  0.5488888888888889\n",
      "\tEpoch 79: \tAverage Loss:  1.9794486694335938\t ACC train:  0.6071428571428571\t ACC test:  0.5622222222222222\n",
      "\tEpoch 80: \tAverage Loss:  1.9713717041015626\t ACC train:  0.6085714285714285\t ACC test:  0.5755555555555556\n",
      "\tEpoch 81: \tAverage Loss:  1.9626355590820312\t ACC train:  0.5842857142857143\t ACC test:  0.5711111111111111\n",
      "\tEpoch 82: \tAverage Loss:  1.94794677734375\t ACC train:  0.5942857142857143\t ACC test:  0.5488888888888889\n",
      "\tEpoch 83: \tAverage Loss:  1.9393991088867188\t ACC train:  0.6042857142857143\t ACC test:  0.5711111111111111\n",
      "\tEpoch 84: \tAverage Loss:  1.9347839965820313\t ACC train:  0.6157142857142858\t ACC test:  0.5777777777777777\n",
      "\tEpoch 85: \tAverage Loss:  1.9273196411132814\t ACC train:  0.5985714285714285\t ACC test:  0.5755555555555556\n",
      "\tEpoch 86: \tAverage Loss:  1.9210338745117188\t ACC train:  0.6171428571428571\t ACC test:  0.5555555555555556\n",
      "\tEpoch 87: \tAverage Loss:  1.9127937622070312\t ACC train:  0.6171428571428571\t ACC test:  0.5622222222222222\n",
      "\tEpoch 88: \tAverage Loss:  1.9032772216796876\t ACC train:  0.6057142857142858\t ACC test:  0.5555555555555556\n",
      "\tEpoch 89: \tAverage Loss:  1.9029559326171874\t ACC train:  0.6128571428571429\t ACC test:  0.5622222222222222\n",
      "\tEpoch 90: \tAverage Loss:  1.8933388061523437\t ACC train:  0.6157142857142858\t ACC test:  0.5711111111111111\n",
      "\tEpoch 91: \tAverage Loss:  1.889010009765625\t ACC train:  0.6142857142857143\t ACC test:  0.5688888888888889\n",
      "\tEpoch 92: \tAverage Loss:  1.8801781005859375\t ACC train:  0.6085714285714285\t ACC test:  0.5755555555555556\n",
      "\tEpoch 93: \tAverage Loss:  1.8771588134765624\t ACC train:  0.6071428571428571\t ACC test:  0.5622222222222222\n",
      "\tEpoch 94: \tAverage Loss:  1.87132275390625\t ACC train:  0.6071428571428571\t ACC test:  0.5622222222222222\n",
      "\tEpoch 95: \tAverage Loss:  1.8682239990234375\t ACC train:  0.6171428571428571\t ACC test:  0.58\n",
      "\tEpoch 96: \tAverage Loss:  1.8616032104492188\t ACC train:  0.6242857142857143\t ACC test:  0.5777777777777777\n",
      "\tEpoch 97: \tAverage Loss:  1.8540692138671875\t ACC train:  0.6114285714285714\t ACC test:  0.5733333333333334\n",
      "\tEpoch 98: \tAverage Loss:  1.8559196166992187\t ACC train:  0.6157142857142858\t ACC test:  0.5711111111111111\n",
      "\tEpoch 99: \tAverage Loss:  1.8496693725585938\t ACC train:  0.62\t ACC test:  0.5755555555555556\n",
      "\tEpoch 100: \tAverage Loss:  1.8431807250976562\t ACC train:  0.6228571428571429\t ACC test:  0.5733333333333334\n",
      "\tEpoch 101: \tAverage Loss:  1.8412950439453124\t ACC train:  0.6242857142857143\t ACC test:  0.5911111111111111\n",
      "\tEpoch 102: \tAverage Loss:  1.8341701049804688\t ACC train:  0.6257142857142857\t ACC test:  0.5777777777777777\n",
      "\tEpoch 103: \tAverage Loss:  1.8301685180664062\t ACC train:  0.6228571428571429\t ACC test:  0.5755555555555556\n",
      "\tEpoch 104: \tAverage Loss:  1.8257263793945313\t ACC train:  0.6285714285714286\t ACC test:  0.58\n",
      "\tEpoch 105: \tAverage Loss:  1.8223138427734376\t ACC train:  0.6228571428571429\t ACC test:  0.5844444444444444\n",
      "\tEpoch 106: \tAverage Loss:  1.8231582641601562\t ACC train:  0.6314285714285715\t ACC test:  0.5977777777777777\n",
      "\tEpoch 107: \tAverage Loss:  1.8179375610351562\t ACC train:  0.6285714285714286\t ACC test:  0.5844444444444444\n",
      "\tEpoch 108: \tAverage Loss:  1.8161548461914063\t ACC train:  0.6228571428571429\t ACC test:  0.5977777777777777\n",
      "\tEpoch 109: \tAverage Loss:  1.8100995483398437\t ACC train:  0.6357142857142857\t ACC test:  0.6022222222222222\n",
      "\tEpoch 110: \tAverage Loss:  1.8116179809570312\t ACC train:  0.6271428571428571\t ACC test:  0.5911111111111111\n",
      "\tEpoch 111: \tAverage Loss:  1.8040242309570313\t ACC train:  0.62\t ACC test:  0.5822222222222222\n",
      "\tEpoch 112: \tAverage Loss:  1.8042955932617188\t ACC train:  0.6357142857142857\t ACC test:  0.6088888888888889\n",
      "\tEpoch 113: \tAverage Loss:  1.802106201171875\t ACC train:  0.64\t ACC test:  0.6\n",
      "\tEpoch 114: \tAverage Loss:  1.7959417114257812\t ACC train:  0.6371428571428571\t ACC test:  0.6\n",
      "\tEpoch 115: \tAverage Loss:  1.7948924560546875\t ACC train:  0.6342857142857142\t ACC test:  0.5933333333333334\n",
      "\tEpoch 116: \tAverage Loss:  1.7925396728515626\t ACC train:  0.64\t ACC test:  0.6133333333333333\n",
      "\tEpoch 117: \tAverage Loss:  1.7891414794921876\t ACC train:  0.64\t ACC test:  0.5933333333333334\n",
      "\tEpoch 118: \tAverage Loss:  1.7874290771484376\t ACC train:  0.6342857142857142\t ACC test:  0.6\n",
      "\tEpoch 119: \tAverage Loss:  1.783850830078125\t ACC train:  0.64\t ACC test:  0.5911111111111111\n",
      "\tEpoch 120: \tAverage Loss:  1.7816426391601563\t ACC train:  0.64\t ACC test:  0.6022222222222222\n",
      "\tEpoch 121: \tAverage Loss:  1.7778797912597657\t ACC train:  0.6442857142857142\t ACC test:  0.6066666666666667\n",
      "\tEpoch 122: \tAverage Loss:  1.7765176391601563\t ACC train:  0.6514285714285715\t ACC test:  0.6244444444444445\n",
      "\tEpoch 123: \tAverage Loss:  1.7772276611328126\t ACC train:  0.6471428571428571\t ACC test:  0.6088888888888889\n",
      "\tEpoch 124: \tAverage Loss:  1.7727892456054688\t ACC train:  0.65\t ACC test:  0.6\n",
      "\tEpoch 125: \tAverage Loss:  1.7723445434570313\t ACC train:  0.6442857142857142\t ACC test:  0.6111111111111112\n",
      "\tEpoch 126: \tAverage Loss:  1.7692007446289062\t ACC train:  0.64\t ACC test:  0.6133333333333333\n",
      "\tEpoch 127: \tAverage Loss:  1.7681602172851563\t ACC train:  0.6357142857142857\t ACC test:  0.6066666666666667\n",
      "\tEpoch 128: \tAverage Loss:  1.7651447143554688\t ACC train:  0.6357142857142857\t ACC test:  0.6266666666666667\n",
      "\tEpoch 129: \tAverage Loss:  1.7629441528320313\t ACC train:  0.6371428571428571\t ACC test:  0.6111111111111112\n",
      "\tEpoch 130: \tAverage Loss:  1.7628334350585937\t ACC train:  0.65\t ACC test:  0.6133333333333333\n",
      "\tEpoch 131: \tAverage Loss:  1.7608156127929688\t ACC train:  0.6528571428571428\t ACC test:  0.6133333333333333\n",
      "\tEpoch 132: \tAverage Loss:  1.7573880004882811\t ACC train:  0.6485714285714286\t ACC test:  0.62\n",
      "\tEpoch 133: \tAverage Loss:  1.7559696350097656\t ACC train:  0.6428571428571429\t ACC test:  0.62\n",
      "\tEpoch 134: \tAverage Loss:  1.7549085693359374\t ACC train:  0.6514285714285715\t ACC test:  0.6222222222222222\n",
      "\tEpoch 135: \tAverage Loss:  1.7525472412109375\t ACC train:  0.6414285714285715\t ACC test:  0.6155555555555555\n",
      "\tEpoch 136: \tAverage Loss:  1.752285888671875\t ACC train:  0.6485714285714286\t ACC test:  0.6177777777777778\n",
      "\tEpoch 137: \tAverage Loss:  1.7530535888671874\t ACC train:  0.65\t ACC test:  0.6155555555555555\n",
      "\tEpoch 138: \tAverage Loss:  1.7494366760253905\t ACC train:  0.64\t ACC test:  0.6266666666666667\n",
      "\tEpoch 139: \tAverage Loss:  1.749354705810547\t ACC train:  0.6485714285714286\t ACC test:  0.6266666666666667\n",
      "\tEpoch 140: \tAverage Loss:  1.74567724609375\t ACC train:  0.6528571428571428\t ACC test:  0.6222222222222222\n",
      "\tEpoch 141: \tAverage Loss:  1.7440193481445312\t ACC train:  0.6514285714285715\t ACC test:  0.6177777777777778\n",
      "\tEpoch 142: \tAverage Loss:  1.7437050170898438\t ACC train:  0.6514285714285715\t ACC test:  0.6311111111111111\n",
      "\tEpoch 143: \tAverage Loss:  1.7419441833496094\t ACC train:  0.6414285714285715\t ACC test:  0.6177777777777778\n",
      "\tEpoch 144: \tAverage Loss:  1.7396156005859376\t ACC train:  0.6471428571428571\t ACC test:  0.6311111111111111\n",
      "\tEpoch 145: \tAverage Loss:  1.7399962158203126\t ACC train:  0.6414285714285715\t ACC test:  0.6311111111111111\n",
      "\tEpoch 146: \tAverage Loss:  1.7369884338378907\t ACC train:  0.65\t ACC test:  0.6266666666666667\n",
      "\tEpoch 147: \tAverage Loss:  1.736045654296875\t ACC train:  0.6485714285714286\t ACC test:  0.62\n",
      "\tEpoch 148: \tAverage Loss:  1.7351895446777343\t ACC train:  0.6585714285714286\t ACC test:  0.6355555555555555\n",
      "\tEpoch 149: \tAverage Loss:  1.7340287780761718\t ACC train:  0.6514285714285715\t ACC test:  0.6288888888888889\n",
      "\tEpoch 150: \tAverage Loss:  1.732935333251953\t ACC train:  0.6542857142857142\t ACC test:  0.6244444444444445\n",
      "\tEpoch 151: \tAverage Loss:  1.7314879760742188\t ACC train:  0.6528571428571428\t ACC test:  0.6355555555555555\n",
      "\tEpoch 152: \tAverage Loss:  1.7320005493164063\t ACC train:  0.6557142857142857\t ACC test:  0.62\n",
      "\tEpoch 153: \tAverage Loss:  1.7311055603027343\t ACC train:  0.65\t ACC test:  0.6288888888888889\n",
      "\tEpoch 154: \tAverage Loss:  1.7294253540039062\t ACC train:  0.6528571428571428\t ACC test:  0.6266666666666667\n",
      "\tEpoch 155: \tAverage Loss:  1.7288901977539062\t ACC train:  0.6528571428571428\t ACC test:  0.6288888888888889\n",
      "\tEpoch 156: \tAverage Loss:  1.726551788330078\t ACC train:  0.6514285714285715\t ACC test:  0.6288888888888889\n",
      "\tEpoch 157: \tAverage Loss:  1.7251607360839845\t ACC train:  0.6471428571428571\t ACC test:  0.6266666666666667\n",
      "\tEpoch 158: \tAverage Loss:  1.7232814025878906\t ACC train:  0.6514285714285715\t ACC test:  0.6311111111111111\n",
      "\tEpoch 159: \tAverage Loss:  1.7216598205566407\t ACC train:  0.6557142857142857\t ACC test:  0.6311111111111111\n",
      "\tEpoch 160: \tAverage Loss:  1.7200640258789062\t ACC train:  0.6542857142857142\t ACC test:  0.6288888888888889\n",
      "\tEpoch 161: \tAverage Loss:  1.719737030029297\t ACC train:  0.6528571428571428\t ACC test:  0.62\n",
      "\tEpoch 162: \tAverage Loss:  1.7205987548828126\t ACC train:  0.6571428571428571\t ACC test:  0.6266666666666667\n",
      "\tEpoch 163: \tAverage Loss:  1.7195205383300782\t ACC train:  0.65\t ACC test:  0.6333333333333333\n",
      "\tEpoch 164: \tAverage Loss:  1.7178258666992188\t ACC train:  0.6571428571428571\t ACC test:  0.6311111111111111\n",
      "\tEpoch 165: \tAverage Loss:  1.714394287109375\t ACC train:  0.65\t ACC test:  0.6266666666666667\n",
      "\tEpoch 166: \tAverage Loss:  1.7152981262207032\t ACC train:  0.6585714285714286\t ACC test:  0.6355555555555555\n",
      "\tEpoch 167: \tAverage Loss:  1.7124099426269532\t ACC train:  0.6571428571428571\t ACC test:  0.6333333333333333\n",
      "\tEpoch 168: \tAverage Loss:  1.7164312438964844\t ACC train:  0.6514285714285715\t ACC test:  0.6377777777777778\n",
      "\tEpoch 169: \tAverage Loss:  1.7137930297851562\t ACC train:  0.6542857142857142\t ACC test:  0.6333333333333333\n",
      "\tEpoch 170: \tAverage Loss:  1.7112083435058594\t ACC train:  0.6571428571428571\t ACC test:  0.6377777777777778\n",
      "\tEpoch 171: \tAverage Loss:  1.711254913330078\t ACC train:  0.6557142857142857\t ACC test:  0.6333333333333333\n",
      "\tEpoch 172: \tAverage Loss:  1.7089147338867188\t ACC train:  0.6614285714285715\t ACC test:  0.6311111111111111\n",
      "\tEpoch 173: \tAverage Loss:  1.709601043701172\t ACC train:  0.6557142857142857\t ACC test:  0.6377777777777778\n",
      "\tEpoch 174: \tAverage Loss:  1.708359161376953\t ACC train:  0.6542857142857142\t ACC test:  0.6222222222222222\n",
      "\tEpoch 175: \tAverage Loss:  1.7068900756835939\t ACC train:  0.6457142857142857\t ACC test:  0.6288888888888889\n",
      "\tEpoch 176: \tAverage Loss:  1.7072994384765625\t ACC train:  0.6557142857142857\t ACC test:  0.6288888888888889\n",
      "\tEpoch 177: \tAverage Loss:  1.7038226318359375\t ACC train:  0.6514285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 178: \tAverage Loss:  1.7049237976074219\t ACC train:  0.6614285714285715\t ACC test:  0.6355555555555555\n",
      "\tEpoch 179: \tAverage Loss:  1.7032764587402345\t ACC train:  0.6642857142857143\t ACC test:  0.64\n",
      "\tEpoch 180: \tAverage Loss:  1.7031698608398438\t ACC train:  0.6542857142857142\t ACC test:  0.6377777777777778\n",
      "\tEpoch 181: \tAverage Loss:  1.7048803405761719\t ACC train:  0.6614285714285715\t ACC test:  0.64\n",
      "\tEpoch 182: \tAverage Loss:  1.701696746826172\t ACC train:  0.6585714285714286\t ACC test:  0.64\n",
      "\tEpoch 183: \tAverage Loss:  1.7004835510253906\t ACC train:  0.6671428571428571\t ACC test:  0.6444444444444445\n",
      "\tEpoch 184: \tAverage Loss:  1.6989265441894532\t ACC train:  0.6642857142857143\t ACC test:  0.6488888888888888\n",
      "\tEpoch 185: \tAverage Loss:  1.7019682006835937\t ACC train:  0.6657142857142857\t ACC test:  0.6422222222222222\n",
      "\tEpoch 186: \tAverage Loss:  1.6966373596191406\t ACC train:  0.6642857142857143\t ACC test:  0.6422222222222222\n",
      "\tEpoch 187: \tAverage Loss:  1.69738916015625\t ACC train:  0.66\t ACC test:  0.6333333333333333\n",
      "\tEpoch 188: \tAverage Loss:  1.6974515380859374\t ACC train:  0.6671428571428571\t ACC test:  0.6422222222222222\n",
      "\tEpoch 189: \tAverage Loss:  1.6982526245117187\t ACC train:  0.66\t ACC test:  0.6311111111111111\n",
      "\tEpoch 190: \tAverage Loss:  1.697774658203125\t ACC train:  0.6642857142857143\t ACC test:  0.6422222222222222\n",
      "\tEpoch 191: \tAverage Loss:  1.6955553588867187\t ACC train:  0.6671428571428571\t ACC test:  0.6355555555555555\n",
      "\tEpoch 192: \tAverage Loss:  1.6941743469238282\t ACC train:  0.66\t ACC test:  0.6422222222222222\n",
      "\tEpoch 193: \tAverage Loss:  1.693439697265625\t ACC train:  0.6685714285714286\t ACC test:  0.6422222222222222\n",
      "\tEpoch 194: \tAverage Loss:  1.6951356811523437\t ACC train:  0.6642857142857143\t ACC test:  0.6444444444444445\n",
      "\tEpoch 195: \tAverage Loss:  1.6920972900390625\t ACC train:  0.6657142857142857\t ACC test:  0.6466666666666666\n",
      "\tEpoch 196: \tAverage Loss:  1.6920926513671875\t ACC train:  0.6671428571428571\t ACC test:  0.6422222222222222\n",
      "\tEpoch 197: \tAverage Loss:  1.6902069702148437\t ACC train:  0.6557142857142857\t ACC test:  0.6377777777777778\n",
      "\tEpoch 198: \tAverage Loss:  1.6904153747558595\t ACC train:  0.67\t ACC test:  0.6444444444444445\n",
      "\tEpoch 199: \tAverage Loss:  1.690251007080078\t ACC train:  0.6671428571428571\t ACC test:  0.6444444444444445\n",
      "\tEpoch 200: \tAverage Loss:  1.689603790283203\t ACC train:  0.6628571428571428\t ACC test:  0.6377777777777778\n",
      "\tEpoch 201: \tAverage Loss:  1.6880752258300782\t ACC train:  0.6671428571428571\t ACC test:  0.64\n",
      "\tEpoch 202: \tAverage Loss:  1.6869808349609374\t ACC train:  0.6657142857142857\t ACC test:  0.6444444444444445\n",
      "\tEpoch 203: \tAverage Loss:  1.6856157836914063\t ACC train:  0.6657142857142857\t ACC test:  0.6377777777777778\n",
      "\tEpoch 204: \tAverage Loss:  1.6850316772460938\t ACC train:  0.6657142857142857\t ACC test:  0.64\n",
      "\tEpoch 205: \tAverage Loss:  1.6846028442382812\t ACC train:  0.66\t ACC test:  0.6422222222222222\n",
      "\tEpoch 206: \tAverage Loss:  1.6837347412109376\t ACC train:  0.6728571428571428\t ACC test:  0.6444444444444445\n",
      "\tEpoch 207: \tAverage Loss:  1.6832803649902344\t ACC train:  0.6642857142857143\t ACC test:  0.6444444444444445\n",
      "\tEpoch 208: \tAverage Loss:  1.6841956481933593\t ACC train:  0.6685714285714286\t ACC test:  0.6422222222222222\n",
      "\tEpoch 209: \tAverage Loss:  1.6843184814453125\t ACC train:  0.6614285714285715\t ACC test:  0.6466666666666666\n",
      "\tEpoch 210: \tAverage Loss:  1.6820614624023438\t ACC train:  0.6657142857142857\t ACC test:  0.6444444444444445\n",
      "\tEpoch 211: \tAverage Loss:  1.683261474609375\t ACC train:  0.6657142857142857\t ACC test:  0.6422222222222222\n",
      "\tEpoch 212: \tAverage Loss:  1.6811708068847657\t ACC train:  0.6642857142857143\t ACC test:  0.6466666666666666\n",
      "\tEpoch 213: \tAverage Loss:  1.6804062805175781\t ACC train:  0.67\t ACC test:  0.6422222222222222\n",
      "\tEpoch 214: \tAverage Loss:  1.6786072082519532\t ACC train:  0.67\t ACC test:  0.6444444444444445\n",
      "\tEpoch 215: \tAverage Loss:  1.6782727661132812\t ACC train:  0.6685714285714286\t ACC test:  0.6422222222222222\n",
      "\tEpoch 216: \tAverage Loss:  1.6780394287109375\t ACC train:  0.6671428571428571\t ACC test:  0.6422222222222222\n",
      "\tEpoch 217: \tAverage Loss:  1.6786477966308593\t ACC train:  0.6628571428571428\t ACC test:  0.6422222222222222\n",
      "\tEpoch 218: \tAverage Loss:  1.6778744812011719\t ACC train:  0.6671428571428571\t ACC test:  0.6466666666666666\n",
      "\tEpoch 219: \tAverage Loss:  1.6765491638183594\t ACC train:  0.6642857142857143\t ACC test:  0.6444444444444445\n",
      "\tEpoch 220: \tAverage Loss:  1.6739801940917969\t ACC train:  0.6714285714285714\t ACC test:  0.6444444444444445\n",
      "\tEpoch 221: \tAverage Loss:  1.6763732299804688\t ACC train:  0.6742857142857143\t ACC test:  0.6488888888888888\n",
      "\tEpoch 222: \tAverage Loss:  1.6748942565917968\t ACC train:  0.6685714285714286\t ACC test:  0.6488888888888888\n",
      "\tEpoch 223: \tAverage Loss:  1.6748674621582031\t ACC train:  0.6657142857142857\t ACC test:  0.6377777777777778\n",
      "\tEpoch 224: \tAverage Loss:  1.6729352416992187\t ACC train:  0.67\t ACC test:  0.6444444444444445\n",
      "\tEpoch 225: \tAverage Loss:  1.6723489990234375\t ACC train:  0.6614285714285715\t ACC test:  0.6422222222222222\n",
      "\tEpoch 226: \tAverage Loss:  1.6712827758789062\t ACC train:  0.6657142857142857\t ACC test:  0.6466666666666666\n",
      "\tEpoch 227: \tAverage Loss:  1.6702708740234375\t ACC train:  0.6671428571428571\t ACC test:  0.6422222222222222\n",
      "\tEpoch 228: \tAverage Loss:  1.6714755554199219\t ACC train:  0.6685714285714286\t ACC test:  0.6488888888888888\n",
      "\tEpoch 229: \tAverage Loss:  1.6705779724121095\t ACC train:  0.6757142857142857\t ACC test:  0.64\n",
      "\tEpoch 230: \tAverage Loss:  1.6697857666015625\t ACC train:  0.6685714285714286\t ACC test:  0.6466666666666666\n",
      "\tEpoch 231: \tAverage Loss:  1.6696319580078125\t ACC train:  0.6728571428571428\t ACC test:  0.64\n",
      "\tEpoch 232: \tAverage Loss:  1.6692974853515625\t ACC train:  0.6742857142857143\t ACC test:  0.6466666666666666\n",
      "\tEpoch 233: \tAverage Loss:  1.667673309326172\t ACC train:  0.6685714285714286\t ACC test:  0.64\n",
      "\tEpoch 234: \tAverage Loss:  1.6686425476074218\t ACC train:  0.6714285714285714\t ACC test:  0.6466666666666666\n",
      "\tEpoch 235: \tAverage Loss:  1.6672506103515625\t ACC train:  0.6657142857142857\t ACC test:  0.6511111111111111\n",
      "\tEpoch 236: \tAverage Loss:  1.6650325927734375\t ACC train:  0.6657142857142857\t ACC test:  0.6444444444444445\n",
      "\tEpoch 237: \tAverage Loss:  1.6653912658691405\t ACC train:  0.6742857142857143\t ACC test:  0.6466666666666666\n",
      "\tEpoch 238: \tAverage Loss:  1.6635466613769532\t ACC train:  0.6671428571428571\t ACC test:  0.6422222222222222\n",
      "\tEpoch 239: \tAverage Loss:  1.6634919128417969\t ACC train:  0.6728571428571428\t ACC test:  0.6488888888888888\n",
      "\tEpoch 240: \tAverage Loss:  1.6641767883300782\t ACC train:  0.67\t ACC test:  0.6422222222222222\n",
      "\tEpoch 241: \tAverage Loss:  1.663996826171875\t ACC train:  0.6728571428571428\t ACC test:  0.6466666666666666\n",
      "\tEpoch 242: \tAverage Loss:  1.6622007446289062\t ACC train:  0.6714285714285714\t ACC test:  0.6466666666666666\n",
      "\tEpoch 243: \tAverage Loss:  1.6615606079101561\t ACC train:  0.6728571428571428\t ACC test:  0.6488888888888888\n",
      "\tEpoch 244: \tAverage Loss:  1.6614010620117188\t ACC train:  0.6671428571428571\t ACC test:  0.6488888888888888\n",
      "\tEpoch 245: \tAverage Loss:  1.6621915893554688\t ACC train:  0.6714285714285714\t ACC test:  0.6488888888888888\n",
      "\tEpoch 246: \tAverage Loss:  1.6605929565429687\t ACC train:  0.6728571428571428\t ACC test:  0.6444444444444445\n",
      "\tEpoch 247: \tAverage Loss:  1.6609301147460938\t ACC train:  0.6657142857142857\t ACC test:  0.64\n",
      "\tEpoch 248: \tAverage Loss:  1.6611448669433593\t ACC train:  0.6714285714285714\t ACC test:  0.6511111111111111\n",
      "\tEpoch 249: \tAverage Loss:  1.6593126220703125\t ACC train:  0.67\t ACC test:  0.6444444444444445\n",
      "\tEpoch 250: \tAverage Loss:  1.6582237243652345\t ACC train:  0.6728571428571428\t ACC test:  0.6488888888888888\n",
      "\tEpoch 251: \tAverage Loss:  1.658393798828125\t ACC train:  0.6742857142857143\t ACC test:  0.6466666666666666\n",
      "\tEpoch 252: \tAverage Loss:  1.6569725646972657\t ACC train:  0.6757142857142857\t ACC test:  0.6488888888888888\n",
      "\tEpoch 253: \tAverage Loss:  1.6573877258300782\t ACC train:  0.6714285714285714\t ACC test:  0.6466666666666666\n",
      "\tEpoch 254: \tAverage Loss:  1.6564602355957032\t ACC train:  0.6714285714285714\t ACC test:  0.6511111111111111\n",
      "\tEpoch 255: \tAverage Loss:  1.6568724670410155\t ACC train:  0.6671428571428571\t ACC test:  0.6488888888888888\n",
      "\tEpoch 256: \tAverage Loss:  1.655458038330078\t ACC train:  0.67\t ACC test:  0.6422222222222222\n",
      "\tEpoch 257: \tAverage Loss:  1.6549085693359376\t ACC train:  0.6714285714285714\t ACC test:  0.6466666666666666\n",
      "\tEpoch 258: \tAverage Loss:  1.6554183654785157\t ACC train:  0.6671428571428571\t ACC test:  0.6488888888888888\n",
      "\tEpoch 259: \tAverage Loss:  1.6541846313476563\t ACC train:  0.6671428571428571\t ACC test:  0.6422222222222222\n",
      "\tEpoch 260: \tAverage Loss:  1.6524785461425782\t ACC train:  0.6742857142857143\t ACC test:  0.6444444444444445\n",
      "\tEpoch 261: \tAverage Loss:  1.653517303466797\t ACC train:  0.6671428571428571\t ACC test:  0.6444444444444445\n",
      "\tEpoch 262: \tAverage Loss:  1.6527409973144531\t ACC train:  0.6728571428571428\t ACC test:  0.6511111111111111\n",
      "\tEpoch 263: \tAverage Loss:  1.6518645935058593\t ACC train:  0.6685714285714286\t ACC test:  0.6466666666666666\n",
      "\tEpoch 264: \tAverage Loss:  1.6505126037597657\t ACC train:  0.67\t ACC test:  0.6466666666666666\n",
      "\tEpoch 265: \tAverage Loss:  1.6498665161132813\t ACC train:  0.6742857142857143\t ACC test:  0.6422222222222222\n",
      "\tEpoch 266: \tAverage Loss:  1.6496729736328124\t ACC train:  0.6642857142857143\t ACC test:  0.6377777777777778\n",
      "\tEpoch 267: \tAverage Loss:  1.6492622985839844\t ACC train:  0.6542857142857142\t ACC test:  0.6311111111111111\n",
      "\tEpoch 268: \tAverage Loss:  1.6486764526367188\t ACC train:  0.6314285714285715\t ACC test:  0.6111111111111112\n",
      "\tEpoch 269: \tAverage Loss:  1.648287109375\t ACC train:  0.6342857142857142\t ACC test:  0.6022222222222222\n",
      "\tEpoch 270: \tAverage Loss:  1.6480955200195313\t ACC train:  0.6285714285714286\t ACC test:  0.6022222222222222\n",
      "\tEpoch 271: \tAverage Loss:  1.646746795654297\t ACC train:  0.62\t ACC test:  0.5933333333333334\n",
      "\tEpoch 272: \tAverage Loss:  1.6465358276367188\t ACC train:  0.6214285714285714\t ACC test:  0.5955555555555555\n",
      "\tEpoch 273: \tAverage Loss:  1.6461995239257812\t ACC train:  0.6157142857142858\t ACC test:  0.5711111111111111\n",
      "\tEpoch 274: \tAverage Loss:  1.645660369873047\t ACC train:  0.6114285714285714\t ACC test:  0.5666666666666667\n",
      "\tEpoch 275: \tAverage Loss:  1.6464118957519531\t ACC train:  0.6085714285714285\t ACC test:  0.5733333333333334\n",
      "\tEpoch 276: \tAverage Loss:  1.6456370849609374\t ACC train:  0.6071428571428571\t ACC test:  0.56\n",
      "\tEpoch 277: \tAverage Loss:  1.6446026000976564\t ACC train:  0.6028571428571429\t ACC test:  0.5244444444444445\n",
      "\tEpoch 278: \tAverage Loss:  1.6439181823730469\t ACC train:  0.6014285714285714\t ACC test:  0.5466666666666666\n",
      "\tEpoch 279: \tAverage Loss:  1.644328887939453\t ACC train:  0.5928571428571429\t ACC test:  0.5466666666666666\n",
      "\tEpoch 280: \tAverage Loss:  1.64374072265625\t ACC train:  0.5814285714285714\t ACC test:  0.5377777777777778\n",
      "\tEpoch 281: \tAverage Loss:  1.6430209045410156\t ACC train:  0.5957142857142858\t ACC test:  0.5466666666666666\n",
      "\tEpoch 282: \tAverage Loss:  1.6421943359375\t ACC train:  0.6128571428571429\t ACC test:  0.5622222222222222\n",
      "\tEpoch 283: \tAverage Loss:  1.6419921264648438\t ACC train:  0.64\t ACC test:  0.5711111111111111\n",
      "\tEpoch 284: \tAverage Loss:  1.6417649230957032\t ACC train:  0.66\t ACC test:  0.6044444444444445\n",
      "\tEpoch 285: \tAverage Loss:  1.6418089904785156\t ACC train:  0.6585714285714286\t ACC test:  0.5911111111111111\n",
      "\tEpoch 286: \tAverage Loss:  1.6402298889160156\t ACC train:  0.6457142857142857\t ACC test:  0.6022222222222222\n",
      "\tEpoch 287: \tAverage Loss:  1.6402023010253906\t ACC train:  0.6628571428571428\t ACC test:  0.5933333333333334\n",
      "\tEpoch 288: \tAverage Loss:  1.6399064331054687\t ACC train:  0.6571428571428571\t ACC test:  0.6088888888888889\n",
      "\tEpoch 289: \tAverage Loss:  1.6403403930664062\t ACC train:  0.6557142857142857\t ACC test:  0.6088888888888889\n",
      "\tEpoch 290: \tAverage Loss:  1.6392447204589844\t ACC train:  0.6728571428571428\t ACC test:  0.6177777777777778\n",
      "\tEpoch 291: \tAverage Loss:  1.638433807373047\t ACC train:  0.6557142857142857\t ACC test:  0.6133333333333333\n",
      "\tEpoch 292: \tAverage Loss:  1.6380185546875\t ACC train:  0.6714285714285714\t ACC test:  0.6311111111111111\n",
      "\tEpoch 293: \tAverage Loss:  1.63750048828125\t ACC train:  0.6714285714285714\t ACC test:  0.6288888888888889\n",
      "\tEpoch 294: \tAverage Loss:  1.6365281372070313\t ACC train:  0.6714285714285714\t ACC test:  0.6355555555555555\n",
      "\tEpoch 295: \tAverage Loss:  1.6372359313964844\t ACC train:  0.6785714285714286\t ACC test:  0.6444444444444445\n",
      "\tEpoch 296: \tAverage Loss:  1.6365366821289062\t ACC train:  0.6914285714285714\t ACC test:  0.6422222222222222\n",
      "\tEpoch 297: \tAverage Loss:  1.6358411560058594\t ACC train:  0.6828571428571428\t ACC test:  0.6444444444444445\n",
      "\tEpoch 298: \tAverage Loss:  1.635220458984375\t ACC train:  0.69\t ACC test:  0.6555555555555556\n",
      "\tEpoch 299: \tAverage Loss:  1.6359282531738282\t ACC train:  0.6814285714285714\t ACC test:  0.6577777777777778\n",
      "\tEpoch 300: \tAverage Loss:  1.6348764038085937\t ACC train:  0.7014285714285714\t ACC test:  0.6488888888888888\n",
      "\tEpoch 301: \tAverage Loss:  1.6342354736328124\t ACC train:  0.6957142857142857\t ACC test:  0.6444444444444445\n",
      "\tEpoch 302: \tAverage Loss:  1.6340658569335937\t ACC train:  0.6871428571428572\t ACC test:  0.66\n",
      "\tEpoch 303: \tAverage Loss:  1.6338775939941406\t ACC train:  0.6971428571428572\t ACC test:  0.6555555555555556\n",
      "\tEpoch 304: \tAverage Loss:  1.633516876220703\t ACC train:  0.7\t ACC test:  0.6533333333333333\n",
      "\tEpoch 305: \tAverage Loss:  1.6325188293457031\t ACC train:  0.7042857142857143\t ACC test:  0.6555555555555556\n",
      "\tEpoch 306: \tAverage Loss:  1.6318241577148438\t ACC train:  0.6985714285714286\t ACC test:  0.6488888888888888\n",
      "\tEpoch 307: \tAverage Loss:  1.6327286376953125\t ACC train:  0.7028571428571428\t ACC test:  0.6533333333333333\n",
      "\tEpoch 308: \tAverage Loss:  1.6314473876953124\t ACC train:  0.6985714285714286\t ACC test:  0.6577777777777778\n",
      "\tEpoch 309: \tAverage Loss:  1.631261474609375\t ACC train:  0.7085714285714285\t ACC test:  0.6688888888888889\n",
      "\tEpoch 310: \tAverage Loss:  1.6303163146972657\t ACC train:  0.6914285714285714\t ACC test:  0.6555555555555556\n",
      "\tEpoch 311: \tAverage Loss:  1.6301611022949218\t ACC train:  0.7042857142857143\t ACC test:  0.6622222222222223\n",
      "\tEpoch 312: \tAverage Loss:  1.630833251953125\t ACC train:  0.6985714285714286\t ACC test:  0.6511111111111111\n",
      "\tEpoch 313: \tAverage Loss:  1.629019287109375\t ACC train:  0.7128571428571429\t ACC test:  0.6577777777777778\n",
      "\tEpoch 314: \tAverage Loss:  1.6288497009277343\t ACC train:  0.71\t ACC test:  0.6644444444444444\n",
      "\tEpoch 315: \tAverage Loss:  1.629565673828125\t ACC train:  0.7114285714285714\t ACC test:  0.6688888888888889\n",
      "\tEpoch 316: \tAverage Loss:  1.6277703857421875\t ACC train:  0.7114285714285714\t ACC test:  0.6622222222222223\n",
      "\tEpoch 317: \tAverage Loss:  1.6274205627441407\t ACC train:  0.7157142857142857\t ACC test:  0.6533333333333333\n",
      "\tEpoch 318: \tAverage Loss:  1.6280281982421876\t ACC train:  0.7228571428571429\t ACC test:  0.6777777777777778\n",
      "\tEpoch 319: \tAverage Loss:  1.6273928833007814\t ACC train:  0.7071428571428572\t ACC test:  0.66\n",
      "\tEpoch 320: \tAverage Loss:  1.6267080688476563\t ACC train:  0.72\t ACC test:  0.6666666666666666\n",
      "\tEpoch 321: \tAverage Loss:  1.6257863464355469\t ACC train:  0.7085714285714285\t ACC test:  0.6711111111111111\n",
      "\tEpoch 322: \tAverage Loss:  1.6251414794921875\t ACC train:  0.7114285714285714\t ACC test:  0.6555555555555556\n",
      "\tEpoch 323: \tAverage Loss:  1.6258800048828126\t ACC train:  0.7271428571428571\t ACC test:  0.6844444444444444\n",
      "\tEpoch 324: \tAverage Loss:  1.6273456726074218\t ACC train:  0.7085714285714285\t ACC test:  0.6666666666666666\n",
      "\tEpoch 325: \tAverage Loss:  1.62545703125\t ACC train:  0.72\t ACC test:  0.6866666666666666\n",
      "\tEpoch 326: \tAverage Loss:  1.6259585571289064\t ACC train:  0.71\t ACC test:  0.6644444444444444\n",
      "\tEpoch 327: \tAverage Loss:  1.6247191772460938\t ACC train:  0.7271428571428571\t ACC test:  0.6866666666666666\n",
      "\tEpoch 328: \tAverage Loss:  1.6245775451660156\t ACC train:  0.7185714285714285\t ACC test:  0.6755555555555556\n",
      "\tEpoch 329: \tAverage Loss:  1.6235160827636719\t ACC train:  0.7271428571428571\t ACC test:  0.68\n",
      "\tEpoch 330: \tAverage Loss:  1.6230834045410156\t ACC train:  0.7257142857142858\t ACC test:  0.6866666666666666\n",
      "\tEpoch 331: \tAverage Loss:  1.622681396484375\t ACC train:  0.7242857142857143\t ACC test:  0.6755555555555556\n",
      "\tEpoch 332: \tAverage Loss:  1.6228221740722657\t ACC train:  0.7271428571428571\t ACC test:  0.6955555555555556\n",
      "\tEpoch 333: \tAverage Loss:  1.6220528869628905\t ACC train:  0.7114285714285714\t ACC test:  0.6711111111111111\n",
      "\tEpoch 334: \tAverage Loss:  1.6221362609863281\t ACC train:  0.73\t ACC test:  0.6844444444444444\n",
      "\tEpoch 335: \tAverage Loss:  1.621441650390625\t ACC train:  0.7271428571428571\t ACC test:  0.6844444444444444\n",
      "\tEpoch 336: \tAverage Loss:  1.6209036865234374\t ACC train:  0.7271428571428571\t ACC test:  0.6844444444444444\n",
      "\tEpoch 337: \tAverage Loss:  1.6214324340820312\t ACC train:  0.73\t ACC test:  0.6866666666666666\n",
      "\tEpoch 338: \tAverage Loss:  1.6206898498535156\t ACC train:  0.7271428571428571\t ACC test:  0.6688888888888889\n",
      "\tEpoch 339: \tAverage Loss:  1.6202001342773438\t ACC train:  0.7271428571428571\t ACC test:  0.6844444444444444\n",
      "\tEpoch 340: \tAverage Loss:  1.6209012756347656\t ACC train:  0.7257142857142858\t ACC test:  0.68\n",
      "\tEpoch 341: \tAverage Loss:  1.619737091064453\t ACC train:  0.73\t ACC test:  0.6844444444444444\n",
      "\tEpoch 342: \tAverage Loss:  1.6189932556152344\t ACC train:  0.7357142857142858\t ACC test:  0.6844444444444444\n",
      "\tEpoch 343: \tAverage Loss:  1.6186021118164062\t ACC train:  0.73\t ACC test:  0.6866666666666666\n",
      "\tEpoch 344: \tAverage Loss:  1.6185781860351562\t ACC train:  0.73\t ACC test:  0.6888888888888889\n",
      "\tEpoch 345: \tAverage Loss:  1.618313751220703\t ACC train:  0.7285714285714285\t ACC test:  0.6822222222222222\n",
      "\tEpoch 346: \tAverage Loss:  1.6178520812988282\t ACC train:  0.7271428571428571\t ACC test:  0.6888888888888889\n",
      "\tEpoch 347: \tAverage Loss:  1.6179030456542969\t ACC train:  0.7314285714285714\t ACC test:  0.6822222222222222\n",
      "\tEpoch 348: \tAverage Loss:  1.6179420471191406\t ACC train:  0.7285714285714285\t ACC test:  0.6911111111111111\n",
      "\tEpoch 349: \tAverage Loss:  1.6167974243164063\t ACC train:  0.7357142857142858\t ACC test:  0.6866666666666666\n",
      "\tEpoch 350: \tAverage Loss:  1.6168196105957031\t ACC train:  0.7342857142857143\t ACC test:  0.6933333333333334\n",
      "\tEpoch 351: \tAverage Loss:  1.6158424377441407\t ACC train:  0.7342857142857143\t ACC test:  0.6888888888888889\n",
      "\tEpoch 352: \tAverage Loss:  1.6157301025390625\t ACC train:  0.7357142857142858\t ACC test:  0.6888888888888889\n",
      "\tEpoch 353: \tAverage Loss:  1.6157926940917968\t ACC train:  0.7357142857142858\t ACC test:  0.6866666666666666\n",
      "\tEpoch 354: \tAverage Loss:  1.6154597778320312\t ACC train:  0.7328571428571429\t ACC test:  0.6911111111111111\n",
      "\tEpoch 355: \tAverage Loss:  1.6146925659179687\t ACC train:  0.7328571428571429\t ACC test:  0.6911111111111111\n",
      "\tEpoch 356: \tAverage Loss:  1.6145824279785157\t ACC train:  0.7357142857142858\t ACC test:  0.6955555555555556\n",
      "\tEpoch 357: \tAverage Loss:  1.6140067443847657\t ACC train:  0.7328571428571429\t ACC test:  0.6911111111111111\n",
      "\tEpoch 358: \tAverage Loss:  1.613675048828125\t ACC train:  0.73\t ACC test:  0.6933333333333334\n",
      "\tEpoch 359: \tAverage Loss:  1.6141509399414062\t ACC train:  0.7342857142857143\t ACC test:  0.6977777777777778\n",
      "\tEpoch 360: \tAverage Loss:  1.6131995239257813\t ACC train:  0.7342857142857143\t ACC test:  0.6977777777777778\n",
      "\tEpoch 361: \tAverage Loss:  1.613559326171875\t ACC train:  0.7385714285714285\t ACC test:  0.6977777777777778\n",
      "\tEpoch 362: \tAverage Loss:  1.6131575622558594\t ACC train:  0.7342857142857143\t ACC test:  0.7022222222222222\n",
      "\tEpoch 363: \tAverage Loss:  1.6120337829589844\t ACC train:  0.7385714285714285\t ACC test:  0.6955555555555556\n",
      "\tEpoch 364: \tAverage Loss:  1.6116233825683595\t ACC train:  0.7328571428571429\t ACC test:  0.7\n",
      "\tEpoch 365: \tAverage Loss:  1.6117633056640626\t ACC train:  0.7357142857142858\t ACC test:  0.7111111111111111\n",
      "\tEpoch 366: \tAverage Loss:  1.6114675903320312\t ACC train:  0.7385714285714285\t ACC test:  0.7\n",
      "\tEpoch 367: \tAverage Loss:  1.610962860107422\t ACC train:  0.74\t ACC test:  0.7044444444444444\n",
      "\tEpoch 368: \tAverage Loss:  1.6108485107421875\t ACC train:  0.7385714285714285\t ACC test:  0.6977777777777778\n",
      "\tEpoch 369: \tAverage Loss:  1.6108631591796876\t ACC train:  0.7342857142857143\t ACC test:  0.7044444444444444\n",
      "\tEpoch 370: \tAverage Loss:  1.610170166015625\t ACC train:  0.7342857142857143\t ACC test:  0.6933333333333334\n",
      "\tEpoch 371: \tAverage Loss:  1.6098280334472657\t ACC train:  0.7357142857142858\t ACC test:  0.7\n",
      "\tEpoch 372: \tAverage Loss:  1.6101028137207032\t ACC train:  0.73\t ACC test:  0.6977777777777778\n",
      "\tEpoch 373: \tAverage Loss:  1.609636199951172\t ACC train:  0.7342857142857143\t ACC test:  0.7044444444444444\n",
      "\tEpoch 374: \tAverage Loss:  1.609636474609375\t ACC train:  0.7385714285714285\t ACC test:  0.6933333333333334\n",
      "\tEpoch 375: \tAverage Loss:  1.608565216064453\t ACC train:  0.7385714285714285\t ACC test:  0.7066666666666667\n",
      "\tEpoch 376: \tAverage Loss:  1.608801483154297\t ACC train:  0.7371428571428571\t ACC test:  0.7\n",
      "\tEpoch 377: \tAverage Loss:  1.6085729064941405\t ACC train:  0.7371428571428571\t ACC test:  0.7044444444444444\n",
      "\tEpoch 378: \tAverage Loss:  1.6075214538574218\t ACC train:  0.7357142857142858\t ACC test:  0.7066666666666667\n",
      "\tEpoch 379: \tAverage Loss:  1.6074523315429687\t ACC train:  0.7357142857142858\t ACC test:  0.7022222222222222\n",
      "\tEpoch 380: \tAverage Loss:  1.6071745300292968\t ACC train:  0.7328571428571429\t ACC test:  0.7044444444444444\n",
      "\tEpoch 381: \tAverage Loss:  1.6071561279296875\t ACC train:  0.7342857142857143\t ACC test:  0.7\n",
      "\tEpoch 382: \tAverage Loss:  1.6061784362792968\t ACC train:  0.7385714285714285\t ACC test:  0.7066666666666667\n",
      "\tEpoch 383: \tAverage Loss:  1.6069496459960937\t ACC train:  0.7357142857142858\t ACC test:  0.7022222222222222\n",
      "\tEpoch 384: \tAverage Loss:  1.607033935546875\t ACC train:  0.7414285714285714\t ACC test:  0.7111111111111111\n",
      "\tEpoch 385: \tAverage Loss:  1.606426788330078\t ACC train:  0.7342857142857143\t ACC test:  0.7\n",
      "\tEpoch 386: \tAverage Loss:  1.606447509765625\t ACC train:  0.7414285714285714\t ACC test:  0.7088888888888889\n",
      "\tEpoch 387: \tAverage Loss:  1.6055927734375\t ACC train:  0.7385714285714285\t ACC test:  0.6955555555555556\n",
      "\tEpoch 388: \tAverage Loss:  1.6057257690429687\t ACC train:  0.7442857142857143\t ACC test:  0.7111111111111111\n",
      "\tEpoch 389: \tAverage Loss:  1.6053454895019532\t ACC train:  0.7414285714285714\t ACC test:  0.6977777777777778\n",
      "\tEpoch 390: \tAverage Loss:  1.6047606811523438\t ACC train:  0.7414285714285714\t ACC test:  0.7133333333333334\n",
      "\tEpoch 391: \tAverage Loss:  1.6049736633300782\t ACC train:  0.7385714285714285\t ACC test:  0.7022222222222222\n",
      "\tEpoch 392: \tAverage Loss:  1.604054656982422\t ACC train:  0.7457142857142857\t ACC test:  0.7111111111111111\n",
      "\tEpoch 393: \tAverage Loss:  1.6035258483886718\t ACC train:  0.7428571428571429\t ACC test:  0.7044444444444444\n",
      "\tEpoch 394: \tAverage Loss:  1.6031949462890625\t ACC train:  0.7471428571428571\t ACC test:  0.7088888888888889\n",
      "\tEpoch 395: \tAverage Loss:  1.60308349609375\t ACC train:  0.7414285714285714\t ACC test:  0.7088888888888889\n",
      "\tEpoch 396: \tAverage Loss:  1.602449462890625\t ACC train:  0.7471428571428571\t ACC test:  0.7111111111111111\n",
      "\tEpoch 397: \tAverage Loss:  1.6026739807128907\t ACC train:  0.7414285714285714\t ACC test:  0.7133333333333334\n",
      "\tEpoch 398: \tAverage Loss:  1.6024829406738281\t ACC train:  0.7457142857142857\t ACC test:  0.7133333333333334\n",
      "\tEpoch 399: \tAverage Loss:  1.6017494201660156\t ACC train:  0.74\t ACC test:  0.7022222222222222\n",
      "\tEpoch 400: \tAverage Loss:  1.6017004089355469\t ACC train:  0.7414285714285714\t ACC test:  0.7066666666666667\n",
      "\tEpoch 401: \tAverage Loss:  1.6017353820800782\t ACC train:  0.7414285714285714\t ACC test:  0.7066666666666667\n",
      "\tEpoch 402: \tAverage Loss:  1.6016500549316406\t ACC train:  0.7428571428571429\t ACC test:  0.7044444444444444\n",
      "\tEpoch 403: \tAverage Loss:  1.6010527954101563\t ACC train:  0.7385714285714285\t ACC test:  0.7088888888888889\n",
      "\tEpoch 404: \tAverage Loss:  1.6002679138183593\t ACC train:  0.7457142857142857\t ACC test:  0.7111111111111111\n",
      "\tEpoch 405: \tAverage Loss:  1.6004567260742188\t ACC train:  0.7428571428571429\t ACC test:  0.7088888888888889\n",
      "\tEpoch 406: \tAverage Loss:  1.600076904296875\t ACC train:  0.7485714285714286\t ACC test:  0.7088888888888889\n",
      "\tEpoch 407: \tAverage Loss:  1.600652618408203\t ACC train:  0.7457142857142857\t ACC test:  0.7066666666666667\n",
      "\tEpoch 408: \tAverage Loss:  1.5996691284179687\t ACC train:  0.75\t ACC test:  0.7088888888888889\n",
      "\tEpoch 409: \tAverage Loss:  1.5998424072265625\t ACC train:  0.7414285714285714\t ACC test:  0.7088888888888889\n",
      "\tEpoch 410: \tAverage Loss:  1.5998442993164061\t ACC train:  0.7528571428571429\t ACC test:  0.7088888888888889\n",
      "\tEpoch 411: \tAverage Loss:  1.5990986022949218\t ACC train:  0.74\t ACC test:  0.7044444444444444\n",
      "\tEpoch 412: \tAverage Loss:  1.6000146484375\t ACC train:  0.7485714285714286\t ACC test:  0.7088888888888889\n",
      "\tEpoch 413: \tAverage Loss:  1.5993321228027344\t ACC train:  0.74\t ACC test:  0.7066666666666667\n",
      "\tEpoch 414: \tAverage Loss:  1.59833349609375\t ACC train:  0.7528571428571429\t ACC test:  0.7088888888888889\n",
      "\tEpoch 415: \tAverage Loss:  1.5982250061035157\t ACC train:  0.7471428571428571\t ACC test:  0.7088888888888889\n",
      "\tEpoch 416: \tAverage Loss:  1.597590576171875\t ACC train:  0.7457142857142857\t ACC test:  0.7133333333333334\n",
      "\tEpoch 417: \tAverage Loss:  1.5974913635253907\t ACC train:  0.7485714285714286\t ACC test:  0.7133333333333334\n",
      "\tEpoch 418: \tAverage Loss:  1.597638946533203\t ACC train:  0.7414285714285714\t ACC test:  0.7066666666666667\n",
      "\tEpoch 419: \tAverage Loss:  1.5973796081542968\t ACC train:  0.7542857142857143\t ACC test:  0.7088888888888889\n",
      "\tEpoch 420: \tAverage Loss:  1.5972830200195312\t ACC train:  0.7414285714285714\t ACC test:  0.7066666666666667\n",
      "\tEpoch 421: \tAverage Loss:  1.5967882385253906\t ACC train:  0.75\t ACC test:  0.7111111111111111\n",
      "\tEpoch 422: \tAverage Loss:  1.596391143798828\t ACC train:  0.7457142857142857\t ACC test:  0.7088888888888889\n",
      "\tEpoch 423: \tAverage Loss:  1.5963521423339844\t ACC train:  0.7528571428571429\t ACC test:  0.7155555555555555\n",
      "\tEpoch 424: \tAverage Loss:  1.596032745361328\t ACC train:  0.7471428571428571\t ACC test:  0.7111111111111111\n",
      "\tEpoch 425: \tAverage Loss:  1.595264404296875\t ACC train:  0.7485714285714286\t ACC test:  0.7088888888888889\n",
      "\tEpoch 426: \tAverage Loss:  1.59497314453125\t ACC train:  0.7514285714285714\t ACC test:  0.7111111111111111\n",
      "\tEpoch 427: \tAverage Loss:  1.5951255493164063\t ACC train:  0.7428571428571429\t ACC test:  0.7133333333333334\n",
      "\tEpoch 428: \tAverage Loss:  1.5949541625976562\t ACC train:  0.7542857142857143\t ACC test:  0.7133333333333334\n",
      "\tEpoch 429: \tAverage Loss:  1.5943865051269532\t ACC train:  0.7485714285714286\t ACC test:  0.7088888888888889\n",
      "\tEpoch 430: \tAverage Loss:  1.593991943359375\t ACC train:  0.7557142857142857\t ACC test:  0.7133333333333334\n",
      "\tEpoch 431: \tAverage Loss:  1.594205596923828\t ACC train:  0.7528571428571429\t ACC test:  0.7155555555555555\n",
      "\tEpoch 432: \tAverage Loss:  1.5936337585449218\t ACC train:  0.7471428571428571\t ACC test:  0.7133333333333334\n",
      "\tEpoch 433: \tAverage Loss:  1.5935261840820312\t ACC train:  0.7542857142857143\t ACC test:  0.7111111111111111\n",
      "\tEpoch 434: \tAverage Loss:  1.5929447326660156\t ACC train:  0.7471428571428571\t ACC test:  0.7111111111111111\n",
      "\tEpoch 435: \tAverage Loss:  1.5928748779296875\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 436: \tAverage Loss:  1.593361785888672\t ACC train:  0.7457142857142857\t ACC test:  0.7066666666666667\n",
      "\tEpoch 437: \tAverage Loss:  1.5934688110351563\t ACC train:  0.7557142857142857\t ACC test:  0.7177777777777777\n",
      "\tEpoch 438: \tAverage Loss:  1.593302947998047\t ACC train:  0.7428571428571429\t ACC test:  0.7088888888888889\n",
      "\tEpoch 439: \tAverage Loss:  1.5937164306640625\t ACC train:  0.7571428571428571\t ACC test:  0.7155555555555555\n",
      "\tEpoch 440: \tAverage Loss:  1.593289306640625\t ACC train:  0.7485714285714286\t ACC test:  0.7133333333333334\n",
      "\tEpoch 441: \tAverage Loss:  1.5929441528320312\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 442: \tAverage Loss:  1.5921990966796875\t ACC train:  0.7485714285714286\t ACC test:  0.7155555555555555\n",
      "\tEpoch 443: \tAverage Loss:  1.5917555847167968\t ACC train:  0.7571428571428571\t ACC test:  0.7155555555555555\n",
      "\tEpoch 444: \tAverage Loss:  1.5912669372558594\t ACC train:  0.7542857142857143\t ACC test:  0.7133333333333334\n",
      "\tEpoch 445: \tAverage Loss:  1.5906540222167969\t ACC train:  0.7628571428571429\t ACC test:  0.7088888888888889\n",
      "\tEpoch 446: \tAverage Loss:  1.5900358581542968\t ACC train:  0.7585714285714286\t ACC test:  0.7155555555555555\n",
      "\tEpoch 447: \tAverage Loss:  1.5900686645507813\t ACC train:  0.7542857142857143\t ACC test:  0.7088888888888889\n",
      "\tEpoch 448: \tAverage Loss:  1.590165313720703\t ACC train:  0.7628571428571429\t ACC test:  0.7111111111111111\n",
      "\tEpoch 449: \tAverage Loss:  1.5901478881835938\t ACC train:  0.7485714285714286\t ACC test:  0.7088888888888889\n",
      "\tEpoch 450: \tAverage Loss:  1.589787353515625\t ACC train:  0.76\t ACC test:  0.7155555555555555\n",
      "\tEpoch 451: \tAverage Loss:  1.5900484619140625\t ACC train:  0.75\t ACC test:  0.7133333333333334\n",
      "\tEpoch 452: \tAverage Loss:  1.5894492797851563\t ACC train:  0.76\t ACC test:  0.7133333333333334\n",
      "\tEpoch 453: \tAverage Loss:  1.5886008911132812\t ACC train:  0.7542857142857143\t ACC test:  0.7155555555555555\n",
      "\tEpoch 454: \tAverage Loss:  1.5881087646484375\t ACC train:  0.7557142857142857\t ACC test:  0.7133333333333334\n",
      "\tEpoch 455: \tAverage Loss:  1.5880906677246094\t ACC train:  0.7628571428571429\t ACC test:  0.7155555555555555\n",
      "\tEpoch 456: \tAverage Loss:  1.5877760314941407\t ACC train:  0.7514285714285714\t ACC test:  0.7155555555555555\n",
      "\tEpoch 457: \tAverage Loss:  1.588258087158203\t ACC train:  0.7628571428571429\t ACC test:  0.7177777777777777\n",
      "\tEpoch 458: \tAverage Loss:  1.5882618103027344\t ACC train:  0.7528571428571429\t ACC test:  0.7155555555555555\n",
      "\tEpoch 459: \tAverage Loss:  1.5881382751464843\t ACC train:  0.7614285714285715\t ACC test:  0.7155555555555555\n",
      "\tEpoch 460: \tAverage Loss:  1.5874935302734374\t ACC train:  0.7571428571428571\t ACC test:  0.7155555555555555\n",
      "\tEpoch 461: \tAverage Loss:  1.5868118896484376\t ACC train:  0.7585714285714286\t ACC test:  0.72\n",
      "\tEpoch 462: \tAverage Loss:  1.5862403259277345\t ACC train:  0.76\t ACC test:  0.7155555555555555\n",
      "\tEpoch 463: \tAverage Loss:  1.585768585205078\t ACC train:  0.7557142857142857\t ACC test:  0.7133333333333334\n",
      "\tEpoch 464: \tAverage Loss:  1.586048858642578\t ACC train:  0.7628571428571429\t ACC test:  0.7155555555555555\n",
      "\tEpoch 465: \tAverage Loss:  1.5859676513671874\t ACC train:  0.7514285714285714\t ACC test:  0.7155555555555555\n",
      "\tEpoch 466: \tAverage Loss:  1.58606689453125\t ACC train:  0.7628571428571429\t ACC test:  0.7133333333333334\n",
      "\tEpoch 467: \tAverage Loss:  1.5859911499023438\t ACC train:  0.7542857142857143\t ACC test:  0.7111111111111111\n",
      "\tEpoch 468: \tAverage Loss:  1.5855457763671874\t ACC train:  0.7614285714285715\t ACC test:  0.72\n",
      "\tEpoch 469: \tAverage Loss:  1.5853464660644532\t ACC train:  0.7571428571428571\t ACC test:  0.7133333333333334\n",
      "\tEpoch 470: \tAverage Loss:  1.5842154235839845\t ACC train:  0.7614285714285715\t ACC test:  0.7177777777777777\n",
      "\tEpoch 471: \tAverage Loss:  1.5837818603515625\t ACC train:  0.76\t ACC test:  0.7155555555555555\n",
      "\tEpoch 472: \tAverage Loss:  1.5838619079589844\t ACC train:  0.7571428571428571\t ACC test:  0.7177777777777777\n",
      "\tEpoch 473: \tAverage Loss:  1.5832413635253906\t ACC train:  0.7628571428571429\t ACC test:  0.7177777777777777\n",
      "\tEpoch 474: \tAverage Loss:  1.5830555725097657\t ACC train:  0.7642857142857142\t ACC test:  0.7155555555555555\n",
      "\tEpoch 475: \tAverage Loss:  1.5827918395996095\t ACC train:  0.7642857142857142\t ACC test:  0.7155555555555555\n",
      "\tEpoch 476: \tAverage Loss:  1.5825420227050782\t ACC train:  0.7642857142857142\t ACC test:  0.72\n",
      "\tEpoch 477: \tAverage Loss:  1.5822349853515625\t ACC train:  0.7614285714285715\t ACC test:  0.7177777777777777\n",
      "\tEpoch 478: \tAverage Loss:  1.5821111450195313\t ACC train:  0.7642857142857142\t ACC test:  0.7155555555555555\n",
      "\tEpoch 479: \tAverage Loss:  1.581616455078125\t ACC train:  0.7642857142857142\t ACC test:  0.72\n",
      "\tEpoch 480: \tAverage Loss:  1.5816573486328125\t ACC train:  0.7642857142857142\t ACC test:  0.7177777777777777\n",
      "\tEpoch 481: \tAverage Loss:  1.58154443359375\t ACC train:  0.7614285714285715\t ACC test:  0.7155555555555555\n",
      "\tEpoch 482: \tAverage Loss:  1.58132763671875\t ACC train:  0.7585714285714286\t ACC test:  0.7133333333333334\n",
      "\tEpoch 483: \tAverage Loss:  1.5809085693359375\t ACC train:  0.7628571428571429\t ACC test:  0.7222222222222222\n",
      "\tEpoch 484: \tAverage Loss:  1.5809546508789063\t ACC train:  0.76\t ACC test:  0.7177777777777777\n",
      "\tEpoch 485: \tAverage Loss:  1.580575469970703\t ACC train:  0.7628571428571429\t ACC test:  0.72\n",
      "\tEpoch 486: \tAverage Loss:  1.5804090576171874\t ACC train:  0.7557142857142857\t ACC test:  0.7155555555555555\n",
      "\tEpoch 487: \tAverage Loss:  1.5793965759277344\t ACC train:  0.7614285714285715\t ACC test:  0.7222222222222222\n",
      "\tEpoch 488: \tAverage Loss:  1.579409210205078\t ACC train:  0.7628571428571429\t ACC test:  0.7244444444444444\n",
      "\tEpoch 489: \tAverage Loss:  1.5786655883789062\t ACC train:  0.7657142857142857\t ACC test:  0.7177777777777777\n",
      "\tEpoch 490: \tAverage Loss:  1.5785789489746094\t ACC train:  0.7657142857142857\t ACC test:  0.7177777777777777\n",
      "\tEpoch 491: \tAverage Loss:  1.5781521606445312\t ACC train:  0.7657142857142857\t ACC test:  0.7155555555555555\n",
      "\tEpoch 492: \tAverage Loss:  1.578182342529297\t ACC train:  0.7614285714285715\t ACC test:  0.72\n",
      "\tEpoch 493: \tAverage Loss:  1.5781197509765625\t ACC train:  0.7657142857142857\t ACC test:  0.7266666666666667\n",
      "\tEpoch 494: \tAverage Loss:  1.5779188537597657\t ACC train:  0.7657142857142857\t ACC test:  0.7177777777777777\n",
      "\tEpoch 495: \tAverage Loss:  1.577963348388672\t ACC train:  0.7614285714285715\t ACC test:  0.72\n",
      "\tEpoch 496: \tAverage Loss:  1.5777394104003906\t ACC train:  0.7642857142857142\t ACC test:  0.7177777777777777\n",
      "\tEpoch 497: \tAverage Loss:  1.5770461120605468\t ACC train:  0.7671428571428571\t ACC test:  0.7222222222222222\n",
      "\tEpoch 498: \tAverage Loss:  1.577099090576172\t ACC train:  0.7642857142857142\t ACC test:  0.7177777777777777\n",
      "\tEpoch 499: \tAverage Loss:  1.5768067932128906\t ACC train:  0.7642857142857142\t ACC test:  0.7266666666666667\n",
      "\tEpoch 500: \tAverage Loss:  1.5761890563964844\t ACC train:  0.7628571428571429\t ACC test:  0.72\n",
      "\tEpoch 501: \tAverage Loss:  1.5757686767578125\t ACC train:  0.7657142857142857\t ACC test:  0.72\n",
      "\tEpoch 502: \tAverage Loss:  1.5754674377441407\t ACC train:  0.7657142857142857\t ACC test:  0.7222222222222222\n",
      "\tEpoch 503: \tAverage Loss:  1.5748956298828125\t ACC train:  0.7671428571428571\t ACC test:  0.72\n",
      "\tEpoch 504: \tAverage Loss:  1.5750520324707031\t ACC train:  0.7657142857142857\t ACC test:  0.7244444444444444\n",
      "\tEpoch 505: \tAverage Loss:  1.574764404296875\t ACC train:  0.7657142857142857\t ACC test:  0.72\n",
      "\tEpoch 506: \tAverage Loss:  1.574666259765625\t ACC train:  0.7657142857142857\t ACC test:  0.72\n",
      "\tEpoch 507: \tAverage Loss:  1.5748147888183595\t ACC train:  0.7585714285714286\t ACC test:  0.7155555555555555\n",
      "\tEpoch 508: \tAverage Loss:  1.5746965942382813\t ACC train:  0.7657142857142857\t ACC test:  0.7266666666666667\n",
      "\tEpoch 509: \tAverage Loss:  1.5744376525878907\t ACC train:  0.7657142857142857\t ACC test:  0.7177777777777777\n",
      "\tEpoch 510: \tAverage Loss:  1.5744617614746095\t ACC train:  0.77\t ACC test:  0.7177777777777777\n",
      "\tEpoch 511: \tAverage Loss:  1.5748024291992186\t ACC train:  0.76\t ACC test:  0.7177777777777777\n",
      "\tEpoch 512: \tAverage Loss:  1.5736094360351562\t ACC train:  0.7628571428571429\t ACC test:  0.7177777777777777\n",
      "\tEpoch 513: \tAverage Loss:  1.5737079772949218\t ACC train:  0.7614285714285715\t ACC test:  0.7177777777777777\n",
      "\tEpoch 514: \tAverage Loss:  1.5730064697265624\t ACC train:  0.7642857142857142\t ACC test:  0.72\n",
      "\tEpoch 515: \tAverage Loss:  1.5730775756835937\t ACC train:  0.7671428571428571\t ACC test:  0.72\n",
      "\tEpoch 516: \tAverage Loss:  1.5723418579101562\t ACC train:  0.7714285714285715\t ACC test:  0.7177777777777777\n",
      "\tEpoch 517: \tAverage Loss:  1.5720172424316405\t ACC train:  0.7657142857142857\t ACC test:  0.72\n",
      "\tEpoch 518: \tAverage Loss:  1.5717027587890624\t ACC train:  0.7657142857142857\t ACC test:  0.7222222222222222\n",
      "\tEpoch 519: \tAverage Loss:  1.5708645629882811\t ACC train:  0.7657142857142857\t ACC test:  0.7266666666666667\n",
      "\tEpoch 520: \tAverage Loss:  1.5702825927734374\t ACC train:  0.77\t ACC test:  0.7244444444444444\n",
      "\tEpoch 521: \tAverage Loss:  1.5705823364257812\t ACC train:  0.77\t ACC test:  0.7266666666666667\n",
      "\tEpoch 522: \tAverage Loss:  1.570303680419922\t ACC train:  0.77\t ACC test:  0.7222222222222222\n",
      "\tEpoch 523: \tAverage Loss:  1.569744659423828\t ACC train:  0.7714285714285715\t ACC test:  0.7266666666666667\n",
      "\tEpoch 524: \tAverage Loss:  1.5696957092285155\t ACC train:  0.7614285714285715\t ACC test:  0.7155555555555555\n",
      "\tEpoch 525: \tAverage Loss:  1.5692537231445312\t ACC train:  0.7671428571428571\t ACC test:  0.7244444444444444\n",
      "\tEpoch 526: \tAverage Loss:  1.5695669250488282\t ACC train:  0.7685714285714286\t ACC test:  0.7244444444444444\n",
      "\tEpoch 527: \tAverage Loss:  1.568707305908203\t ACC train:  0.7728571428571429\t ACC test:  0.7266666666666667\n",
      "\tEpoch 528: \tAverage Loss:  1.568845428466797\t ACC train:  0.7671428571428571\t ACC test:  0.7244444444444444\n",
      "\tEpoch 529: \tAverage Loss:  1.568163604736328\t ACC train:  0.7657142857142857\t ACC test:  0.7133333333333334\n",
      "\tEpoch 530: \tAverage Loss:  1.5675056457519532\t ACC train:  0.7628571428571429\t ACC test:  0.7222222222222222\n",
      "\tEpoch 531: \tAverage Loss:  1.5671363525390625\t ACC train:  0.7671428571428571\t ACC test:  0.72\n",
      "\tEpoch 532: \tAverage Loss:  1.5676832885742187\t ACC train:  0.7714285714285715\t ACC test:  0.7266666666666667\n",
      "\tEpoch 533: \tAverage Loss:  1.5678872375488282\t ACC train:  0.7657142857142857\t ACC test:  0.7133333333333334\n",
      "\tEpoch 534: \tAverage Loss:  1.5678138732910156\t ACC train:  0.7728571428571429\t ACC test:  0.7266666666666667\n",
      "\tEpoch 535: \tAverage Loss:  1.5671749267578126\t ACC train:  0.7685714285714286\t ACC test:  0.72\n",
      "\tEpoch 536: \tAverage Loss:  1.5671228942871094\t ACC train:  0.7657142857142857\t ACC test:  0.7222222222222222\n",
      "\tEpoch 537: \tAverage Loss:  1.5672285766601564\t ACC train:  0.7714285714285715\t ACC test:  0.7177777777777777\n",
      "\tEpoch 538: \tAverage Loss:  1.566359405517578\t ACC train:  0.7685714285714286\t ACC test:  0.7244444444444444\n",
      "\tEpoch 539: \tAverage Loss:  1.5659309692382812\t ACC train:  0.7671428571428571\t ACC test:  0.7244444444444444\n",
      "\tEpoch 540: \tAverage Loss:  1.5655847778320313\t ACC train:  0.7685714285714286\t ACC test:  0.7244444444444444\n",
      "\tEpoch 541: \tAverage Loss:  1.564871551513672\t ACC train:  0.7714285714285715\t ACC test:  0.7244444444444444\n",
      "\tEpoch 542: \tAverage Loss:  1.5645779418945311\t ACC train:  0.7628571428571429\t ACC test:  0.72\n",
      "\tEpoch 543: \tAverage Loss:  1.5647312927246093\t ACC train:  0.7742857142857142\t ACC test:  0.7266666666666667\n",
      "\tEpoch 544: \tAverage Loss:  1.5645794677734375\t ACC train:  0.7714285714285715\t ACC test:  0.7177777777777777\n",
      "\tEpoch 545: \tAverage Loss:  1.5641146240234376\t ACC train:  0.7671428571428571\t ACC test:  0.7244444444444444\n",
      "\tEpoch 546: \tAverage Loss:  1.5633373107910156\t ACC train:  0.7685714285714286\t ACC test:  0.7222222222222222\n",
      "\tEpoch 547: \tAverage Loss:  1.5628445434570313\t ACC train:  0.7685714285714286\t ACC test:  0.7266666666666667\n",
      "\tEpoch 548: \tAverage Loss:  1.562545379638672\t ACC train:  0.77\t ACC test:  0.7266666666666667\n",
      "\tEpoch 549: \tAverage Loss:  1.5620469970703126\t ACC train:  0.7671428571428571\t ACC test:  0.72\n",
      "\tEpoch 550: \tAverage Loss:  1.5624151000976563\t ACC train:  0.7714285714285715\t ACC test:  0.7311111111111112\n",
      "\tEpoch 551: \tAverage Loss:  1.562068603515625\t ACC train:  0.7714285714285715\t ACC test:  0.7244444444444444\n",
      "\tEpoch 552: \tAverage Loss:  1.5615948486328124\t ACC train:  0.7685714285714286\t ACC test:  0.72\n",
      "\tEpoch 553: \tAverage Loss:  1.5609535522460938\t ACC train:  0.77\t ACC test:  0.7222222222222222\n",
      "\tEpoch 554: \tAverage Loss:  1.5606723022460938\t ACC train:  0.7714285714285715\t ACC test:  0.7266666666666667\n",
      "\tEpoch 555: \tAverage Loss:  1.5599515380859375\t ACC train:  0.7728571428571429\t ACC test:  0.7244444444444444\n",
      "\tEpoch 556: \tAverage Loss:  1.55998486328125\t ACC train:  0.7728571428571429\t ACC test:  0.7288888888888889\n",
      "\tEpoch 557: \tAverage Loss:  1.558945526123047\t ACC train:  0.77\t ACC test:  0.7244444444444444\n",
      "\tEpoch 558: \tAverage Loss:  1.5595416564941407\t ACC train:  0.7657142857142857\t ACC test:  0.7266666666666667\n",
      "\tEpoch 559: \tAverage Loss:  1.5589456481933595\t ACC train:  0.7757142857142857\t ACC test:  0.7244444444444444\n",
      "\tEpoch 560: \tAverage Loss:  1.5587688293457032\t ACC train:  0.7828571428571428\t ACC test:  0.7266666666666667\n",
      "\tEpoch 561: \tAverage Loss:  1.55814208984375\t ACC train:  0.7714285714285715\t ACC test:  0.7222222222222222\n",
      "\tEpoch 562: \tAverage Loss:  1.5576822509765624\t ACC train:  0.78\t ACC test:  0.7244444444444444\n",
      "\tEpoch 563: \tAverage Loss:  1.5574588012695312\t ACC train:  0.7771428571428571\t ACC test:  0.7266666666666667\n",
      "\tEpoch 564: \tAverage Loss:  1.5575675659179689\t ACC train:  0.7757142857142857\t ACC test:  0.7355555555555555\n",
      "\tEpoch 565: \tAverage Loss:  1.5583100891113282\t ACC train:  0.7785714285714286\t ACC test:  0.7333333333333333\n",
      "\tEpoch 566: \tAverage Loss:  1.5558599853515624\t ACC train:  0.7757142857142857\t ACC test:  0.7333333333333333\n",
      "\tEpoch 567: \tAverage Loss:  1.5557747802734374\t ACC train:  0.7928571428571428\t ACC test:  0.74\n",
      "\tEpoch 568: \tAverage Loss:  1.5559684753417968\t ACC train:  0.7785714285714286\t ACC test:  0.7422222222222222\n",
      "\tEpoch 569: \tAverage Loss:  1.5562337036132812\t ACC train:  0.8142857142857143\t ACC test:  0.7577777777777778\n",
      "\tEpoch 570: \tAverage Loss:  1.5562242736816407\t ACC train:  0.7942857142857143\t ACC test:  0.7644444444444445\n",
      "\tEpoch 571: \tAverage Loss:  1.55537060546875\t ACC train:  0.8171428571428572\t ACC test:  0.7844444444444445\n",
      "\tEpoch 572: \tAverage Loss:  1.5547056884765624\t ACC train:  0.8185714285714286\t ACC test:  0.7822222222222223\n",
      "\tEpoch 573: \tAverage Loss:  1.5514424438476562\t ACC train:  0.8528571428571429\t ACC test:  0.8044444444444444\n",
      "\tEpoch 574: \tAverage Loss:  1.5490997619628906\t ACC train:  0.85\t ACC test:  0.8066666666666666\n",
      "\tEpoch 575: \tAverage Loss:  1.5462274475097657\t ACC train:  0.8514285714285714\t ACC test:  0.8177777777777778\n",
      "\tEpoch 576: \tAverage Loss:  1.5430154724121095\t ACC train:  0.8457142857142858\t ACC test:  0.8066666666666666\n",
      "\tEpoch 577: \tAverage Loss:  1.5408335571289062\t ACC train:  0.8471428571428572\t ACC test:  0.8044444444444444\n",
      "\tEpoch 578: \tAverage Loss:  1.5395672302246093\t ACC train:  0.8485714285714285\t ACC test:  0.8088888888888889\n",
      "\tEpoch 579: \tAverage Loss:  1.5383372802734374\t ACC train:  0.8657142857142858\t ACC test:  0.8244444444444444\n",
      "\tEpoch 580: \tAverage Loss:  1.5349885864257813\t ACC train:  0.8642857142857143\t ACC test:  0.84\n",
      "\tEpoch 581: \tAverage Loss:  1.5351557922363281\t ACC train:  0.8571428571428571\t ACC test:  0.8222222222222222\n",
      "\tEpoch 582: \tAverage Loss:  1.5331669311523437\t ACC train:  0.8557142857142858\t ACC test:  0.8377777777777777\n",
      "\tEpoch 583: \tAverage Loss:  1.5299972229003906\t ACC train:  0.8657142857142858\t ACC test:  0.8377777777777777\n",
      "\tEpoch 584: \tAverage Loss:  1.5290270690917969\t ACC train:  0.8614285714285714\t ACC test:  0.8466666666666667\n",
      "\tEpoch 585: \tAverage Loss:  1.5281846923828124\t ACC train:  0.8685714285714285\t ACC test:  0.8533333333333334\n",
      "\tEpoch 586: \tAverage Loss:  1.5257338256835937\t ACC train:  0.8742857142857143\t ACC test:  0.8577777777777778\n",
      "\tEpoch 587: \tAverage Loss:  1.5239467163085938\t ACC train:  0.8785714285714286\t ACC test:  0.84\n",
      "\tEpoch 588: \tAverage Loss:  1.5218832397460937\t ACC train:  0.8771428571428571\t ACC test:  0.8466666666666667\n",
      "\tEpoch 589: \tAverage Loss:  1.5206488952636719\t ACC train:  0.8828571428571429\t ACC test:  0.8533333333333334\n",
      "\tEpoch 590: \tAverage Loss:  1.5190461730957032\t ACC train:  0.8914285714285715\t ACC test:  0.8577777777777778\n",
      "\tEpoch 591: \tAverage Loss:  1.5172353210449219\t ACC train:  0.8828571428571429\t ACC test:  0.8533333333333334\n",
      "\tEpoch 592: \tAverage Loss:  1.5167095336914063\t ACC train:  0.8885714285714286\t ACC test:  0.8644444444444445\n",
      "\tEpoch 593: \tAverage Loss:  1.5161442565917969\t ACC train:  0.8828571428571429\t ACC test:  0.86\n",
      "\tEpoch 594: \tAverage Loss:  1.5138543395996094\t ACC train:  0.8942857142857142\t ACC test:  0.8577777777777778\n",
      "\tEpoch 595: \tAverage Loss:  1.5130783081054688\t ACC train:  0.8828571428571429\t ACC test:  0.8711111111111111\n",
      "\tEpoch 596: \tAverage Loss:  1.5166122131347657\t ACC train:  0.8842857142857142\t ACC test:  0.8688888888888889\n",
      "\tEpoch 597: \tAverage Loss:  1.5216126403808594\t ACC train:  0.8714285714285714\t ACC test:  0.8533333333333334\n",
      "\tEpoch 598: \tAverage Loss:  1.5343193054199218\t ACC train:  0.8642857142857143\t ACC test:  0.8511111111111112\n",
      "\tEpoch 599: \tAverage Loss:  1.5338397827148438\t ACC train:  0.8842857142857142\t ACC test:  0.8688888888888889\n",
      "\tEpoch 600: \tAverage Loss:  1.5199052124023438\t ACC train:  0.8914285714285715\t ACC test:  0.8666666666666667\n",
      "\tEpoch 601: \tAverage Loss:  1.5109610900878907\t ACC train:  0.8814285714285715\t ACC test:  0.86\n",
      "\tEpoch 602: \tAverage Loss:  1.5211932373046875\t ACC train:  0.8871428571428571\t ACC test:  0.8688888888888889\n",
      "\tEpoch 603: \tAverage Loss:  1.5208658752441406\t ACC train:  0.9014285714285715\t ACC test:  0.8666666666666667\n",
      "\tEpoch 604: \tAverage Loss:  1.507078857421875\t ACC train:  0.8871428571428571\t ACC test:  0.8666666666666667\n",
      "\tEpoch 605: \tAverage Loss:  1.5139148864746095\t ACC train:  0.89\t ACC test:  0.8622222222222222\n",
      "\tEpoch 606: \tAverage Loss:  1.5157633666992187\t ACC train:  0.9\t ACC test:  0.8666666666666667\n",
      "\tEpoch 607: \tAverage Loss:  1.5057893981933594\t ACC train:  0.8957142857142857\t ACC test:  0.8666666666666667\n",
      "\tEpoch 608: \tAverage Loss:  1.5093037109375\t ACC train:  0.8857142857142857\t ACC test:  0.8711111111111111\n",
      "\tEpoch 609: \tAverage Loss:  1.5129323120117188\t ACC train:  0.8957142857142857\t ACC test:  0.8688888888888889\n",
      "\tEpoch 610: \tAverage Loss:  1.5022268676757813\t ACC train:  0.8942857142857142\t ACC test:  0.8666666666666667\n",
      "\tEpoch 611: \tAverage Loss:  1.5068483276367188\t ACC train:  0.8971428571428571\t ACC test:  0.8688888888888889\n",
      "\tEpoch 612: \tAverage Loss:  1.5083366088867187\t ACC train:  0.9057142857142857\t ACC test:  0.8733333333333333\n",
      "\tEpoch 613: \tAverage Loss:  1.5030091857910157\t ACC train:  0.9\t ACC test:  0.8688888888888889\n",
      "\tEpoch 614: \tAverage Loss:  1.5049666442871095\t ACC train:  0.8985714285714286\t ACC test:  0.8755555555555555\n",
      "\tEpoch 615: \tAverage Loss:  1.5033323364257813\t ACC train:  0.8971428571428571\t ACC test:  0.8711111111111111\n",
      "\tEpoch 616: \tAverage Loss:  1.5004723815917969\t ACC train:  0.8985714285714286\t ACC test:  0.8777777777777778\n",
      "\tEpoch 617: \tAverage Loss:  1.5023808288574219\t ACC train:  0.9028571428571428\t ACC test:  0.8666666666666667\n",
      "\tEpoch 618: \tAverage Loss:  1.500251434326172\t ACC train:  0.9\t ACC test:  0.8711111111111111\n",
      "\tEpoch 619: \tAverage Loss:  1.4979032287597656\t ACC train:  0.9114285714285715\t ACC test:  0.8755555555555555\n",
      "\tEpoch 620: \tAverage Loss:  1.4997165832519532\t ACC train:  0.8971428571428571\t ACC test:  0.88\n",
      "\tEpoch 621: \tAverage Loss:  1.4972103881835936\t ACC train:  0.9085714285714286\t ACC test:  0.8688888888888889\n",
      "\tEpoch 622: \tAverage Loss:  1.4969212036132813\t ACC train:  0.8957142857142857\t ACC test:  0.8711111111111111\n",
      "\tEpoch 623: \tAverage Loss:  1.4986807861328124\t ACC train:  0.9028571428571428\t ACC test:  0.8711111111111111\n",
      "\tEpoch 624: \tAverage Loss:  1.496008544921875\t ACC train:  0.9085714285714286\t ACC test:  0.8622222222222222\n",
      "\tEpoch 625: \tAverage Loss:  1.4950978698730468\t ACC train:  0.9057142857142857\t ACC test:  0.8777777777777778\n",
      "\tEpoch 626: \tAverage Loss:  1.4948762512207032\t ACC train:  0.9071428571428571\t ACC test:  0.8711111111111111\n",
      "\tEpoch 627: \tAverage Loss:  1.49517236328125\t ACC train:  0.9085714285714286\t ACC test:  0.8755555555555555\n",
      "\tEpoch 628: \tAverage Loss:  1.4946658935546875\t ACC train:  0.9071428571428571\t ACC test:  0.8733333333333333\n",
      "\tEpoch 629: \tAverage Loss:  1.4932437438964843\t ACC train:  0.9085714285714286\t ACC test:  0.8755555555555555\n",
      "\tEpoch 630: \tAverage Loss:  1.4930543212890626\t ACC train:  0.9157142857142857\t ACC test:  0.8733333333333333\n",
      "\tEpoch 631: \tAverage Loss:  1.4924630126953125\t ACC train:  0.91\t ACC test:  0.8777777777777778\n",
      "\tEpoch 632: \tAverage Loss:  1.4919117126464845\t ACC train:  0.9171428571428571\t ACC test:  0.8755555555555555\n",
      "\tEpoch 633: \tAverage Loss:  1.4910283813476561\t ACC train:  0.9057142857142857\t ACC test:  0.8777777777777778\n",
      "\tEpoch 634: \tAverage Loss:  1.4903699340820313\t ACC train:  0.9171428571428571\t ACC test:  0.8755555555555555\n",
      "\tEpoch 635: \tAverage Loss:  1.4914308471679687\t ACC train:  0.9157142857142857\t ACC test:  0.88\n",
      "\tEpoch 636: \tAverage Loss:  1.489816162109375\t ACC train:  0.9114285714285715\t ACC test:  0.8733333333333333\n",
      "\tEpoch 637: \tAverage Loss:  1.48992529296875\t ACC train:  0.9057142857142857\t ACC test:  0.8711111111111111\n",
      "\tEpoch 638: \tAverage Loss:  1.4889519653320313\t ACC train:  0.9128571428571428\t ACC test:  0.8733333333333333\n",
      "\tEpoch 639: \tAverage Loss:  1.4890107116699218\t ACC train:  0.91\t ACC test:  0.8711111111111111\n",
      "\tEpoch 640: \tAverage Loss:  1.486617431640625\t ACC train:  0.91\t ACC test:  0.8755555555555555\n",
      "\tEpoch 641: \tAverage Loss:  1.487689178466797\t ACC train:  0.9128571428571428\t ACC test:  0.8755555555555555\n",
      "\tEpoch 642: \tAverage Loss:  1.4872031555175782\t ACC train:  0.9157142857142857\t ACC test:  0.8822222222222222\n",
      "\tEpoch 643: \tAverage Loss:  1.4868663024902344\t ACC train:  0.92\t ACC test:  0.8755555555555555\n",
      "\tEpoch 644: \tAverage Loss:  1.4838848876953126\t ACC train:  0.9114285714285715\t ACC test:  0.88\n",
      "\tEpoch 645: \tAverage Loss:  1.4860254516601563\t ACC train:  0.9071428571428571\t ACC test:  0.88\n",
      "\tEpoch 646: \tAverage Loss:  1.4848661193847656\t ACC train:  0.9157142857142857\t ACC test:  0.8866666666666667\n",
      "\tEpoch 647: \tAverage Loss:  1.4864144897460938\t ACC train:  0.9185714285714286\t ACC test:  0.8777777777777778\n",
      "\tEpoch 648: \tAverage Loss:  1.4838485107421875\t ACC train:  0.9142857142857143\t ACC test:  0.8822222222222222\n",
      "\tEpoch 649: \tAverage Loss:  1.4845882873535157\t ACC train:  0.92\t ACC test:  0.88\n",
      "\tEpoch 650: \tAverage Loss:  1.484417755126953\t ACC train:  0.9128571428571428\t ACC test:  0.8822222222222222\n",
      "\tEpoch 651: \tAverage Loss:  1.4855216064453125\t ACC train:  0.9171428571428571\t ACC test:  0.88\n",
      "\tEpoch 652: \tAverage Loss:  1.4843938903808593\t ACC train:  0.92\t ACC test:  0.8777777777777778\n",
      "\tEpoch 653: \tAverage Loss:  1.4846175537109374\t ACC train:  0.9214285714285714\t ACC test:  0.8911111111111111\n",
      "\tEpoch 654: \tAverage Loss:  1.4836089782714843\t ACC train:  0.9257142857142857\t ACC test:  0.8844444444444445\n",
      "\tEpoch 655: \tAverage Loss:  1.4827113342285156\t ACC train:  0.9228571428571428\t ACC test:  0.8911111111111111\n",
      "\tEpoch 656: \tAverage Loss:  1.483320098876953\t ACC train:  0.91\t ACC test:  0.8777777777777778\n",
      "\tEpoch 657: \tAverage Loss:  1.4808819580078125\t ACC train:  0.9257142857142857\t ACC test:  0.8866666666666667\n",
      "\tEpoch 658: \tAverage Loss:  1.48126953125\t ACC train:  0.9157142857142857\t ACC test:  0.88\n",
      "\tEpoch 659: \tAverage Loss:  1.4808272094726562\t ACC train:  0.9257142857142857\t ACC test:  0.8888888888888888\n",
      "\tEpoch 660: \tAverage Loss:  1.4814108581542969\t ACC train:  0.9257142857142857\t ACC test:  0.88\n",
      "\tEpoch 661: \tAverage Loss:  1.479744384765625\t ACC train:  0.91\t ACC test:  0.8977777777777778\n",
      "\tEpoch 662: \tAverage Loss:  1.4807788391113281\t ACC train:  0.9085714285714286\t ACC test:  0.8866666666666667\n",
      "\tEpoch 663: \tAverage Loss:  1.4791905212402343\t ACC train:  0.92\t ACC test:  0.8911111111111111\n",
      "\tEpoch 664: \tAverage Loss:  1.4791351928710939\t ACC train:  0.9271428571428572\t ACC test:  0.8933333333333333\n",
      "\tEpoch 665: \tAverage Loss:  1.4791392211914063\t ACC train:  0.9242857142857143\t ACC test:  0.8844444444444445\n",
      "\tEpoch 666: \tAverage Loss:  1.4786969604492188\t ACC train:  0.9242857142857143\t ACC test:  0.8933333333333333\n",
      "\tEpoch 667: \tAverage Loss:  1.4774705200195313\t ACC train:  0.9328571428571428\t ACC test:  0.8911111111111111\n",
      "\tEpoch 668: \tAverage Loss:  1.4776095581054687\t ACC train:  0.9214285714285714\t ACC test:  0.8933333333333333\n",
      "\tEpoch 669: \tAverage Loss:  1.47761279296875\t ACC train:  0.9214285714285714\t ACC test:  0.8955555555555555\n",
      "\tEpoch 670: \tAverage Loss:  1.4757598571777344\t ACC train:  0.9328571428571428\t ACC test:  0.8933333333333333\n",
      "\tEpoch 671: \tAverage Loss:  1.4785511169433594\t ACC train:  0.9242857142857143\t ACC test:  0.8955555555555555\n",
      "\tEpoch 672: \tAverage Loss:  1.4788633728027343\t ACC train:  0.9328571428571428\t ACC test:  0.8911111111111111\n",
      "\tEpoch 673: \tAverage Loss:  1.476807861328125\t ACC train:  0.9357142857142857\t ACC test:  0.9111111111111111\n",
      "\tEpoch 674: \tAverage Loss:  1.4755582275390624\t ACC train:  0.9328571428571428\t ACC test:  0.8933333333333333\n",
      "\tEpoch 675: \tAverage Loss:  1.4741553649902344\t ACC train:  0.9242857142857143\t ACC test:  0.8911111111111111\n",
      "\tEpoch 676: \tAverage Loss:  1.4724840087890625\t ACC train:  0.9328571428571428\t ACC test:  0.8977777777777778\n",
      "\tEpoch 677: \tAverage Loss:  1.4747221984863281\t ACC train:  0.9342857142857143\t ACC test:  0.8977777777777778\n",
      "\tEpoch 678: \tAverage Loss:  1.473412567138672\t ACC train:  0.93\t ACC test:  0.8955555555555555\n",
      "\tEpoch 679: \tAverage Loss:  1.4746402587890626\t ACC train:  0.9328571428571428\t ACC test:  0.8955555555555555\n",
      "\tEpoch 680: \tAverage Loss:  1.4744542541503907\t ACC train:  0.94\t ACC test:  0.9022222222222223\n",
      "\tEpoch 681: \tAverage Loss:  1.4723022155761718\t ACC train:  0.9257142857142857\t ACC test:  0.8911111111111111\n",
      "\tEpoch 682: \tAverage Loss:  1.4734297790527344\t ACC train:  0.9314285714285714\t ACC test:  0.8977777777777778\n",
      "\tEpoch 683: \tAverage Loss:  1.4718779602050782\t ACC train:  0.9314285714285714\t ACC test:  0.9066666666666666\n",
      "\tEpoch 684: \tAverage Loss:  1.4707294006347655\t ACC train:  0.9314285714285714\t ACC test:  0.8955555555555555\n",
      "\tEpoch 685: \tAverage Loss:  1.469787322998047\t ACC train:  0.9342857142857143\t ACC test:  0.8911111111111111\n",
      "\tEpoch 686: \tAverage Loss:  1.471157989501953\t ACC train:  0.9242857142857143\t ACC test:  0.8911111111111111\n",
      "\tEpoch 687: \tAverage Loss:  1.4713564147949219\t ACC train:  0.94\t ACC test:  0.9\n",
      "\tEpoch 688: \tAverage Loss:  1.4699481201171876\t ACC train:  0.9428571428571428\t ACC test:  0.8933333333333333\n",
      "\tEpoch 689: \tAverage Loss:  1.4700075073242187\t ACC train:  0.9371428571428572\t ACC test:  0.9\n",
      "\tEpoch 690: \tAverage Loss:  1.4701072387695313\t ACC train:  0.9428571428571428\t ACC test:  0.9\n",
      "\tEpoch 691: \tAverage Loss:  1.4694180297851562\t ACC train:  0.9428571428571428\t ACC test:  0.9022222222222223\n",
      "\tEpoch 692: \tAverage Loss:  1.4690341186523437\t ACC train:  0.9328571428571428\t ACC test:  0.8911111111111111\n",
      "\tEpoch 693: \tAverage Loss:  1.4691996459960937\t ACC train:  0.94\t ACC test:  0.9\n",
      "\tEpoch 694: \tAverage Loss:  1.4674280395507813\t ACC train:  0.9314285714285714\t ACC test:  0.9022222222222223\n",
      "\tEpoch 695: \tAverage Loss:  1.4679861450195313\t ACC train:  0.94\t ACC test:  0.9022222222222223\n",
      "\tEpoch 696: \tAverage Loss:  1.4654151306152343\t ACC train:  0.94\t ACC test:  0.9044444444444445\n",
      "\tEpoch 697: \tAverage Loss:  1.4670690307617187\t ACC train:  0.9457142857142857\t ACC test:  0.8977777777777778\n",
      "\tEpoch 698: \tAverage Loss:  1.4673853149414062\t ACC train:  0.9457142857142857\t ACC test:  0.9155555555555556\n",
      "\tEpoch 699: \tAverage Loss:  1.4682096557617188\t ACC train:  0.9428571428571428\t ACC test:  0.9088888888888889\n",
      "\tEpoch 700: \tAverage Loss:  1.4676071472167969\t ACC train:  0.9414285714285714\t ACC test:  0.9\n",
      "\tEpoch 701: \tAverage Loss:  1.4679411926269532\t ACC train:  0.9457142857142857\t ACC test:  0.9088888888888889\n",
      "\tEpoch 702: \tAverage Loss:  1.4658706665039063\t ACC train:  0.9471428571428572\t ACC test:  0.9022222222222223\n",
      "\tEpoch 703: \tAverage Loss:  1.469007598876953\t ACC train:  0.9485714285714286\t ACC test:  0.9\n",
      "\tEpoch 704: \tAverage Loss:  1.4634419555664062\t ACC train:  0.9514285714285714\t ACC test:  0.9111111111111111\n",
      "\tEpoch 705: \tAverage Loss:  1.4621358947753906\t ACC train:  0.9471428571428572\t ACC test:  0.9133333333333333\n",
      "\tEpoch 706: \tAverage Loss:  1.46406787109375\t ACC train:  0.9457142857142857\t ACC test:  0.8933333333333333\n",
      "\tEpoch 707: \tAverage Loss:  1.4618546752929686\t ACC train:  0.9371428571428572\t ACC test:  0.9066666666666666\n",
      "\tEpoch 708: \tAverage Loss:  1.4635404968261718\t ACC train:  0.9471428571428572\t ACC test:  0.9111111111111111\n",
      "\tEpoch 709: \tAverage Loss:  1.4619295349121093\t ACC train:  0.9457142857142857\t ACC test:  0.8955555555555555\n",
      "\tEpoch 710: \tAverage Loss:  1.4614948120117188\t ACC train:  0.9471428571428572\t ACC test:  0.9111111111111111\n",
      "\tEpoch 711: \tAverage Loss:  1.462099090576172\t ACC train:  0.9428571428571428\t ACC test:  0.9111111111111111\n",
      "\tEpoch 712: \tAverage Loss:  1.4610579528808594\t ACC train:  0.9471428571428572\t ACC test:  0.9133333333333333\n",
      "\tEpoch 713: \tAverage Loss:  1.4625880432128906\t ACC train:  0.9514285714285714\t ACC test:  0.9088888888888889\n",
      "\tEpoch 714: \tAverage Loss:  1.4629038696289063\t ACC train:  0.9471428571428572\t ACC test:  0.9088888888888889\n",
      "\tEpoch 715: \tAverage Loss:  1.4636830749511718\t ACC train:  0.9371428571428572\t ACC test:  0.9044444444444445\n",
      "\tEpoch 716: \tAverage Loss:  1.4619629211425782\t ACC train:  0.9428571428571428\t ACC test:  0.9177777777777778\n",
      "\tEpoch 717: \tAverage Loss:  1.459981414794922\t ACC train:  0.9442857142857143\t ACC test:  0.9022222222222223\n",
      "\tEpoch 718: \tAverage Loss:  1.4574018249511718\t ACC train:  0.9514285714285714\t ACC test:  0.9155555555555556\n",
      "\tEpoch 719: \tAverage Loss:  1.4600845642089844\t ACC train:  0.9485714285714286\t ACC test:  0.9133333333333333\n",
      "\tEpoch 720: \tAverage Loss:  1.4592893371582032\t ACC train:  0.9428571428571428\t ACC test:  0.9111111111111111\n",
      "\tEpoch 721: \tAverage Loss:  1.4554639587402343\t ACC train:  0.9528571428571428\t ACC test:  0.9155555555555556\n",
      "\tEpoch 722: \tAverage Loss:  1.456658935546875\t ACC train:  0.9442857142857143\t ACC test:  0.9177777777777778\n",
      "\tEpoch 723: \tAverage Loss:  1.4559129028320312\t ACC train:  0.9528571428571428\t ACC test:  0.9066666666666666\n",
      "\tEpoch 724: \tAverage Loss:  1.4572340393066405\t ACC train:  0.9528571428571428\t ACC test:  0.9133333333333333\n",
      "\tEpoch 725: \tAverage Loss:  1.4575177307128906\t ACC train:  0.9557142857142857\t ACC test:  0.92\n",
      "\tEpoch 726: \tAverage Loss:  1.4532085571289062\t ACC train:  0.9557142857142857\t ACC test:  0.9222222222222223\n",
      "\tEpoch 727: \tAverage Loss:  1.4533448791503907\t ACC train:  0.9528571428571428\t ACC test:  0.9266666666666666\n",
      "\tEpoch 728: \tAverage Loss:  1.455394317626953\t ACC train:  0.95\t ACC test:  0.9111111111111111\n",
      "\tEpoch 729: \tAverage Loss:  1.457808074951172\t ACC train:  0.9442857142857143\t ACC test:  0.9133333333333333\n",
      "\tEpoch 730: \tAverage Loss:  1.4620849914550782\t ACC train:  0.9457142857142857\t ACC test:  0.9\n",
      "\tEpoch 731: \tAverage Loss:  1.4650890502929688\t ACC train:  0.9528571428571428\t ACC test:  0.9244444444444444\n",
      "\tEpoch 732: \tAverage Loss:  1.4690111083984374\t ACC train:  0.9542857142857143\t ACC test:  0.9177777777777778\n",
      "\tEpoch 733: \tAverage Loss:  1.4580514526367188\t ACC train:  0.9685714285714285\t ACC test:  0.92\n",
      "\tEpoch 734: \tAverage Loss:  1.455224609375\t ACC train:  0.9528571428571428\t ACC test:  0.92\n",
      "\tEpoch 735: \tAverage Loss:  1.4521847229003906\t ACC train:  0.9585714285714285\t ACC test:  0.9133333333333333\n",
      "\tEpoch 736: \tAverage Loss:  1.4553474731445313\t ACC train:  0.9542857142857143\t ACC test:  0.9177777777777778\n",
      "\tEpoch 737: \tAverage Loss:  1.451142578125\t ACC train:  0.9642857142857143\t ACC test:  0.9155555555555556\n",
      "\tEpoch 738: \tAverage Loss:  1.453006378173828\t ACC train:  0.9428571428571428\t ACC test:  0.9244444444444444\n",
      "\tEpoch 739: \tAverage Loss:  1.4513270263671876\t ACC train:  0.9514285714285714\t ACC test:  0.9177777777777778\n",
      "\tEpoch 740: \tAverage Loss:  1.4510860595703126\t ACC train:  0.9557142857142857\t ACC test:  0.9088888888888889\n",
      "\tEpoch 741: \tAverage Loss:  1.4512817993164062\t ACC train:  0.9528571428571428\t ACC test:  0.9177777777777778\n",
      "\tEpoch 742: \tAverage Loss:  1.455243927001953\t ACC train:  0.9528571428571428\t ACC test:  0.9111111111111111\n",
      "\tEpoch 743: \tAverage Loss:  1.4494669799804687\t ACC train:  0.9528571428571428\t ACC test:  0.9222222222222223\n",
      "\tEpoch 744: \tAverage Loss:  1.4502804870605468\t ACC train:  0.9514285714285714\t ACC test:  0.92\n",
      "\tEpoch 745: \tAverage Loss:  1.4513084411621093\t ACC train:  0.9542857142857143\t ACC test:  0.92\n",
      "\tEpoch 746: \tAverage Loss:  1.4519202880859374\t ACC train:  0.9628571428571429\t ACC test:  0.9244444444444444\n",
      "\tEpoch 747: \tAverage Loss:  1.4541295166015624\t ACC train:  0.9571428571428572\t ACC test:  0.9155555555555556\n",
      "\tEpoch 748: \tAverage Loss:  1.4521641540527344\t ACC train:  0.9614285714285714\t ACC test:  0.9222222222222223\n",
      "\tEpoch 749: \tAverage Loss:  1.4523079528808593\t ACC train:  0.9557142857142857\t ACC test:  0.9288888888888889\n",
      "\tEpoch 750: \tAverage Loss:  1.4480193481445311\t ACC train:  0.9585714285714285\t ACC test:  0.9155555555555556\n",
      "\tEpoch 751: \tAverage Loss:  1.4475438537597656\t ACC train:  0.9585714285714285\t ACC test:  0.9222222222222223\n",
      "\tEpoch 752: \tAverage Loss:  1.4489757690429688\t ACC train:  0.9614285714285714\t ACC test:  0.9222222222222223\n",
      "\tEpoch 753: \tAverage Loss:  1.4477529296875\t ACC train:  0.96\t ACC test:  0.9266666666666666\n",
      "\tEpoch 754: \tAverage Loss:  1.4487011413574218\t ACC train:  0.9614285714285714\t ACC test:  0.9222222222222223\n",
      "\tEpoch 755: \tAverage Loss:  1.4452015075683593\t ACC train:  0.9685714285714285\t ACC test:  0.9311111111111111\n",
      "\tEpoch 756: \tAverage Loss:  1.4473655395507812\t ACC train:  0.9628571428571429\t ACC test:  0.9355555555555556\n",
      "\tEpoch 757: \tAverage Loss:  1.4459779052734374\t ACC train:  0.9614285714285714\t ACC test:  0.9288888888888889\n",
      "\tEpoch 758: \tAverage Loss:  1.447170928955078\t ACC train:  0.9585714285714285\t ACC test:  0.9266666666666666\n",
      "\tEpoch 759: \tAverage Loss:  1.4480704040527344\t ACC train:  0.9585714285714285\t ACC test:  0.9266666666666666\n",
      "\tEpoch 760: \tAverage Loss:  1.4478154907226561\t ACC train:  0.9628571428571429\t ACC test:  0.9222222222222223\n",
      "\tEpoch 761: \tAverage Loss:  1.4459227905273437\t ACC train:  0.96\t ACC test:  0.9288888888888889\n",
      "\tEpoch 762: \tAverage Loss:  1.444392303466797\t ACC train:  0.9671428571428572\t ACC test:  0.9244444444444444\n",
      "\tEpoch 763: \tAverage Loss:  1.4447140197753907\t ACC train:  0.96\t ACC test:  0.9222222222222223\n",
      "\tEpoch 764: \tAverage Loss:  1.444846221923828\t ACC train:  0.9671428571428572\t ACC test:  0.9288888888888889\n",
      "\tEpoch 765: \tAverage Loss:  1.4441959533691406\t ACC train:  0.9671428571428572\t ACC test:  0.9244444444444444\n",
      "\tEpoch 766: \tAverage Loss:  1.4435982971191406\t ACC train:  0.97\t ACC test:  0.9244444444444444\n",
      "\tEpoch 767: \tAverage Loss:  1.4430137939453125\t ACC train:  0.9628571428571429\t ACC test:  0.92\n",
      "\tEpoch 768: \tAverage Loss:  1.4433135375976562\t ACC train:  0.9657142857142857\t ACC test:  0.9266666666666666\n",
      "\tEpoch 769: \tAverage Loss:  1.44171240234375\t ACC train:  0.9628571428571429\t ACC test:  0.9266666666666666\n",
      "\tEpoch 770: \tAverage Loss:  1.4417094116210938\t ACC train:  0.9714285714285714\t ACC test:  0.9333333333333333\n",
      "\tEpoch 771: \tAverage Loss:  1.442882110595703\t ACC train:  0.9714285714285714\t ACC test:  0.9222222222222223\n",
      "\tEpoch 772: \tAverage Loss:  1.4417705078125\t ACC train:  0.9685714285714285\t ACC test:  0.9333333333333333\n",
      "\tEpoch 773: \tAverage Loss:  1.441901397705078\t ACC train:  0.9657142857142857\t ACC test:  0.9266666666666666\n",
      "\tEpoch 774: \tAverage Loss:  1.4437522888183594\t ACC train:  0.9671428571428572\t ACC test:  0.9288888888888889\n",
      "\tEpoch 775: \tAverage Loss:  1.4401492309570312\t ACC train:  0.9714285714285714\t ACC test:  0.9266666666666666\n",
      "\tEpoch 776: \tAverage Loss:  1.4395102233886719\t ACC train:  0.9714285714285714\t ACC test:  0.9355555555555556\n",
      "\tEpoch 777: \tAverage Loss:  1.4410977478027345\t ACC train:  0.9642857142857143\t ACC test:  0.9288888888888889\n",
      "\tEpoch 778: \tAverage Loss:  1.439298828125\t ACC train:  0.9742857142857143\t ACC test:  0.9422222222222222\n",
      "\tEpoch 779: \tAverage Loss:  1.4412368774414062\t ACC train:  0.9642857142857143\t ACC test:  0.9355555555555556\n",
      "\tEpoch 780: \tAverage Loss:  1.4391648254394531\t ACC train:  0.96\t ACC test:  0.9377777777777778\n",
      "\tEpoch 781: \tAverage Loss:  1.4375315246582032\t ACC train:  0.9714285714285714\t ACC test:  0.9266666666666666\n",
      "\tEpoch 782: \tAverage Loss:  1.4383597412109375\t ACC train:  0.9642857142857143\t ACC test:  0.9333333333333333\n",
      "\tEpoch 783: \tAverage Loss:  1.4378695678710938\t ACC train:  0.9742857142857143\t ACC test:  0.9311111111111111\n",
      "\tEpoch 784: \tAverage Loss:  1.4354925231933593\t ACC train:  0.97\t ACC test:  0.9355555555555556\n",
      "\tEpoch 785: \tAverage Loss:  1.441229766845703\t ACC train:  0.9742857142857143\t ACC test:  0.9377777777777778\n",
      "\tEpoch 786: \tAverage Loss:  1.4370470581054688\t ACC train:  0.9714285714285714\t ACC test:  0.9333333333333333\n",
      "\tEpoch 787: \tAverage Loss:  1.4364859313964844\t ACC train:  0.9685714285714285\t ACC test:  0.9333333333333333\n",
      "\tEpoch 788: \tAverage Loss:  1.44104443359375\t ACC train:  0.9671428571428572\t ACC test:  0.9466666666666667\n",
      "\tEpoch 789: \tAverage Loss:  1.4423475341796874\t ACC train:  0.9714285714285714\t ACC test:  0.9311111111111111\n",
      "\tEpoch 790: \tAverage Loss:  1.4390364990234374\t ACC train:  0.9785714285714285\t ACC test:  0.9422222222222222\n",
      "\tEpoch 791: \tAverage Loss:  1.4385373840332032\t ACC train:  0.9728571428571429\t ACC test:  0.9377777777777778\n",
      "\tEpoch 792: \tAverage Loss:  1.4356385803222655\t ACC train:  0.97\t ACC test:  0.9333333333333333\n",
      "\tEpoch 793: \tAverage Loss:  1.4401139831542968\t ACC train:  0.9771428571428571\t ACC test:  0.9422222222222222\n",
      "\tEpoch 794: \tAverage Loss:  1.435922119140625\t ACC train:  0.9728571428571429\t ACC test:  0.9355555555555556\n",
      "\tEpoch 795: \tAverage Loss:  1.4339696044921875\t ACC train:  0.97\t ACC test:  0.9377777777777778\n",
      "\tEpoch 796: \tAverage Loss:  1.4357824401855468\t ACC train:  0.9728571428571429\t ACC test:  0.9466666666666667\n",
      "\tEpoch 797: \tAverage Loss:  1.438929901123047\t ACC train:  0.9728571428571429\t ACC test:  0.94\n",
      "\tEpoch 798: \tAverage Loss:  1.4355859375\t ACC train:  0.9785714285714285\t ACC test:  0.9377777777777778\n",
      "Stopping early at epoch 798. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 800\n",
      "\tEpoch 1: \tAverage Loss:  3.7582677001953124\t ACC train:  0.49625\t ACC test:  0.5133333333333333\n",
      "\tEpoch 2: \tAverage Loss:  3.726404296875\t ACC train:  0.49625\t ACC test:  0.5133333333333333\n",
      "\tEpoch 3: \tAverage Loss:  3.6969796142578124\t ACC train:  0.49625\t ACC test:  0.5133333333333333\n",
      "\tEpoch 4: \tAverage Loss:  3.669371826171875\t ACC train:  0.49625\t ACC test:  0.5133333333333333\n",
      "\tEpoch 5: \tAverage Loss:  3.64328466796875\t ACC train:  0.49625\t ACC test:  0.5133333333333333\n",
      "\tEpoch 6: \tAverage Loss:  3.61802294921875\t ACC train:  0.49625\t ACC test:  0.5133333333333333\n",
      "\tEpoch 7: \tAverage Loss:  3.5938565673828125\t ACC train:  0.49625\t ACC test:  0.5133333333333333\n",
      "\tEpoch 8: \tAverage Loss:  3.571722412109375\t ACC train:  0.48875\t ACC test:  0.4822222222222222\n",
      "\tEpoch 9: \tAverage Loss:  3.5499010009765626\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 10: \tAverage Loss:  3.531630859375\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  3.5108778076171876\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  3.493271728515625\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  3.4756317138671875\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  3.4600882568359377\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  3.4413773193359374\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  3.428248291015625\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  3.411169921875\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  3.390172119140625\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  3.3787060546875\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  3.357289794921875\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  3.35147216796875\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  3.3290029296875\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  3.3230828857421875\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  3.306020751953125\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  3.2813675537109375\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  3.268678955078125\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  3.2560596923828125\t ACC train:  0.525\t ACC test:  0.5177777777777778\n",
      "\tEpoch 28: \tAverage Loss:  3.2338731689453124\t ACC train:  0.565\t ACC test:  0.5355555555555556\n",
      "\tEpoch 29: \tAverage Loss:  3.230557861328125\t ACC train:  0.5475\t ACC test:  0.5\n",
      "\tEpoch 30: \tAverage Loss:  3.215536376953125\t ACC train:  0.53875\t ACC test:  0.5444444444444444\n",
      "\tEpoch 31: \tAverage Loss:  3.20360400390625\t ACC train:  0.525\t ACC test:  0.4955555555555556\n",
      "\tEpoch 32: \tAverage Loss:  3.179418701171875\t ACC train:  0.5125\t ACC test:  0.4955555555555556\n",
      "\tEpoch 33: \tAverage Loss:  3.1817569580078127\t ACC train:  0.51625\t ACC test:  0.5111111111111111\n",
      "\tEpoch 34: \tAverage Loss:  3.144874755859375\t ACC train:  0.52125\t ACC test:  0.5044444444444445\n",
      "\tEpoch 35: \tAverage Loss:  3.1364605712890623\t ACC train:  0.5375\t ACC test:  0.5222222222222223\n",
      "\tEpoch 36: \tAverage Loss:  3.132159423828125\t ACC train:  0.59125\t ACC test:  0.5444444444444444\n",
      "\tEpoch 37: \tAverage Loss:  3.1017939453125\t ACC train:  0.58\t ACC test:  0.5533333333333333\n",
      "\tEpoch 38: \tAverage Loss:  3.085115478515625\t ACC train:  0.56875\t ACC test:  0.5133333333333333\n",
      "\tEpoch 39: \tAverage Loss:  3.066893310546875\t ACC train:  0.5525\t ACC test:  0.5311111111111111\n",
      "\tEpoch 40: \tAverage Loss:  3.052537353515625\t ACC train:  0.53125\t ACC test:  0.5266666666666666\n",
      "\tEpoch 41: \tAverage Loss:  3.0499139404296876\t ACC train:  0.51625\t ACC test:  0.5066666666666667\n",
      "\tEpoch 42: \tAverage Loss:  3.0210966796875\t ACC train:  0.4825\t ACC test:  0.4822222222222222\n",
      "\tEpoch 43: \tAverage Loss:  2.9970936279296874\t ACC train:  0.475\t ACC test:  0.4777777777777778\n",
      "\tEpoch 44: \tAverage Loss:  2.985430908203125\t ACC train:  0.4975\t ACC test:  0.4822222222222222\n",
      "\tEpoch 45: \tAverage Loss:  2.956869873046875\t ACC train:  0.475\t ACC test:  0.47555555555555556\n",
      "\tEpoch 46: \tAverage Loss:  2.928543212890625\t ACC train:  0.4675\t ACC test:  0.4711111111111111\n",
      "\tEpoch 47: \tAverage Loss:  2.9327716064453124\t ACC train:  0.4875\t ACC test:  0.48\n",
      "\tEpoch 48: \tAverage Loss:  2.896555908203125\t ACC train:  0.4975\t ACC test:  0.4777777777777778\n",
      "\tEpoch 49: \tAverage Loss:  2.8921455078125\t ACC train:  0.48\t ACC test:  0.46444444444444444\n",
      "\tEpoch 50: \tAverage Loss:  2.868151123046875\t ACC train:  0.47375\t ACC test:  0.4822222222222222\n",
      "\tEpoch 51: \tAverage Loss:  2.830978759765625\t ACC train:  0.485\t ACC test:  0.4711111111111111\n",
      "\tEpoch 52: \tAverage Loss:  2.8243736572265625\t ACC train:  0.485\t ACC test:  0.48444444444444446\n",
      "\tEpoch 53: \tAverage Loss:  2.8014022216796874\t ACC train:  0.48625\t ACC test:  0.48444444444444446\n",
      "\tEpoch 54: \tAverage Loss:  2.76039501953125\t ACC train:  0.48375\t ACC test:  0.4622222222222222\n",
      "\tEpoch 55: \tAverage Loss:  2.7512008056640624\t ACC train:  0.49875\t ACC test:  0.4666666666666667\n",
      "\tEpoch 56: \tAverage Loss:  2.7477447509765627\t ACC train:  0.49625\t ACC test:  0.4711111111111111\n",
      "\tEpoch 57: \tAverage Loss:  2.71624267578125\t ACC train:  0.49125\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  2.702944580078125\t ACC train:  0.49875\t ACC test:  0.48444444444444446\n",
      "\tEpoch 59: \tAverage Loss:  2.683744934082031\t ACC train:  0.4925\t ACC test:  0.4955555555555556\n",
      "\tEpoch 60: \tAverage Loss:  2.657544128417969\t ACC train:  0.5\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  2.6489183349609373\t ACC train:  0.495\t ACC test:  0.4955555555555556\n",
      "\tEpoch 62: \tAverage Loss:  2.6211299438476563\t ACC train:  0.495\t ACC test:  0.49333333333333335\n",
      "\tEpoch 63: \tAverage Loss:  2.6053450927734376\t ACC train:  0.49875\t ACC test:  0.4888888888888889\n",
      "\tEpoch 64: \tAverage Loss:  2.590911804199219\t ACC train:  0.50375\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  2.5678482666015623\t ACC train:  0.49625\t ACC test:  0.5044444444444445\n",
      "\tEpoch 66: \tAverage Loss:  2.5484127197265627\t ACC train:  0.50125\t ACC test:  0.4955555555555556\n",
      "\tEpoch 67: \tAverage Loss:  2.5291060791015627\t ACC train:  0.50375\t ACC test:  0.4955555555555556\n",
      "\tEpoch 68: \tAverage Loss:  2.5027132568359374\t ACC train:  0.49375\t ACC test:  0.4955555555555556\n",
      "\tEpoch 69: \tAverage Loss:  2.4946453247070313\t ACC train:  0.49375\t ACC test:  0.4955555555555556\n",
      "\tEpoch 70: \tAverage Loss:  2.4737626342773438\t ACC train:  0.495\t ACC test:  0.49777777777777776\n",
      "\tEpoch 71: \tAverage Loss:  2.45938037109375\t ACC train:  0.505\t ACC test:  0.5\n",
      "\tEpoch 72: \tAverage Loss:  2.4413668212890625\t ACC train:  0.5075\t ACC test:  0.5\n",
      "\tEpoch 73: \tAverage Loss:  2.42530517578125\t ACC train:  0.505\t ACC test:  0.5044444444444445\n",
      "\tEpoch 74: \tAverage Loss:  2.40662451171875\t ACC train:  0.50375\t ACC test:  0.5044444444444445\n",
      "\tEpoch 75: \tAverage Loss:  2.3938970947265625\t ACC train:  0.5025\t ACC test:  0.49777777777777776\n",
      "\tEpoch 76: \tAverage Loss:  2.369160400390625\t ACC train:  0.505\t ACC test:  0.5\n",
      "\tEpoch 77: \tAverage Loss:  2.3741119384765623\t ACC train:  0.50875\t ACC test:  0.5088888888888888\n",
      "\tEpoch 78: \tAverage Loss:  2.3593565063476563\t ACC train:  0.5075\t ACC test:  0.49777777777777776\n",
      "\tEpoch 79: \tAverage Loss:  2.335790954589844\t ACC train:  0.505\t ACC test:  0.5\n",
      "\tEpoch 80: \tAverage Loss:  2.330975830078125\t ACC train:  0.50625\t ACC test:  0.5044444444444445\n",
      "\tEpoch 81: \tAverage Loss:  2.320650695800781\t ACC train:  0.5025\t ACC test:  0.49777777777777776\n",
      "\tEpoch 82: \tAverage Loss:  2.301771728515625\t ACC train:  0.5025\t ACC test:  0.4955555555555556\n",
      "\tEpoch 83: \tAverage Loss:  2.294638427734375\t ACC train:  0.5025\t ACC test:  0.5\n",
      "\tEpoch 84: \tAverage Loss:  2.2805278930664064\t ACC train:  0.50125\t ACC test:  0.5044444444444445\n",
      "\tEpoch 85: \tAverage Loss:  2.272500244140625\t ACC train:  0.50375\t ACC test:  0.49777777777777776\n",
      "\tEpoch 86: \tAverage Loss:  2.262037170410156\t ACC train:  0.5125\t ACC test:  0.4955555555555556\n",
      "\tEpoch 87: \tAverage Loss:  2.2542427978515627\t ACC train:  0.50625\t ACC test:  0.5\n",
      "\tEpoch 88: \tAverage Loss:  2.242593505859375\t ACC train:  0.50625\t ACC test:  0.5111111111111111\n",
      "\tEpoch 89: \tAverage Loss:  2.236948913574219\t ACC train:  0.5075\t ACC test:  0.5\n",
      "\tEpoch 90: \tAverage Loss:  2.2258779907226565\t ACC train:  0.51125\t ACC test:  0.5044444444444445\n",
      "\tEpoch 91: \tAverage Loss:  2.2211041259765625\t ACC train:  0.505\t ACC test:  0.5088888888888888\n",
      "\tEpoch 92: \tAverage Loss:  2.207818359375\t ACC train:  0.505\t ACC test:  0.5044444444444445\n",
      "\tEpoch 93: \tAverage Loss:  2.197542236328125\t ACC train:  0.505\t ACC test:  0.5022222222222222\n",
      "\tEpoch 94: \tAverage Loss:  2.1937598876953124\t ACC train:  0.5075\t ACC test:  0.5\n",
      "\tEpoch 95: \tAverage Loss:  2.1897824096679686\t ACC train:  0.50875\t ACC test:  0.5044444444444445\n",
      "\tEpoch 96: \tAverage Loss:  2.1795421142578126\t ACC train:  0.51\t ACC test:  0.4955555555555556\n",
      "\tEpoch 97: \tAverage Loss:  2.173283935546875\t ACC train:  0.5075\t ACC test:  0.5066666666666667\n",
      "\tEpoch 98: \tAverage Loss:  2.16676123046875\t ACC train:  0.50875\t ACC test:  0.5044444444444445\n",
      "\tEpoch 99: \tAverage Loss:  2.1606282348632813\t ACC train:  0.5075\t ACC test:  0.5066666666666667\n",
      "\tEpoch 100: \tAverage Loss:  2.154980224609375\t ACC train:  0.51125\t ACC test:  0.5\n",
      "\tEpoch 101: \tAverage Loss:  2.145649719238281\t ACC train:  0.51\t ACC test:  0.5044444444444445\n",
      "\tEpoch 102: \tAverage Loss:  2.143777648925781\t ACC train:  0.50625\t ACC test:  0.49777777777777776\n",
      "\tEpoch 103: \tAverage Loss:  2.13461474609375\t ACC train:  0.515\t ACC test:  0.5022222222222222\n",
      "\tEpoch 104: \tAverage Loss:  2.1346546630859375\t ACC train:  0.51\t ACC test:  0.5066666666666667\n",
      "\tEpoch 105: \tAverage Loss:  2.1293998413085937\t ACC train:  0.51\t ACC test:  0.5\n",
      "\tEpoch 106: \tAverage Loss:  2.1228077392578126\t ACC train:  0.51125\t ACC test:  0.5066666666666667\n",
      "\tEpoch 107: \tAverage Loss:  2.1191465454101563\t ACC train:  0.51125\t ACC test:  0.5066666666666667\n",
      "\tEpoch 108: \tAverage Loss:  2.1149381103515625\t ACC train:  0.5125\t ACC test:  0.5044444444444445\n",
      "\tEpoch 109: \tAverage Loss:  2.1102098999023435\t ACC train:  0.51125\t ACC test:  0.5044444444444445\n",
      "\tEpoch 110: \tAverage Loss:  2.1036629028320313\t ACC train:  0.51125\t ACC test:  0.5111111111111111\n",
      "\tEpoch 111: \tAverage Loss:  2.1002203369140626\t ACC train:  0.51125\t ACC test:  0.5022222222222222\n",
      "\tEpoch 112: \tAverage Loss:  2.099771240234375\t ACC train:  0.5125\t ACC test:  0.5044444444444445\n",
      "\tEpoch 113: \tAverage Loss:  2.092320068359375\t ACC train:  0.51\t ACC test:  0.5088888888888888\n",
      "\tEpoch 114: \tAverage Loss:  2.0874495849609374\t ACC train:  0.51875\t ACC test:  0.5066666666666667\n",
      "\tEpoch 115: \tAverage Loss:  2.0856209106445314\t ACC train:  0.51375\t ACC test:  0.5022222222222222\n",
      "\tEpoch 116: \tAverage Loss:  2.081943603515625\t ACC train:  0.5075\t ACC test:  0.5066666666666667\n",
      "\tEpoch 117: \tAverage Loss:  2.076794860839844\t ACC train:  0.51125\t ACC test:  0.5088888888888888\n",
      "\tEpoch 118: \tAverage Loss:  2.0748001708984374\t ACC train:  0.5125\t ACC test:  0.5066666666666667\n",
      "\tEpoch 119: \tAverage Loss:  2.072692138671875\t ACC train:  0.51125\t ACC test:  0.5066666666666667\n",
      "\tEpoch 120: \tAverage Loss:  2.0712473754882814\t ACC train:  0.515\t ACC test:  0.5088888888888888\n",
      "\tEpoch 121: \tAverage Loss:  2.0661724853515624\t ACC train:  0.51625\t ACC test:  0.5022222222222222\n",
      "\tEpoch 122: \tAverage Loss:  2.0640359497070313\t ACC train:  0.5225\t ACC test:  0.5088888888888888\n",
      "\tEpoch 123: \tAverage Loss:  2.06211279296875\t ACC train:  0.51\t ACC test:  0.5044444444444445\n",
      "\tEpoch 124: \tAverage Loss:  2.055773254394531\t ACC train:  0.51125\t ACC test:  0.5022222222222222\n",
      "\tEpoch 125: \tAverage Loss:  2.0552752075195313\t ACC train:  0.5125\t ACC test:  0.5066666666666667\n",
      "\tEpoch 126: \tAverage Loss:  2.0514443359375\t ACC train:  0.5075\t ACC test:  0.5088888888888888\n",
      "\tEpoch 127: \tAverage Loss:  2.049456848144531\t ACC train:  0.5125\t ACC test:  0.5066666666666667\n",
      "\tEpoch 128: \tAverage Loss:  2.0447674560546876\t ACC train:  0.51375\t ACC test:  0.5066666666666667\n",
      "\tEpoch 129: \tAverage Loss:  2.0434012451171877\t ACC train:  0.515\t ACC test:  0.5044444444444445\n",
      "\tEpoch 130: \tAverage Loss:  2.043138916015625\t ACC train:  0.51375\t ACC test:  0.5022222222222222\n",
      "\tEpoch 131: \tAverage Loss:  2.03985498046875\t ACC train:  0.51125\t ACC test:  0.49777777777777776\n",
      "\tEpoch 132: \tAverage Loss:  2.037016418457031\t ACC train:  0.5125\t ACC test:  0.5044444444444445\n",
      "\tEpoch 133: \tAverage Loss:  2.0342440795898438\t ACC train:  0.50625\t ACC test:  0.5044444444444445\n",
      "\tEpoch 134: \tAverage Loss:  2.0338103637695313\t ACC train:  0.50875\t ACC test:  0.5088888888888888\n",
      "\tEpoch 135: \tAverage Loss:  2.0302089233398437\t ACC train:  0.50875\t ACC test:  0.5066666666666667\n",
      "\tEpoch 136: \tAverage Loss:  2.0294235229492186\t ACC train:  0.515\t ACC test:  0.49777777777777776\n",
      "\tEpoch 137: \tAverage Loss:  2.0273248291015626\t ACC train:  0.51\t ACC test:  0.5088888888888888\n",
      "\tEpoch 138: \tAverage Loss:  2.0235096435546875\t ACC train:  0.50875\t ACC test:  0.5066666666666667\n",
      "\tEpoch 139: \tAverage Loss:  2.022502746582031\t ACC train:  0.515\t ACC test:  0.5044444444444445\n",
      "\tEpoch 140: \tAverage Loss:  2.0198849487304686\t ACC train:  0.51125\t ACC test:  0.5111111111111111\n",
      "\tEpoch 141: \tAverage Loss:  2.01871533203125\t ACC train:  0.5075\t ACC test:  0.5044444444444445\n",
      "\tEpoch 142: \tAverage Loss:  2.0151604614257814\t ACC train:  0.50875\t ACC test:  0.5111111111111111\n",
      "\tEpoch 143: \tAverage Loss:  2.0129537353515623\t ACC train:  0.51125\t ACC test:  0.5111111111111111\n",
      "\tEpoch 144: \tAverage Loss:  2.0125789184570313\t ACC train:  0.51375\t ACC test:  0.5177777777777778\n",
      "\tEpoch 145: \tAverage Loss:  2.0116638793945314\t ACC train:  0.515\t ACC test:  0.5022222222222222\n",
      "\tEpoch 146: \tAverage Loss:  2.0080204467773437\t ACC train:  0.50375\t ACC test:  0.52\n",
      "\tEpoch 147: \tAverage Loss:  2.00878564453125\t ACC train:  0.515\t ACC test:  0.5111111111111111\n",
      "\tEpoch 148: \tAverage Loss:  2.00639453125\t ACC train:  0.51125\t ACC test:  0.5155555555555555\n",
      "\tEpoch 149: \tAverage Loss:  2.0049412841796874\t ACC train:  0.515\t ACC test:  0.5044444444444445\n",
      "\tEpoch 150: \tAverage Loss:  2.002762939453125\t ACC train:  0.51125\t ACC test:  0.52\n",
      "\tEpoch 151: \tAverage Loss:  2.0018749389648436\t ACC train:  0.5125\t ACC test:  0.5088888888888888\n",
      "\tEpoch 152: \tAverage Loss:  2.0004451904296876\t ACC train:  0.51375\t ACC test:  0.5066666666666667\n",
      "\tEpoch 153: \tAverage Loss:  1.9983015747070312\t ACC train:  0.50625\t ACC test:  0.5155555555555555\n",
      "\tEpoch 154: \tAverage Loss:  1.9985739135742187\t ACC train:  0.51375\t ACC test:  0.5066666666666667\n",
      "\tEpoch 155: \tAverage Loss:  1.9950849609375\t ACC train:  0.51625\t ACC test:  0.5111111111111111\n",
      "\tEpoch 156: \tAverage Loss:  1.9957745361328125\t ACC train:  0.515\t ACC test:  0.5133333333333333\n",
      "\tEpoch 157: \tAverage Loss:  1.9915581665039062\t ACC train:  0.51125\t ACC test:  0.5155555555555555\n",
      "\tEpoch 158: \tAverage Loss:  1.9913870239257812\t ACC train:  0.5125\t ACC test:  0.5066666666666667\n",
      "\tEpoch 159: \tAverage Loss:  1.9897098388671874\t ACC train:  0.5125\t ACC test:  0.5088888888888888\n",
      "\tEpoch 160: \tAverage Loss:  1.987886962890625\t ACC train:  0.515\t ACC test:  0.5111111111111111\n",
      "\tEpoch 161: \tAverage Loss:  1.9863743896484376\t ACC train:  0.51375\t ACC test:  0.5\n",
      "\tEpoch 162: \tAverage Loss:  1.9860847778320312\t ACC train:  0.51625\t ACC test:  0.5155555555555555\n",
      "\tEpoch 163: \tAverage Loss:  1.9859815063476562\t ACC train:  0.5175\t ACC test:  0.5088888888888888\n",
      "\tEpoch 164: \tAverage Loss:  1.9866483764648437\t ACC train:  0.51625\t ACC test:  0.5155555555555555\n",
      "\tEpoch 165: \tAverage Loss:  1.981691650390625\t ACC train:  0.51375\t ACC test:  0.5111111111111111\n",
      "\tEpoch 166: \tAverage Loss:  1.981014892578125\t ACC train:  0.51625\t ACC test:  0.5044444444444445\n",
      "\tEpoch 167: \tAverage Loss:  1.978566650390625\t ACC train:  0.5175\t ACC test:  0.5088888888888888\n",
      "\tEpoch 168: \tAverage Loss:  1.978422607421875\t ACC train:  0.5175\t ACC test:  0.52\n",
      "\tEpoch 169: \tAverage Loss:  1.9772742309570313\t ACC train:  0.51625\t ACC test:  0.5133333333333333\n",
      "\tEpoch 170: \tAverage Loss:  1.9759733276367188\t ACC train:  0.52\t ACC test:  0.5088888888888888\n",
      "\tEpoch 171: \tAverage Loss:  1.9745621337890624\t ACC train:  0.51875\t ACC test:  0.5177777777777778\n",
      "\tEpoch 172: \tAverage Loss:  1.9741940307617187\t ACC train:  0.5225\t ACC test:  0.5133333333333333\n",
      "\tEpoch 173: \tAverage Loss:  1.9733784790039062\t ACC train:  0.52125\t ACC test:  0.5133333333333333\n",
      "\tEpoch 174: \tAverage Loss:  1.9733638305664063\t ACC train:  0.51625\t ACC test:  0.52\n",
      "\tEpoch 175: \tAverage Loss:  1.9726063842773438\t ACC train:  0.5125\t ACC test:  0.5088888888888888\n",
      "\tEpoch 176: \tAverage Loss:  1.969574462890625\t ACC train:  0.5175\t ACC test:  0.5266666666666666\n",
      "\tEpoch 177: \tAverage Loss:  1.9678509521484375\t ACC train:  0.51875\t ACC test:  0.5266666666666666\n",
      "\tEpoch 178: \tAverage Loss:  1.9684430541992188\t ACC train:  0.52\t ACC test:  0.5266666666666666\n",
      "\tEpoch 179: \tAverage Loss:  1.9655396728515624\t ACC train:  0.5275\t ACC test:  0.5222222222222223\n",
      "\tEpoch 180: \tAverage Loss:  1.9656470947265625\t ACC train:  0.52125\t ACC test:  0.5155555555555555\n",
      "\tEpoch 181: \tAverage Loss:  1.9666778564453125\t ACC train:  0.53\t ACC test:  0.5177777777777778\n",
      "\tEpoch 182: \tAverage Loss:  1.9649149169921876\t ACC train:  0.5275\t ACC test:  0.5133333333333333\n",
      "\tEpoch 183: \tAverage Loss:  1.96285986328125\t ACC train:  0.51375\t ACC test:  0.52\n",
      "\tEpoch 184: \tAverage Loss:  1.9625262451171874\t ACC train:  0.52125\t ACC test:  0.5244444444444445\n",
      "\tEpoch 185: \tAverage Loss:  1.9619865112304689\t ACC train:  0.54\t ACC test:  0.5311111111111111\n",
      "\tEpoch 186: \tAverage Loss:  1.9624498901367187\t ACC train:  0.52625\t ACC test:  0.5355555555555556\n",
      "\tEpoch 187: \tAverage Loss:  1.957120849609375\t ACC train:  0.5225\t ACC test:  0.52\n",
      "\tEpoch 188: \tAverage Loss:  1.9596359252929687\t ACC train:  0.52\t ACC test:  0.5155555555555555\n",
      "\tEpoch 189: \tAverage Loss:  1.9580230712890625\t ACC train:  0.5225\t ACC test:  0.5155555555555555\n",
      "\tEpoch 190: \tAverage Loss:  1.957177490234375\t ACC train:  0.535\t ACC test:  0.52\n",
      "\tEpoch 191: \tAverage Loss:  1.955982421875\t ACC train:  0.52875\t ACC test:  0.5266666666666666\n",
      "\tEpoch 192: \tAverage Loss:  1.9544138793945312\t ACC train:  0.5225\t ACC test:  0.5266666666666666\n",
      "\tEpoch 193: \tAverage Loss:  1.9553101196289062\t ACC train:  0.535\t ACC test:  0.5355555555555556\n",
      "\tEpoch 194: \tAverage Loss:  1.9545123291015625\t ACC train:  0.52875\t ACC test:  0.5244444444444445\n",
      "\tEpoch 195: \tAverage Loss:  1.9517366333007813\t ACC train:  0.52625\t ACC test:  0.5244444444444445\n",
      "\tEpoch 196: \tAverage Loss:  1.9517340698242187\t ACC train:  0.53625\t ACC test:  0.5177777777777778\n",
      "\tEpoch 197: \tAverage Loss:  1.9520791015625\t ACC train:  0.5425\t ACC test:  0.5355555555555556\n",
      "\tEpoch 198: \tAverage Loss:  1.9492448120117187\t ACC train:  0.5325\t ACC test:  0.5466666666666666\n",
      "\tEpoch 199: \tAverage Loss:  1.9490187377929689\t ACC train:  0.5325\t ACC test:  0.5444444444444444\n",
      "\tEpoch 200: \tAverage Loss:  1.9475363159179688\t ACC train:  0.52875\t ACC test:  0.5377777777777778\n",
      "\tEpoch 201: \tAverage Loss:  1.9462066040039063\t ACC train:  0.53375\t ACC test:  0.5288888888888889\n",
      "\tEpoch 202: \tAverage Loss:  1.9458713989257812\t ACC train:  0.54625\t ACC test:  0.5377777777777778\n",
      "\tEpoch 203: \tAverage Loss:  1.9439695434570312\t ACC train:  0.535\t ACC test:  0.54\n",
      "\tEpoch 204: \tAverage Loss:  1.9485796508789062\t ACC train:  0.535\t ACC test:  0.5377777777777778\n",
      "\tEpoch 205: \tAverage Loss:  1.9443748168945312\t ACC train:  0.53625\t ACC test:  0.5333333333333333\n",
      "\tEpoch 206: \tAverage Loss:  1.9451493530273438\t ACC train:  0.53625\t ACC test:  0.5355555555555556\n",
      "\tEpoch 207: \tAverage Loss:  1.9439797973632813\t ACC train:  0.53875\t ACC test:  0.5622222222222222\n",
      "\tEpoch 208: \tAverage Loss:  1.9407998046875\t ACC train:  0.55\t ACC test:  0.5555555555555556\n",
      "\tEpoch 209: \tAverage Loss:  1.9395506591796876\t ACC train:  0.545\t ACC test:  0.54\n",
      "\tEpoch 210: \tAverage Loss:  1.94082275390625\t ACC train:  0.545\t ACC test:  0.56\n",
      "\tEpoch 211: \tAverage Loss:  1.9357445678710938\t ACC train:  0.5475\t ACC test:  0.5511111111111111\n",
      "\tEpoch 212: \tAverage Loss:  1.9381192016601563\t ACC train:  0.5575\t ACC test:  0.5577777777777778\n",
      "\tEpoch 213: \tAverage Loss:  1.9381106567382813\t ACC train:  0.5475\t ACC test:  0.5333333333333333\n",
      "\tEpoch 214: \tAverage Loss:  1.9392935791015624\t ACC train:  0.55375\t ACC test:  0.5733333333333334\n",
      "\tEpoch 215: \tAverage Loss:  1.9401550903320313\t ACC train:  0.56\t ACC test:  0.5666666666666667\n",
      "\tEpoch 216: \tAverage Loss:  1.93665869140625\t ACC train:  0.5525\t ACC test:  0.56\n",
      "\tEpoch 217: \tAverage Loss:  1.9326640625\t ACC train:  0.56875\t ACC test:  0.58\n",
      "\tEpoch 218: \tAverage Loss:  1.9334622192382813\t ACC train:  0.5575\t ACC test:  0.5733333333333334\n",
      "\tEpoch 219: \tAverage Loss:  1.9375040893554687\t ACC train:  0.56375\t ACC test:  0.5688888888888889\n",
      "\tEpoch 220: \tAverage Loss:  1.9344891967773437\t ACC train:  0.54875\t ACC test:  0.5622222222222222\n",
      "\tEpoch 221: \tAverage Loss:  1.9330372314453126\t ACC train:  0.5525\t ACC test:  0.5622222222222222\n",
      "\tEpoch 222: \tAverage Loss:  1.9269752197265626\t ACC train:  0.555\t ACC test:  0.5711111111111111\n",
      "\tEpoch 223: \tAverage Loss:  1.92887939453125\t ACC train:  0.5625\t ACC test:  0.5733333333333334\n",
      "\tEpoch 224: \tAverage Loss:  1.928388671875\t ACC train:  0.5725\t ACC test:  0.5755555555555556\n",
      "\tEpoch 225: \tAverage Loss:  1.9266991577148438\t ACC train:  0.575\t ACC test:  0.5844444444444444\n",
      "\tEpoch 226: \tAverage Loss:  1.9251705322265624\t ACC train:  0.57125\t ACC test:  0.5777777777777777\n",
      "\tEpoch 227: \tAverage Loss:  1.9252759399414063\t ACC train:  0.5675\t ACC test:  0.5888888888888889\n",
      "\tEpoch 228: \tAverage Loss:  1.9250455932617188\t ACC train:  0.575\t ACC test:  0.5955555555555555\n",
      "\tEpoch 229: \tAverage Loss:  1.9270216064453125\t ACC train:  0.57375\t ACC test:  0.6044444444444445\n",
      "\tEpoch 230: \tAverage Loss:  1.9223607788085937\t ACC train:  0.59875\t ACC test:  0.6088888888888889\n",
      "\tEpoch 231: \tAverage Loss:  1.9223150024414062\t ACC train:  0.59\t ACC test:  0.58\n",
      "\tEpoch 232: \tAverage Loss:  1.91732177734375\t ACC train:  0.59\t ACC test:  0.6066666666666667\n",
      "\tEpoch 233: \tAverage Loss:  1.92184326171875\t ACC train:  0.6\t ACC test:  0.6155555555555555\n",
      "\tEpoch 234: \tAverage Loss:  1.9199281005859374\t ACC train:  0.605\t ACC test:  0.6044444444444445\n",
      "\tEpoch 235: \tAverage Loss:  1.9192549438476563\t ACC train:  0.61375\t ACC test:  0.6155555555555555\n",
      "\tEpoch 236: \tAverage Loss:  1.9107929077148438\t ACC train:  0.60625\t ACC test:  0.6266666666666667\n",
      "\tEpoch 237: \tAverage Loss:  1.9157310791015625\t ACC train:  0.625\t ACC test:  0.6266666666666667\n",
      "\tEpoch 238: \tAverage Loss:  1.9184352416992188\t ACC train:  0.6325\t ACC test:  0.6355555555555555\n",
      "\tEpoch 239: \tAverage Loss:  1.9182555541992188\t ACC train:  0.63875\t ACC test:  0.6377777777777778\n",
      "\tEpoch 240: \tAverage Loss:  1.9096180419921875\t ACC train:  0.64625\t ACC test:  0.6533333333333333\n",
      "\tEpoch 241: \tAverage Loss:  1.9099656372070313\t ACC train:  0.6175\t ACC test:  0.6466666666666666\n",
      "\tEpoch 242: \tAverage Loss:  1.9103251953125\t ACC train:  0.64\t ACC test:  0.6511111111111111\n",
      "\tEpoch 243: \tAverage Loss:  1.9103157348632813\t ACC train:  0.64375\t ACC test:  0.6244444444444445\n",
      "\tEpoch 244: \tAverage Loss:  1.913041015625\t ACC train:  0.66\t ACC test:  0.6488888888888888\n",
      "\tEpoch 245: \tAverage Loss:  1.9070591430664063\t ACC train:  0.645\t ACC test:  0.7066666666666667\n",
      "\tEpoch 246: \tAverage Loss:  1.9042306518554688\t ACC train:  0.645\t ACC test:  0.6688888888888889\n",
      "\tEpoch 247: \tAverage Loss:  1.907071044921875\t ACC train:  0.65875\t ACC test:  0.6644444444444444\n",
      "\tEpoch 248: \tAverage Loss:  1.9029126586914062\t ACC train:  0.6625\t ACC test:  0.6844444444444444\n",
      "\tEpoch 249: \tAverage Loss:  1.9021691284179687\t ACC train:  0.6525\t ACC test:  0.6711111111111111\n",
      "\tEpoch 250: \tAverage Loss:  1.90059619140625\t ACC train:  0.67\t ACC test:  0.6555555555555556\n",
      "\tEpoch 251: \tAverage Loss:  1.9038652954101563\t ACC train:  0.675\t ACC test:  0.6933333333333334\n",
      "\tEpoch 252: \tAverage Loss:  1.894687255859375\t ACC train:  0.68625\t ACC test:  0.6822222222222222\n",
      "\tEpoch 253: \tAverage Loss:  1.8954608764648437\t ACC train:  0.665\t ACC test:  0.6822222222222222\n",
      "\tEpoch 254: \tAverage Loss:  1.89188720703125\t ACC train:  0.69875\t ACC test:  0.6711111111111111\n",
      "\tEpoch 255: \tAverage Loss:  1.8903244018554688\t ACC train:  0.7075\t ACC test:  0.7244444444444444\n",
      "\tEpoch 256: \tAverage Loss:  1.8845365600585937\t ACC train:  0.6975\t ACC test:  0.7133333333333334\n",
      "\tEpoch 257: \tAverage Loss:  1.88760791015625\t ACC train:  0.70125\t ACC test:  0.7244444444444444\n",
      "\tEpoch 258: \tAverage Loss:  1.8808759765625\t ACC train:  0.71\t ACC test:  0.7266666666666667\n",
      "\tEpoch 259: \tAverage Loss:  1.8780136108398438\t ACC train:  0.7225\t ACC test:  0.7422222222222222\n",
      "\tEpoch 260: \tAverage Loss:  1.87943994140625\t ACC train:  0.72625\t ACC test:  0.7244444444444444\n",
      "\tEpoch 261: \tAverage Loss:  1.8781640014648437\t ACC train:  0.725\t ACC test:  0.7533333333333333\n",
      "\tEpoch 262: \tAverage Loss:  1.883401611328125\t ACC train:  0.74375\t ACC test:  0.7666666666666667\n",
      "\tEpoch 263: \tAverage Loss:  1.8698750610351562\t ACC train:  0.75375\t ACC test:  0.7711111111111111\n",
      "\tEpoch 264: \tAverage Loss:  1.8651661376953126\t ACC train:  0.7475\t ACC test:  0.7555555555555555\n",
      "\tEpoch 265: \tAverage Loss:  1.8717144165039064\t ACC train:  0.7625\t ACC test:  0.7777777777777778\n",
      "\tEpoch 266: \tAverage Loss:  1.8530722045898438\t ACC train:  0.7575\t ACC test:  0.7533333333333333\n",
      "\tEpoch 267: \tAverage Loss:  1.8680084228515625\t ACC train:  0.77875\t ACC test:  0.7688888888888888\n",
      "\tEpoch 268: \tAverage Loss:  1.8705482788085936\t ACC train:  0.79375\t ACC test:  0.78\n",
      "\tEpoch 269: \tAverage Loss:  1.8590340576171875\t ACC train:  0.77875\t ACC test:  0.8\n",
      "\tEpoch 270: \tAverage Loss:  1.8559017333984376\t ACC train:  0.7675\t ACC test:  0.8133333333333334\n",
      "\tEpoch 271: \tAverage Loss:  1.8512183837890626\t ACC train:  0.7925\t ACC test:  0.8177777777777778\n",
      "\tEpoch 272: \tAverage Loss:  1.848099365234375\t ACC train:  0.80375\t ACC test:  0.7933333333333333\n",
      "\tEpoch 273: \tAverage Loss:  1.8396109008789063\t ACC train:  0.8025\t ACC test:  0.8066666666666666\n",
      "\tEpoch 274: \tAverage Loss:  1.8380324096679688\t ACC train:  0.8175\t ACC test:  0.82\n",
      "\tEpoch 275: \tAverage Loss:  1.8302805786132812\t ACC train:  0.8125\t ACC test:  0.8288888888888889\n",
      "\tEpoch 276: \tAverage Loss:  1.8282200317382813\t ACC train:  0.8375\t ACC test:  0.8377777777777777\n",
      "\tEpoch 277: \tAverage Loss:  1.8209297485351563\t ACC train:  0.835\t ACC test:  0.8288888888888889\n",
      "\tEpoch 278: \tAverage Loss:  1.8299789428710938\t ACC train:  0.83\t ACC test:  0.8333333333333334\n",
      "\tEpoch 279: \tAverage Loss:  1.8283235473632813\t ACC train:  0.82125\t ACC test:  0.8444444444444444\n",
      "\tEpoch 280: \tAverage Loss:  1.8140101318359374\t ACC train:  0.8325\t ACC test:  0.8355555555555556\n",
      "\tEpoch 281: \tAverage Loss:  1.817801513671875\t ACC train:  0.84875\t ACC test:  0.8377777777777777\n",
      "\tEpoch 282: \tAverage Loss:  1.8079742431640624\t ACC train:  0.84125\t ACC test:  0.8511111111111112\n",
      "\tEpoch 283: \tAverage Loss:  1.8052874755859376\t ACC train:  0.87\t ACC test:  0.86\n",
      "\tEpoch 284: \tAverage Loss:  1.8014696044921874\t ACC train:  0.865\t ACC test:  0.86\n",
      "\tEpoch 285: \tAverage Loss:  1.8049794921875\t ACC train:  0.85875\t ACC test:  0.8777777777777778\n",
      "\tEpoch 286: \tAverage Loss:  1.7945482177734375\t ACC train:  0.88\t ACC test:  0.88\n",
      "\tEpoch 287: \tAverage Loss:  1.7902958984375\t ACC train:  0.86875\t ACC test:  0.8622222222222222\n",
      "\tEpoch 288: \tAverage Loss:  1.7821295776367188\t ACC train:  0.88875\t ACC test:  0.9\n",
      "\tEpoch 289: \tAverage Loss:  1.780334228515625\t ACC train:  0.88\t ACC test:  0.8688888888888889\n",
      "\tEpoch 290: \tAverage Loss:  1.7805886840820313\t ACC train:  0.885\t ACC test:  0.8933333333333333\n",
      "\tEpoch 291: \tAverage Loss:  1.7788193969726562\t ACC train:  0.895\t ACC test:  0.9022222222222223\n",
      "\tEpoch 292: \tAverage Loss:  1.7719676513671876\t ACC train:  0.8925\t ACC test:  0.8911111111111111\n",
      "\tEpoch 293: \tAverage Loss:  1.7663219604492189\t ACC train:  0.9025\t ACC test:  0.9066666666666666\n",
      "\tEpoch 294: \tAverage Loss:  1.7683104248046875\t ACC train:  0.8975\t ACC test:  0.9133333333333333\n",
      "\tEpoch 295: \tAverage Loss:  1.7686054077148436\t ACC train:  0.91625\t ACC test:  0.9133333333333333\n",
      "\tEpoch 296: \tAverage Loss:  1.76292529296875\t ACC train:  0.9225\t ACC test:  0.9155555555555556\n",
      "\tEpoch 297: \tAverage Loss:  1.7604343872070312\t ACC train:  0.91\t ACC test:  0.9177777777777778\n",
      "\tEpoch 298: \tAverage Loss:  1.755980712890625\t ACC train:  0.91125\t ACC test:  0.9044444444444445\n",
      "\tEpoch 299: \tAverage Loss:  1.7526532592773438\t ACC train:  0.9175\t ACC test:  0.92\n",
      "\tEpoch 300: \tAverage Loss:  1.749895751953125\t ACC train:  0.93375\t ACC test:  0.9266666666666666\n",
      "\tEpoch 301: \tAverage Loss:  1.745377197265625\t ACC train:  0.92375\t ACC test:  0.9222222222222223\n",
      "\tEpoch 302: \tAverage Loss:  1.7437826538085937\t ACC train:  0.915\t ACC test:  0.9355555555555556\n",
      "\tEpoch 303: \tAverage Loss:  1.748019775390625\t ACC train:  0.935\t ACC test:  0.9355555555555556\n",
      "\tEpoch 304: \tAverage Loss:  1.7421529541015626\t ACC train:  0.93625\t ACC test:  0.9466666666666667\n",
      "\tEpoch 305: \tAverage Loss:  1.7387678833007814\t ACC train:  0.93375\t ACC test:  0.9422222222222222\n",
      "\tEpoch 306: \tAverage Loss:  1.740569091796875\t ACC train:  0.94\t ACC test:  0.94\n",
      "\tEpoch 307: \tAverage Loss:  1.7348790283203126\t ACC train:  0.94625\t ACC test:  0.94\n",
      "\tEpoch 308: \tAverage Loss:  1.7333239135742187\t ACC train:  0.94875\t ACC test:  0.9466666666666667\n",
      "\tEpoch 309: \tAverage Loss:  1.7275650634765625\t ACC train:  0.95375\t ACC test:  0.9422222222222222\n",
      "\tEpoch 310: \tAverage Loss:  1.7296122436523438\t ACC train:  0.9575\t ACC test:  0.9555555555555556\n",
      "\tEpoch 311: \tAverage Loss:  1.7239761962890625\t ACC train:  0.96125\t ACC test:  0.9577777777777777\n",
      "\tEpoch 312: \tAverage Loss:  1.7224635009765625\t ACC train:  0.96\t ACC test:  0.96\n",
      "\tEpoch 313: \tAverage Loss:  1.7150069580078124\t ACC train:  0.9625\t ACC test:  0.9644444444444444\n",
      "\tEpoch 314: \tAverage Loss:  1.7135442504882812\t ACC train:  0.97\t ACC test:  0.9666666666666667\n",
      "\tEpoch 315: \tAverage Loss:  1.7103001098632813\t ACC train:  0.97125\t ACC test:  0.9644444444444444\n",
      "\tEpoch 316: \tAverage Loss:  1.7137120361328124\t ACC train:  0.9675\t ACC test:  0.9555555555555556\n",
      "\tEpoch 317: \tAverage Loss:  1.711279052734375\t ACC train:  0.97875\t ACC test:  0.9711111111111111\n",
      "\tEpoch 318: \tAverage Loss:  1.7080586547851562\t ACC train:  0.97\t ACC test:  0.9644444444444444\n",
      "\tEpoch 319: \tAverage Loss:  1.7076871948242187\t ACC train:  0.97\t ACC test:  0.9711111111111111\n",
      "\tEpoch 320: \tAverage Loss:  1.7055986328125\t ACC train:  0.9725\t ACC test:  0.9688888888888889\n",
      "\tEpoch 321: \tAverage Loss:  1.7059637451171874\t ACC train:  0.9725\t ACC test:  0.9711111111111111\n",
      "\tEpoch 322: \tAverage Loss:  1.7004267578125\t ACC train:  0.97\t ACC test:  0.9711111111111111\n",
      "\tEpoch 323: \tAverage Loss:  1.7000802612304688\t ACC train:  0.97625\t ACC test:  0.9711111111111111\n",
      "\tEpoch 324: \tAverage Loss:  1.6985217895507811\t ACC train:  0.9825\t ACC test:  0.9733333333333334\n",
      "\tEpoch 325: \tAverage Loss:  1.696259033203125\t ACC train:  0.9825\t ACC test:  0.98\n",
      "\tEpoch 326: \tAverage Loss:  1.6953671875\t ACC train:  0.98375\t ACC test:  0.9711111111111111\n",
      "\tEpoch 327: \tAverage Loss:  1.6943128051757812\t ACC train:  0.98375\t ACC test:  0.98\n",
      "\tEpoch 328: \tAverage Loss:  1.6932034912109375\t ACC train:  0.98125\t ACC test:  0.9822222222222222\n",
      "\tEpoch 329: \tAverage Loss:  1.6908445434570312\t ACC train:  0.98875\t ACC test:  0.9777777777777777\n",
      "\tEpoch 330: \tAverage Loss:  1.6876239624023437\t ACC train:  0.9875\t ACC test:  0.9777777777777777\n",
      "\tEpoch 331: \tAverage Loss:  1.6882279663085937\t ACC train:  0.9875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 332: \tAverage Loss:  1.6904295654296875\t ACC train:  0.98375\t ACC test:  0.98\n",
      "\tEpoch 333: \tAverage Loss:  1.6851640625\t ACC train:  0.99125\t ACC test:  0.98\n",
      "\tEpoch 334: \tAverage Loss:  1.6847971801757813\t ACC train:  0.98875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 335: \tAverage Loss:  1.6851658325195313\t ACC train:  0.9925\t ACC test:  0.98\n",
      "\tEpoch 336: \tAverage Loss:  1.682345703125\t ACC train:  0.9925\t ACC test:  0.9777777777777777\n",
      "\tEpoch 337: \tAverage Loss:  1.682088623046875\t ACC train:  0.99125\t ACC test:  0.9844444444444445\n",
      "\tEpoch 338: \tAverage Loss:  1.6825120239257811\t ACC train:  0.995\t ACC test:  0.9844444444444445\n",
      "\tEpoch 339: \tAverage Loss:  1.6798560791015624\t ACC train:  0.9925\t ACC test:  0.9844444444444445\n",
      "\tEpoch 340: \tAverage Loss:  1.6774772338867188\t ACC train:  0.99125\t ACC test:  0.9866666666666667\n",
      "\tEpoch 341: \tAverage Loss:  1.6801915283203126\t ACC train:  0.99625\t ACC test:  0.9844444444444445\n",
      "\tEpoch 342: \tAverage Loss:  1.6778197631835938\t ACC train:  0.9925\t ACC test:  0.9822222222222222\n",
      "\tEpoch 343: \tAverage Loss:  1.6757867431640625\t ACC train:  0.99125\t ACC test:  0.9844444444444445\n",
      "\tEpoch 344: \tAverage Loss:  1.6748060302734376\t ACC train:  0.99375\t ACC test:  0.9822222222222222\n",
      "\tEpoch 345: \tAverage Loss:  1.6745205688476563\t ACC train:  0.9975\t ACC test:  0.9866666666666667\n",
      "\tEpoch 346: \tAverage Loss:  1.6728447875976562\t ACC train:  0.99625\t ACC test:  0.9844444444444445\n",
      "\tEpoch 347: \tAverage Loss:  1.6745526733398437\t ACC train:  0.99625\t ACC test:  0.9844444444444445\n",
      "\tEpoch 348: \tAverage Loss:  1.6711915893554687\t ACC train:  0.99875\t ACC test:  0.9866666666666667\n",
      "\tEpoch 349: \tAverage Loss:  1.6711168212890626\t ACC train:  0.9975\t ACC test:  0.9888888888888889\n",
      "\tEpoch 350: \tAverage Loss:  1.6696060180664063\t ACC train:  0.9975\t ACC test:  0.9911111111111112\n",
      "\tEpoch 351: \tAverage Loss:  1.6697332763671875\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 352: \tAverage Loss:  1.6677667846679687\t ACC train:  0.995\t ACC test:  0.9911111111111112\n",
      "\tEpoch 353: \tAverage Loss:  1.6663341064453125\t ACC train:  0.99875\t ACC test:  0.9888888888888889\n",
      "\tEpoch 354: \tAverage Loss:  1.666138427734375\t ACC train:  0.99625\t ACC test:  0.9844444444444445\n",
      "\tEpoch 355: \tAverage Loss:  1.6671622924804688\t ACC train:  0.99875\t ACC test:  0.9866666666666667\n",
      "\tEpoch 356: \tAverage Loss:  1.6661707763671876\t ACC train:  0.995\t ACC test:  0.9933333333333333\n",
      "\tEpoch 357: \tAverage Loss:  1.6665079956054687\t ACC train:  0.99875\t ACC test:  0.9911111111111112\n",
      "\tEpoch 358: \tAverage Loss:  1.6644110107421874\t ACC train:  0.99625\t ACC test:  0.9822222222222222\n",
      "\tEpoch 359: \tAverage Loss:  1.6653154907226562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 360: \tAverage Loss:  1.6627158813476564\t ACC train:  0.99875\t ACC test:  0.9888888888888889\n",
      "\tEpoch 361: \tAverage Loss:  1.660870849609375\t ACC train:  0.99875\t ACC test:  0.9888888888888889\n",
      "\tEpoch 362: \tAverage Loss:  1.662279296875\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 363: \tAverage Loss:  1.662603759765625\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 364: \tAverage Loss:  1.66165087890625\t ACC train:  0.99875\t ACC test:  0.9888888888888889\n",
      "\tEpoch 365: \tAverage Loss:  1.6617254028320312\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 366: \tAverage Loss:  1.6594143676757813\t ACC train:  0.99875\t ACC test:  0.9933333333333333\n",
      "\tEpoch 367: \tAverage Loss:  1.659638671875\t ACC train:  0.99875\t ACC test:  0.9911111111111112\n",
      "\tEpoch 368: \tAverage Loss:  1.6593998413085937\t ACC train:  0.99875\t ACC test:  0.9911111111111112\n",
      "\tEpoch 369: \tAverage Loss:  1.6588836059570313\t ACC train:  0.99875\t ACC test:  0.9955555555555555\n",
      "\tEpoch 370: \tAverage Loss:  1.6578170166015624\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 371: \tAverage Loss:  1.6593648681640625\t ACC train:  0.99875\t ACC test:  0.9888888888888889\n",
      "\tEpoch 372: \tAverage Loss:  1.6575391235351562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 373: \tAverage Loss:  1.6556641235351564\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 374: \tAverage Loss:  1.6561689453125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 375: \tAverage Loss:  1.65590283203125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 376: \tAverage Loss:  1.6556682739257813\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 377: \tAverage Loss:  1.6543119506835937\t ACC train:  0.99875\t ACC test:  0.9933333333333333\n",
      "\tEpoch 378: \tAverage Loss:  1.6544130859375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 379: \tAverage Loss:  1.6530101928710939\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 380: \tAverage Loss:  1.6537262573242189\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 381: \tAverage Loss:  1.6530109252929688\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 382: \tAverage Loss:  1.6523607788085937\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 383: \tAverage Loss:  1.6521460571289062\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 384: \tAverage Loss:  1.6507222290039063\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 385: \tAverage Loss:  1.651318359375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 386: \tAverage Loss:  1.6489984741210937\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 387: \tAverage Loss:  1.6492279663085938\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 388: \tAverage Loss:  1.6500910034179688\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 389: \tAverage Loss:  1.6481275634765624\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 390: \tAverage Loss:  1.6478890991210937\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 391: \tAverage Loss:  1.6481365356445312\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 392: \tAverage Loss:  1.646878173828125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 393: \tAverage Loss:  1.6477482299804687\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 394: \tAverage Loss:  1.64726611328125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 395: \tAverage Loss:  1.64695654296875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 396: \tAverage Loss:  1.6458775024414063\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 397: \tAverage Loss:  1.6455571899414063\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 398: \tAverage Loss:  1.6459058837890626\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 399: \tAverage Loss:  1.6442182006835937\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 400: \tAverage Loss:  1.6450781860351562\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 401: \tAverage Loss:  1.6432882690429687\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 402: \tAverage Loss:  1.6440454711914063\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 403: \tAverage Loss:  1.6431730346679687\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 404: \tAverage Loss:  1.6421787109375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 405: \tAverage Loss:  1.642657958984375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 406: \tAverage Loss:  1.6419013671875\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 407: \tAverage Loss:  1.6415809326171875\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 408: \tAverage Loss:  1.6418635864257813\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 409: \tAverage Loss:  1.6400709228515624\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 410: \tAverage Loss:  1.6407478637695312\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 411: \tAverage Loss:  1.6413982543945314\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 412: \tAverage Loss:  1.6396123657226562\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 413: \tAverage Loss:  1.6390975341796874\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 414: \tAverage Loss:  1.6387744140625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 415: \tAverage Loss:  1.6386480712890625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 416: \tAverage Loss:  1.6382208251953125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 417: \tAverage Loss:  1.6383905639648437\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 418: \tAverage Loss:  1.6376806640625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 419: \tAverage Loss:  1.63699755859375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 420: \tAverage Loss:  1.6370745239257813\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 421: \tAverage Loss:  1.6366915893554688\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 422: \tAverage Loss:  1.6372660522460938\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 423: \tAverage Loss:  1.636587158203125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 424: \tAverage Loss:  1.6358502197265625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 425: \tAverage Loss:  1.6349873657226563\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 426: \tAverage Loss:  1.6353645629882811\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 427: \tAverage Loss:  1.6343153686523437\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 428: \tAverage Loss:  1.6341447143554688\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 429: \tAverage Loss:  1.6342330322265626\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 430: \tAverage Loss:  1.6333526611328124\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 431: \tAverage Loss:  1.6336207885742187\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 432: \tAverage Loss:  1.6333548583984374\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 433: \tAverage Loss:  1.6318948364257813\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 434: \tAverage Loss:  1.6321724243164062\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 435: \tAverage Loss:  1.6314874267578126\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 436: \tAverage Loss:  1.6309806518554688\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 437: \tAverage Loss:  1.6308612060546874\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 438: \tAverage Loss:  1.631227294921875\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 439: \tAverage Loss:  1.6298726196289062\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 440: \tAverage Loss:  1.62977001953125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 441: \tAverage Loss:  1.6299696044921874\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 442: \tAverage Loss:  1.6290769653320312\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 443: \tAverage Loss:  1.628820556640625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 444: \tAverage Loss:  1.6276934814453126\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 445: \tAverage Loss:  1.6279265747070313\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 446: \tAverage Loss:  1.6278485717773437\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 447: \tAverage Loss:  1.6273611450195313\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 448: \tAverage Loss:  1.626516845703125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 449: \tAverage Loss:  1.6255332641601563\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 450: \tAverage Loss:  1.625964599609375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 451: \tAverage Loss:  1.6252542724609376\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 452: \tAverage Loss:  1.6257686767578126\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 453: \tAverage Loss:  1.625003173828125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 454: \tAverage Loss:  1.6234871826171875\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 455: \tAverage Loss:  1.623941162109375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 456: \tAverage Loss:  1.6228740844726564\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 457: \tAverage Loss:  1.6222695922851562\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 458: \tAverage Loss:  1.6229465942382812\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 459: \tAverage Loss:  1.6217178955078124\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 460: \tAverage Loss:  1.6209730834960938\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 461: \tAverage Loss:  1.6208140258789063\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 462: \tAverage Loss:  1.6207669677734375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 463: \tAverage Loss:  1.6193065795898438\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 464: \tAverage Loss:  1.6189645385742188\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 465: \tAverage Loss:  1.6186380615234375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 466: \tAverage Loss:  1.6188595581054688\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 467: \tAverage Loss:  1.6174630126953125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 468: \tAverage Loss:  1.617452392578125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 469: \tAverage Loss:  1.6162483520507813\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 470: \tAverage Loss:  1.6154509887695312\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 471: \tAverage Loss:  1.6151649169921876\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 472: \tAverage Loss:  1.614807861328125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 473: \tAverage Loss:  1.6138435668945312\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 474: \tAverage Loss:  1.6127070922851563\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 475: \tAverage Loss:  1.6123790283203125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 476: \tAverage Loss:  1.6118364868164063\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 477: \tAverage Loss:  1.6111536865234375\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 478: \tAverage Loss:  1.6106416625976563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 479: \tAverage Loss:  1.6091134643554688\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 480: \tAverage Loss:  1.6086657104492188\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 481: \tAverage Loss:  1.60753662109375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 482: \tAverage Loss:  1.6070987548828124\t ACC train:  0.99875\t ACC test:  0.9866666666666667\n",
      "\tEpoch 483: \tAverage Loss:  1.6061656494140626\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 484: \tAverage Loss:  1.6043997802734375\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 485: \tAverage Loss:  1.603680908203125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 486: \tAverage Loss:  1.6028211059570312\t ACC train:  0.99875\t ACC test:  0.9866666666666667\n",
      "\tEpoch 487: \tAverage Loss:  1.6015496826171876\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 488: \tAverage Loss:  1.6014114990234376\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 489: \tAverage Loss:  1.5995255126953125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 490: \tAverage Loss:  1.5981258544921875\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 491: \tAverage Loss:  1.59672998046875\t ACC train:  0.99875\t ACC test:  0.9866666666666667\n",
      "\tEpoch 492: \tAverage Loss:  1.5957477416992187\t ACC train:  0.99875\t ACC test:  0.9866666666666667\n",
      "\tEpoch 493: \tAverage Loss:  1.5941270751953125\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 494: \tAverage Loss:  1.5931648559570313\t ACC train:  0.99875\t ACC test:  0.9866666666666667\n",
      "\tEpoch 495: \tAverage Loss:  1.5899195556640624\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 496: \tAverage Loss:  1.5884984130859374\t ACC train:  0.99875\t ACC test:  0.98\n",
      "\tEpoch 497: \tAverage Loss:  1.5866868896484374\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 498: \tAverage Loss:  1.5851784057617186\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 499: \tAverage Loss:  1.5826984252929688\t ACC train:  0.99875\t ACC test:  0.9777777777777777\n",
      "\tEpoch 500: \tAverage Loss:  1.5800081176757812\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 501: \tAverage Loss:  1.5791714477539063\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 502: \tAverage Loss:  1.5770624389648438\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 503: \tAverage Loss:  1.5728562622070312\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 504: \tAverage Loss:  1.5699225463867188\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 505: \tAverage Loss:  1.570535400390625\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 506: \tAverage Loss:  1.5655911865234375\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 507: \tAverage Loss:  1.56281005859375\t ACC train:  0.995\t ACC test:  0.9777777777777777\n",
      "\tEpoch 508: \tAverage Loss:  1.5607354125976562\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 509: \tAverage Loss:  1.5571170654296875\t ACC train:  0.995\t ACC test:  0.9777777777777777\n",
      "\tEpoch 510: \tAverage Loss:  1.5541438598632813\t ACC train:  0.99375\t ACC test:  0.9733333333333334\n",
      "\tEpoch 511: \tAverage Loss:  1.5522879638671876\t ACC train:  0.9925\t ACC test:  0.9777777777777777\n",
      "\tEpoch 512: \tAverage Loss:  1.549564697265625\t ACC train:  0.99375\t ACC test:  0.9755555555555555\n",
      "\tEpoch 513: \tAverage Loss:  1.5448909301757812\t ACC train:  0.9925\t ACC test:  0.9755555555555555\n",
      "\tEpoch 514: \tAverage Loss:  1.541899658203125\t ACC train:  0.99375\t ACC test:  0.9755555555555555\n",
      "\tEpoch 515: \tAverage Loss:  1.53810009765625\t ACC train:  0.9925\t ACC test:  0.9755555555555555\n",
      "\tEpoch 516: \tAverage Loss:  1.5361370849609375\t ACC train:  0.9925\t ACC test:  0.9733333333333334\n",
      "\tEpoch 517: \tAverage Loss:  1.5323311157226562\t ACC train:  0.9925\t ACC test:  0.9711111111111111\n",
      "\tEpoch 518: \tAverage Loss:  1.5283804931640625\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 519: \tAverage Loss:  1.523296630859375\t ACC train:  0.99\t ACC test:  0.9755555555555555\n",
      "\tEpoch 520: \tAverage Loss:  1.5202710571289062\t ACC train:  0.99125\t ACC test:  0.9711111111111111\n",
      "\tEpoch 521: \tAverage Loss:  1.5160955810546874\t ACC train:  0.99\t ACC test:  0.9711111111111111\n",
      "\tEpoch 522: \tAverage Loss:  1.5110950317382812\t ACC train:  0.9875\t ACC test:  0.9733333333333334\n",
      "\tEpoch 523: \tAverage Loss:  1.5078882446289064\t ACC train:  0.98875\t ACC test:  0.9688888888888889\n",
      "\tEpoch 524: \tAverage Loss:  1.5040291137695312\t ACC train:  0.98875\t ACC test:  0.9733333333333334\n",
      "\tEpoch 525: \tAverage Loss:  1.4988160400390624\t ACC train:  0.99125\t ACC test:  0.9666666666666667\n",
      "\tEpoch 526: \tAverage Loss:  1.49544580078125\t ACC train:  0.985\t ACC test:  0.9733333333333334\n",
      "\tEpoch 527: \tAverage Loss:  1.4930012817382812\t ACC train:  0.98625\t ACC test:  0.9688888888888889\n",
      "\tEpoch 528: \tAverage Loss:  1.4882081298828125\t ACC train:  0.99125\t ACC test:  0.9666666666666667\n",
      "\tEpoch 529: \tAverage Loss:  1.4845274658203125\t ACC train:  0.9875\t ACC test:  0.9688888888888889\n",
      "\tEpoch 530: \tAverage Loss:  1.4796172485351562\t ACC train:  0.98875\t ACC test:  0.9688888888888889\n",
      "\tEpoch 531: \tAverage Loss:  1.4769085083007814\t ACC train:  0.9875\t ACC test:  0.9733333333333334\n",
      "\tEpoch 532: \tAverage Loss:  1.4734483032226562\t ACC train:  0.9925\t ACC test:  0.9688888888888889\n",
      "\tEpoch 533: \tAverage Loss:  1.4696187744140625\t ACC train:  0.99\t ACC test:  0.9688888888888889\n",
      "\tEpoch 534: \tAverage Loss:  1.4655897216796876\t ACC train:  0.99125\t ACC test:  0.9711111111111111\n",
      "\tEpoch 535: \tAverage Loss:  1.4627013549804688\t ACC train:  0.98875\t ACC test:  0.9688888888888889\n",
      "\tEpoch 536: \tAverage Loss:  1.4606978759765625\t ACC train:  0.9925\t ACC test:  0.9711111111111111\n",
      "\tEpoch 537: \tAverage Loss:  1.4575010986328125\t ACC train:  0.99125\t ACC test:  0.9688888888888889\n",
      "\tEpoch 538: \tAverage Loss:  1.4547887573242186\t ACC train:  0.99125\t ACC test:  0.9711111111111111\n",
      "\tEpoch 539: \tAverage Loss:  1.4522662963867188\t ACC train:  0.99\t ACC test:  0.9733333333333334\n",
      "\tEpoch 540: \tAverage Loss:  1.4502098388671876\t ACC train:  0.99125\t ACC test:  0.9666666666666667\n",
      "\tEpoch 541: \tAverage Loss:  1.4471363525390626\t ACC train:  0.99375\t ACC test:  0.9711111111111111\n",
      "\tEpoch 542: \tAverage Loss:  1.44440576171875\t ACC train:  0.99125\t ACC test:  0.9755555555555555\n",
      "\tEpoch 543: \tAverage Loss:  1.442944580078125\t ACC train:  0.99375\t ACC test:  0.9733333333333334\n",
      "\tEpoch 544: \tAverage Loss:  1.4404369506835937\t ACC train:  0.9925\t ACC test:  0.9711111111111111\n",
      "\tEpoch 545: \tAverage Loss:  1.43818115234375\t ACC train:  0.9925\t ACC test:  0.9711111111111111\n",
      "\tEpoch 546: \tAverage Loss:  1.435540771484375\t ACC train:  0.99125\t ACC test:  0.9777777777777777\n",
      "\tEpoch 547: \tAverage Loss:  1.434802734375\t ACC train:  0.99125\t ACC test:  0.9755555555555555\n",
      "\tEpoch 548: \tAverage Loss:  1.432395263671875\t ACC train:  0.995\t ACC test:  0.9688888888888889\n",
      "\tEpoch 549: \tAverage Loss:  1.430526611328125\t ACC train:  0.995\t ACC test:  0.9711111111111111\n",
      "\tEpoch 550: \tAverage Loss:  1.4290111694335939\t ACC train:  0.99375\t ACC test:  0.9733333333333334\n",
      "\tEpoch 551: \tAverage Loss:  1.4271873168945313\t ACC train:  0.9925\t ACC test:  0.9755555555555555\n",
      "\tEpoch 552: \tAverage Loss:  1.4262510375976563\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 553: \tAverage Loss:  1.4249537963867187\t ACC train:  0.995\t ACC test:  0.9733333333333334\n",
      "\tEpoch 554: \tAverage Loss:  1.422657989501953\t ACC train:  0.9925\t ACC test:  0.9733333333333334\n",
      "\tEpoch 555: \tAverage Loss:  1.4213085327148438\t ACC train:  0.995\t ACC test:  0.9711111111111111\n",
      "\tEpoch 556: \tAverage Loss:  1.4203348999023437\t ACC train:  0.995\t ACC test:  0.9711111111111111\n",
      "\tEpoch 557: \tAverage Loss:  1.4186231689453126\t ACC train:  0.99375\t ACC test:  0.9733333333333334\n",
      "\tEpoch 558: \tAverage Loss:  1.4177233276367187\t ACC train:  0.99375\t ACC test:  0.9733333333333334\n",
      "\tEpoch 559: \tAverage Loss:  1.4170773315429688\t ACC train:  0.995\t ACC test:  0.9733333333333334\n",
      "\tEpoch 560: \tAverage Loss:  1.4149613647460937\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 561: \tAverage Loss:  1.4141317749023437\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 562: \tAverage Loss:  1.4127674560546875\t ACC train:  0.995\t ACC test:  0.9711111111111111\n",
      "\tEpoch 563: \tAverage Loss:  1.4117195434570313\t ACC train:  0.995\t ACC test:  0.9733333333333334\n",
      "\tEpoch 564: \tAverage Loss:  1.4106968383789062\t ACC train:  0.99375\t ACC test:  0.9777777777777777\n",
      "\tEpoch 565: \tAverage Loss:  1.4098612060546876\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 566: \tAverage Loss:  1.4091724853515626\t ACC train:  0.995\t ACC test:  0.9711111111111111\n",
      "\tEpoch 567: \tAverage Loss:  1.4080169372558593\t ACC train:  0.9925\t ACC test:  0.9777777777777777\n",
      "\tEpoch 568: \tAverage Loss:  1.407835693359375\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 569: \tAverage Loss:  1.4054993286132813\t ACC train:  0.995\t ACC test:  0.9711111111111111\n",
      "\tEpoch 570: \tAverage Loss:  1.4054066772460938\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 571: \tAverage Loss:  1.4038968505859375\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 572: \tAverage Loss:  1.40341162109375\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 573: \tAverage Loss:  1.4026351928710938\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 574: \tAverage Loss:  1.4020897827148437\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 575: \tAverage Loss:  1.4009783325195313\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 576: \tAverage Loss:  1.4001812133789062\t ACC train:  0.99625\t ACC test:  0.9711111111111111\n",
      "\tEpoch 577: \tAverage Loss:  1.3990557250976563\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 578: \tAverage Loss:  1.39895263671875\t ACC train:  0.995\t ACC test:  0.9755555555555555\n",
      "\tEpoch 579: \tAverage Loss:  1.3977086181640626\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 580: \tAverage Loss:  1.397419677734375\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 581: \tAverage Loss:  1.39633154296875\t ACC train:  0.99375\t ACC test:  0.9755555555555555\n",
      "\tEpoch 582: \tAverage Loss:  1.395953125\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 583: \tAverage Loss:  1.394922119140625\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 584: \tAverage Loss:  1.3939003295898438\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 585: \tAverage Loss:  1.3934120483398438\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 586: \tAverage Loss:  1.39280859375\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 587: \tAverage Loss:  1.3919022216796875\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 588: \tAverage Loss:  1.3912660522460938\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 589: \tAverage Loss:  1.3902061767578124\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 590: \tAverage Loss:  1.3897591552734374\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 591: \tAverage Loss:  1.38906298828125\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 592: \tAverage Loss:  1.3877682495117187\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 593: \tAverage Loss:  1.38750634765625\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 594: \tAverage Loss:  1.386947021484375\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 595: \tAverage Loss:  1.385941162109375\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 596: \tAverage Loss:  1.38533984375\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 597: \tAverage Loss:  1.3847294311523437\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 598: \tAverage Loss:  1.3843211669921875\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 599: \tAverage Loss:  1.3836741333007812\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 600: \tAverage Loss:  1.38306396484375\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 601: \tAverage Loss:  1.382307373046875\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 602: \tAverage Loss:  1.3817844848632812\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 603: \tAverage Loss:  1.381326171875\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 604: \tAverage Loss:  1.3806556396484375\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 605: \tAverage Loss:  1.3801146240234374\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 606: \tAverage Loss:  1.3796930236816407\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 607: \tAverage Loss:  1.37904345703125\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 608: \tAverage Loss:  1.3785523681640626\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 609: \tAverage Loss:  1.3781776123046876\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 610: \tAverage Loss:  1.3775022583007812\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 611: \tAverage Loss:  1.377179443359375\t ACC train:  0.99625\t ACC test:  0.9733333333333334\n",
      "\tEpoch 612: \tAverage Loss:  1.376776611328125\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 613: \tAverage Loss:  1.3764476318359375\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 614: \tAverage Loss:  1.3754915771484375\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 615: \tAverage Loss:  1.37521240234375\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 616: \tAverage Loss:  1.3745855712890624\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 617: \tAverage Loss:  1.374306640625\t ACC train:  0.9975\t ACC test:  0.9733333333333334\n",
      "\tEpoch 618: \tAverage Loss:  1.3738046875\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 619: \tAverage Loss:  1.373185546875\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 620: \tAverage Loss:  1.3729224243164062\t ACC train:  0.9975\t ACC test:  0.9733333333333334\n",
      "\tEpoch 621: \tAverage Loss:  1.3723724365234375\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 622: \tAverage Loss:  1.3719092407226563\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 623: \tAverage Loss:  1.3715695190429686\t ACC train:  0.9975\t ACC test:  0.9733333333333334\n",
      "\tEpoch 624: \tAverage Loss:  1.37111328125\t ACC train:  0.99625\t ACC test:  0.9755555555555555\n",
      "\tEpoch 625: \tAverage Loss:  1.370683349609375\t ACC train:  0.9975\t ACC test:  0.9733333333333334\n",
      "\tEpoch 626: \tAverage Loss:  1.3701603088378906\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 627: \tAverage Loss:  1.3698904418945312\t ACC train:  0.99625\t ACC test:  0.9777777777777777\n",
      "\tEpoch 628: \tAverage Loss:  1.369469970703125\t ACC train:  0.9975\t ACC test:  0.9733333333333334\n",
      "\tEpoch 629: \tAverage Loss:  1.3689408569335937\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 630: \tAverage Loss:  1.368525390625\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 631: \tAverage Loss:  1.3681856689453125\t ACC train:  0.9975\t ACC test:  0.9733333333333334\n",
      "\tEpoch 632: \tAverage Loss:  1.3677953186035157\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 633: \tAverage Loss:  1.3672614135742187\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 634: \tAverage Loss:  1.3671346435546874\t ACC train:  0.9975\t ACC test:  0.9733333333333334\n",
      "\tEpoch 635: \tAverage Loss:  1.366569305419922\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 636: \tAverage Loss:  1.3662216186523437\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 637: \tAverage Loss:  1.36575390625\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 638: \tAverage Loss:  1.3654156494140626\t ACC train:  0.9975\t ACC test:  0.9733333333333334\n",
      "\tEpoch 639: \tAverage Loss:  1.3650578002929687\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 640: \tAverage Loss:  1.3646751708984375\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 641: \tAverage Loss:  1.3645270080566407\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 642: \tAverage Loss:  1.3640050048828125\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 643: \tAverage Loss:  1.3638675842285157\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 644: \tAverage Loss:  1.3634862670898438\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 645: \tAverage Loss:  1.36324853515625\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 646: \tAverage Loss:  1.363102813720703\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 647: \tAverage Loss:  1.3626436462402345\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 648: \tAverage Loss:  1.3627488098144531\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 649: \tAverage Loss:  1.3626737670898437\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 650: \tAverage Loss:  1.3622911376953124\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 651: \tAverage Loss:  1.361958953857422\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 652: \tAverage Loss:  1.3615709838867187\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 653: \tAverage Loss:  1.3615877075195313\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 654: \tAverage Loss:  1.36123583984375\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 655: \tAverage Loss:  1.360769287109375\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 656: \tAverage Loss:  1.3604544067382813\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 657: \tAverage Loss:  1.3603716430664063\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 658: \tAverage Loss:  1.3601287841796874\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 659: \tAverage Loss:  1.3597633666992188\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 660: \tAverage Loss:  1.3594308166503906\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 661: \tAverage Loss:  1.3593756713867187\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 662: \tAverage Loss:  1.3590578002929687\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 663: \tAverage Loss:  1.3588094482421875\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 664: \tAverage Loss:  1.3586073608398437\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 665: \tAverage Loss:  1.3584939270019531\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 666: \tAverage Loss:  1.35819482421875\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 667: \tAverage Loss:  1.3582154541015625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 668: \tAverage Loss:  1.3580389404296875\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 669: \tAverage Loss:  1.3578599243164062\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 670: \tAverage Loss:  1.3576654052734376\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 671: \tAverage Loss:  1.3574366149902344\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 672: \tAverage Loss:  1.3572132568359374\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 673: \tAverage Loss:  1.3571021118164062\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 674: \tAverage Loss:  1.3570806579589845\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 675: \tAverage Loss:  1.3567112426757812\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 676: \tAverage Loss:  1.3567947387695312\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 677: \tAverage Loss:  1.3566905517578125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 678: \tAverage Loss:  1.3567030639648439\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 679: \tAverage Loss:  1.356712646484375\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 680: \tAverage Loss:  1.3567742309570312\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 681: \tAverage Loss:  1.3569278564453124\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 682: \tAverage Loss:  1.3573722534179689\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 683: \tAverage Loss:  1.3571409301757813\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 684: \tAverage Loss:  1.3567702026367188\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 685: \tAverage Loss:  1.3565890502929687\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 686: \tAverage Loss:  1.3556985473632812\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 687: \tAverage Loss:  1.3549534606933593\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 688: \tAverage Loss:  1.3548084106445313\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 689: \tAverage Loss:  1.3547220153808595\t ACC train:  0.9975\t ACC test:  0.9755555555555555\n",
      "\tEpoch 690: \tAverage Loss:  1.35464794921875\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 691: \tAverage Loss:  1.354551025390625\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 692: \tAverage Loss:  1.354348876953125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 693: \tAverage Loss:  1.3540996704101562\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 694: \tAverage Loss:  1.3538113708496093\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 695: \tAverage Loss:  1.3536407775878907\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 696: \tAverage Loss:  1.35352880859375\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 697: \tAverage Loss:  1.3534359130859375\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 698: \tAverage Loss:  1.3534075927734375\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 699: \tAverage Loss:  1.3532774658203126\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 700: \tAverage Loss:  1.3531544189453124\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 701: \tAverage Loss:  1.3528887023925782\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 702: \tAverage Loss:  1.353079345703125\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 703: \tAverage Loss:  1.3527139282226563\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 704: \tAverage Loss:  1.3526954956054686\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 705: \tAverage Loss:  1.352577392578125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 706: \tAverage Loss:  1.35230712890625\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 707: \tAverage Loss:  1.3522097473144532\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 708: \tAverage Loss:  1.3522262573242188\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 709: \tAverage Loss:  1.3518529968261719\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 710: \tAverage Loss:  1.3520508728027343\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 711: \tAverage Loss:  1.352032958984375\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 712: \tAverage Loss:  1.3517142639160156\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 713: \tAverage Loss:  1.35208642578125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 714: \tAverage Loss:  1.3516780395507813\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 715: \tAverage Loss:  1.3516302490234375\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 716: \tAverage Loss:  1.3516226806640625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 717: \tAverage Loss:  1.3516634521484374\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 718: \tAverage Loss:  1.351418975830078\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 719: \tAverage Loss:  1.3514413452148437\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 720: \tAverage Loss:  1.351173095703125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 721: \tAverage Loss:  1.35107861328125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 722: \tAverage Loss:  1.350748260498047\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 723: \tAverage Loss:  1.3506402587890625\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 724: \tAverage Loss:  1.350434600830078\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 725: \tAverage Loss:  1.3501479187011718\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 726: \tAverage Loss:  1.3499668579101562\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 727: \tAverage Loss:  1.3499170532226563\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 728: \tAverage Loss:  1.3498851318359375\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 729: \tAverage Loss:  1.3498272705078125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 730: \tAverage Loss:  1.3497466125488282\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 731: \tAverage Loss:  1.349743682861328\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 732: \tAverage Loss:  1.3496359558105469\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 733: \tAverage Loss:  1.3497516479492186\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 734: \tAverage Loss:  1.3496357421875\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 735: \tAverage Loss:  1.349888916015625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 736: \tAverage Loss:  1.3494982299804688\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 737: \tAverage Loss:  1.3493482360839844\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 738: \tAverage Loss:  1.349419189453125\t ACC train:  0.9975\t ACC test:  0.9866666666666667\n",
      "\tEpoch 739: \tAverage Loss:  1.3493267517089844\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 740: \tAverage Loss:  1.3491752319335937\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 741: \tAverage Loss:  1.3490996704101563\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 742: \tAverage Loss:  1.3488851013183594\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 743: \tAverage Loss:  1.3484890747070313\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 744: \tAverage Loss:  1.348343048095703\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 745: \tAverage Loss:  1.3484337463378906\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 746: \tAverage Loss:  1.3484063110351563\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 747: \tAverage Loss:  1.3483171081542968\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 748: \tAverage Loss:  1.3480316467285156\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 749: \tAverage Loss:  1.3478244018554688\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 750: \tAverage Loss:  1.3476653442382813\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 751: \tAverage Loss:  1.3476011962890626\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 752: \tAverage Loss:  1.3474524841308593\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 753: \tAverage Loss:  1.3474295654296875\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 754: \tAverage Loss:  1.3473566589355468\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 755: \tAverage Loss:  1.3472505493164062\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 756: \tAverage Loss:  1.3472398986816407\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 757: \tAverage Loss:  1.3471624145507812\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 758: \tAverage Loss:  1.3472442626953125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 759: \tAverage Loss:  1.346999725341797\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 760: \tAverage Loss:  1.34689453125\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 761: \tAverage Loss:  1.346697998046875\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 762: \tAverage Loss:  1.3467406005859375\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 763: \tAverage Loss:  1.346642547607422\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 764: \tAverage Loss:  1.34653662109375\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 765: \tAverage Loss:  1.3464862670898436\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 766: \tAverage Loss:  1.3465851745605468\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 767: \tAverage Loss:  1.3468762817382813\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 768: \tAverage Loss:  1.346563720703125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 769: \tAverage Loss:  1.3468409729003907\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 770: \tAverage Loss:  1.3470526123046875\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 771: \tAverage Loss:  1.3468517456054687\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 772: \tAverage Loss:  1.3468455810546875\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 773: \tAverage Loss:  1.346557861328125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 774: \tAverage Loss:  1.3463947143554686\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 775: \tAverage Loss:  1.3461988830566407\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 776: \tAverage Loss:  1.3461365356445312\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 777: \tAverage Loss:  1.3457236938476562\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 778: \tAverage Loss:  1.3454601745605468\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 779: \tAverage Loss:  1.3453588562011718\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 780: \tAverage Loss:  1.3452841796875\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 781: \tAverage Loss:  1.3455608825683594\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 782: \tAverage Loss:  1.345625457763672\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 783: \tAverage Loss:  1.3457573852539062\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 784: \tAverage Loss:  1.345651824951172\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 785: \tAverage Loss:  1.3457481079101563\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 786: \tAverage Loss:  1.3452598876953126\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 787: \tAverage Loss:  1.3450130004882812\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 788: \tAverage Loss:  1.3448807067871094\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 789: \tAverage Loss:  1.3446572265625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 790: \tAverage Loss:  1.3444967651367188\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 791: \tAverage Loss:  1.3445442504882812\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 792: \tAverage Loss:  1.3443604736328125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 793: \tAverage Loss:  1.344662078857422\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 794: \tAverage Loss:  1.3447579040527344\t ACC train:  0.9975\t ACC test:  0.9866666666666667\n",
      "\tEpoch 795: \tAverage Loss:  1.3449340209960938\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 796: \tAverage Loss:  1.3449630432128907\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 797: \tAverage Loss:  1.3445133056640626\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 798: \tAverage Loss:  1.344299041748047\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 799: \tAverage Loss:  1.3440341186523437\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 800: \tAverage Loss:  1.343877197265625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 801: \tAverage Loss:  1.34385107421875\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 802: \tAverage Loss:  1.3437216186523437\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 803: \tAverage Loss:  1.3436697387695313\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 804: \tAverage Loss:  1.343604278564453\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 805: \tAverage Loss:  1.3434555969238282\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 806: \tAverage Loss:  1.3434518127441406\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 807: \tAverage Loss:  1.3435006408691406\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 808: \tAverage Loss:  1.3436118774414063\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 809: \tAverage Loss:  1.3434079284667968\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 810: \tAverage Loss:  1.3434703369140626\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 811: \tAverage Loss:  1.3433236694335937\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 812: \tAverage Loss:  1.3433025512695314\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 813: \tAverage Loss:  1.343405029296875\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 814: \tAverage Loss:  1.3432306518554689\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 815: \tAverage Loss:  1.3432750244140625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 816: \tAverage Loss:  1.3429502563476563\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 817: \tAverage Loss:  1.3428529052734375\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 818: \tAverage Loss:  1.3427344665527343\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 819: \tAverage Loss:  1.342589111328125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 820: \tAverage Loss:  1.3423831481933595\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 821: \tAverage Loss:  1.3423231506347657\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 822: \tAverage Loss:  1.34232177734375\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 823: \tAverage Loss:  1.3421768493652344\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 824: \tAverage Loss:  1.342131622314453\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 825: \tAverage Loss:  1.342347137451172\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 826: \tAverage Loss:  1.342224090576172\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 827: \tAverage Loss:  1.3423150634765626\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 828: \tAverage Loss:  1.342160400390625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 829: \tAverage Loss:  1.3419325256347656\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 830: \tAverage Loss:  1.3419581909179688\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 831: \tAverage Loss:  1.341872100830078\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 832: \tAverage Loss:  1.3419286499023437\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 833: \tAverage Loss:  1.3418863220214843\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 834: \tAverage Loss:  1.341743133544922\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 835: \tAverage Loss:  1.3413934936523437\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 836: \tAverage Loss:  1.3413246154785157\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 837: \tAverage Loss:  1.3412817993164063\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 838: \tAverage Loss:  1.3412304077148438\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 839: \tAverage Loss:  1.3410790405273438\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 840: \tAverage Loss:  1.341031005859375\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 841: \tAverage Loss:  1.3409486694335937\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 842: \tAverage Loss:  1.3409589233398438\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 843: \tAverage Loss:  1.34084033203125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 844: \tAverage Loss:  1.3408543395996093\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 845: \tAverage Loss:  1.3408911743164063\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 846: \tAverage Loss:  1.3407995910644532\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 847: \tAverage Loss:  1.340837646484375\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 848: \tAverage Loss:  1.340834228515625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 849: \tAverage Loss:  1.3408937683105469\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 850: \tAverage Loss:  1.34093701171875\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 851: \tAverage Loss:  1.3410894165039062\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 852: \tAverage Loss:  1.3409840087890625\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 853: \tAverage Loss:  1.340921875\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 854: \tAverage Loss:  1.3406978454589844\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 855: \tAverage Loss:  1.3407380981445312\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 856: \tAverage Loss:  1.340765167236328\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 857: \tAverage Loss:  1.3411276245117187\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 858: \tAverage Loss:  1.3404405517578124\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 859: \tAverage Loss:  1.3408539428710937\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 860: \tAverage Loss:  1.3413562316894532\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 861: \tAverage Loss:  1.3408606567382813\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 862: \tAverage Loss:  1.3408998413085937\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 863: \tAverage Loss:  1.3404964599609375\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 864: \tAverage Loss:  1.3403049926757813\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 865: \tAverage Loss:  1.3401508178710937\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 866: \tAverage Loss:  1.3401751403808593\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 867: \tAverage Loss:  1.3401710205078126\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 868: \tAverage Loss:  1.33993701171875\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 869: \tAverage Loss:  1.339800018310547\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 870: \tAverage Loss:  1.3399515380859375\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 871: \tAverage Loss:  1.3399932250976563\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 872: \tAverage Loss:  1.3400842895507812\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 873: \tAverage Loss:  1.3396700134277344\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 874: \tAverage Loss:  1.3393801574707032\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 875: \tAverage Loss:  1.3392955322265625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 876: \tAverage Loss:  1.3393084106445312\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 877: \tAverage Loss:  1.3392757873535157\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 878: \tAverage Loss:  1.3391688842773437\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 879: \tAverage Loss:  1.339071990966797\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 880: \tAverage Loss:  1.339017303466797\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 881: \tAverage Loss:  1.3389549560546874\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 882: \tAverage Loss:  1.3391413269042969\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 883: \tAverage Loss:  1.3389242248535156\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 884: \tAverage Loss:  1.3390670471191406\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 885: \tAverage Loss:  1.3388717041015625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 886: \tAverage Loss:  1.3386123046875\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 887: \tAverage Loss:  1.3385524597167968\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 888: \tAverage Loss:  1.338466766357422\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 889: \tAverage Loss:  1.3383624572753907\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 890: \tAverage Loss:  1.3383278198242188\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 891: \tAverage Loss:  1.3381682739257812\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 892: \tAverage Loss:  1.3381666870117188\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 893: \tAverage Loss:  1.3380868225097655\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 894: \tAverage Loss:  1.3381554260253907\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 895: \tAverage Loss:  1.3382138671875\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 896: \tAverage Loss:  1.3380662841796875\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 897: \tAverage Loss:  1.3381024169921876\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 898: \tAverage Loss:  1.3380537109375\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 899: \tAverage Loss:  1.3379150085449218\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 900: \tAverage Loss:  1.3377627563476562\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 901: \tAverage Loss:  1.3377057189941406\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 902: \tAverage Loss:  1.3376349487304688\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 903: \tAverage Loss:  1.3376151123046875\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 904: \tAverage Loss:  1.3374944152832031\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 905: \tAverage Loss:  1.337466278076172\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 906: \tAverage Loss:  1.3374766235351563\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 907: \tAverage Loss:  1.3373742370605468\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 908: \tAverage Loss:  1.33728369140625\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 909: \tAverage Loss:  1.3372984313964844\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 910: \tAverage Loss:  1.3372431945800782\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 911: \tAverage Loss:  1.3371980895996094\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 912: \tAverage Loss:  1.3371596374511718\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 913: \tAverage Loss:  1.3370501098632812\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 914: \tAverage Loss:  1.337053985595703\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 915: \tAverage Loss:  1.3370894775390625\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 916: \tAverage Loss:  1.3370059814453126\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 917: \tAverage Loss:  1.3369143676757813\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 918: \tAverage Loss:  1.336972412109375\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 919: \tAverage Loss:  1.3369259643554687\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 920: \tAverage Loss:  1.3369393920898438\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 921: \tAverage Loss:  1.336912353515625\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 922: \tAverage Loss:  1.3371546630859374\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 923: \tAverage Loss:  1.3375488891601564\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 924: \tAverage Loss:  1.3379209289550782\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 925: \tAverage Loss:  1.3386912231445312\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 926: \tAverage Loss:  1.3402993774414063\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 927: \tAverage Loss:  1.3414964294433593\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 928: \tAverage Loss:  1.3433024597167968\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 929: \tAverage Loss:  1.34356591796875\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 930: \tAverage Loss:  1.342381591796875\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 931: \tAverage Loss:  1.339429412841797\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 932: \tAverage Loss:  1.337604705810547\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 933: \tAverage Loss:  1.3370418701171876\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 934: \tAverage Loss:  1.3378601684570313\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 935: \tAverage Loss:  1.3384302978515625\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 936: \tAverage Loss:  1.3378627014160156\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 937: \tAverage Loss:  1.336852752685547\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 938: \tAverage Loss:  1.336296417236328\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 939: \tAverage Loss:  1.3362497253417969\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 940: \tAverage Loss:  1.336391357421875\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 941: \tAverage Loss:  1.3365298767089844\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 942: \tAverage Loss:  1.33618505859375\t ACC train:  0.9975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 943: \tAverage Loss:  1.3359898376464843\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 944: \tAverage Loss:  1.3358129272460937\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 945: \tAverage Loss:  1.3358732299804688\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 946: \tAverage Loss:  1.3357897033691406\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 947: \tAverage Loss:  1.3357750244140625\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 948: \tAverage Loss:  1.335576934814453\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 949: \tAverage Loss:  1.335533905029297\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 950: \tAverage Loss:  1.3354349670410157\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 951: \tAverage Loss:  1.3353250732421875\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 952: \tAverage Loss:  1.3355386657714843\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 953: \tAverage Loss:  1.335317626953125\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 954: \tAverage Loss:  1.335183624267578\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 955: \tAverage Loss:  1.3351562194824218\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 956: \tAverage Loss:  1.335168670654297\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 957: \tAverage Loss:  1.3350775756835938\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 958: \tAverage Loss:  1.3350450439453125\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 959: \tAverage Loss:  1.3350448608398438\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 960: \tAverage Loss:  1.3348827209472656\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 961: \tAverage Loss:  1.3348374328613282\t ACC train:  0.9975\t ACC test:  0.9822222222222222\n",
      "\tEpoch 962: \tAverage Loss:  1.3346783142089844\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 963: \tAverage Loss:  1.3347421264648438\t ACC train:  0.9975\t ACC test:  0.98\n",
      "\tEpoch 964: \tAverage Loss:  1.3347523803710937\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 965: \tAverage Loss:  1.33485009765625\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 966: \tAverage Loss:  1.3354651184082031\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 967: \tAverage Loss:  1.3349053039550782\t ACC train:  0.9975\t ACC test:  0.9844444444444445\n",
      "\tEpoch 968: \tAverage Loss:  1.3352193603515625\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 969: \tAverage Loss:  1.334987030029297\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 970: \tAverage Loss:  1.3344434204101563\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 971: \tAverage Loss:  1.3342605895996094\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 972: \tAverage Loss:  1.3341156311035156\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 973: \tAverage Loss:  1.3343521118164063\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 974: \tAverage Loss:  1.3342884216308595\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 975: \tAverage Loss:  1.3340048828125\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 976: \tAverage Loss:  1.3337484741210937\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 977: \tAverage Loss:  1.3337271118164062\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 978: \tAverage Loss:  1.33361572265625\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 979: \tAverage Loss:  1.3336446838378906\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 980: \tAverage Loss:  1.333584197998047\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 981: \tAverage Loss:  1.3335105895996093\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 982: \tAverage Loss:  1.3333534851074218\t ACC train:  0.99875\t ACC test:  0.9844444444444445\n",
      "\tEpoch 983: \tAverage Loss:  1.333508056640625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 984: \tAverage Loss:  1.333370880126953\t ACC train:  0.99875\t ACC test:  0.9822222222222222\n",
      "\tEpoch 985: \tAverage Loss:  1.333373779296875\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 986: \tAverage Loss:  1.3331258544921876\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 987: \tAverage Loss:  1.3331775512695312\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 988: \tAverage Loss:  1.3330350341796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 989: \tAverage Loss:  1.3329949340820313\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 990: \tAverage Loss:  1.3331777954101562\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 991: \tAverage Loss:  1.3330379028320312\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 992: \tAverage Loss:  1.332938720703125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 993: \tAverage Loss:  1.3328536682128906\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 994: \tAverage Loss:  1.3329157409667969\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 995: \tAverage Loss:  1.3328038940429687\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 996: \tAverage Loss:  1.3327374267578125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 997: \tAverage Loss:  1.3327511291503906\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 998: \tAverage Loss:  1.3327854614257812\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 999: \tAverage Loss:  1.332610137939453\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1000: \tAverage Loss:  1.3326397705078126\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1001: \tAverage Loss:  1.3325376892089844\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1002: \tAverage Loss:  1.3324036865234374\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1003: \tAverage Loss:  1.3323605651855468\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1004: \tAverage Loss:  1.3321817626953125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1005: \tAverage Loss:  1.3322377319335938\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1006: \tAverage Loss:  1.3321535034179688\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1007: \tAverage Loss:  1.3322315673828125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1008: \tAverage Loss:  1.332251495361328\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 1009: \tAverage Loss:  1.3322522888183594\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1010: \tAverage Loss:  1.3320911865234375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1011: \tAverage Loss:  1.3321214294433594\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1012: \tAverage Loss:  1.331893768310547\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1013: \tAverage Loss:  1.3320093078613282\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1014: \tAverage Loss:  1.3320303955078125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1015: \tAverage Loss:  1.3317478942871093\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1016: \tAverage Loss:  1.3317369689941407\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1017: \tAverage Loss:  1.3317073974609375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1018: \tAverage Loss:  1.331541717529297\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1019: \tAverage Loss:  1.3315479736328124\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1020: \tAverage Loss:  1.3315159606933593\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1021: \tAverage Loss:  1.33154345703125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1022: \tAverage Loss:  1.3314396667480468\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1023: \tAverage Loss:  1.3314263916015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1024: \tAverage Loss:  1.3314442443847656\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1025: \tAverage Loss:  1.3314538269042968\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1026: \tAverage Loss:  1.3314138793945312\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1027: \tAverage Loss:  1.3314231567382813\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1028: \tAverage Loss:  1.3312216796875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1029: \tAverage Loss:  1.3311055603027344\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1030: \tAverage Loss:  1.331149658203125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1031: \tAverage Loss:  1.3311084594726563\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1032: \tAverage Loss:  1.33110791015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1033: \tAverage Loss:  1.3309908142089844\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1034: \tAverage Loss:  1.3309190368652344\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1035: \tAverage Loss:  1.331094970703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1036: \tAverage Loss:  1.3310943298339843\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1037: \tAverage Loss:  1.3308769836425782\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1038: \tAverage Loss:  1.3315627136230468\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1039: \tAverage Loss:  1.3312818908691406\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1040: \tAverage Loss:  1.3312143249511719\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1041: \tAverage Loss:  1.3309836730957032\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1042: \tAverage Loss:  1.330777587890625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1043: \tAverage Loss:  1.3306424560546875\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1044: \tAverage Loss:  1.3306470336914062\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1045: \tAverage Loss:  1.3307156066894532\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1046: \tAverage Loss:  1.330848388671875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1047: \tAverage Loss:  1.3311357116699218\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1048: \tAverage Loss:  1.3311034545898437\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1049: \tAverage Loss:  1.331391845703125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1050: \tAverage Loss:  1.3318989868164062\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1051: \tAverage Loss:  1.332501953125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1052: \tAverage Loss:  1.3336987915039062\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1053: \tAverage Loss:  1.334623046875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1054: \tAverage Loss:  1.3345621337890625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1055: \tAverage Loss:  1.3340576782226563\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1056: \tAverage Loss:  1.3327450256347657\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1057: \tAverage Loss:  1.3312268371582032\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1058: \tAverage Loss:  1.3304733276367187\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1059: \tAverage Loss:  1.330192138671875\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1060: \tAverage Loss:  1.330562713623047\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1061: \tAverage Loss:  1.3302767333984375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1062: \tAverage Loss:  1.3302247924804687\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1063: \tAverage Loss:  1.3300830688476561\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1064: \tAverage Loss:  1.3301168212890624\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1065: \tAverage Loss:  1.3301041564941407\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1066: \tAverage Loss:  1.3300481567382811\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1067: \tAverage Loss:  1.3296967163085938\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1068: \tAverage Loss:  1.329665985107422\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1069: \tAverage Loss:  1.32953369140625\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1070: \tAverage Loss:  1.329643310546875\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1071: \tAverage Loss:  1.329532501220703\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1072: \tAverage Loss:  1.329460693359375\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1073: \tAverage Loss:  1.3295857543945313\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1074: \tAverage Loss:  1.3295067749023437\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1075: \tAverage Loss:  1.3294561157226563\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1076: \tAverage Loss:  1.3292635803222657\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1077: \tAverage Loss:  1.329350799560547\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1078: \tAverage Loss:  1.3291812438964843\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1079: \tAverage Loss:  1.3292325134277343\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1080: \tAverage Loss:  1.3292100219726561\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1081: \tAverage Loss:  1.3290995178222655\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1082: \tAverage Loss:  1.3291828002929686\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1083: \tAverage Loss:  1.3290245056152343\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1084: \tAverage Loss:  1.3290517578125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1085: \tAverage Loss:  1.3290670471191406\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1086: \tAverage Loss:  1.3289920959472656\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1087: \tAverage Loss:  1.3289577331542968\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1088: \tAverage Loss:  1.3288802490234375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1089: \tAverage Loss:  1.3288785705566406\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1090: \tAverage Loss:  1.328798614501953\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1091: \tAverage Loss:  1.3287643432617187\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1092: \tAverage Loss:  1.3288065795898438\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1093: \tAverage Loss:  1.3287010803222656\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1094: \tAverage Loss:  1.3286778869628906\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1095: \tAverage Loss:  1.32872802734375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1096: \tAverage Loss:  1.328845184326172\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1097: \tAverage Loss:  1.3289086608886718\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1098: \tAverage Loss:  1.3289505310058594\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1099: \tAverage Loss:  1.3290134887695313\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1100: \tAverage Loss:  1.3287549743652343\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1101: \tAverage Loss:  1.32865771484375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1102: \tAverage Loss:  1.3285989379882812\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1103: \tAverage Loss:  1.3285164184570313\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1104: \tAverage Loss:  1.3286959228515625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1105: \tAverage Loss:  1.3286559143066405\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1106: \tAverage Loss:  1.3286239624023437\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1107: \tAverage Loss:  1.3285003356933593\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1108: \tAverage Loss:  1.3283297119140625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1109: \tAverage Loss:  1.328234405517578\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1110: \tAverage Loss:  1.328293670654297\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1111: \tAverage Loss:  1.3283401794433594\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1112: \tAverage Loss:  1.3283126525878906\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1113: \tAverage Loss:  1.328437042236328\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1114: \tAverage Loss:  1.3283497314453125\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1115: \tAverage Loss:  1.3284058227539062\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1116: \tAverage Loss:  1.3284019470214843\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1117: \tAverage Loss:  1.3285003356933593\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1118: \tAverage Loss:  1.3285617065429687\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1119: \tAverage Loss:  1.3290353393554688\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1120: \tAverage Loss:  1.3291156616210937\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1121: \tAverage Loss:  1.3289966430664062\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1122: \tAverage Loss:  1.3291237182617188\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1123: \tAverage Loss:  1.3289207153320313\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1124: \tAverage Loss:  1.3289172668457032\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1125: \tAverage Loss:  1.3287445068359376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1126: \tAverage Loss:  1.3287630310058594\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1127: \tAverage Loss:  1.3287440490722657\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1128: \tAverage Loss:  1.3287979736328126\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1129: \tAverage Loss:  1.3283153076171874\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1130: \tAverage Loss:  1.3277605285644531\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1131: \tAverage Loss:  1.3276116638183593\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1132: \tAverage Loss:  1.3277101440429688\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1133: \tAverage Loss:  1.327605926513672\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1134: \tAverage Loss:  1.3274630432128907\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1135: \tAverage Loss:  1.3273005676269531\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1136: \tAverage Loss:  1.3272455139160155\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1137: \tAverage Loss:  1.3272594604492187\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1138: \tAverage Loss:  1.3273162231445312\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1139: \tAverage Loss:  1.3271963500976562\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1140: \tAverage Loss:  1.3274028930664064\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1141: \tAverage Loss:  1.3272557373046876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1142: \tAverage Loss:  1.327130584716797\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1143: \tAverage Loss:  1.3270164489746095\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1144: \tAverage Loss:  1.327008514404297\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1145: \tAverage Loss:  1.326996795654297\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1146: \tAverage Loss:  1.3269671936035157\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1147: \tAverage Loss:  1.3270843505859375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1148: \tAverage Loss:  1.3269768981933594\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1149: \tAverage Loss:  1.3269676208496093\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1150: \tAverage Loss:  1.3270462646484376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1151: \tAverage Loss:  1.3271498718261718\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1152: \tAverage Loss:  1.327045166015625\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1153: \tAverage Loss:  1.3271859130859376\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1154: \tAverage Loss:  1.327001953125\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1155: \tAverage Loss:  1.3271863403320312\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1156: \tAverage Loss:  1.3271885375976562\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1157: \tAverage Loss:  1.327223907470703\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1158: \tAverage Loss:  1.3272416076660156\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1159: \tAverage Loss:  1.3273332214355469\t ACC train:  1.0\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1160: \tAverage Loss:  1.32772021484375\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1161: \tAverage Loss:  1.3277680358886719\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1162: \tAverage Loss:  1.3278670654296876\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1163: \tAverage Loss:  1.327735565185547\t ACC train:  1.0\t ACC test:  0.9844444444444445\n",
      "Stopping early at epoch 1163. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 900\n",
      "\tEpoch 1: \tAverage Loss:  4.3080379638671875\t ACC train:  0.4822222222222222\t ACC test:  0.4266666666666667\n",
      "\tEpoch 2: \tAverage Loss:  4.272237548828125\t ACC train:  0.5066666666666667\t ACC test:  0.5066666666666667\n",
      "\tEpoch 3: \tAverage Loss:  4.239681274414062\t ACC train:  0.5088888888888888\t ACC test:  0.5333333333333333\n",
      "\tEpoch 4: \tAverage Loss:  4.209288940429688\t ACC train:  0.5033333333333333\t ACC test:  0.5022222222222222\n",
      "\tEpoch 5: \tAverage Loss:  4.1813814697265625\t ACC train:  0.5322222222222223\t ACC test:  0.49777777777777776\n",
      "\tEpoch 6: \tAverage Loss:  4.155321899414062\t ACC train:  0.5144444444444445\t ACC test:  0.48\n",
      "\tEpoch 7: \tAverage Loss:  4.133385498046875\t ACC train:  0.52\t ACC test:  0.4888888888888889\n",
      "\tEpoch 8: \tAverage Loss:  4.1118759765625\t ACC train:  0.49444444444444446\t ACC test:  0.5177777777777778\n",
      "\tEpoch 9: \tAverage Loss:  4.08930517578125\t ACC train:  0.5288888888888889\t ACC test:  0.5\n",
      "\tEpoch 10: \tAverage Loss:  4.068489135742188\t ACC train:  0.5111111111111111\t ACC test:  0.4888888888888889\n",
      "\tEpoch 11: \tAverage Loss:  4.047757080078125\t ACC train:  0.51\t ACC test:  0.5155555555555555\n",
      "\tEpoch 12: \tAverage Loss:  4.028514892578125\t ACC train:  0.5022222222222222\t ACC test:  0.5111111111111111\n",
      "\tEpoch 13: \tAverage Loss:  4.009311157226563\t ACC train:  0.49666666666666665\t ACC test:  0.5088888888888888\n",
      "\tEpoch 14: \tAverage Loss:  3.9907991943359375\t ACC train:  0.4922222222222222\t ACC test:  0.4911111111111111\n",
      "\tEpoch 15: \tAverage Loss:  3.973938232421875\t ACC train:  0.5211111111111111\t ACC test:  0.5022222222222222\n",
      "\tEpoch 16: \tAverage Loss:  3.956545654296875\t ACC train:  0.5077777777777778\t ACC test:  0.52\n",
      "\tEpoch 17: \tAverage Loss:  3.9401798095703127\t ACC train:  0.4711111111111111\t ACC test:  0.5\n",
      "\tEpoch 18: \tAverage Loss:  3.9257099609375\t ACC train:  0.4722222222222222\t ACC test:  0.45111111111111113\n",
      "\tEpoch 19: \tAverage Loss:  3.9101575927734373\t ACC train:  0.48777777777777775\t ACC test:  0.5266666666666666\n",
      "\tEpoch 20: \tAverage Loss:  3.8935733642578123\t ACC train:  0.47555555555555556\t ACC test:  0.4777777777777778\n",
      "\tEpoch 21: \tAverage Loss:  3.8794481201171873\t ACC train:  0.4677777777777778\t ACC test:  0.4711111111111111\n",
      "\tEpoch 22: \tAverage Loss:  3.8649078369140626\t ACC train:  0.5011111111111111\t ACC test:  0.48\n",
      "\tEpoch 23: \tAverage Loss:  3.8506951904296876\t ACC train:  0.4922222222222222\t ACC test:  0.4711111111111111\n",
      "\tEpoch 24: \tAverage Loss:  3.8386324462890626\t ACC train:  0.4666666666666667\t ACC test:  0.4822222222222222\n",
      "\tEpoch 25: \tAverage Loss:  3.8262467041015626\t ACC train:  0.4911111111111111\t ACC test:  0.4711111111111111\n",
      "\tEpoch 26: \tAverage Loss:  3.811994873046875\t ACC train:  0.47\t ACC test:  0.43555555555555553\n",
      "\tEpoch 27: \tAverage Loss:  3.8001861572265625\t ACC train:  0.47333333333333333\t ACC test:  0.4688888888888889\n",
      "\tEpoch 28: \tAverage Loss:  3.78981396484375\t ACC train:  0.4777777777777778\t ACC test:  0.4577777777777778\n",
      "\tEpoch 29: \tAverage Loss:  3.776032470703125\t ACC train:  0.4777777777777778\t ACC test:  0.4622222222222222\n",
      "\tEpoch 30: \tAverage Loss:  3.767611083984375\t ACC train:  0.48444444444444446\t ACC test:  0.4577777777777778\n",
      "\tEpoch 31: \tAverage Loss:  3.75258251953125\t ACC train:  0.4866666666666667\t ACC test:  0.4622222222222222\n",
      "\tEpoch 32: \tAverage Loss:  3.743307861328125\t ACC train:  0.4444444444444444\t ACC test:  0.4888888888888889\n",
      "\tEpoch 33: \tAverage Loss:  3.73219189453125\t ACC train:  0.4688888888888889\t ACC test:  0.42\n",
      "\tEpoch 34: \tAverage Loss:  3.7213699951171875\t ACC train:  0.45555555555555555\t ACC test:  0.43333333333333335\n",
      "\tEpoch 35: \tAverage Loss:  3.7089580078125\t ACC train:  0.4622222222222222\t ACC test:  0.4488888888888889\n",
      "\tEpoch 36: \tAverage Loss:  3.70045263671875\t ACC train:  0.48777777777777775\t ACC test:  0.4622222222222222\n",
      "\tEpoch 37: \tAverage Loss:  3.6854267578125\t ACC train:  0.47444444444444445\t ACC test:  0.45555555555555555\n",
      "\tEpoch 38: \tAverage Loss:  3.678556884765625\t ACC train:  0.4822222222222222\t ACC test:  0.4666666666666667\n",
      "\tEpoch 39: \tAverage Loss:  3.6633863525390624\t ACC train:  0.47333333333333333\t ACC test:  0.4533333333333333\n",
      "\tEpoch 40: \tAverage Loss:  3.65302734375\t ACC train:  0.47\t ACC test:  0.45111111111111113\n",
      "\tEpoch 41: \tAverage Loss:  3.63679443359375\t ACC train:  0.47444444444444445\t ACC test:  0.44666666666666666\n",
      "\tEpoch 42: \tAverage Loss:  3.6264549560546877\t ACC train:  0.4777777777777778\t ACC test:  0.46\n",
      "\tEpoch 43: \tAverage Loss:  3.610416259765625\t ACC train:  0.4866666666666667\t ACC test:  0.46\n",
      "\tEpoch 44: \tAverage Loss:  3.5961737060546874\t ACC train:  0.4855555555555556\t ACC test:  0.46\n",
      "\tEpoch 45: \tAverage Loss:  3.5795950927734377\t ACC train:  0.48777777777777775\t ACC test:  0.4711111111111111\n",
      "\tEpoch 46: \tAverage Loss:  3.56083984375\t ACC train:  0.49333333333333335\t ACC test:  0.4822222222222222\n",
      "\tEpoch 47: \tAverage Loss:  3.5411094970703125\t ACC train:  0.5022222222222222\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  3.524949951171875\t ACC train:  0.5033333333333333\t ACC test:  0.4911111111111111\n",
      "\tEpoch 49: \tAverage Loss:  3.5008724365234376\t ACC train:  0.5177777777777778\t ACC test:  0.5044444444444445\n",
      "\tEpoch 50: \tAverage Loss:  3.4831297607421874\t ACC train:  0.5411111111111111\t ACC test:  0.5244444444444445\n",
      "\tEpoch 51: \tAverage Loss:  3.4509080810546875\t ACC train:  0.5644444444444444\t ACC test:  0.5511111111111111\n",
      "\tEpoch 52: \tAverage Loss:  3.43719580078125\t ACC train:  0.58\t ACC test:  0.56\n",
      "\tEpoch 53: \tAverage Loss:  3.40906396484375\t ACC train:  0.6022222222222222\t ACC test:  0.5711111111111111\n",
      "\tEpoch 54: \tAverage Loss:  3.3771314697265624\t ACC train:  0.6111111111111112\t ACC test:  0.5866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  3.343744140625\t ACC train:  0.62\t ACC test:  0.5866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  3.318088623046875\t ACC train:  0.6077777777777778\t ACC test:  0.5844444444444444\n",
      "\tEpoch 57: \tAverage Loss:  3.29148046875\t ACC train:  0.6155555555555555\t ACC test:  0.5844444444444444\n",
      "\tEpoch 58: \tAverage Loss:  3.2579483642578126\t ACC train:  0.6044444444444445\t ACC test:  0.5866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  3.2238486328125\t ACC train:  0.6055555555555555\t ACC test:  0.5955555555555555\n",
      "\tEpoch 60: \tAverage Loss:  3.199892333984375\t ACC train:  0.6066666666666667\t ACC test:  0.5888888888888889\n",
      "\tEpoch 61: \tAverage Loss:  3.1636707763671876\t ACC train:  0.61\t ACC test:  0.5644444444444444\n",
      "\tEpoch 62: \tAverage Loss:  3.1452628173828123\t ACC train:  0.6122222222222222\t ACC test:  0.5711111111111111\n",
      "\tEpoch 63: \tAverage Loss:  3.10219580078125\t ACC train:  0.5966666666666667\t ACC test:  0.5555555555555556\n",
      "\tEpoch 64: \tAverage Loss:  3.0687559814453125\t ACC train:  0.5888888888888889\t ACC test:  0.5577777777777778\n",
      "\tEpoch 65: \tAverage Loss:  3.049439697265625\t ACC train:  0.6144444444444445\t ACC test:  0.5711111111111111\n",
      "\tEpoch 66: \tAverage Loss:  3.0119083251953125\t ACC train:  0.5966666666666667\t ACC test:  0.5666666666666667\n",
      "\tEpoch 67: \tAverage Loss:  3.002178955078125\t ACC train:  0.59\t ACC test:  0.5711111111111111\n",
      "\tEpoch 68: \tAverage Loss:  2.96231982421875\t ACC train:  0.5955555555555555\t ACC test:  0.5555555555555556\n",
      "\tEpoch 69: \tAverage Loss:  2.9453858642578123\t ACC train:  0.5988888888888889\t ACC test:  0.5777777777777777\n",
      "\tEpoch 70: \tAverage Loss:  2.918143798828125\t ACC train:  0.5966666666666667\t ACC test:  0.5644444444444444\n",
      "\tEpoch 71: \tAverage Loss:  2.8943031005859376\t ACC train:  0.5866666666666667\t ACC test:  0.56\n",
      "\tEpoch 72: \tAverage Loss:  2.8755184326171874\t ACC train:  0.5911111111111111\t ACC test:  0.5666666666666667\n",
      "\tEpoch 73: \tAverage Loss:  2.8430870361328124\t ACC train:  0.6055555555555555\t ACC test:  0.5866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  2.824177490234375\t ACC train:  0.6033333333333334\t ACC test:  0.5755555555555556\n",
      "\tEpoch 75: \tAverage Loss:  2.802937744140625\t ACC train:  0.5844444444444444\t ACC test:  0.5733333333333334\n",
      "\tEpoch 76: \tAverage Loss:  2.784089599609375\t ACC train:  0.5788888888888889\t ACC test:  0.5933333333333334\n",
      "\tEpoch 77: \tAverage Loss:  2.7699539794921875\t ACC train:  0.5833333333333334\t ACC test:  0.5777777777777777\n",
      "\tEpoch 78: \tAverage Loss:  2.7488709716796875\t ACC train:  0.6\t ACC test:  0.5555555555555556\n",
      "\tEpoch 79: \tAverage Loss:  2.7347249755859373\t ACC train:  0.6066666666666667\t ACC test:  0.5822222222222222\n",
      "\tEpoch 80: \tAverage Loss:  2.7145692138671875\t ACC train:  0.5977777777777777\t ACC test:  0.5622222222222222\n",
      "\tEpoch 81: \tAverage Loss:  2.6897008056640623\t ACC train:  0.5922222222222222\t ACC test:  0.5666666666666667\n",
      "\tEpoch 82: \tAverage Loss:  2.68118701171875\t ACC train:  0.5833333333333334\t ACC test:  0.5977777777777777\n",
      "\tEpoch 83: \tAverage Loss:  2.6602728271484377\t ACC train:  0.5944444444444444\t ACC test:  0.5777777777777777\n",
      "\tEpoch 84: \tAverage Loss:  2.651415283203125\t ACC train:  0.6\t ACC test:  0.5822222222222222\n",
      "\tEpoch 85: \tAverage Loss:  2.635567138671875\t ACC train:  0.6077777777777778\t ACC test:  0.5755555555555556\n",
      "\tEpoch 86: \tAverage Loss:  2.625199462890625\t ACC train:  0.6022222222222222\t ACC test:  0.5711111111111111\n",
      "\tEpoch 87: \tAverage Loss:  2.608175048828125\t ACC train:  0.5966666666666667\t ACC test:  0.5755555555555556\n",
      "\tEpoch 88: \tAverage Loss:  2.58853955078125\t ACC train:  0.6033333333333334\t ACC test:  0.5844444444444444\n",
      "\tEpoch 89: \tAverage Loss:  2.580137939453125\t ACC train:  0.6111111111111112\t ACC test:  0.5711111111111111\n",
      "\tEpoch 90: \tAverage Loss:  2.5719381103515624\t ACC train:  0.6088888888888889\t ACC test:  0.5888888888888889\n",
      "\tEpoch 91: \tAverage Loss:  2.5640740966796876\t ACC train:  0.6011111111111112\t ACC test:  0.58\n",
      "\tEpoch 92: \tAverage Loss:  2.5548062744140627\t ACC train:  0.6055555555555555\t ACC test:  0.5933333333333334\n",
      "\tEpoch 93: \tAverage Loss:  2.541061767578125\t ACC train:  0.6122222222222222\t ACC test:  0.5777777777777777\n",
      "\tEpoch 94: \tAverage Loss:  2.532150146484375\t ACC train:  0.5977777777777777\t ACC test:  0.5866666666666667\n",
      "\tEpoch 95: \tAverage Loss:  2.5148270263671875\t ACC train:  0.6222222222222222\t ACC test:  0.5755555555555556\n",
      "\tEpoch 96: \tAverage Loss:  2.509472900390625\t ACC train:  0.6066666666666667\t ACC test:  0.5755555555555556\n",
      "\tEpoch 97: \tAverage Loss:  2.4971123046875\t ACC train:  0.6133333333333333\t ACC test:  0.5733333333333334\n",
      "\tEpoch 98: \tAverage Loss:  2.489182861328125\t ACC train:  0.6244444444444445\t ACC test:  0.5866666666666667\n",
      "\tEpoch 99: \tAverage Loss:  2.4866016845703127\t ACC train:  0.6144444444444445\t ACC test:  0.5666666666666667\n",
      "\tEpoch 100: \tAverage Loss:  2.4752923583984376\t ACC train:  0.6088888888888889\t ACC test:  0.5866666666666667\n",
      "\tEpoch 101: \tAverage Loss:  2.46940087890625\t ACC train:  0.6266666666666667\t ACC test:  0.5955555555555555\n",
      "\tEpoch 102: \tAverage Loss:  2.4582132568359376\t ACC train:  0.6166666666666667\t ACC test:  0.5844444444444444\n",
      "\tEpoch 103: \tAverage Loss:  2.4584720458984375\t ACC train:  0.6122222222222222\t ACC test:  0.6022222222222222\n",
      "\tEpoch 104: \tAverage Loss:  2.449326416015625\t ACC train:  0.6166666666666667\t ACC test:  0.5822222222222222\n",
      "\tEpoch 105: \tAverage Loss:  2.4425396728515625\t ACC train:  0.6211111111111111\t ACC test:  0.5733333333333334\n",
      "\tEpoch 106: \tAverage Loss:  2.4391363525390624\t ACC train:  0.6155555555555555\t ACC test:  0.5888888888888889\n",
      "\tEpoch 107: \tAverage Loss:  2.432561279296875\t ACC train:  0.6088888888888889\t ACC test:  0.6\n",
      "\tEpoch 108: \tAverage Loss:  2.4254530029296877\t ACC train:  0.6155555555555555\t ACC test:  0.5911111111111111\n",
      "\tEpoch 109: \tAverage Loss:  2.4130042724609373\t ACC train:  0.6177777777777778\t ACC test:  0.5822222222222222\n",
      "\tEpoch 110: \tAverage Loss:  2.4114217529296873\t ACC train:  0.6177777777777778\t ACC test:  0.5955555555555555\n",
      "\tEpoch 111: \tAverage Loss:  2.41136962890625\t ACC train:  0.62\t ACC test:  0.6\n",
      "\tEpoch 112: \tAverage Loss:  2.4016802978515623\t ACC train:  0.6222222222222222\t ACC test:  0.5911111111111111\n",
      "\tEpoch 113: \tAverage Loss:  2.39762060546875\t ACC train:  0.6244444444444445\t ACC test:  0.5844444444444444\n",
      "\tEpoch 114: \tAverage Loss:  2.3882410888671877\t ACC train:  0.6155555555555555\t ACC test:  0.5933333333333334\n",
      "\tEpoch 115: \tAverage Loss:  2.3953564453125\t ACC train:  0.6188888888888889\t ACC test:  0.5888888888888889\n",
      "\tEpoch 116: \tAverage Loss:  2.3812789306640627\t ACC train:  0.6222222222222222\t ACC test:  0.6111111111111112\n",
      "\tEpoch 117: \tAverage Loss:  2.3753310546875\t ACC train:  0.6144444444444445\t ACC test:  0.5866666666666667\n",
      "\tEpoch 118: \tAverage Loss:  2.372798095703125\t ACC train:  0.6233333333333333\t ACC test:  0.5911111111111111\n",
      "\tEpoch 119: \tAverage Loss:  2.3719794921875\t ACC train:  0.62\t ACC test:  0.6044444444444445\n",
      "\tEpoch 120: \tAverage Loss:  2.3642181396484374\t ACC train:  0.6288888888888889\t ACC test:  0.6\n",
      "\tEpoch 121: \tAverage Loss:  2.36259375\t ACC train:  0.6266666666666667\t ACC test:  0.5911111111111111\n",
      "\tEpoch 122: \tAverage Loss:  2.3573753662109374\t ACC train:  0.6433333333333333\t ACC test:  0.6044444444444445\n",
      "\tEpoch 123: \tAverage Loss:  2.3562508544921874\t ACC train:  0.6333333333333333\t ACC test:  0.6\n",
      "\tEpoch 124: \tAverage Loss:  2.3510831298828125\t ACC train:  0.6277777777777778\t ACC test:  0.6\n",
      "\tEpoch 125: \tAverage Loss:  2.3485111083984376\t ACC train:  0.6244444444444445\t ACC test:  0.5844444444444444\n",
      "\tEpoch 126: \tAverage Loss:  2.341716796875\t ACC train:  0.6288888888888889\t ACC test:  0.5933333333333334\n",
      "\tEpoch 127: \tAverage Loss:  2.34112890625\t ACC train:  0.6244444444444445\t ACC test:  0.58\n",
      "\tEpoch 128: \tAverage Loss:  2.342888916015625\t ACC train:  0.63\t ACC test:  0.5977777777777777\n",
      "\tEpoch 129: \tAverage Loss:  2.3373546142578125\t ACC train:  0.6366666666666667\t ACC test:  0.5977777777777777\n",
      "\tEpoch 130: \tAverage Loss:  2.3306226806640624\t ACC train:  0.63\t ACC test:  0.6244444444444445\n",
      "\tEpoch 131: \tAverage Loss:  2.3279642333984376\t ACC train:  0.6422222222222222\t ACC test:  0.5977777777777777\n",
      "\tEpoch 132: \tAverage Loss:  2.3291158447265623\t ACC train:  0.6244444444444445\t ACC test:  0.5933333333333334\n",
      "\tEpoch 133: \tAverage Loss:  2.323159912109375\t ACC train:  0.6377777777777778\t ACC test:  0.6111111111111112\n",
      "\tEpoch 134: \tAverage Loss:  2.318371154785156\t ACC train:  0.6355555555555555\t ACC test:  0.5866666666666667\n",
      "\tEpoch 135: \tAverage Loss:  2.319647155761719\t ACC train:  0.6266666666666667\t ACC test:  0.6022222222222222\n",
      "\tEpoch 136: \tAverage Loss:  2.316425048828125\t ACC train:  0.6366666666666667\t ACC test:  0.6066666666666667\n",
      "\tEpoch 137: \tAverage Loss:  2.314185302734375\t ACC train:  0.6411111111111111\t ACC test:  0.6088888888888889\n",
      "\tEpoch 138: \tAverage Loss:  2.3109473876953124\t ACC train:  0.6277777777777778\t ACC test:  0.6022222222222222\n",
      "\tEpoch 139: \tAverage Loss:  2.305271240234375\t ACC train:  0.6377777777777778\t ACC test:  0.5888888888888889\n",
      "\tEpoch 140: \tAverage Loss:  2.3041019287109377\t ACC train:  0.6333333333333333\t ACC test:  0.6133333333333333\n",
      "\tEpoch 141: \tAverage Loss:  2.303265869140625\t ACC train:  0.6366666666666667\t ACC test:  0.6022222222222222\n",
      "\tEpoch 142: \tAverage Loss:  2.2952933349609377\t ACC train:  0.6455555555555555\t ACC test:  0.5977777777777777\n",
      "\tEpoch 143: \tAverage Loss:  2.3004915771484375\t ACC train:  0.6355555555555555\t ACC test:  0.6044444444444445\n",
      "\tEpoch 144: \tAverage Loss:  2.2954000854492187\t ACC train:  0.6366666666666667\t ACC test:  0.6088888888888889\n",
      "\tEpoch 145: \tAverage Loss:  2.2928670654296877\t ACC train:  0.6377777777777778\t ACC test:  0.6155555555555555\n",
      "\tEpoch 146: \tAverage Loss:  2.29414013671875\t ACC train:  0.6344444444444445\t ACC test:  0.6133333333333333\n",
      "\tEpoch 147: \tAverage Loss:  2.2902489013671876\t ACC train:  0.6333333333333333\t ACC test:  0.6022222222222222\n",
      "\tEpoch 148: \tAverage Loss:  2.287022705078125\t ACC train:  0.6377777777777778\t ACC test:  0.5955555555555555\n",
      "\tEpoch 149: \tAverage Loss:  2.2877469482421877\t ACC train:  0.6377777777777778\t ACC test:  0.6266666666666667\n",
      "\tEpoch 150: \tAverage Loss:  2.281981201171875\t ACC train:  0.64\t ACC test:  0.5933333333333334\n",
      "\tEpoch 151: \tAverage Loss:  2.280295471191406\t ACC train:  0.6322222222222222\t ACC test:  0.6088888888888889\n",
      "\tEpoch 152: \tAverage Loss:  2.275888244628906\t ACC train:  0.6333333333333333\t ACC test:  0.6066666666666667\n",
      "\tEpoch 153: \tAverage Loss:  2.2799579467773436\t ACC train:  0.6355555555555555\t ACC test:  0.6044444444444445\n",
      "\tEpoch 154: \tAverage Loss:  2.2743653564453123\t ACC train:  0.6333333333333333\t ACC test:  0.6022222222222222\n",
      "\tEpoch 155: \tAverage Loss:  2.273861083984375\t ACC train:  0.6355555555555555\t ACC test:  0.6066666666666667\n",
      "\tEpoch 156: \tAverage Loss:  2.2753014526367186\t ACC train:  0.6377777777777778\t ACC test:  0.6066666666666667\n",
      "\tEpoch 157: \tAverage Loss:  2.268967529296875\t ACC train:  0.6422222222222222\t ACC test:  0.6044444444444445\n",
      "\tEpoch 158: \tAverage Loss:  2.26996240234375\t ACC train:  0.6377777777777778\t ACC test:  0.6022222222222222\n",
      "\tEpoch 159: \tAverage Loss:  2.2685066528320315\t ACC train:  0.6411111111111111\t ACC test:  0.6133333333333333\n",
      "\tEpoch 160: \tAverage Loss:  2.2664577026367185\t ACC train:  0.6411111111111111\t ACC test:  0.6155555555555555\n",
      "\tEpoch 161: \tAverage Loss:  2.2657420654296874\t ACC train:  0.6377777777777778\t ACC test:  0.6133333333333333\n",
      "\tEpoch 162: \tAverage Loss:  2.26479296875\t ACC train:  0.6388888888888888\t ACC test:  0.6044444444444445\n",
      "\tEpoch 163: \tAverage Loss:  2.2581122436523438\t ACC train:  0.6433333333333333\t ACC test:  0.6066666666666667\n",
      "\tEpoch 164: \tAverage Loss:  2.2543587036132813\t ACC train:  0.6377777777777778\t ACC test:  0.6177777777777778\n",
      "\tEpoch 165: \tAverage Loss:  2.256429016113281\t ACC train:  0.6355555555555555\t ACC test:  0.6022222222222222\n",
      "\tEpoch 166: \tAverage Loss:  2.255633056640625\t ACC train:  0.6477777777777778\t ACC test:  0.6177777777777778\n",
      "\tEpoch 167: \tAverage Loss:  2.253176086425781\t ACC train:  0.6388888888888888\t ACC test:  0.62\n",
      "\tEpoch 168: \tAverage Loss:  2.251218566894531\t ACC train:  0.6344444444444445\t ACC test:  0.6088888888888889\n",
      "\tEpoch 169: \tAverage Loss:  2.250628479003906\t ACC train:  0.6444444444444445\t ACC test:  0.6177777777777778\n",
      "\tEpoch 170: \tAverage Loss:  2.2453881225585937\t ACC train:  0.6422222222222222\t ACC test:  0.6244444444444445\n",
      "\tEpoch 171: \tAverage Loss:  2.249455139160156\t ACC train:  0.6433333333333333\t ACC test:  0.6111111111111112\n",
      "\tEpoch 172: \tAverage Loss:  2.24907421875\t ACC train:  0.6422222222222222\t ACC test:  0.62\n",
      "\tEpoch 173: \tAverage Loss:  2.2459616088867187\t ACC train:  0.6388888888888888\t ACC test:  0.6155555555555555\n",
      "\tEpoch 174: \tAverage Loss:  2.245678283691406\t ACC train:  0.6377777777777778\t ACC test:  0.6066666666666667\n",
      "\tEpoch 175: \tAverage Loss:  2.247239440917969\t ACC train:  0.6433333333333333\t ACC test:  0.6088888888888889\n",
      "\tEpoch 176: \tAverage Loss:  2.2390896606445314\t ACC train:  0.64\t ACC test:  0.6244444444444445\n",
      "\tEpoch 177: \tAverage Loss:  2.2402444458007813\t ACC train:  0.6411111111111111\t ACC test:  0.6244444444444445\n",
      "\tEpoch 178: \tAverage Loss:  2.2425882568359374\t ACC train:  0.6411111111111111\t ACC test:  0.6155555555555555\n",
      "\tEpoch 179: \tAverage Loss:  2.2356786499023436\t ACC train:  0.65\t ACC test:  0.6088888888888889\n",
      "\tEpoch 180: \tAverage Loss:  2.2326771850585936\t ACC train:  0.6466666666666666\t ACC test:  0.62\n",
      "\tEpoch 181: \tAverage Loss:  2.2327479248046873\t ACC train:  0.6433333333333333\t ACC test:  0.6266666666666667\n",
      "\tEpoch 182: \tAverage Loss:  2.2330806884765626\t ACC train:  0.6455555555555555\t ACC test:  0.6133333333333333\n",
      "\tEpoch 183: \tAverage Loss:  2.2314876708984377\t ACC train:  0.6444444444444445\t ACC test:  0.6333333333333333\n",
      "\tEpoch 184: \tAverage Loss:  2.229375305175781\t ACC train:  0.6444444444444445\t ACC test:  0.6266666666666667\n",
      "\tEpoch 185: \tAverage Loss:  2.232732666015625\t ACC train:  0.6411111111111111\t ACC test:  0.6222222222222222\n",
      "\tEpoch 186: \tAverage Loss:  2.2297095336914063\t ACC train:  0.6466666666666666\t ACC test:  0.6222222222222222\n",
      "\tEpoch 187: \tAverage Loss:  2.2262387084960937\t ACC train:  0.65\t ACC test:  0.62\n",
      "\tEpoch 188: \tAverage Loss:  2.224593933105469\t ACC train:  0.6466666666666666\t ACC test:  0.62\n",
      "\tEpoch 189: \tAverage Loss:  2.224677490234375\t ACC train:  0.6477777777777778\t ACC test:  0.6177777777777778\n",
      "\tEpoch 190: \tAverage Loss:  2.2263974609375\t ACC train:  0.6522222222222223\t ACC test:  0.6333333333333333\n",
      "\tEpoch 191: \tAverage Loss:  2.224463134765625\t ACC train:  0.65\t ACC test:  0.6288888888888889\n",
      "\tEpoch 192: \tAverage Loss:  2.2236744384765625\t ACC train:  0.6477777777777778\t ACC test:  0.6177777777777778\n",
      "\tEpoch 193: \tAverage Loss:  2.221157958984375\t ACC train:  0.6511111111111111\t ACC test:  0.6177777777777778\n",
      "\tEpoch 194: \tAverage Loss:  2.218498779296875\t ACC train:  0.6488888888888888\t ACC test:  0.6177777777777778\n",
      "\tEpoch 195: \tAverage Loss:  2.219319580078125\t ACC train:  0.6488888888888888\t ACC test:  0.6288888888888889\n",
      "\tEpoch 196: \tAverage Loss:  2.2201614990234373\t ACC train:  0.6488888888888888\t ACC test:  0.6266666666666667\n",
      "\tEpoch 197: \tAverage Loss:  2.2174090576171874\t ACC train:  0.6455555555555555\t ACC test:  0.6177777777777778\n",
      "\tEpoch 198: \tAverage Loss:  2.2168308715820313\t ACC train:  0.6533333333333333\t ACC test:  0.6222222222222222\n",
      "\tEpoch 199: \tAverage Loss:  2.219547546386719\t ACC train:  0.6488888888888888\t ACC test:  0.6222222222222222\n",
      "\tEpoch 200: \tAverage Loss:  2.2123179931640626\t ACC train:  0.6544444444444445\t ACC test:  0.6177777777777778\n",
      "\tEpoch 201: \tAverage Loss:  2.2107990112304687\t ACC train:  0.6544444444444445\t ACC test:  0.6133333333333333\n",
      "\tEpoch 202: \tAverage Loss:  2.2100662841796876\t ACC train:  0.6544444444444445\t ACC test:  0.6288888888888889\n",
      "\tEpoch 203: \tAverage Loss:  2.210613952636719\t ACC train:  0.6533333333333333\t ACC test:  0.6088888888888889\n",
      "\tEpoch 204: \tAverage Loss:  2.2077216796875\t ACC train:  0.6488888888888888\t ACC test:  0.6266666666666667\n",
      "\tEpoch 205: \tAverage Loss:  2.209527893066406\t ACC train:  0.65\t ACC test:  0.6177777777777778\n",
      "\tEpoch 206: \tAverage Loss:  2.211345947265625\t ACC train:  0.6566666666666666\t ACC test:  0.6311111111111111\n",
      "\tEpoch 207: \tAverage Loss:  2.208217590332031\t ACC train:  0.6455555555555555\t ACC test:  0.6333333333333333\n",
      "\tEpoch 208: \tAverage Loss:  2.2047714233398437\t ACC train:  0.6577777777777778\t ACC test:  0.6222222222222222\n",
      "\tEpoch 209: \tAverage Loss:  2.2047532348632815\t ACC train:  0.6477777777777778\t ACC test:  0.6244444444444445\n",
      "\tEpoch 210: \tAverage Loss:  2.20428662109375\t ACC train:  0.6455555555555555\t ACC test:  0.6222222222222222\n",
      "\tEpoch 211: \tAverage Loss:  2.205221130371094\t ACC train:  0.65\t ACC test:  0.6266666666666667\n",
      "\tEpoch 212: \tAverage Loss:  2.1995640869140627\t ACC train:  0.6544444444444445\t ACC test:  0.64\n",
      "\tEpoch 213: \tAverage Loss:  2.2013118896484376\t ACC train:  0.6488888888888888\t ACC test:  0.6266666666666667\n",
      "\tEpoch 214: \tAverage Loss:  2.2020531005859376\t ACC train:  0.6522222222222223\t ACC test:  0.6222222222222222\n",
      "\tEpoch 215: \tAverage Loss:  2.199222595214844\t ACC train:  0.6544444444444445\t ACC test:  0.6311111111111111\n",
      "\tEpoch 216: \tAverage Loss:  2.19683251953125\t ACC train:  0.6577777777777778\t ACC test:  0.6244444444444445\n",
      "\tEpoch 217: \tAverage Loss:  2.196304748535156\t ACC train:  0.6511111111111111\t ACC test:  0.6333333333333333\n",
      "\tEpoch 218: \tAverage Loss:  2.1983093872070314\t ACC train:  0.65\t ACC test:  0.62\n",
      "\tEpoch 219: \tAverage Loss:  2.1990458984375\t ACC train:  0.6522222222222223\t ACC test:  0.6266666666666667\n",
      "\tEpoch 220: \tAverage Loss:  2.1956115112304686\t ACC train:  0.66\t ACC test:  0.6266666666666667\n",
      "\tEpoch 221: \tAverage Loss:  2.1941611328125\t ACC train:  0.6555555555555556\t ACC test:  0.6177777777777778\n",
      "\tEpoch 222: \tAverage Loss:  2.19347265625\t ACC train:  0.65\t ACC test:  0.6355555555555555\n",
      "\tEpoch 223: \tAverage Loss:  2.1908426513671877\t ACC train:  0.6622222222222223\t ACC test:  0.6333333333333333\n",
      "\tEpoch 224: \tAverage Loss:  2.1936066284179687\t ACC train:  0.6577777777777778\t ACC test:  0.64\n",
      "\tEpoch 225: \tAverage Loss:  2.190960876464844\t ACC train:  0.6588888888888889\t ACC test:  0.6311111111111111\n",
      "\tEpoch 226: \tAverage Loss:  2.191746032714844\t ACC train:  0.6588888888888889\t ACC test:  0.6355555555555555\n",
      "\tEpoch 227: \tAverage Loss:  2.191941650390625\t ACC train:  0.6577777777777778\t ACC test:  0.6288888888888889\n",
      "\tEpoch 228: \tAverage Loss:  2.1901724243164065\t ACC train:  0.66\t ACC test:  0.6288888888888889\n",
      "\tEpoch 229: \tAverage Loss:  2.193148742675781\t ACC train:  0.6633333333333333\t ACC test:  0.64\n",
      "\tEpoch 230: \tAverage Loss:  2.1916849365234374\t ACC train:  0.6566666666666666\t ACC test:  0.6266666666666667\n",
      "\tEpoch 231: \tAverage Loss:  2.1901644287109376\t ACC train:  0.6566666666666666\t ACC test:  0.6311111111111111\n",
      "\tEpoch 232: \tAverage Loss:  2.188978088378906\t ACC train:  0.6577777777777778\t ACC test:  0.64\n",
      "\tEpoch 233: \tAverage Loss:  2.1864443969726564\t ACC train:  0.6577777777777778\t ACC test:  0.6244444444444445\n",
      "\tEpoch 234: \tAverage Loss:  2.184027099609375\t ACC train:  0.6555555555555556\t ACC test:  0.6288888888888889\n",
      "\tEpoch 235: \tAverage Loss:  2.1876552734375\t ACC train:  0.6633333333333333\t ACC test:  0.6333333333333333\n",
      "\tEpoch 236: \tAverage Loss:  2.183235107421875\t ACC train:  0.66\t ACC test:  0.6466666666666666\n",
      "\tEpoch 237: \tAverage Loss:  2.1833158569335938\t ACC train:  0.6611111111111111\t ACC test:  0.6422222222222222\n",
      "\tEpoch 238: \tAverage Loss:  2.1819852905273436\t ACC train:  0.6588888888888889\t ACC test:  0.6244444444444445\n",
      "\tEpoch 239: \tAverage Loss:  2.182118896484375\t ACC train:  0.6622222222222223\t ACC test:  0.6333333333333333\n",
      "\tEpoch 240: \tAverage Loss:  2.181681579589844\t ACC train:  0.6644444444444444\t ACC test:  0.6333333333333333\n",
      "\tEpoch 241: \tAverage Loss:  2.179300964355469\t ACC train:  0.6711111111111111\t ACC test:  0.6444444444444445\n",
      "\tEpoch 242: \tAverage Loss:  2.1808838500976564\t ACC train:  0.6644444444444444\t ACC test:  0.6422222222222222\n",
      "\tEpoch 243: \tAverage Loss:  2.1811621704101563\t ACC train:  0.6677777777777778\t ACC test:  0.64\n",
      "\tEpoch 244: \tAverage Loss:  2.180253662109375\t ACC train:  0.6533333333333333\t ACC test:  0.6222222222222222\n",
      "\tEpoch 245: \tAverage Loss:  2.1769903564453124\t ACC train:  0.6622222222222223\t ACC test:  0.6422222222222222\n",
      "\tEpoch 246: \tAverage Loss:  2.180711181640625\t ACC train:  0.66\t ACC test:  0.6333333333333333\n",
      "\tEpoch 247: \tAverage Loss:  2.1761907348632814\t ACC train:  0.6633333333333333\t ACC test:  0.64\n",
      "\tEpoch 248: \tAverage Loss:  2.1765882568359376\t ACC train:  0.6666666666666666\t ACC test:  0.6422222222222222\n",
      "\tEpoch 249: \tAverage Loss:  2.175079345703125\t ACC train:  0.66\t ACC test:  0.64\n",
      "\tEpoch 250: \tAverage Loss:  2.171017822265625\t ACC train:  0.67\t ACC test:  0.6422222222222222\n",
      "\tEpoch 251: \tAverage Loss:  2.1751823120117186\t ACC train:  0.6666666666666666\t ACC test:  0.64\n",
      "\tEpoch 252: \tAverage Loss:  2.1752854614257813\t ACC train:  0.6677777777777778\t ACC test:  0.6444444444444445\n",
      "\tEpoch 253: \tAverage Loss:  2.1730293579101563\t ACC train:  0.6655555555555556\t ACC test:  0.6355555555555555\n",
      "\tEpoch 254: \tAverage Loss:  2.174236083984375\t ACC train:  0.6688888888888889\t ACC test:  0.64\n",
      "\tEpoch 255: \tAverage Loss:  2.172862060546875\t ACC train:  0.6655555555555556\t ACC test:  0.6355555555555555\n",
      "\tEpoch 256: \tAverage Loss:  2.1732959594726564\t ACC train:  0.6711111111111111\t ACC test:  0.6333333333333333\n",
      "\tEpoch 257: \tAverage Loss:  2.1720379638671874\t ACC train:  0.6655555555555556\t ACC test:  0.6377777777777778\n",
      "\tEpoch 258: \tAverage Loss:  2.1690532836914063\t ACC train:  0.6655555555555556\t ACC test:  0.6488888888888888\n",
      "\tEpoch 259: \tAverage Loss:  2.1714942626953126\t ACC train:  0.6688888888888889\t ACC test:  0.6333333333333333\n",
      "\tEpoch 260: \tAverage Loss:  2.1689999389648436\t ACC train:  0.6666666666666666\t ACC test:  0.6422222222222222\n",
      "\tEpoch 261: \tAverage Loss:  2.1706304931640625\t ACC train:  0.6666666666666666\t ACC test:  0.64\n",
      "\tEpoch 262: \tAverage Loss:  2.1664847412109376\t ACC train:  0.6655555555555556\t ACC test:  0.6377777777777778\n",
      "\tEpoch 263: \tAverage Loss:  2.1682041015625\t ACC train:  0.6711111111111111\t ACC test:  0.6355555555555555\n",
      "\tEpoch 264: \tAverage Loss:  2.1660439453125\t ACC train:  0.6733333333333333\t ACC test:  0.6444444444444445\n",
      "\tEpoch 265: \tAverage Loss:  2.164598876953125\t ACC train:  0.67\t ACC test:  0.6533333333333333\n",
      "\tEpoch 266: \tAverage Loss:  2.167181884765625\t ACC train:  0.67\t ACC test:  0.6466666666666666\n",
      "\tEpoch 267: \tAverage Loss:  2.1652123413085937\t ACC train:  0.6722222222222223\t ACC test:  0.6422222222222222\n",
      "\tEpoch 268: \tAverage Loss:  2.164163391113281\t ACC train:  0.6744444444444444\t ACC test:  0.6422222222222222\n",
      "\tEpoch 269: \tAverage Loss:  2.1633399047851563\t ACC train:  0.6722222222222223\t ACC test:  0.64\n",
      "\tEpoch 270: \tAverage Loss:  2.167001037597656\t ACC train:  0.6666666666666666\t ACC test:  0.6355555555555555\n",
      "\tEpoch 271: \tAverage Loss:  2.161248291015625\t ACC train:  0.67\t ACC test:  0.6355555555555555\n",
      "\tEpoch 272: \tAverage Loss:  2.1628836669921876\t ACC train:  0.6722222222222223\t ACC test:  0.6444444444444445\n",
      "\tEpoch 273: \tAverage Loss:  2.1603018798828124\t ACC train:  0.6733333333333333\t ACC test:  0.6488888888888888\n",
      "\tEpoch 274: \tAverage Loss:  2.1622379150390625\t ACC train:  0.6744444444444444\t ACC test:  0.64\n",
      "\tEpoch 275: \tAverage Loss:  2.161129150390625\t ACC train:  0.6755555555555556\t ACC test:  0.6533333333333333\n",
      "\tEpoch 276: \tAverage Loss:  2.1622582397460937\t ACC train:  0.67\t ACC test:  0.64\n",
      "\tEpoch 277: \tAverage Loss:  2.159345764160156\t ACC train:  0.6766666666666666\t ACC test:  0.6422222222222222\n",
      "\tEpoch 278: \tAverage Loss:  2.157961975097656\t ACC train:  0.6722222222222223\t ACC test:  0.6466666666666666\n",
      "\tEpoch 279: \tAverage Loss:  2.158232849121094\t ACC train:  0.6744444444444444\t ACC test:  0.6466666666666666\n",
      "\tEpoch 280: \tAverage Loss:  2.1594174194335936\t ACC train:  0.6766666666666666\t ACC test:  0.6444444444444445\n",
      "\tEpoch 281: \tAverage Loss:  2.160220886230469\t ACC train:  0.6733333333333333\t ACC test:  0.6377777777777778\n",
      "\tEpoch 282: \tAverage Loss:  2.158739562988281\t ACC train:  0.6777777777777778\t ACC test:  0.6444444444444445\n",
      "\tEpoch 283: \tAverage Loss:  2.1566669311523436\t ACC train:  0.67\t ACC test:  0.6511111111111111\n",
      "\tEpoch 284: \tAverage Loss:  2.1550137329101564\t ACC train:  0.6744444444444444\t ACC test:  0.6533333333333333\n",
      "\tEpoch 285: \tAverage Loss:  2.1564320678710938\t ACC train:  0.68\t ACC test:  0.6422222222222222\n",
      "\tEpoch 286: \tAverage Loss:  2.157577880859375\t ACC train:  0.6766666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 287: \tAverage Loss:  2.155406188964844\t ACC train:  0.6788888888888889\t ACC test:  0.6466666666666666\n",
      "\tEpoch 288: \tAverage Loss:  2.153782958984375\t ACC train:  0.6711111111111111\t ACC test:  0.6444444444444445\n",
      "\tEpoch 289: \tAverage Loss:  2.153015441894531\t ACC train:  0.6722222222222223\t ACC test:  0.6377777777777778\n",
      "\tEpoch 290: \tAverage Loss:  2.1549736328125\t ACC train:  0.6722222222222223\t ACC test:  0.6511111111111111\n",
      "\tEpoch 291: \tAverage Loss:  2.1539324340820314\t ACC train:  0.6766666666666666\t ACC test:  0.6444444444444445\n",
      "\tEpoch 292: \tAverage Loss:  2.1543440551757813\t ACC train:  0.6711111111111111\t ACC test:  0.6555555555555556\n",
      "\tEpoch 293: \tAverage Loss:  2.1523029174804686\t ACC train:  0.6755555555555556\t ACC test:  0.6422222222222222\n",
      "\tEpoch 294: \tAverage Loss:  2.149724853515625\t ACC train:  0.6766666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 295: \tAverage Loss:  2.1512664184570314\t ACC train:  0.6755555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 296: \tAverage Loss:  2.152478454589844\t ACC train:  0.6711111111111111\t ACC test:  0.6511111111111111\n",
      "\tEpoch 297: \tAverage Loss:  2.1510885009765626\t ACC train:  0.6766666666666666\t ACC test:  0.6488888888888888\n",
      "\tEpoch 298: \tAverage Loss:  2.1503939819335938\t ACC train:  0.6788888888888889\t ACC test:  0.6533333333333333\n",
      "\tEpoch 299: \tAverage Loss:  2.14994287109375\t ACC train:  0.6755555555555556\t ACC test:  0.6533333333333333\n",
      "\tEpoch 300: \tAverage Loss:  2.1484203491210936\t ACC train:  0.6777777777777778\t ACC test:  0.6555555555555556\n",
      "\tEpoch 301: \tAverage Loss:  2.14991748046875\t ACC train:  0.6766666666666666\t ACC test:  0.6466666666666666\n",
      "\tEpoch 302: \tAverage Loss:  2.1489415283203126\t ACC train:  0.6755555555555556\t ACC test:  0.66\n",
      "\tEpoch 303: \tAverage Loss:  2.1482697143554685\t ACC train:  0.6777777777777778\t ACC test:  0.6511111111111111\n",
      "\tEpoch 304: \tAverage Loss:  2.146363098144531\t ACC train:  0.68\t ACC test:  0.6533333333333333\n",
      "\tEpoch 305: \tAverage Loss:  2.146033508300781\t ACC train:  0.6822222222222222\t ACC test:  0.6511111111111111\n",
      "\tEpoch 306: \tAverage Loss:  2.1458016357421874\t ACC train:  0.6755555555555556\t ACC test:  0.6422222222222222\n",
      "\tEpoch 307: \tAverage Loss:  2.1449506225585937\t ACC train:  0.6788888888888889\t ACC test:  0.6488888888888888\n",
      "\tEpoch 308: \tAverage Loss:  2.1459981689453125\t ACC train:  0.6822222222222222\t ACC test:  0.6533333333333333\n",
      "\tEpoch 309: \tAverage Loss:  2.14430224609375\t ACC train:  0.68\t ACC test:  0.6511111111111111\n",
      "\tEpoch 310: \tAverage Loss:  2.145056640625\t ACC train:  0.6788888888888889\t ACC test:  0.6533333333333333\n",
      "\tEpoch 311: \tAverage Loss:  2.1451566162109375\t ACC train:  0.68\t ACC test:  0.66\n",
      "\tEpoch 312: \tAverage Loss:  2.1438632202148438\t ACC train:  0.6777777777777778\t ACC test:  0.6533333333333333\n",
      "\tEpoch 313: \tAverage Loss:  2.1439710083007815\t ACC train:  0.6788888888888889\t ACC test:  0.6444444444444445\n",
      "\tEpoch 314: \tAverage Loss:  2.1430013427734376\t ACC train:  0.6777777777777778\t ACC test:  0.6577777777777778\n",
      "\tEpoch 315: \tAverage Loss:  2.145032470703125\t ACC train:  0.6788888888888889\t ACC test:  0.6511111111111111\n",
      "\tEpoch 316: \tAverage Loss:  2.1429779052734377\t ACC train:  0.6788888888888889\t ACC test:  0.6555555555555556\n",
      "\tEpoch 317: \tAverage Loss:  2.1424672241210936\t ACC train:  0.6788888888888889\t ACC test:  0.6555555555555556\n",
      "\tEpoch 318: \tAverage Loss:  2.1433103637695314\t ACC train:  0.6822222222222222\t ACC test:  0.6555555555555556\n",
      "\tEpoch 319: \tAverage Loss:  2.142237731933594\t ACC train:  0.6755555555555556\t ACC test:  0.6511111111111111\n",
      "\tEpoch 320: \tAverage Loss:  2.1409284057617186\t ACC train:  0.6822222222222222\t ACC test:  0.6555555555555556\n",
      "\tEpoch 321: \tAverage Loss:  2.141577941894531\t ACC train:  0.6811111111111111\t ACC test:  0.6555555555555556\n",
      "\tEpoch 322: \tAverage Loss:  2.1404486694335936\t ACC train:  0.6822222222222222\t ACC test:  0.6511111111111111\n",
      "\tEpoch 323: \tAverage Loss:  2.139992126464844\t ACC train:  0.6788888888888889\t ACC test:  0.6555555555555556\n",
      "\tEpoch 324: \tAverage Loss:  2.1406965942382814\t ACC train:  0.68\t ACC test:  0.66\n",
      "\tEpoch 325: \tAverage Loss:  2.139174743652344\t ACC train:  0.6766666666666666\t ACC test:  0.6511111111111111\n",
      "\tEpoch 326: \tAverage Loss:  2.1389746704101564\t ACC train:  0.6744444444444444\t ACC test:  0.6533333333333333\n",
      "\tEpoch 327: \tAverage Loss:  2.138834899902344\t ACC train:  0.6811111111111111\t ACC test:  0.6511111111111111\n",
      "\tEpoch 328: \tAverage Loss:  2.138213317871094\t ACC train:  0.6833333333333333\t ACC test:  0.6555555555555556\n",
      "\tEpoch 329: \tAverage Loss:  2.137865539550781\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 330: \tAverage Loss:  2.1379480590820314\t ACC train:  0.6822222222222222\t ACC test:  0.6555555555555556\n",
      "\tEpoch 331: \tAverage Loss:  2.137036376953125\t ACC train:  0.6833333333333333\t ACC test:  0.6555555555555556\n",
      "\tEpoch 332: \tAverage Loss:  2.137695556640625\t ACC train:  0.6822222222222222\t ACC test:  0.6577777777777778\n",
      "\tEpoch 333: \tAverage Loss:  2.135765563964844\t ACC train:  0.6833333333333333\t ACC test:  0.6577777777777778\n",
      "\tEpoch 334: \tAverage Loss:  2.1352366943359375\t ACC train:  0.6844444444444444\t ACC test:  0.6533333333333333\n",
      "\tEpoch 335: \tAverage Loss:  2.1364964599609375\t ACC train:  0.6844444444444444\t ACC test:  0.66\n",
      "\tEpoch 336: \tAverage Loss:  2.1346717529296875\t ACC train:  0.6833333333333333\t ACC test:  0.6577777777777778\n",
      "\tEpoch 337: \tAverage Loss:  2.135373046875\t ACC train:  0.6811111111111111\t ACC test:  0.6555555555555556\n",
      "\tEpoch 338: \tAverage Loss:  2.1344130249023436\t ACC train:  0.6844444444444444\t ACC test:  0.6577777777777778\n",
      "\tEpoch 339: \tAverage Loss:  2.1350596313476564\t ACC train:  0.6833333333333333\t ACC test:  0.6577777777777778\n",
      "\tEpoch 340: \tAverage Loss:  2.1329310302734377\t ACC train:  0.6822222222222222\t ACC test:  0.6555555555555556\n",
      "\tEpoch 341: \tAverage Loss:  2.1338909912109374\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 342: \tAverage Loss:  2.1333154907226564\t ACC train:  0.6844444444444444\t ACC test:  0.6577777777777778\n",
      "\tEpoch 343: \tAverage Loss:  2.131685302734375\t ACC train:  0.6833333333333333\t ACC test:  0.66\n",
      "\tEpoch 344: \tAverage Loss:  2.1323378295898436\t ACC train:  0.68\t ACC test:  0.6577777777777778\n",
      "\tEpoch 345: \tAverage Loss:  2.132062805175781\t ACC train:  0.68\t ACC test:  0.6577777777777778\n",
      "\tEpoch 346: \tAverage Loss:  2.1316160888671876\t ACC train:  0.6777777777777778\t ACC test:  0.66\n",
      "\tEpoch 347: \tAverage Loss:  2.1308973388671877\t ACC train:  0.6811111111111111\t ACC test:  0.6577777777777778\n",
      "\tEpoch 348: \tAverage Loss:  2.1304771728515624\t ACC train:  0.6866666666666666\t ACC test:  0.6577777777777778\n",
      "\tEpoch 349: \tAverage Loss:  2.1296720581054687\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 350: \tAverage Loss:  2.130064208984375\t ACC train:  0.6855555555555556\t ACC test:  0.6533333333333333\n",
      "\tEpoch 351: \tAverage Loss:  2.1305059814453124\t ACC train:  0.6822222222222222\t ACC test:  0.6577777777777778\n",
      "\tEpoch 352: \tAverage Loss:  2.1306348876953125\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 353: \tAverage Loss:  2.1296533203125\t ACC train:  0.6844444444444444\t ACC test:  0.6577777777777778\n",
      "\tEpoch 354: \tAverage Loss:  2.1300803833007813\t ACC train:  0.6844444444444444\t ACC test:  0.6577777777777778\n",
      "\tEpoch 355: \tAverage Loss:  2.1279546508789062\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 356: \tAverage Loss:  2.1292250366210936\t ACC train:  0.6833333333333333\t ACC test:  0.6555555555555556\n",
      "\tEpoch 357: \tAverage Loss:  2.1279600219726564\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 358: \tAverage Loss:  2.1274054565429688\t ACC train:  0.6855555555555556\t ACC test:  0.66\n",
      "\tEpoch 359: \tAverage Loss:  2.12692919921875\t ACC train:  0.6833333333333333\t ACC test:  0.6533333333333333\n",
      "\tEpoch 360: \tAverage Loss:  2.1275650634765624\t ACC train:  0.6844444444444444\t ACC test:  0.6555555555555556\n",
      "\tEpoch 361: \tAverage Loss:  2.126701904296875\t ACC train:  0.6844444444444444\t ACC test:  0.6533333333333333\n",
      "\tEpoch 362: \tAverage Loss:  2.1264989013671873\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 363: \tAverage Loss:  2.1276156005859375\t ACC train:  0.6844444444444444\t ACC test:  0.6577777777777778\n",
      "\tEpoch 364: \tAverage Loss:  2.125461853027344\t ACC train:  0.6833333333333333\t ACC test:  0.6577777777777778\n",
      "\tEpoch 365: \tAverage Loss:  2.125729431152344\t ACC train:  0.6844444444444444\t ACC test:  0.6577777777777778\n",
      "\tEpoch 366: \tAverage Loss:  2.1255475463867186\t ACC train:  0.6866666666666666\t ACC test:  0.6622222222222223\n",
      "\tEpoch 367: \tAverage Loss:  2.1255947265625\t ACC train:  0.6822222222222222\t ACC test:  0.6577777777777778\n",
      "\tEpoch 368: \tAverage Loss:  2.124832763671875\t ACC train:  0.6844444444444444\t ACC test:  0.66\n",
      "\tEpoch 369: \tAverage Loss:  2.1238633422851563\t ACC train:  0.6844444444444444\t ACC test:  0.66\n",
      "\tEpoch 370: \tAverage Loss:  2.125117614746094\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 371: \tAverage Loss:  2.125229248046875\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 372: \tAverage Loss:  2.1239072875976563\t ACC train:  0.6855555555555556\t ACC test:  0.66\n",
      "\tEpoch 373: \tAverage Loss:  2.1229434814453123\t ACC train:  0.6844444444444444\t ACC test:  0.6577777777777778\n",
      "\tEpoch 374: \tAverage Loss:  2.1234720458984375\t ACC train:  0.6855555555555556\t ACC test:  0.66\n",
      "\tEpoch 375: \tAverage Loss:  2.122708679199219\t ACC train:  0.6866666666666666\t ACC test:  0.6577777777777778\n",
      "\tEpoch 376: \tAverage Loss:  2.1227399291992186\t ACC train:  0.6855555555555556\t ACC test:  0.6555555555555556\n",
      "\tEpoch 377: \tAverage Loss:  2.1219417724609375\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 378: \tAverage Loss:  2.121936950683594\t ACC train:  0.6844444444444444\t ACC test:  0.6577777777777778\n",
      "\tEpoch 379: \tAverage Loss:  2.1224967041015623\t ACC train:  0.6855555555555556\t ACC test:  0.66\n",
      "\tEpoch 380: \tAverage Loss:  2.122068420410156\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 381: \tAverage Loss:  2.121882568359375\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 382: \tAverage Loss:  2.1199369506835937\t ACC train:  0.6844444444444444\t ACC test:  0.66\n",
      "\tEpoch 383: \tAverage Loss:  2.1209124755859374\t ACC train:  0.6855555555555556\t ACC test:  0.66\n",
      "\tEpoch 384: \tAverage Loss:  2.119813903808594\t ACC train:  0.6866666666666666\t ACC test:  0.6577777777777778\n",
      "\tEpoch 385: \tAverage Loss:  2.119639343261719\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 386: \tAverage Loss:  2.1195589599609375\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 387: \tAverage Loss:  2.11970947265625\t ACC train:  0.6855555555555556\t ACC test:  0.6555555555555556\n",
      "\tEpoch 388: \tAverage Loss:  2.1193107299804685\t ACC train:  0.6877777777777778\t ACC test:  0.6577777777777778\n",
      "\tEpoch 389: \tAverage Loss:  2.118006103515625\t ACC train:  0.6877777777777778\t ACC test:  0.6577777777777778\n",
      "\tEpoch 390: \tAverage Loss:  2.1190219116210938\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 391: \tAverage Loss:  2.1191088256835937\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 392: \tAverage Loss:  2.1189232177734376\t ACC train:  0.6855555555555556\t ACC test:  0.66\n",
      "\tEpoch 393: \tAverage Loss:  2.117627990722656\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 394: \tAverage Loss:  2.117411376953125\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 395: \tAverage Loss:  2.1178004760742186\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 396: \tAverage Loss:  2.116863342285156\t ACC train:  0.6877777777777778\t ACC test:  0.6577777777777778\n",
      "\tEpoch 397: \tAverage Loss:  2.1179515380859373\t ACC train:  0.6855555555555556\t ACC test:  0.6577777777777778\n",
      "\tEpoch 398: \tAverage Loss:  2.116428894042969\t ACC train:  0.6855555555555556\t ACC test:  0.66\n",
      "\tEpoch 399: \tAverage Loss:  2.115519714355469\t ACC train:  0.6855555555555556\t ACC test:  0.66\n",
      "\tEpoch 400: \tAverage Loss:  2.1155076904296877\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 401: \tAverage Loss:  2.115025451660156\t ACC train:  0.6866666666666666\t ACC test:  0.66\n",
      "\tEpoch 402: \tAverage Loss:  2.1152509765625\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 403: \tAverage Loss:  2.114434020996094\t ACC train:  0.6877777777777778\t ACC test:  0.6577777777777778\n",
      "\tEpoch 404: \tAverage Loss:  2.11471533203125\t ACC train:  0.6888888888888889\t ACC test:  0.6555555555555556\n",
      "\tEpoch 405: \tAverage Loss:  2.1132708740234376\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 406: \tAverage Loss:  2.1135392456054687\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 407: \tAverage Loss:  2.1141514892578126\t ACC train:  0.6866666666666666\t ACC test:  0.6555555555555556\n",
      "\tEpoch 408: \tAverage Loss:  2.1142567749023438\t ACC train:  0.6877777777777778\t ACC test:  0.6577777777777778\n",
      "\tEpoch 409: \tAverage Loss:  2.1151536254882815\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 410: \tAverage Loss:  2.11333056640625\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 411: \tAverage Loss:  2.112747863769531\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 412: \tAverage Loss:  2.113424987792969\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 413: \tAverage Loss:  2.112921691894531\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 414: \tAverage Loss:  2.1121979370117185\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 415: \tAverage Loss:  2.112109191894531\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 416: \tAverage Loss:  2.111223693847656\t ACC train:  0.6877777777777778\t ACC test:  0.6622222222222223\n",
      "\tEpoch 417: \tAverage Loss:  2.111923095703125\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 418: \tAverage Loss:  2.1114237060546874\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 419: \tAverage Loss:  2.1101634521484374\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 420: \tAverage Loss:  2.1107037353515623\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 421: \tAverage Loss:  2.111419616699219\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 422: \tAverage Loss:  2.1104503784179687\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 423: \tAverage Loss:  2.1112925415039063\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 424: \tAverage Loss:  2.110674621582031\t ACC train:  0.6877777777777778\t ACC test:  0.6577777777777778\n",
      "\tEpoch 425: \tAverage Loss:  2.1109727172851565\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 426: \tAverage Loss:  2.110614685058594\t ACC train:  0.6888888888888889\t ACC test:  0.6622222222222223\n",
      "\tEpoch 427: \tAverage Loss:  2.109943115234375\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 428: \tAverage Loss:  2.110473937988281\t ACC train:  0.69\t ACC test:  0.6577777777777778\n",
      "\tEpoch 429: \tAverage Loss:  2.1090860595703127\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 430: \tAverage Loss:  2.1085734252929687\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 431: \tAverage Loss:  2.107908935546875\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 432: \tAverage Loss:  2.107708740234375\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 433: \tAverage Loss:  2.107542724609375\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 434: \tAverage Loss:  2.1077139282226565\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 435: \tAverage Loss:  2.10701318359375\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 436: \tAverage Loss:  2.1071016845703125\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 437: \tAverage Loss:  2.1076892700195313\t ACC train:  0.69\t ACC test:  0.6577777777777778\n",
      "\tEpoch 438: \tAverage Loss:  2.107351257324219\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 439: \tAverage Loss:  2.1088458251953126\t ACC train:  0.6888888888888889\t ACC test:  0.6577777777777778\n",
      "\tEpoch 440: \tAverage Loss:  2.107487609863281\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 441: \tAverage Loss:  2.10654296875\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 442: \tAverage Loss:  2.1055562744140626\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 443: \tAverage Loss:  2.105525146484375\t ACC train:  0.69\t ACC test:  0.6577777777777778\n",
      "\tEpoch 444: \tAverage Loss:  2.1047415771484377\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 445: \tAverage Loss:  2.1041393432617186\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 446: \tAverage Loss:  2.1046131591796877\t ACC train:  0.6888888888888889\t ACC test:  0.6622222222222223\n",
      "\tEpoch 447: \tAverage Loss:  2.1039630126953126\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 448: \tAverage Loss:  2.10371484375\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 449: \tAverage Loss:  2.1029680786132814\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 450: \tAverage Loss:  2.1038443603515624\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 451: \tAverage Loss:  2.102994384765625\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 452: \tAverage Loss:  2.1032691650390625\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 453: \tAverage Loss:  2.102924255371094\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 454: \tAverage Loss:  2.1026694946289064\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 455: \tAverage Loss:  2.1017423095703127\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 456: \tAverage Loss:  2.1021685791015625\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 457: \tAverage Loss:  2.1015391845703126\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 458: \tAverage Loss:  2.1014097900390625\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 459: \tAverage Loss:  2.101360412597656\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 460: \tAverage Loss:  2.1010994873046873\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 461: \tAverage Loss:  2.1008125\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 462: \tAverage Loss:  2.1001541748046875\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 463: \tAverage Loss:  2.1002531127929687\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 464: \tAverage Loss:  2.10081787109375\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 465: \tAverage Loss:  2.100065673828125\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 466: \tAverage Loss:  2.099590087890625\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 467: \tAverage Loss:  2.099564697265625\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 468: \tAverage Loss:  2.09938720703125\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 469: \tAverage Loss:  2.099070251464844\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 470: \tAverage Loss:  2.099080383300781\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 471: \tAverage Loss:  2.0986275634765623\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 472: \tAverage Loss:  2.0989310302734374\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 473: \tAverage Loss:  2.098402160644531\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 474: \tAverage Loss:  2.0980148315429688\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 475: \tAverage Loss:  2.097724609375\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 476: \tAverage Loss:  2.097761535644531\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 477: \tAverage Loss:  2.0973795166015625\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 478: \tAverage Loss:  2.0971815795898436\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 479: \tAverage Loss:  2.09717333984375\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 480: \tAverage Loss:  2.0976295166015624\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 481: \tAverage Loss:  2.0967059936523436\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 482: \tAverage Loss:  2.0959789428710938\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 483: \tAverage Loss:  2.0964080810546877\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 484: \tAverage Loss:  2.0957637329101564\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 485: \tAverage Loss:  2.0962041625976564\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 486: \tAverage Loss:  2.095387756347656\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 487: \tAverage Loss:  2.0958291625976564\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 488: \tAverage Loss:  2.0964725341796875\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 489: \tAverage Loss:  2.0954164428710937\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 490: \tAverage Loss:  2.09489892578125\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 491: \tAverage Loss:  2.095020263671875\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 492: \tAverage Loss:  2.0947940063476564\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 493: \tAverage Loss:  2.0955068359375\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 494: \tAverage Loss:  2.095896484375\t ACC train:  0.69\t ACC test:  0.6577777777777778\n",
      "\tEpoch 495: \tAverage Loss:  2.096974426269531\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 496: \tAverage Loss:  2.0964552612304685\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 497: \tAverage Loss:  2.096547119140625\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 498: \tAverage Loss:  2.0974228515625\t ACC train:  0.6911111111111111\t ACC test:  0.6644444444444444\n",
      "\tEpoch 499: \tAverage Loss:  2.0975843505859375\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 500: \tAverage Loss:  2.0967022705078127\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 501: \tAverage Loss:  2.0954578247070312\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 502: \tAverage Loss:  2.094042785644531\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 503: \tAverage Loss:  2.092452087402344\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 504: \tAverage Loss:  2.0919061889648436\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 505: \tAverage Loss:  2.091931579589844\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 506: \tAverage Loss:  2.0915985717773435\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 507: \tAverage Loss:  2.091820007324219\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 508: \tAverage Loss:  2.0914775390625\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 509: \tAverage Loss:  2.09138720703125\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 510: \tAverage Loss:  2.0913500366210935\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 511: \tAverage Loss:  2.0908406982421877\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 512: \tAverage Loss:  2.0904498291015625\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 513: \tAverage Loss:  2.0898685913085937\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 514: \tAverage Loss:  2.08998876953125\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 515: \tAverage Loss:  2.0900870361328123\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 516: \tAverage Loss:  2.0892171020507813\t ACC train:  0.69\t ACC test:  0.6577777777777778\n",
      "\tEpoch 517: \tAverage Loss:  2.0889508056640627\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 518: \tAverage Loss:  2.089122375488281\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 519: \tAverage Loss:  2.088775085449219\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 520: \tAverage Loss:  2.0883057861328127\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 521: \tAverage Loss:  2.0888500366210936\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 522: \tAverage Loss:  2.0883084106445313\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 523: \tAverage Loss:  2.0882601318359373\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 524: \tAverage Loss:  2.0878836669921874\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 525: \tAverage Loss:  2.088269470214844\t ACC train:  0.69\t ACC test:  0.6644444444444444\n",
      "\tEpoch 526: \tAverage Loss:  2.0880953369140625\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 527: \tAverage Loss:  2.0870346069335937\t ACC train:  0.69\t ACC test:  0.6577777777777778\n",
      "\tEpoch 528: \tAverage Loss:  2.0871605834960936\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 529: \tAverage Loss:  2.0869735717773437\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 530: \tAverage Loss:  2.0866324462890624\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 531: \tAverage Loss:  2.086632873535156\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 532: \tAverage Loss:  2.0866613159179686\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 533: \tAverage Loss:  2.0860155029296874\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 534: \tAverage Loss:  2.0858834838867186\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 535: \tAverage Loss:  2.08566552734375\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 536: \tAverage Loss:  2.0854144287109375\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 537: \tAverage Loss:  2.08490185546875\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 538: \tAverage Loss:  2.085034606933594\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 539: \tAverage Loss:  2.084769592285156\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 540: \tAverage Loss:  2.084742614746094\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 541: \tAverage Loss:  2.0846619873046874\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 542: \tAverage Loss:  2.084682861328125\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 543: \tAverage Loss:  2.084744140625\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 544: \tAverage Loss:  2.0841141967773438\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 545: \tAverage Loss:  2.0837261352539063\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 546: \tAverage Loss:  2.0834637451171876\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 547: \tAverage Loss:  2.0832941284179687\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 548: \tAverage Loss:  2.0833408813476564\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 549: \tAverage Loss:  2.0830096435546874\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 550: \tAverage Loss:  2.082670227050781\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 551: \tAverage Loss:  2.08255712890625\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 552: \tAverage Loss:  2.0824808349609376\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 553: \tAverage Loss:  2.082076843261719\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 554: \tAverage Loss:  2.0822049560546874\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 555: \tAverage Loss:  2.081664306640625\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 556: \tAverage Loss:  2.0816678466796876\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 557: \tAverage Loss:  2.0814918212890623\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 558: \tAverage Loss:  2.081495849609375\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 559: \tAverage Loss:  2.0809483642578126\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 560: \tAverage Loss:  2.08100830078125\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 561: \tAverage Loss:  2.0807952270507815\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 562: \tAverage Loss:  2.08094140625\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 563: \tAverage Loss:  2.080458251953125\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 564: \tAverage Loss:  2.0808182373046873\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 565: \tAverage Loss:  2.0809395751953126\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 566: \tAverage Loss:  2.080506774902344\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 567: \tAverage Loss:  2.0810534057617187\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 568: \tAverage Loss:  2.0817943115234376\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 569: \tAverage Loss:  2.082390869140625\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 570: \tAverage Loss:  2.0833200073242186\t ACC train:  0.69\t ACC test:  0.66\n",
      "\tEpoch 571: \tAverage Loss:  2.0835531616210936\t ACC train:  0.6911111111111111\t ACC test:  0.6644444444444444\n",
      "\tEpoch 572: \tAverage Loss:  2.083579650878906\t ACC train:  0.6877777777777778\t ACC test:  0.66\n",
      "\tEpoch 573: \tAverage Loss:  2.0866876831054686\t ACC train:  0.6911111111111111\t ACC test:  0.6644444444444444\n",
      "\tEpoch 574: \tAverage Loss:  2.086325927734375\t ACC train:  0.6888888888888889\t ACC test:  0.6555555555555556\n",
      "\tEpoch 575: \tAverage Loss:  2.0861365966796876\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 576: \tAverage Loss:  2.084042663574219\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 577: \tAverage Loss:  2.0819243774414065\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 578: \tAverage Loss:  2.079080993652344\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 579: \tAverage Loss:  2.078865234375\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 580: \tAverage Loss:  2.0790877075195313\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 581: \tAverage Loss:  2.07893505859375\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 582: \tAverage Loss:  2.078648986816406\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 583: \tAverage Loss:  2.077455322265625\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 584: \tAverage Loss:  2.0766215209960937\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 585: \tAverage Loss:  2.0768959350585936\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 586: \tAverage Loss:  2.0763837280273436\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 587: \tAverage Loss:  2.0761973266601563\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 588: \tAverage Loss:  2.0763532104492186\t ACC train:  0.6888888888888889\t ACC test:  0.66\n",
      "\tEpoch 589: \tAverage Loss:  2.0756752319335936\t ACC train:  0.6888888888888889\t ACC test:  0.6622222222222223\n",
      "\tEpoch 590: \tAverage Loss:  2.075819152832031\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 591: \tAverage Loss:  2.0747916259765624\t ACC train:  0.6888888888888889\t ACC test:  0.6622222222222223\n",
      "\tEpoch 592: \tAverage Loss:  2.0754508056640626\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 593: \tAverage Loss:  2.0751424560546874\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 594: \tAverage Loss:  2.0748822631835937\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 595: \tAverage Loss:  2.0749850463867188\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 596: \tAverage Loss:  2.0738780517578124\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 597: \tAverage Loss:  2.0739107055664063\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 598: \tAverage Loss:  2.07379638671875\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 599: \tAverage Loss:  2.0737058715820313\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 600: \tAverage Loss:  2.0743319091796875\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 601: \tAverage Loss:  2.074162353515625\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 602: \tAverage Loss:  2.073689453125\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 603: \tAverage Loss:  2.073764831542969\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 604: \tAverage Loss:  2.0732747802734375\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 605: \tAverage Loss:  2.0732979125976563\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 606: \tAverage Loss:  2.072454772949219\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 607: \tAverage Loss:  2.0718849487304687\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 608: \tAverage Loss:  2.07238232421875\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 609: \tAverage Loss:  2.072046875\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 610: \tAverage Loss:  2.07209375\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 611: \tAverage Loss:  2.0717059326171876\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 612: \tAverage Loss:  2.0717515869140626\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 613: \tAverage Loss:  2.0712135620117187\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 614: \tAverage Loss:  2.0705432739257814\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 615: \tAverage Loss:  2.0710231323242185\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 616: \tAverage Loss:  2.0707000122070314\t ACC train:  0.6911111111111111\t ACC test:  0.6644444444444444\n",
      "\tEpoch 617: \tAverage Loss:  2.0703507080078123\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 618: \tAverage Loss:  2.0696824951171875\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 619: \tAverage Loss:  2.0701129760742187\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 620: \tAverage Loss:  2.0700127563476562\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 621: \tAverage Loss:  2.069375\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 622: \tAverage Loss:  2.069563232421875\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 623: \tAverage Loss:  2.069228210449219\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 624: \tAverage Loss:  2.06894775390625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 625: \tAverage Loss:  2.0689044189453125\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 626: \tAverage Loss:  2.0691365356445313\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 627: \tAverage Loss:  2.0685294189453125\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 628: \tAverage Loss:  2.0681834716796876\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 629: \tAverage Loss:  2.068174865722656\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 630: \tAverage Loss:  2.067303955078125\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 631: \tAverage Loss:  2.067546691894531\t ACC train:  0.69\t ACC test:  0.6622222222222223\n",
      "\tEpoch 632: \tAverage Loss:  2.0676347045898438\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 633: \tAverage Loss:  2.067521240234375\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 634: \tAverage Loss:  2.0672755126953124\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 635: \tAverage Loss:  2.0665595703125\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 636: \tAverage Loss:  2.066580322265625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 637: \tAverage Loss:  2.0667035522460937\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 638: \tAverage Loss:  2.0660999145507812\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 639: \tAverage Loss:  2.0656055908203124\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 640: \tAverage Loss:  2.0654264526367188\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 641: \tAverage Loss:  2.065784606933594\t ACC train:  0.6911111111111111\t ACC test:  0.6644444444444444\n",
      "\tEpoch 642: \tAverage Loss:  2.065148132324219\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 643: \tAverage Loss:  2.0657305908203125\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 644: \tAverage Loss:  2.0645899047851564\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 645: \tAverage Loss:  2.0654635620117188\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 646: \tAverage Loss:  2.0647703247070313\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 647: \tAverage Loss:  2.064697509765625\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 648: \tAverage Loss:  2.06464013671875\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 649: \tAverage Loss:  2.065029541015625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 650: \tAverage Loss:  2.065021179199219\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 651: \tAverage Loss:  2.0644133911132814\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 652: \tAverage Loss:  2.064313232421875\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 653: \tAverage Loss:  2.0647702026367187\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 654: \tAverage Loss:  2.063754211425781\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 655: \tAverage Loss:  2.063628356933594\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 656: \tAverage Loss:  2.063923034667969\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 657: \tAverage Loss:  2.0636876220703124\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 658: \tAverage Loss:  2.0636678466796874\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 659: \tAverage Loss:  2.062757629394531\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 660: \tAverage Loss:  2.063479248046875\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 661: \tAverage Loss:  2.062827392578125\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 662: \tAverage Loss:  2.062642822265625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 663: \tAverage Loss:  2.0616939697265626\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 664: \tAverage Loss:  2.0619586181640623\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 665: \tAverage Loss:  2.0617509155273437\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 666: \tAverage Loss:  2.0625528564453126\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 667: \tAverage Loss:  2.061465576171875\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 668: \tAverage Loss:  2.0614578247070314\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 669: \tAverage Loss:  2.0617256469726564\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 670: \tAverage Loss:  2.0618509521484376\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 671: \tAverage Loss:  2.0622769775390624\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 672: \tAverage Loss:  2.061299560546875\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 673: \tAverage Loss:  2.0620001220703124\t ACC train:  0.6911111111111111\t ACC test:  0.6644444444444444\n",
      "\tEpoch 674: \tAverage Loss:  2.0620845947265627\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 675: \tAverage Loss:  2.060634521484375\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 676: \tAverage Loss:  2.060861572265625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 677: \tAverage Loss:  2.060497619628906\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 678: \tAverage Loss:  2.058962646484375\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 679: \tAverage Loss:  2.058258850097656\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 680: \tAverage Loss:  2.0572178344726564\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 681: \tAverage Loss:  2.0581029052734374\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 682: \tAverage Loss:  2.057846923828125\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 683: \tAverage Loss:  2.0575634155273437\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 684: \tAverage Loss:  2.057368103027344\t ACC train:  0.6911111111111111\t ACC test:  0.6644444444444444\n",
      "\tEpoch 685: \tAverage Loss:  2.056607604980469\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 686: \tAverage Loss:  2.0568530883789062\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 687: \tAverage Loss:  2.0572706298828125\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 688: \tAverage Loss:  2.0572153930664063\t ACC train:  0.6911111111111111\t ACC test:  0.66\n",
      "\tEpoch 689: \tAverage Loss:  2.0569313354492187\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 690: \tAverage Loss:  2.056008850097656\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 691: \tAverage Loss:  2.0560612182617186\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 692: \tAverage Loss:  2.0555159912109375\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 693: \tAverage Loss:  2.055836181640625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 694: \tAverage Loss:  2.0548665771484376\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 695: \tAverage Loss:  2.0557327270507812\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 696: \tAverage Loss:  2.0552239990234376\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 697: \tAverage Loss:  2.0545001220703125\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 698: \tAverage Loss:  2.0539192504882813\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 699: \tAverage Loss:  2.0545179443359376\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 700: \tAverage Loss:  2.054849365234375\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 701: \tAverage Loss:  2.0536939697265626\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 702: \tAverage Loss:  2.0535733032226564\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 703: \tAverage Loss:  2.053142333984375\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 704: \tAverage Loss:  2.0537181396484376\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 705: \tAverage Loss:  2.0541572265625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 706: \tAverage Loss:  2.053241455078125\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 707: \tAverage Loss:  2.053702392578125\t ACC train:  0.6911111111111111\t ACC test:  0.6622222222222223\n",
      "\tEpoch 708: \tAverage Loss:  2.054474853515625\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 709: \tAverage Loss:  2.0538685913085937\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 710: \tAverage Loss:  2.053865661621094\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 711: \tAverage Loss:  2.053734375\t ACC train:  0.6911111111111111\t ACC test:  0.6644444444444444\n",
      "\tEpoch 712: \tAverage Loss:  2.052334899902344\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 713: \tAverage Loss:  2.0523103637695312\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 714: \tAverage Loss:  2.0526591796875\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 715: \tAverage Loss:  2.0520836181640627\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 716: \tAverage Loss:  2.0514619140625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 717: \tAverage Loss:  2.050605285644531\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 718: \tAverage Loss:  2.0504334716796877\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 719: \tAverage Loss:  2.0503167114257814\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 720: \tAverage Loss:  2.0492470092773436\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 721: \tAverage Loss:  2.0504658203125\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 722: \tAverage Loss:  2.0492571411132814\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 723: \tAverage Loss:  2.049558044433594\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 724: \tAverage Loss:  2.0486990966796874\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 725: \tAverage Loss:  2.0486742553710937\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 726: \tAverage Loss:  2.049145690917969\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 727: \tAverage Loss:  2.0480693969726564\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 728: \tAverage Loss:  2.0491115112304685\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 729: \tAverage Loss:  2.0471740112304686\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 730: \tAverage Loss:  2.048671203613281\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 731: \tAverage Loss:  2.047251953125\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 732: \tAverage Loss:  2.0474247436523436\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 733: \tAverage Loss:  2.048115478515625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 734: \tAverage Loss:  2.0473004760742186\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 735: \tAverage Loss:  2.0476649169921877\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 736: \tAverage Loss:  2.0477263793945313\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 737: \tAverage Loss:  2.0467596435546875\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 738: \tAverage Loss:  2.0472159423828127\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 739: \tAverage Loss:  2.04599658203125\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 740: \tAverage Loss:  2.0470145263671875\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 741: \tAverage Loss:  2.0444258422851562\t ACC train:  0.6933333333333334\t ACC test:  0.66\n",
      "\tEpoch 742: \tAverage Loss:  2.0450814208984376\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 743: \tAverage Loss:  2.044928466796875\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 744: \tAverage Loss:  2.0442110595703125\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 745: \tAverage Loss:  2.0440234375\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 746: \tAverage Loss:  2.0435233154296877\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 747: \tAverage Loss:  2.0433226318359377\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 748: \tAverage Loss:  2.042826843261719\t ACC train:  0.6933333333333334\t ACC test:  0.66\n",
      "\tEpoch 749: \tAverage Loss:  2.0434046020507814\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 750: \tAverage Loss:  2.0418509521484376\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 751: \tAverage Loss:  2.0421085815429687\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 752: \tAverage Loss:  2.0415202026367187\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 753: \tAverage Loss:  2.0412203369140625\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 754: \tAverage Loss:  2.041360595703125\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 755: \tAverage Loss:  2.0395742797851564\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 756: \tAverage Loss:  2.0401035766601563\t ACC train:  0.6922222222222222\t ACC test:  0.6666666666666666\n",
      "\tEpoch 757: \tAverage Loss:  2.04111962890625\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 758: \tAverage Loss:  2.040409118652344\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 759: \tAverage Loss:  2.0407242431640626\t ACC train:  0.6933333333333334\t ACC test:  0.66\n",
      "\tEpoch 760: \tAverage Loss:  2.0396603393554686\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 761: \tAverage Loss:  2.0398447265625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 762: \tAverage Loss:  2.0387945556640625\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 763: \tAverage Loss:  2.040546569824219\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 764: \tAverage Loss:  2.0398355102539063\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 765: \tAverage Loss:  2.03908251953125\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 766: \tAverage Loss:  2.0382003784179688\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 767: \tAverage Loss:  2.0390743408203127\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 768: \tAverage Loss:  2.0372764282226563\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 769: \tAverage Loss:  2.036887939453125\t ACC train:  0.6933333333333334\t ACC test:  0.66\n",
      "\tEpoch 770: \tAverage Loss:  2.036520751953125\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 771: \tAverage Loss:  2.0351165161132814\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 772: \tAverage Loss:  2.036491638183594\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 773: \tAverage Loss:  2.037929748535156\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 774: \tAverage Loss:  2.0365068359375\t ACC train:  0.6933333333333334\t ACC test:  0.66\n",
      "\tEpoch 775: \tAverage Loss:  2.0359034423828124\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 776: \tAverage Loss:  2.034462890625\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 777: \tAverage Loss:  2.0345537719726563\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 778: \tAverage Loss:  2.035423828125\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 779: \tAverage Loss:  2.0355654907226564\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 780: \tAverage Loss:  2.0362399291992186\t ACC train:  0.6933333333333334\t ACC test:  0.66\n",
      "\tEpoch 781: \tAverage Loss:  2.0336244506835937\t ACC train:  0.6933333333333334\t ACC test:  0.66\n",
      "\tEpoch 782: \tAverage Loss:  2.0331768798828125\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 783: \tAverage Loss:  2.034758544921875\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 784: \tAverage Loss:  2.0325321655273436\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 785: \tAverage Loss:  2.033014404296875\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 786: \tAverage Loss:  2.0330347900390624\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 787: \tAverage Loss:  2.0312697143554685\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 788: \tAverage Loss:  2.0330843505859373\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 789: \tAverage Loss:  2.0310042724609376\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 790: \tAverage Loss:  2.0310252685546875\t ACC train:  0.6933333333333334\t ACC test:  0.66\n",
      "\tEpoch 791: \tAverage Loss:  2.03132666015625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 792: \tAverage Loss:  2.030794128417969\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 793: \tAverage Loss:  2.029834045410156\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 794: \tAverage Loss:  2.0299345703125\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 795: \tAverage Loss:  2.0293099975585935\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 796: \tAverage Loss:  2.028819580078125\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 797: \tAverage Loss:  2.0278795166015624\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 798: \tAverage Loss:  2.0275001220703124\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 799: \tAverage Loss:  2.0272372436523436\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 800: \tAverage Loss:  2.0271126098632815\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 801: \tAverage Loss:  2.0281661376953126\t ACC train:  0.6933333333333334\t ACC test:  0.66\n",
      "\tEpoch 802: \tAverage Loss:  2.026292663574219\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 803: \tAverage Loss:  2.025155517578125\t ACC train:  0.6922222222222222\t ACC test:  0.66\n",
      "\tEpoch 804: \tAverage Loss:  2.0257904052734377\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 805: \tAverage Loss:  2.0251707763671876\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 806: \tAverage Loss:  2.026197021484375\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 807: \tAverage Loss:  2.0245887451171876\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 808: \tAverage Loss:  2.02498779296875\t ACC train:  0.6922222222222222\t ACC test:  0.6555555555555556\n",
      "\tEpoch 809: \tAverage Loss:  2.024306640625\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 810: \tAverage Loss:  2.025129943847656\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 811: \tAverage Loss:  2.024411560058594\t ACC train:  0.6922222222222222\t ACC test:  0.6622222222222223\n",
      "\tEpoch 812: \tAverage Loss:  2.0221111450195313\t ACC train:  0.6922222222222222\t ACC test:  0.6644444444444444\n",
      "\tEpoch 813: \tAverage Loss:  2.0229130249023437\t ACC train:  0.6933333333333334\t ACC test:  0.6644444444444444\n",
      "\tEpoch 814: \tAverage Loss:  2.0208628540039064\t ACC train:  0.6944444444444444\t ACC test:  0.6622222222222223\n",
      "\tEpoch 815: \tAverage Loss:  2.020857482910156\t ACC train:  0.6933333333333334\t ACC test:  0.6622222222222223\n",
      "\tEpoch 816: \tAverage Loss:  2.0201043701171875\t ACC train:  0.6922222222222222\t ACC test:  0.6666666666666666\n",
      "\tEpoch 817: \tAverage Loss:  2.020039611816406\t ACC train:  0.6944444444444444\t ACC test:  0.6622222222222223\n",
      "\tEpoch 818: \tAverage Loss:  2.0194366455078123\t ACC train:  0.7011111111111111\t ACC test:  0.6666666666666666\n",
      "\tEpoch 819: \tAverage Loss:  2.0166484375\t ACC train:  0.6966666666666667\t ACC test:  0.6644444444444444\n",
      "\tEpoch 820: \tAverage Loss:  2.0197194213867187\t ACC train:  0.7\t ACC test:  0.6688888888888889\n",
      "\tEpoch 821: \tAverage Loss:  2.0172962646484374\t ACC train:  0.7044444444444444\t ACC test:  0.6622222222222223\n",
      "\tEpoch 822: \tAverage Loss:  2.0166292724609374\t ACC train:  0.6977777777777778\t ACC test:  0.6777777777777778\n",
      "\tEpoch 823: \tAverage Loss:  2.018592346191406\t ACC train:  0.7022222222222222\t ACC test:  0.6733333333333333\n",
      "\tEpoch 824: \tAverage Loss:  2.0153538208007813\t ACC train:  0.7166666666666667\t ACC test:  0.6733333333333333\n",
      "\tEpoch 825: \tAverage Loss:  2.0171595458984375\t ACC train:  0.7066666666666667\t ACC test:  0.6755555555555556\n",
      "\tEpoch 826: \tAverage Loss:  2.0137594604492186\t ACC train:  0.7088888888888889\t ACC test:  0.6866666666666666\n",
      "\tEpoch 827: \tAverage Loss:  2.0145400390625\t ACC train:  0.7266666666666667\t ACC test:  0.7022222222222222\n",
      "\tEpoch 828: \tAverage Loss:  2.0121332397460936\t ACC train:  0.7233333333333334\t ACC test:  0.7022222222222222\n",
      "\tEpoch 829: \tAverage Loss:  2.013562194824219\t ACC train:  0.7322222222222222\t ACC test:  0.7022222222222222\n",
      "\tEpoch 830: \tAverage Loss:  2.0121288452148436\t ACC train:  0.7555555555555555\t ACC test:  0.7177777777777777\n",
      "\tEpoch 831: \tAverage Loss:  2.0139451904296877\t ACC train:  0.7366666666666667\t ACC test:  0.7155555555555555\n",
      "\tEpoch 832: \tAverage Loss:  2.0135797119140624\t ACC train:  0.7266666666666667\t ACC test:  0.7022222222222222\n",
      "\tEpoch 833: \tAverage Loss:  2.011266357421875\t ACC train:  0.7144444444444444\t ACC test:  0.7066666666666667\n",
      "\tEpoch 834: \tAverage Loss:  2.011035583496094\t ACC train:  0.7322222222222222\t ACC test:  0.7066666666666667\n",
      "\tEpoch 835: \tAverage Loss:  2.009170166015625\t ACC train:  0.76\t ACC test:  0.7422222222222222\n",
      "\tEpoch 836: \tAverage Loss:  2.009841735839844\t ACC train:  0.7811111111111111\t ACC test:  0.7577777777777778\n",
      "\tEpoch 837: \tAverage Loss:  2.0070892333984376\t ACC train:  0.7966666666666666\t ACC test:  0.7733333333333333\n",
      "\tEpoch 838: \tAverage Loss:  2.0059317626953126\t ACC train:  0.8044444444444444\t ACC test:  0.7955555555555556\n",
      "\tEpoch 839: \tAverage Loss:  2.0062440185546877\t ACC train:  0.8133333333333334\t ACC test:  0.7888888888888889\n",
      "\tEpoch 840: \tAverage Loss:  2.0055635986328126\t ACC train:  0.8177777777777778\t ACC test:  0.7888888888888889\n",
      "\tEpoch 841: \tAverage Loss:  2.004537780761719\t ACC train:  0.8055555555555556\t ACC test:  0.7844444444444445\n",
      "\tEpoch 842: \tAverage Loss:  2.0057893676757814\t ACC train:  0.7844444444444445\t ACC test:  0.7733333333333333\n",
      "\tEpoch 843: \tAverage Loss:  2.0026324462890623\t ACC train:  0.8055555555555556\t ACC test:  0.7955555555555556\n",
      "\tEpoch 844: \tAverage Loss:  2.0014595947265623\t ACC train:  0.8155555555555556\t ACC test:  0.7911111111111111\n",
      "\tEpoch 845: \tAverage Loss:  2.002329833984375\t ACC train:  0.8377777777777777\t ACC test:  0.8177777777777778\n",
      "\tEpoch 846: \tAverage Loss:  2.0018259887695313\t ACC train:  0.8566666666666667\t ACC test:  0.8155555555555556\n",
      "\tEpoch 847: \tAverage Loss:  1.9985240478515625\t ACC train:  0.8622222222222222\t ACC test:  0.8444444444444444\n",
      "\tEpoch 848: \tAverage Loss:  1.998496337890625\t ACC train:  0.8522222222222222\t ACC test:  0.8355555555555556\n",
      "\tEpoch 849: \tAverage Loss:  1.9994944458007813\t ACC train:  0.8611111111111112\t ACC test:  0.8288888888888889\n",
      "\tEpoch 850: \tAverage Loss:  1.9973676147460937\t ACC train:  0.8577777777777778\t ACC test:  0.8333333333333334\n",
      "\tEpoch 851: \tAverage Loss:  1.9982549438476562\t ACC train:  0.8211111111111111\t ACC test:  0.8\n",
      "\tEpoch 852: \tAverage Loss:  1.9955369262695313\t ACC train:  0.8522222222222222\t ACC test:  0.8177777777777778\n",
      "\tEpoch 853: \tAverage Loss:  1.9957675170898437\t ACC train:  0.8666666666666667\t ACC test:  0.8355555555555556\n",
      "\tEpoch 854: \tAverage Loss:  1.9931455078125\t ACC train:  0.8888888888888888\t ACC test:  0.8733333333333333\n",
      "\tEpoch 855: \tAverage Loss:  1.9925916137695312\t ACC train:  0.89\t ACC test:  0.8577777777777778\n",
      "\tEpoch 856: \tAverage Loss:  1.991459716796875\t ACC train:  0.8966666666666666\t ACC test:  0.8622222222222222\n",
      "\tEpoch 857: \tAverage Loss:  1.9907440185546874\t ACC train:  0.8888888888888888\t ACC test:  0.8711111111111111\n",
      "\tEpoch 858: \tAverage Loss:  1.9906630859375\t ACC train:  0.8711111111111111\t ACC test:  0.8577777777777778\n",
      "\tEpoch 859: \tAverage Loss:  1.9959030151367188\t ACC train:  0.8877777777777778\t ACC test:  0.8466666666666667\n",
      "\tEpoch 860: \tAverage Loss:  1.99138671875\t ACC train:  0.8466666666666667\t ACC test:  0.8488888888888889\n",
      "\tEpoch 861: \tAverage Loss:  1.9932979125976562\t ACC train:  0.8911111111111111\t ACC test:  0.8644444444444445\n",
      "\tEpoch 862: \tAverage Loss:  1.9865867309570313\t ACC train:  0.8822222222222222\t ACC test:  0.8711111111111111\n",
      "\tEpoch 863: \tAverage Loss:  1.9851632080078125\t ACC train:  0.8888888888888888\t ACC test:  0.8866666666666667\n",
      "\tEpoch 864: \tAverage Loss:  1.98643603515625\t ACC train:  0.8988888888888888\t ACC test:  0.88\n",
      "\tEpoch 865: \tAverage Loss:  1.9824150390625\t ACC train:  0.8977777777777778\t ACC test:  0.8844444444444445\n",
      "\tEpoch 866: \tAverage Loss:  1.9811512451171875\t ACC train:  0.9077777777777778\t ACC test:  0.8822222222222222\n",
      "\tEpoch 867: \tAverage Loss:  1.9808780517578124\t ACC train:  0.9033333333333333\t ACC test:  0.9\n",
      "\tEpoch 868: \tAverage Loss:  1.9813619995117187\t ACC train:  0.8977777777777778\t ACC test:  0.8933333333333333\n",
      "\tEpoch 869: \tAverage Loss:  1.9785371704101562\t ACC train:  0.9077777777777778\t ACC test:  0.8977777777777778\n",
      "\tEpoch 870: \tAverage Loss:  1.9741087036132812\t ACC train:  0.9122222222222223\t ACC test:  0.8866666666666667\n",
      "\tEpoch 871: \tAverage Loss:  1.9745906982421875\t ACC train:  0.9055555555555556\t ACC test:  0.8755555555555555\n",
      "\tEpoch 872: \tAverage Loss:  1.9734985961914062\t ACC train:  0.9044444444444445\t ACC test:  0.8933333333333333\n",
      "\tEpoch 873: \tAverage Loss:  1.9700513305664062\t ACC train:  0.9155555555555556\t ACC test:  0.8977777777777778\n",
      "\tEpoch 874: \tAverage Loss:  1.9720534057617187\t ACC train:  0.9077777777777778\t ACC test:  0.8955555555555555\n",
      "\tEpoch 875: \tAverage Loss:  1.968100830078125\t ACC train:  0.9177777777777778\t ACC test:  0.8955555555555555\n",
      "\tEpoch 876: \tAverage Loss:  1.96358544921875\t ACC train:  0.9133333333333333\t ACC test:  0.8933333333333333\n",
      "\tEpoch 877: \tAverage Loss:  1.9629818725585937\t ACC train:  0.9166666666666666\t ACC test:  0.8977777777777778\n",
      "\tEpoch 878: \tAverage Loss:  1.961208251953125\t ACC train:  0.9055555555555556\t ACC test:  0.9088888888888889\n",
      "\tEpoch 879: \tAverage Loss:  1.9615427856445313\t ACC train:  0.9188888888888889\t ACC test:  0.9088888888888889\n",
      "\tEpoch 880: \tAverage Loss:  1.96080810546875\t ACC train:  0.9166666666666666\t ACC test:  0.9088888888888889\n",
      "\tEpoch 881: \tAverage Loss:  1.9512183837890624\t ACC train:  0.9311111111111111\t ACC test:  0.9377777777777778\n",
      "\tEpoch 882: \tAverage Loss:  1.9504243774414063\t ACC train:  0.9277777777777778\t ACC test:  0.8955555555555555\n",
      "\tEpoch 883: \tAverage Loss:  1.952280029296875\t ACC train:  0.93\t ACC test:  0.9355555555555556\n",
      "\tEpoch 884: \tAverage Loss:  1.9537252197265624\t ACC train:  0.9344444444444444\t ACC test:  0.92\n",
      "\tEpoch 885: \tAverage Loss:  1.94408984375\t ACC train:  0.9255555555555556\t ACC test:  0.9266666666666666\n",
      "\tEpoch 886: \tAverage Loss:  1.9428154296875\t ACC train:  0.9366666666666666\t ACC test:  0.94\n",
      "\tEpoch 887: \tAverage Loss:  1.9410969848632813\t ACC train:  0.9377777777777778\t ACC test:  0.9244444444444444\n",
      "\tEpoch 888: \tAverage Loss:  1.9369558715820312\t ACC train:  0.9355555555555556\t ACC test:  0.92\n",
      "\tEpoch 889: \tAverage Loss:  1.9294447631835938\t ACC train:  0.9466666666666667\t ACC test:  0.9466666666666667\n",
      "\tEpoch 890: \tAverage Loss:  1.9305678100585937\t ACC train:  0.9511111111111111\t ACC test:  0.9422222222222222\n",
      "\tEpoch 891: \tAverage Loss:  1.9271181640625\t ACC train:  0.9477777777777778\t ACC test:  0.9444444444444444\n",
      "\tEpoch 892: \tAverage Loss:  1.92531005859375\t ACC train:  0.96\t ACC test:  0.9422222222222222\n",
      "\tEpoch 893: \tAverage Loss:  1.9182789916992187\t ACC train:  0.9488888888888889\t ACC test:  0.9266666666666666\n",
      "\tEpoch 894: \tAverage Loss:  1.9146361694335938\t ACC train:  0.9611111111111111\t ACC test:  0.9511111111111111\n",
      "\tEpoch 895: \tAverage Loss:  1.9097857666015625\t ACC train:  0.9511111111111111\t ACC test:  0.9644444444444444\n",
      "\tEpoch 896: \tAverage Loss:  1.9046470947265626\t ACC train:  0.9577777777777777\t ACC test:  0.96\n",
      "\tEpoch 897: \tAverage Loss:  1.89829248046875\t ACC train:  0.9677777777777777\t ACC test:  0.9533333333333334\n",
      "\tEpoch 898: \tAverage Loss:  1.8873470458984376\t ACC train:  0.9611111111111111\t ACC test:  0.9666666666666667\n",
      "\tEpoch 899: \tAverage Loss:  1.8839318237304687\t ACC train:  0.9666666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 900: \tAverage Loss:  1.8717186279296876\t ACC train:  0.9688888888888889\t ACC test:  0.9577777777777777\n",
      "\tEpoch 901: \tAverage Loss:  1.8685411987304688\t ACC train:  0.9588888888888889\t ACC test:  0.96\n",
      "\tEpoch 902: \tAverage Loss:  1.8619417114257812\t ACC train:  0.9622222222222222\t ACC test:  0.9577777777777777\n",
      "\tEpoch 903: \tAverage Loss:  1.8559966430664063\t ACC train:  0.9666666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 904: \tAverage Loss:  1.8397998046875\t ACC train:  0.9655555555555555\t ACC test:  0.96\n",
      "\tEpoch 905: \tAverage Loss:  1.8329642333984375\t ACC train:  0.9677777777777777\t ACC test:  0.9733333333333334\n",
      "\tEpoch 906: \tAverage Loss:  1.8278382568359375\t ACC train:  0.9666666666666667\t ACC test:  0.96\n",
      "\tEpoch 907: \tAverage Loss:  1.8211654052734374\t ACC train:  0.9666666666666667\t ACC test:  0.9644444444444444\n",
      "\tEpoch 908: \tAverage Loss:  1.8142605590820313\t ACC train:  0.9688888888888889\t ACC test:  0.9555555555555556\n",
      "\tEpoch 909: \tAverage Loss:  1.7944921875\t ACC train:  0.97\t ACC test:  0.9555555555555556\n",
      "\tEpoch 910: \tAverage Loss:  1.7859222412109375\t ACC train:  0.9633333333333334\t ACC test:  0.9511111111111111\n",
      "\tEpoch 911: \tAverage Loss:  1.7763690795898437\t ACC train:  0.9611111111111111\t ACC test:  0.9488888888888889\n",
      "\tEpoch 912: \tAverage Loss:  1.7676431274414062\t ACC train:  0.9644444444444444\t ACC test:  0.96\n",
      "\tEpoch 913: \tAverage Loss:  1.763911376953125\t ACC train:  0.96\t ACC test:  0.9577777777777777\n",
      "\tEpoch 914: \tAverage Loss:  1.7550762939453124\t ACC train:  0.9566666666666667\t ACC test:  0.9533333333333334\n",
      "\tEpoch 915: \tAverage Loss:  1.741579833984375\t ACC train:  0.9588888888888889\t ACC test:  0.9577777777777777\n",
      "\tEpoch 916: \tAverage Loss:  1.7353552856445313\t ACC train:  0.9544444444444444\t ACC test:  0.9466666666666667\n",
      "\tEpoch 917: \tAverage Loss:  1.7244049072265626\t ACC train:  0.9633333333333334\t ACC test:  0.9533333333333334\n",
      "\tEpoch 918: \tAverage Loss:  1.7173527221679687\t ACC train:  0.9533333333333334\t ACC test:  0.9488888888888889\n",
      "\tEpoch 919: \tAverage Loss:  1.708052978515625\t ACC train:  0.9522222222222222\t ACC test:  0.9533333333333334\n",
      "\tEpoch 920: \tAverage Loss:  1.700773681640625\t ACC train:  0.9511111111111111\t ACC test:  0.9488888888888889\n",
      "\tEpoch 921: \tAverage Loss:  1.693874267578125\t ACC train:  0.9544444444444444\t ACC test:  0.9488888888888889\n",
      "\tEpoch 922: \tAverage Loss:  1.6894126586914062\t ACC train:  0.9444444444444444\t ACC test:  0.9466666666666667\n",
      "\tEpoch 923: \tAverage Loss:  1.6834395141601564\t ACC train:  0.9366666666666666\t ACC test:  0.9466666666666667\n",
      "\tEpoch 924: \tAverage Loss:  1.6812864379882813\t ACC train:  0.9455555555555556\t ACC test:  0.9488888888888889\n",
      "\tEpoch 925: \tAverage Loss:  1.6730507202148437\t ACC train:  0.9466666666666667\t ACC test:  0.9422222222222222\n",
      "\tEpoch 926: \tAverage Loss:  1.6695248413085937\t ACC train:  0.9455555555555556\t ACC test:  0.9466666666666667\n",
      "\tEpoch 927: \tAverage Loss:  1.6647064208984375\t ACC train:  0.9433333333333334\t ACC test:  0.94\n",
      "\tEpoch 928: \tAverage Loss:  1.663373291015625\t ACC train:  0.9488888888888889\t ACC test:  0.9511111111111111\n",
      "\tEpoch 929: \tAverage Loss:  1.6560634765625\t ACC train:  0.9488888888888889\t ACC test:  0.9511111111111111\n",
      "\tEpoch 930: \tAverage Loss:  1.6556983032226562\t ACC train:  0.9444444444444444\t ACC test:  0.9488888888888889\n",
      "\tEpoch 931: \tAverage Loss:  1.6510761108398437\t ACC train:  0.9455555555555556\t ACC test:  0.94\n",
      "\tEpoch 932: \tAverage Loss:  1.6480130615234374\t ACC train:  0.9477777777777778\t ACC test:  0.9422222222222222\n",
      "\tEpoch 933: \tAverage Loss:  1.6452191772460938\t ACC train:  0.9477777777777778\t ACC test:  0.9422222222222222\n",
      "\tEpoch 934: \tAverage Loss:  1.6427332153320313\t ACC train:  0.9466666666666667\t ACC test:  0.9488888888888889\n",
      "\tEpoch 935: \tAverage Loss:  1.6394542236328125\t ACC train:  0.9433333333333334\t ACC test:  0.9422222222222222\n",
      "\tEpoch 936: \tAverage Loss:  1.6377001342773438\t ACC train:  0.9455555555555556\t ACC test:  0.9466666666666667\n",
      "\tEpoch 937: \tAverage Loss:  1.6340191040039063\t ACC train:  0.9488888888888889\t ACC test:  0.9511111111111111\n",
      "\tEpoch 938: \tAverage Loss:  1.6315492553710937\t ACC train:  0.9455555555555556\t ACC test:  0.9488888888888889\n",
      "\tEpoch 939: \tAverage Loss:  1.6290130615234375\t ACC train:  0.9433333333333334\t ACC test:  0.9511111111111111\n",
      "\tEpoch 940: \tAverage Loss:  1.6258681030273439\t ACC train:  0.9477777777777778\t ACC test:  0.9488888888888889\n",
      "\tEpoch 941: \tAverage Loss:  1.6253888549804687\t ACC train:  0.9466666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 942: \tAverage Loss:  1.621641357421875\t ACC train:  0.9444444444444444\t ACC test:  0.9444444444444444\n",
      "\tEpoch 943: \tAverage Loss:  1.620868896484375\t ACC train:  0.9488888888888889\t ACC test:  0.9444444444444444\n",
      "\tEpoch 944: \tAverage Loss:  1.6186033935546875\t ACC train:  0.9466666666666667\t ACC test:  0.9511111111111111\n",
      "\tEpoch 945: \tAverage Loss:  1.6156420288085938\t ACC train:  0.95\t ACC test:  0.9488888888888889\n",
      "\tEpoch 946: \tAverage Loss:  1.6133345947265625\t ACC train:  0.9455555555555556\t ACC test:  0.9466666666666667\n",
      "\tEpoch 947: \tAverage Loss:  1.613842529296875\t ACC train:  0.9488888888888889\t ACC test:  0.9511111111111111\n",
      "\tEpoch 948: \tAverage Loss:  1.6119278564453126\t ACC train:  0.9466666666666667\t ACC test:  0.9466666666666667\n",
      "\tEpoch 949: \tAverage Loss:  1.6090150756835937\t ACC train:  0.9488888888888889\t ACC test:  0.9488888888888889\n",
      "\tEpoch 950: \tAverage Loss:  1.6075098266601562\t ACC train:  0.9455555555555556\t ACC test:  0.9555555555555556\n",
      "\tEpoch 951: \tAverage Loss:  1.60735498046875\t ACC train:  0.9511111111111111\t ACC test:  0.9488888888888889\n",
      "\tEpoch 952: \tAverage Loss:  1.6042139892578124\t ACC train:  0.9466666666666667\t ACC test:  0.9488888888888889\n",
      "\tEpoch 953: \tAverage Loss:  1.6031343994140625\t ACC train:  0.9488888888888889\t ACC test:  0.9488888888888889\n",
      "\tEpoch 954: \tAverage Loss:  1.6035855102539063\t ACC train:  0.95\t ACC test:  0.9533333333333334\n",
      "\tEpoch 955: \tAverage Loss:  1.6018956298828124\t ACC train:  0.9511111111111111\t ACC test:  0.9533333333333334\n",
      "\tEpoch 956: \tAverage Loss:  1.600697021484375\t ACC train:  0.95\t ACC test:  0.9555555555555556\n",
      "\tEpoch 957: \tAverage Loss:  1.6004659423828125\t ACC train:  0.95\t ACC test:  0.9488888888888889\n",
      "\tEpoch 958: \tAverage Loss:  1.5984759521484375\t ACC train:  0.9488888888888889\t ACC test:  0.9577777777777777\n",
      "\tEpoch 959: \tAverage Loss:  1.5961630859375\t ACC train:  0.9555555555555556\t ACC test:  0.9488888888888889\n",
      "\tEpoch 960: \tAverage Loss:  1.5963474731445313\t ACC train:  0.9533333333333334\t ACC test:  0.96\n",
      "\tEpoch 961: \tAverage Loss:  1.59547314453125\t ACC train:  0.9533333333333334\t ACC test:  0.9488888888888889\n",
      "\tEpoch 962: \tAverage Loss:  1.59428271484375\t ACC train:  0.9511111111111111\t ACC test:  0.9533333333333334\n",
      "\tEpoch 963: \tAverage Loss:  1.5938995971679688\t ACC train:  0.9544444444444444\t ACC test:  0.9577777777777777\n",
      "\tEpoch 964: \tAverage Loss:  1.5933108520507813\t ACC train:  0.9477777777777778\t ACC test:  0.9577777777777777\n",
      "\tEpoch 965: \tAverage Loss:  1.591708984375\t ACC train:  0.9533333333333334\t ACC test:  0.9577777777777777\n",
      "\tEpoch 966: \tAverage Loss:  1.5920145874023437\t ACC train:  0.9577777777777777\t ACC test:  0.9555555555555556\n",
      "\tEpoch 967: \tAverage Loss:  1.5905924072265625\t ACC train:  0.9533333333333334\t ACC test:  0.9577777777777777\n",
      "\tEpoch 968: \tAverage Loss:  1.590572509765625\t ACC train:  0.9544444444444444\t ACC test:  0.9511111111111111\n",
      "\tEpoch 969: \tAverage Loss:  1.589589599609375\t ACC train:  0.9522222222222222\t ACC test:  0.9577777777777777\n",
      "\tEpoch 970: \tAverage Loss:  1.588903076171875\t ACC train:  0.9566666666666667\t ACC test:  0.9555555555555556\n",
      "\tEpoch 971: \tAverage Loss:  1.5878329467773438\t ACC train:  0.9544444444444444\t ACC test:  0.9533333333333334\n",
      "\tEpoch 972: \tAverage Loss:  1.5871795654296874\t ACC train:  0.9544444444444444\t ACC test:  0.9533333333333334\n",
      "\tEpoch 973: \tAverage Loss:  1.586697509765625\t ACC train:  0.9566666666666667\t ACC test:  0.96\n",
      "\tEpoch 974: \tAverage Loss:  1.5855211791992188\t ACC train:  0.9588888888888889\t ACC test:  0.9577777777777777\n",
      "\tEpoch 975: \tAverage Loss:  1.5851773681640624\t ACC train:  0.9577777777777777\t ACC test:  0.96\n",
      "\tEpoch 976: \tAverage Loss:  1.5838463134765626\t ACC train:  0.9577777777777777\t ACC test:  0.9622222222222222\n",
      "\tEpoch 977: \tAverage Loss:  1.5842069702148438\t ACC train:  0.9611111111111111\t ACC test:  0.9577777777777777\n",
      "\tEpoch 978: \tAverage Loss:  1.5831639404296876\t ACC train:  0.9588888888888889\t ACC test:  0.9555555555555556\n",
      "\tEpoch 979: \tAverage Loss:  1.582943359375\t ACC train:  0.96\t ACC test:  0.9577777777777777\n",
      "\tEpoch 980: \tAverage Loss:  1.582433349609375\t ACC train:  0.9533333333333334\t ACC test:  0.9577777777777777\n",
      "\tEpoch 981: \tAverage Loss:  1.5818817749023437\t ACC train:  0.9611111111111111\t ACC test:  0.96\n",
      "\tEpoch 982: \tAverage Loss:  1.5818616943359376\t ACC train:  0.9577777777777777\t ACC test:  0.9555555555555556\n",
      "\tEpoch 983: \tAverage Loss:  1.58080615234375\t ACC train:  0.9577777777777777\t ACC test:  0.96\n",
      "\tEpoch 984: \tAverage Loss:  1.5799058837890625\t ACC train:  0.9588888888888889\t ACC test:  0.96\n",
      "\tEpoch 985: \tAverage Loss:  1.580006591796875\t ACC train:  0.9577777777777777\t ACC test:  0.9577777777777777\n",
      "\tEpoch 986: \tAverage Loss:  1.5790140380859374\t ACC train:  0.9588888888888889\t ACC test:  0.96\n",
      "\tEpoch 987: \tAverage Loss:  1.5784507446289062\t ACC train:  0.9577777777777777\t ACC test:  0.96\n",
      "\tEpoch 988: \tAverage Loss:  1.5787164916992187\t ACC train:  0.96\t ACC test:  0.9622222222222222\n",
      "\tEpoch 989: \tAverage Loss:  1.5780648193359375\t ACC train:  0.96\t ACC test:  0.96\n",
      "\tEpoch 990: \tAverage Loss:  1.5770419921875\t ACC train:  0.9588888888888889\t ACC test:  0.96\n",
      "\tEpoch 991: \tAverage Loss:  1.5766912841796874\t ACC train:  0.9622222222222222\t ACC test:  0.96\n",
      "\tEpoch 992: \tAverage Loss:  1.5762410278320313\t ACC train:  0.9577777777777777\t ACC test:  0.96\n",
      "\tEpoch 993: \tAverage Loss:  1.575552490234375\t ACC train:  0.9588888888888889\t ACC test:  0.9622222222222222\n",
      "\tEpoch 994: \tAverage Loss:  1.5756980590820313\t ACC train:  0.9588888888888889\t ACC test:  0.9666666666666667\n",
      "\tEpoch 995: \tAverage Loss:  1.5752506103515624\t ACC train:  0.9577777777777777\t ACC test:  0.9666666666666667\n",
      "\tEpoch 996: \tAverage Loss:  1.5744359130859376\t ACC train:  0.9577777777777777\t ACC test:  0.9622222222222222\n",
      "\tEpoch 997: \tAverage Loss:  1.5742283325195312\t ACC train:  0.9555555555555556\t ACC test:  0.9622222222222222\n",
      "\tEpoch 998: \tAverage Loss:  1.5738538818359376\t ACC train:  0.9588888888888889\t ACC test:  0.9622222222222222\n",
      "\tEpoch 999: \tAverage Loss:  1.5735720825195312\t ACC train:  0.9655555555555555\t ACC test:  0.9622222222222222\n",
      "\tEpoch 1000: \tAverage Loss:  1.5729639892578124\t ACC train:  0.96\t ACC test:  0.96\n",
      "\tEpoch 1001: \tAverage Loss:  1.5721552734375\t ACC train:  0.9622222222222222\t ACC test:  0.9644444444444444\n",
      "\tEpoch 1002: \tAverage Loss:  1.5723260498046876\t ACC train:  0.9611111111111111\t ACC test:  0.9644444444444444\n",
      "\tEpoch 1003: \tAverage Loss:  1.5717202758789062\t ACC train:  0.96\t ACC test:  0.9644444444444444\n",
      "\tEpoch 1004: \tAverage Loss:  1.5711190185546875\t ACC train:  0.9644444444444444\t ACC test:  0.9644444444444444\n",
      "\tEpoch 1005: \tAverage Loss:  1.5721122436523438\t ACC train:  0.9622222222222222\t ACC test:  0.9666666666666667\n",
      "\tEpoch 1006: \tAverage Loss:  1.5711986694335938\t ACC train:  0.9622222222222222\t ACC test:  0.9622222222222222\n",
      "\tEpoch 1007: \tAverage Loss:  1.570267578125\t ACC train:  0.9588888888888889\t ACC test:  0.9666666666666667\n",
      "\tEpoch 1008: \tAverage Loss:  1.56996533203125\t ACC train:  0.9633333333333334\t ACC test:  0.9666666666666667\n",
      "\tEpoch 1009: \tAverage Loss:  1.5696492919921874\t ACC train:  0.9622222222222222\t ACC test:  0.9622222222222222\n",
      "\tEpoch 1010: \tAverage Loss:  1.569634765625\t ACC train:  0.9622222222222222\t ACC test:  0.9644444444444444\n",
      "\tEpoch 1011: \tAverage Loss:  1.5693168334960939\t ACC train:  0.9622222222222222\t ACC test:  0.9644444444444444\n",
      "\tEpoch 1012: \tAverage Loss:  1.56889111328125\t ACC train:  0.9611111111111111\t ACC test:  0.9666666666666667\n",
      "\tEpoch 1013: \tAverage Loss:  1.5686840209960937\t ACC train:  0.9611111111111111\t ACC test:  0.9666666666666667\n",
      "\tEpoch 1014: \tAverage Loss:  1.567883544921875\t ACC train:  0.9655555555555555\t ACC test:  0.9644444444444444\n",
      "\tEpoch 1015: \tAverage Loss:  1.567705322265625\t ACC train:  0.9677777777777777\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1016: \tAverage Loss:  1.5671229248046874\t ACC train:  0.9666666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1017: \tAverage Loss:  1.5670887451171875\t ACC train:  0.9666666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1018: \tAverage Loss:  1.5668471069335939\t ACC train:  0.9666666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1019: \tAverage Loss:  1.5659769287109375\t ACC train:  0.9688888888888889\t ACC test:  0.9666666666666667\n",
      "\tEpoch 1020: \tAverage Loss:  1.5658372192382812\t ACC train:  0.9677777777777777\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1021: \tAverage Loss:  1.566203369140625\t ACC train:  0.9655555555555555\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1022: \tAverage Loss:  1.5654963989257813\t ACC train:  0.9666666666666667\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1023: \tAverage Loss:  1.5649886474609376\t ACC train:  0.9655555555555555\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1024: \tAverage Loss:  1.5646343994140626\t ACC train:  0.9666666666666667\t ACC test:  0.9622222222222222\n",
      "\tEpoch 1025: \tAverage Loss:  1.5645586547851562\t ACC train:  0.9666666666666667\t ACC test:  0.9622222222222222\n",
      "\tEpoch 1026: \tAverage Loss:  1.563711181640625\t ACC train:  0.9688888888888889\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1027: \tAverage Loss:  1.5639083251953125\t ACC train:  0.9633333333333334\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1028: \tAverage Loss:  1.5634550170898438\t ACC train:  0.9655555555555555\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1029: \tAverage Loss:  1.5632206420898438\t ACC train:  0.9666666666666667\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1030: \tAverage Loss:  1.5628919677734374\t ACC train:  0.9688888888888889\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1031: \tAverage Loss:  1.5626296997070312\t ACC train:  0.97\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1032: \tAverage Loss:  1.5618844604492188\t ACC train:  0.9666666666666667\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1033: \tAverage Loss:  1.56178955078125\t ACC train:  0.9666666666666667\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1034: \tAverage Loss:  1.5616565551757813\t ACC train:  0.9644444444444444\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1035: \tAverage Loss:  1.561198974609375\t ACC train:  0.9655555555555555\t ACC test:  0.9688888888888889\n",
      "\tEpoch 1036: \tAverage Loss:  1.5607643432617186\t ACC train:  0.9688888888888889\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1037: \tAverage Loss:  1.5604130859375\t ACC train:  0.97\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1038: \tAverage Loss:  1.5604710083007813\t ACC train:  0.9711111111111111\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1039: \tAverage Loss:  1.5602060546875\t ACC train:  0.97\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1040: \tAverage Loss:  1.5599248657226563\t ACC train:  0.9688888888888889\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1041: \tAverage Loss:  1.5596571655273437\t ACC train:  0.97\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1042: \tAverage Loss:  1.5594754638671875\t ACC train:  0.9677777777777777\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1043: \tAverage Loss:  1.5590433959960937\t ACC train:  0.9711111111111111\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1044: \tAverage Loss:  1.5593241577148438\t ACC train:  0.9711111111111111\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1045: \tAverage Loss:  1.55906591796875\t ACC train:  0.9711111111111111\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1046: \tAverage Loss:  1.5589688110351563\t ACC train:  0.9711111111111111\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1047: \tAverage Loss:  1.55809228515625\t ACC train:  0.9711111111111111\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1048: \tAverage Loss:  1.5575860595703126\t ACC train:  0.9733333333333334\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1049: \tAverage Loss:  1.5581038818359374\t ACC train:  0.97\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1050: \tAverage Loss:  1.5572339477539063\t ACC train:  0.9722222222222222\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1051: \tAverage Loss:  1.5571757202148437\t ACC train:  0.9711111111111111\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1052: \tAverage Loss:  1.5566841430664062\t ACC train:  0.9711111111111111\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1053: \tAverage Loss:  1.5563322143554688\t ACC train:  0.97\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1054: \tAverage Loss:  1.5564402465820313\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1055: \tAverage Loss:  1.555759033203125\t ACC train:  0.9722222222222222\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1056: \tAverage Loss:  1.5559613037109374\t ACC train:  0.97\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1057: \tAverage Loss:  1.5560242309570314\t ACC train:  0.9711111111111111\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1058: \tAverage Loss:  1.5553282470703125\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1059: \tAverage Loss:  1.5551699829101562\t ACC train:  0.9722222222222222\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1060: \tAverage Loss:  1.5552423095703125\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1061: \tAverage Loss:  1.554560302734375\t ACC train:  0.9722222222222222\t ACC test:  0.9733333333333334\n",
      "\tEpoch 1062: \tAverage Loss:  1.5545247802734374\t ACC train:  0.9711111111111111\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1063: \tAverage Loss:  1.5545821533203126\t ACC train:  0.9711111111111111\t ACC test:  0.9711111111111111\n",
      "\tEpoch 1064: \tAverage Loss:  1.554046630859375\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1065: \tAverage Loss:  1.553914306640625\t ACC train:  0.9722222222222222\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1066: \tAverage Loss:  1.5536300659179687\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1067: \tAverage Loss:  1.5532892456054688\t ACC train:  0.9744444444444444\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1068: \tAverage Loss:  1.5526903076171874\t ACC train:  0.9711111111111111\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1069: \tAverage Loss:  1.55269189453125\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1070: \tAverage Loss:  1.5525153198242188\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1071: \tAverage Loss:  1.5523631591796876\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1072: \tAverage Loss:  1.5520672607421875\t ACC train:  0.9733333333333334\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1073: \tAverage Loss:  1.5517333374023436\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1074: \tAverage Loss:  1.5514506225585938\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1075: \tAverage Loss:  1.5513570556640626\t ACC train:  0.9711111111111111\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1076: \tAverage Loss:  1.5509085693359375\t ACC train:  0.9722222222222222\t ACC test:  0.9755555555555555\n",
      "\tEpoch 1077: \tAverage Loss:  1.5509000854492188\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1078: \tAverage Loss:  1.5506214599609376\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1079: \tAverage Loss:  1.550509765625\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1080: \tAverage Loss:  1.55030078125\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1081: \tAverage Loss:  1.550023193359375\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1082: \tAverage Loss:  1.54987158203125\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1083: \tAverage Loss:  1.5495821533203125\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1084: \tAverage Loss:  1.5493429565429688\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1085: \tAverage Loss:  1.5489369506835937\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1086: \tAverage Loss:  1.5492525634765626\t ACC train:  0.9722222222222222\t ACC test:  0.98\n",
      "\tEpoch 1087: \tAverage Loss:  1.5488857421875\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1088: \tAverage Loss:  1.5484844360351562\t ACC train:  0.9722222222222222\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1089: \tAverage Loss:  1.5483551635742188\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1090: \tAverage Loss:  1.5483096923828126\t ACC train:  0.9722222222222222\t ACC test:  0.98\n",
      "\tEpoch 1091: \tAverage Loss:  1.5480736694335937\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1092: \tAverage Loss:  1.5475177612304687\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1093: \tAverage Loss:  1.547546875\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1094: \tAverage Loss:  1.5474176635742187\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1095: \tAverage Loss:  1.5472445068359375\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1096: \tAverage Loss:  1.54711328125\t ACC train:  0.9744444444444444\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1097: \tAverage Loss:  1.5468029174804687\t ACC train:  0.9744444444444444\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1098: \tAverage Loss:  1.547004638671875\t ACC train:  0.9744444444444444\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1099: \tAverage Loss:  1.546472412109375\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1100: \tAverage Loss:  1.5464935913085938\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1101: \tAverage Loss:  1.546306640625\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1102: \tAverage Loss:  1.5455418090820312\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1103: \tAverage Loss:  1.5459440307617187\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1104: \tAverage Loss:  1.5453992309570312\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1105: \tAverage Loss:  1.54511474609375\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1106: \tAverage Loss:  1.5450843505859375\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1107: \tAverage Loss:  1.5450946044921876\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1108: \tAverage Loss:  1.5444933471679687\t ACC train:  0.9766666666666667\t ACC test:  0.98\n",
      "\tEpoch 1109: \tAverage Loss:  1.544438720703125\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1110: \tAverage Loss:  1.544260986328125\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1111: \tAverage Loss:  1.544047119140625\t ACC train:  0.9744444444444444\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1112: \tAverage Loss:  1.5437300415039064\t ACC train:  0.9766666666666667\t ACC test:  0.98\n",
      "\tEpoch 1113: \tAverage Loss:  1.543482177734375\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1114: \tAverage Loss:  1.5432826538085938\t ACC train:  0.9733333333333334\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1115: \tAverage Loss:  1.5432388916015625\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1116: \tAverage Loss:  1.5427869262695313\t ACC train:  0.9777777777777777\t ACC test:  0.98\n",
      "\tEpoch 1117: \tAverage Loss:  1.5428861083984375\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1118: \tAverage Loss:  1.5426234130859375\t ACC train:  0.9777777777777777\t ACC test:  0.98\n",
      "\tEpoch 1119: \tAverage Loss:  1.542362060546875\t ACC train:  0.9755555555555555\t ACC test:  0.9777777777777777\n",
      "\tEpoch 1120: \tAverage Loss:  1.5421571655273438\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1121: \tAverage Loss:  1.542390869140625\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1122: \tAverage Loss:  1.5418823852539063\t ACC train:  0.9766666666666667\t ACC test:  0.98\n",
      "\tEpoch 1123: \tAverage Loss:  1.5416832275390624\t ACC train:  0.9777777777777777\t ACC test:  0.98\n",
      "\tEpoch 1124: \tAverage Loss:  1.5414779052734375\t ACC train:  0.9766666666666667\t ACC test:  0.98\n",
      "\tEpoch 1125: \tAverage Loss:  1.5413697509765625\t ACC train:  0.9766666666666667\t ACC test:  0.98\n",
      "\tEpoch 1126: \tAverage Loss:  1.5414100341796875\t ACC train:  0.9777777777777777\t ACC test:  0.98\n",
      "\tEpoch 1127: \tAverage Loss:  1.5409974975585938\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1128: \tAverage Loss:  1.5411033325195314\t ACC train:  0.9766666666666667\t ACC test:  0.98\n",
      "\tEpoch 1129: \tAverage Loss:  1.5407634887695312\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1130: \tAverage Loss:  1.5405319213867188\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 1131: \tAverage Loss:  1.5407665405273439\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1132: \tAverage Loss:  1.5405123901367188\t ACC train:  0.9777777777777777\t ACC test:  0.98\n",
      "\tEpoch 1133: \tAverage Loss:  1.54019921875\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1134: \tAverage Loss:  1.540494140625\t ACC train:  0.9788888888888889\t ACC test:  0.98\n",
      "\tEpoch 1135: \tAverage Loss:  1.5403153686523436\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1136: \tAverage Loss:  1.5403248291015625\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 1137: \tAverage Loss:  1.5398999633789063\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1138: \tAverage Loss:  1.54027392578125\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 1139: \tAverage Loss:  1.5403494262695312\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1140: \tAverage Loss:  1.5404801025390624\t ACC train:  0.9811111111111112\t ACC test:  0.98\n",
      "\tEpoch 1141: \tAverage Loss:  1.5401095581054687\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1142: \tAverage Loss:  1.5402509765625\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1143: \tAverage Loss:  1.540819580078125\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1144: \tAverage Loss:  1.5409990234375\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1145: \tAverage Loss:  1.5413323364257812\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1146: \tAverage Loss:  1.5417651977539062\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1147: \tAverage Loss:  1.542076904296875\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1148: \tAverage Loss:  1.542891845703125\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1149: \tAverage Loss:  1.5415676879882811\t ACC train:  0.9744444444444444\t ACC test:  0.98\n",
      "\tEpoch 1150: \tAverage Loss:  1.5417261352539062\t ACC train:  0.9844444444444445\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1151: \tAverage Loss:  1.5406846313476563\t ACC train:  0.9755555555555555\t ACC test:  0.98\n",
      "\tEpoch 1152: \tAverage Loss:  1.53924560546875\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1153: \tAverage Loss:  1.5376832885742187\t ACC train:  0.9811111111111112\t ACC test:  0.98\n",
      "\tEpoch 1154: \tAverage Loss:  1.5369850463867187\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 1155: \tAverage Loss:  1.5367919921875\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1156: \tAverage Loss:  1.5366491088867187\t ACC train:  0.9788888888888889\t ACC test:  0.98\n",
      "\tEpoch 1157: \tAverage Loss:  1.536904296875\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1158: \tAverage Loss:  1.53669921875\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 1159: \tAverage Loss:  1.53599609375\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1160: \tAverage Loss:  1.5359672241210938\t ACC train:  0.98\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1161: \tAverage Loss:  1.5357682495117186\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1162: \tAverage Loss:  1.5357052612304687\t ACC train:  0.9811111111111112\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1163: \tAverage Loss:  1.535635498046875\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1164: \tAverage Loss:  1.5354393310546874\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1165: \tAverage Loss:  1.5352156372070314\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 1166: \tAverage Loss:  1.5350199584960937\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1167: \tAverage Loss:  1.5352670288085937\t ACC train:  0.98\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1168: \tAverage Loss:  1.5349600219726562\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1169: \tAverage Loss:  1.534704345703125\t ACC train:  0.98\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1170: \tAverage Loss:  1.5344769287109374\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1171: \tAverage Loss:  1.5341216430664062\t ACC train:  0.9811111111111112\t ACC test:  0.98\n",
      "\tEpoch 1172: \tAverage Loss:  1.5339611206054689\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1173: \tAverage Loss:  1.5338287963867188\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1174: \tAverage Loss:  1.5339009399414063\t ACC train:  0.9811111111111112\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1175: \tAverage Loss:  1.533513427734375\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1176: \tAverage Loss:  1.5334317016601562\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1177: \tAverage Loss:  1.5332093505859374\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1178: \tAverage Loss:  1.5331257934570313\t ACC train:  0.9811111111111112\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1179: \tAverage Loss:  1.53296826171875\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1180: \tAverage Loss:  1.5329783935546875\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1181: \tAverage Loss:  1.5326055908203124\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1182: \tAverage Loss:  1.5325947875976562\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1183: \tAverage Loss:  1.5324100341796876\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1184: \tAverage Loss:  1.532243896484375\t ACC train:  0.9811111111111112\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1185: \tAverage Loss:  1.5321964111328126\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1186: \tAverage Loss:  1.5319981689453126\t ACC train:  0.9811111111111112\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1187: \tAverage Loss:  1.5318814086914063\t ACC train:  0.9844444444444445\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1188: \tAverage Loss:  1.5318909912109375\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1189: \tAverage Loss:  1.5315284423828126\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1190: \tAverage Loss:  1.5316238403320312\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1191: \tAverage Loss:  1.5312430419921874\t ACC train:  0.9844444444444445\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1192: \tAverage Loss:  1.5313360595703125\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1193: \tAverage Loss:  1.5311844482421875\t ACC train:  0.9844444444444445\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1194: \tAverage Loss:  1.5309610595703125\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1195: \tAverage Loss:  1.5308914184570312\t ACC train:  0.9855555555555555\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1196: \tAverage Loss:  1.53087060546875\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1197: \tAverage Loss:  1.5305245361328126\t ACC train:  0.9844444444444445\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1198: \tAverage Loss:  1.5303907470703124\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1199: \tAverage Loss:  1.530320556640625\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1200: \tAverage Loss:  1.5301337890625\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1201: \tAverage Loss:  1.529984375\t ACC train:  0.9844444444444445\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1202: \tAverage Loss:  1.5299044799804689\t ACC train:  0.9844444444444445\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1203: \tAverage Loss:  1.5297843627929688\t ACC train:  0.9844444444444445\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1204: \tAverage Loss:  1.5297274780273438\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1205: \tAverage Loss:  1.5295267944335937\t ACC train:  0.9855555555555555\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1206: \tAverage Loss:  1.529539306640625\t ACC train:  0.9833333333333333\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1207: \tAverage Loss:  1.5293676147460937\t ACC train:  0.9855555555555555\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1208: \tAverage Loss:  1.52928564453125\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1209: \tAverage Loss:  1.5291673583984375\t ACC train:  0.9855555555555555\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1210: \tAverage Loss:  1.52913037109375\t ACC train:  0.9833333333333333\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1211: \tAverage Loss:  1.529102294921875\t ACC train:  0.9855555555555555\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1212: \tAverage Loss:  1.5287094116210938\t ACC train:  0.9833333333333333\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1213: \tAverage Loss:  1.528912353515625\t ACC train:  0.9855555555555555\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1214: \tAverage Loss:  1.5284508056640624\t ACC train:  0.9844444444444445\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1215: \tAverage Loss:  1.5285318603515625\t ACC train:  0.9866666666666667\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1216: \tAverage Loss:  1.5283756713867187\t ACC train:  0.9833333333333333\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1217: \tAverage Loss:  1.5283681640625\t ACC train:  0.9855555555555555\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1218: \tAverage Loss:  1.52836865234375\t ACC train:  0.9833333333333333\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1219: \tAverage Loss:  1.5284302368164062\t ACC train:  0.9855555555555555\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1220: \tAverage Loss:  1.5280426635742188\t ACC train:  0.9833333333333333\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1221: \tAverage Loss:  1.5279812622070312\t ACC train:  0.9866666666666667\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1222: \tAverage Loss:  1.527927001953125\t ACC train:  0.9844444444444445\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1223: \tAverage Loss:  1.527890625\t ACC train:  0.9888888888888889\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1224: \tAverage Loss:  1.5278304443359374\t ACC train:  0.9822222222222222\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1225: \tAverage Loss:  1.5281644897460938\t ACC train:  0.9888888888888889\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1226: \tAverage Loss:  1.5278193359375\t ACC train:  0.9833333333333333\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1227: \tAverage Loss:  1.52740966796875\t ACC train:  0.9888888888888889\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1228: \tAverage Loss:  1.5278121337890624\t ACC train:  0.9833333333333333\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1229: \tAverage Loss:  1.5275211791992187\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1230: \tAverage Loss:  1.527267578125\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1231: \tAverage Loss:  1.527455810546875\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1232: \tAverage Loss:  1.5268064575195313\t ACC train:  0.9822222222222222\t ACC test:  0.9822222222222222\n",
      "\tEpoch 1233: \tAverage Loss:  1.5271519775390625\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1234: \tAverage Loss:  1.5274795532226562\t ACC train:  0.9844444444444445\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1235: \tAverage Loss:  1.526873779296875\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1236: \tAverage Loss:  1.5271092529296875\t ACC train:  0.9822222222222222\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1237: \tAverage Loss:  1.5266788330078125\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1238: \tAverage Loss:  1.52765625\t ACC train:  0.9822222222222222\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1239: \tAverage Loss:  1.5272633666992188\t ACC train:  0.9888888888888889\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1240: \tAverage Loss:  1.5276498413085937\t ACC train:  0.9822222222222222\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1241: \tAverage Loss:  1.5274241943359375\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1242: \tAverage Loss:  1.5274926147460937\t ACC train:  0.9822222222222222\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1243: \tAverage Loss:  1.5268812866210937\t ACC train:  0.9911111111111112\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1244: \tAverage Loss:  1.527606201171875\t ACC train:  0.9822222222222222\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1245: \tAverage Loss:  1.52699169921875\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1246: \tAverage Loss:  1.5261553344726562\t ACC train:  0.9822222222222222\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1247: \tAverage Loss:  1.525974609375\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1248: \tAverage Loss:  1.5257996826171876\t ACC train:  0.9855555555555555\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1249: \tAverage Loss:  1.525250732421875\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1250: \tAverage Loss:  1.5250130615234374\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1251: \tAverage Loss:  1.52469970703125\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1252: \tAverage Loss:  1.5243231811523437\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1253: \tAverage Loss:  1.5242324829101563\t ACC train:  0.9866666666666667\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1254: \tAverage Loss:  1.5243279418945312\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1255: \tAverage Loss:  1.5244378662109375\t ACC train:  0.9866666666666667\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1256: \tAverage Loss:  1.5241509399414062\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1257: \tAverage Loss:  1.5239454345703125\t ACC train:  0.9866666666666667\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1258: \tAverage Loss:  1.5241741333007812\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1259: \tAverage Loss:  1.5238583984375\t ACC train:  0.9866666666666667\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1260: \tAverage Loss:  1.52398681640625\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1261: \tAverage Loss:  1.5237001953125\t ACC train:  0.9855555555555555\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1262: \tAverage Loss:  1.5236351318359376\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1263: \tAverage Loss:  1.523716552734375\t ACC train:  0.9855555555555555\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1264: \tAverage Loss:  1.5235523681640626\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1265: \tAverage Loss:  1.5233434448242187\t ACC train:  0.9866666666666667\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1266: \tAverage Loss:  1.523275146484375\t ACC train:  0.9911111111111112\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1267: \tAverage Loss:  1.523397705078125\t ACC train:  0.9866666666666667\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1268: \tAverage Loss:  1.522991943359375\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1269: \tAverage Loss:  1.522890625\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1270: \tAverage Loss:  1.5227626342773437\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1271: \tAverage Loss:  1.5227239379882813\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1272: \tAverage Loss:  1.5223638305664062\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1273: \tAverage Loss:  1.5223334350585938\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1274: \tAverage Loss:  1.5221319580078125\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1275: \tAverage Loss:  1.5221181640625\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1276: \tAverage Loss:  1.5219962768554687\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1277: \tAverage Loss:  1.521936767578125\t ACC train:  0.9866666666666667\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1278: \tAverage Loss:  1.5219456787109376\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1279: \tAverage Loss:  1.521661376953125\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1280: \tAverage Loss:  1.52159423828125\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1281: \tAverage Loss:  1.5216277465820311\t ACC train:  0.9888888888888889\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1282: \tAverage Loss:  1.5213915405273437\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1283: \tAverage Loss:  1.5213128662109374\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1284: \tAverage Loss:  1.5212304077148437\t ACC train:  0.9888888888888889\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1285: \tAverage Loss:  1.5211395263671874\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1286: \tAverage Loss:  1.5210703735351563\t ACC train:  0.9888888888888889\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1287: \tAverage Loss:  1.5209641723632812\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1288: \tAverage Loss:  1.5208150634765625\t ACC train:  0.9888888888888889\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1289: \tAverage Loss:  1.5209681396484376\t ACC train:  0.9911111111111112\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1290: \tAverage Loss:  1.5206004028320312\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1291: \tAverage Loss:  1.520581298828125\t ACC train:  0.9911111111111112\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1292: \tAverage Loss:  1.5207410888671875\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1293: \tAverage Loss:  1.520486328125\t ACC train:  0.9911111111111112\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1294: \tAverage Loss:  1.5204659423828124\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1295: \tAverage Loss:  1.520218505859375\t ACC train:  0.9922222222222222\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1296: \tAverage Loss:  1.5204935913085937\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1297: \tAverage Loss:  1.5201282958984375\t ACC train:  0.9922222222222222\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1298: \tAverage Loss:  1.5208125\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1299: \tAverage Loss:  1.5205626831054688\t ACC train:  0.9933333333333333\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1300: \tAverage Loss:  1.5201842651367188\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1301: \tAverage Loss:  1.5202036743164062\t ACC train:  0.9922222222222222\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1302: \tAverage Loss:  1.5207112426757812\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1303: \tAverage Loss:  1.520257568359375\t ACC train:  0.9922222222222222\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1304: \tAverage Loss:  1.5205907592773438\t ACC train:  0.9888888888888889\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1305: \tAverage Loss:  1.5203148803710937\t ACC train:  0.9944444444444445\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1306: \tAverage Loss:  1.5207653198242188\t ACC train:  0.9877777777777778\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1307: \tAverage Loss:  1.521057373046875\t ACC train:  0.9944444444444445\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1308: \tAverage Loss:  1.5211442260742187\t ACC train:  0.9888888888888889\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1309: \tAverage Loss:  1.520845947265625\t ACC train:  0.9955555555555555\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1310: \tAverage Loss:  1.5213190307617188\t ACC train:  0.9855555555555555\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1311: \tAverage Loss:  1.5216312866210937\t ACC train:  0.9955555555555555\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1312: \tAverage Loss:  1.5233992309570312\t ACC train:  0.9855555555555555\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1313: \tAverage Loss:  1.52310302734375\t ACC train:  0.9955555555555555\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1314: \tAverage Loss:  1.5228423461914062\t ACC train:  0.9844444444444445\t ACC test:  0.9844444444444445\n",
      "\tEpoch 1315: \tAverage Loss:  1.5228309326171876\t ACC train:  0.9955555555555555\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1316: \tAverage Loss:  1.5232775268554688\t ACC train:  0.9844444444444445\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1317: \tAverage Loss:  1.5221019897460937\t ACC train:  0.9966666666666667\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1318: \tAverage Loss:  1.522205078125\t ACC train:  0.9855555555555555\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1319: \tAverage Loss:  1.5212130737304688\t ACC train:  0.9955555555555555\t ACC test:  0.9911111111111112\n",
      "Stopping early at epoch 1319. No improvement in validation loss for 20 epochs.\n",
      "Training for sample size: 1000\n",
      "\tEpoch 1: \tAverage Loss:  4.732130615234375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 2: \tAverage Loss:  4.69706787109375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 3: \tAverage Loss:  4.665581787109375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 4: \tAverage Loss:  4.639366455078125\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 5: \tAverage Loss:  4.616572509765625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 6: \tAverage Loss:  4.594750244140625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 7: \tAverage Loss:  4.573742919921875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 8: \tAverage Loss:  4.554462646484375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 9: \tAverage Loss:  4.536246337890625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 10: \tAverage Loss:  4.518671142578125\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 11: \tAverage Loss:  4.50217822265625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 12: \tAverage Loss:  4.48417822265625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 13: \tAverage Loss:  4.47014453125\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 14: \tAverage Loss:  4.454262451171875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 15: \tAverage Loss:  4.440324462890625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 16: \tAverage Loss:  4.425040771484375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 17: \tAverage Loss:  4.41051025390625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 18: \tAverage Loss:  4.39647021484375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  4.383716796875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 20: \tAverage Loss:  4.37051416015625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 21: \tAverage Loss:  4.357966552734375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 22: \tAverage Loss:  4.345455810546875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 23: \tAverage Loss:  4.33284326171875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 24: \tAverage Loss:  4.32074462890625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 25: \tAverage Loss:  4.309614990234375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 26: \tAverage Loss:  4.299289306640625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 27: \tAverage Loss:  4.28828564453125\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 28: \tAverage Loss:  4.276016357421875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 29: \tAverage Loss:  4.26458056640625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 30: \tAverage Loss:  4.254622802734375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 31: \tAverage Loss:  4.24457421875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 32: \tAverage Loss:  4.233589965820313\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 33: \tAverage Loss:  4.223222900390625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 34: \tAverage Loss:  4.21351611328125\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 35: \tAverage Loss:  4.20284228515625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  4.1920625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 37: \tAverage Loss:  4.181638671875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 38: \tAverage Loss:  4.171809814453125\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 39: \tAverage Loss:  4.160865966796875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 40: \tAverage Loss:  4.151364013671875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 41: \tAverage Loss:  4.140933837890625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 42: \tAverage Loss:  4.130483520507813\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 43: \tAverage Loss:  4.1193519287109375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 44: \tAverage Loss:  4.11030712890625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 45: \tAverage Loss:  4.099571166992187\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 46: \tAverage Loss:  4.091385009765625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 47: \tAverage Loss:  4.081787841796875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 48: \tAverage Loss:  4.072805541992188\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 49: \tAverage Loss:  4.064173583984375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  4.056399536132813\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 51: \tAverage Loss:  4.047488891601563\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  4.040831909179688\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 53: \tAverage Loss:  4.033876342773437\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 54: \tAverage Loss:  4.027433471679688\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 55: \tAverage Loss:  4.020530029296875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 56: \tAverage Loss:  4.01389453125\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 57: \tAverage Loss:  4.008650024414062\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 58: \tAverage Loss:  4.001748168945313\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 59: \tAverage Loss:  3.9958828125\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 60: \tAverage Loss:  3.9917021484375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 61: \tAverage Loss:  3.985938720703125\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 62: \tAverage Loss:  3.978349609375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 63: \tAverage Loss:  3.97329931640625\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 64: \tAverage Loss:  3.968882080078125\t ACC train:  0.508\t ACC test:  0.4866666666666667\n",
      "\tEpoch 65: \tAverage Loss:  3.9655955810546875\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 66: \tAverage Loss:  3.960229248046875\t ACC train:  0.51\t ACC test:  0.4888888888888889\n",
      "\tEpoch 67: \tAverage Loss:  3.9562318115234376\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 68: \tAverage Loss:  3.9512137451171876\t ACC train:  0.51\t ACC test:  0.4911111111111111\n",
      "\tEpoch 69: \tAverage Loss:  3.9459598388671875\t ACC train:  0.51\t ACC test:  0.4866666666666667\n",
      "\tEpoch 70: \tAverage Loss:  3.9399495849609374\t ACC train:  0.508\t ACC test:  0.4888888888888889\n",
      "\tEpoch 71: \tAverage Loss:  3.937096923828125\t ACC train:  0.512\t ACC test:  0.4888888888888889\n",
      "\tEpoch 72: \tAverage Loss:  3.9337857666015625\t ACC train:  0.513\t ACC test:  0.4911111111111111\n",
      "\tEpoch 73: \tAverage Loss:  3.9291610107421877\t ACC train:  0.511\t ACC test:  0.4866666666666667\n",
      "\tEpoch 74: \tAverage Loss:  3.928015380859375\t ACC train:  0.509\t ACC test:  0.4866666666666667\n",
      "\tEpoch 75: \tAverage Loss:  3.9216983642578125\t ACC train:  0.514\t ACC test:  0.49333333333333335\n",
      "\tEpoch 76: \tAverage Loss:  3.916176025390625\t ACC train:  0.512\t ACC test:  0.4866666666666667\n",
      "\tEpoch 77: \tAverage Loss:  3.910607666015625\t ACC train:  0.514\t ACC test:  0.4866666666666667\n",
      "\tEpoch 78: \tAverage Loss:  3.909359130859375\t ACC train:  0.512\t ACC test:  0.4955555555555556\n",
      "\tEpoch 79: \tAverage Loss:  3.9066378173828125\t ACC train:  0.513\t ACC test:  0.4888888888888889\n",
      "\tEpoch 80: \tAverage Loss:  3.9012255859375\t ACC train:  0.514\t ACC test:  0.49777777777777776\n",
      "\tEpoch 81: \tAverage Loss:  3.8997813720703123\t ACC train:  0.514\t ACC test:  0.49777777777777776\n",
      "\tEpoch 82: \tAverage Loss:  3.892936767578125\t ACC train:  0.515\t ACC test:  0.4911111111111111\n",
      "\tEpoch 83: \tAverage Loss:  3.89287548828125\t ACC train:  0.52\t ACC test:  0.49777777777777776\n",
      "\tEpoch 84: \tAverage Loss:  3.888771484375\t ACC train:  0.524\t ACC test:  0.5177777777777778\n",
      "\tEpoch 85: \tAverage Loss:  3.883641845703125\t ACC train:  0.535\t ACC test:  0.5066666666666667\n",
      "\tEpoch 86: \tAverage Loss:  3.880265625\t ACC train:  0.548\t ACC test:  0.5111111111111111\n",
      "\tEpoch 87: \tAverage Loss:  3.879824951171875\t ACC train:  0.559\t ACC test:  0.5266666666666666\n",
      "\tEpoch 88: \tAverage Loss:  3.8749686279296873\t ACC train:  0.568\t ACC test:  0.5288888888888889\n",
      "\tEpoch 89: \tAverage Loss:  3.871685302734375\t ACC train:  0.578\t ACC test:  0.5444444444444444\n",
      "\tEpoch 90: \tAverage Loss:  3.8728868408203123\t ACC train:  0.585\t ACC test:  0.5488888888888889\n",
      "\tEpoch 91: \tAverage Loss:  3.8622841796875\t ACC train:  0.605\t ACC test:  0.5844444444444444\n",
      "\tEpoch 92: \tAverage Loss:  3.8590714111328124\t ACC train:  0.587\t ACC test:  0.5755555555555556\n",
      "\tEpoch 93: \tAverage Loss:  3.8559495849609373\t ACC train:  0.623\t ACC test:  0.58\n",
      "\tEpoch 94: \tAverage Loss:  3.851554443359375\t ACC train:  0.617\t ACC test:  0.5955555555555555\n",
      "\tEpoch 95: \tAverage Loss:  3.8500640869140623\t ACC train:  0.627\t ACC test:  0.5711111111111111\n",
      "\tEpoch 96: \tAverage Loss:  3.839124267578125\t ACC train:  0.615\t ACC test:  0.5911111111111111\n",
      "\tEpoch 97: \tAverage Loss:  3.8378453369140626\t ACC train:  0.62\t ACC test:  0.6177777777777778\n",
      "\tEpoch 98: \tAverage Loss:  3.835294189453125\t ACC train:  0.642\t ACC test:  0.6222222222222222\n",
      "\tEpoch 99: \tAverage Loss:  3.827635009765625\t ACC train:  0.647\t ACC test:  0.6266666666666667\n",
      "\tEpoch 100: \tAverage Loss:  3.821332763671875\t ACC train:  0.64\t ACC test:  0.6377777777777778\n",
      "\tEpoch 101: \tAverage Loss:  3.8173289794921876\t ACC train:  0.649\t ACC test:  0.6088888888888889\n",
      "\tEpoch 102: \tAverage Loss:  3.808469970703125\t ACC train:  0.642\t ACC test:  0.6355555555555555\n",
      "\tEpoch 103: \tAverage Loss:  3.804314453125\t ACC train:  0.625\t ACC test:  0.6177777777777778\n",
      "\tEpoch 104: \tAverage Loss:  3.789966796875\t ACC train:  0.641\t ACC test:  0.6244444444444445\n",
      "\tEpoch 105: \tAverage Loss:  3.7890758056640625\t ACC train:  0.634\t ACC test:  0.6155555555555555\n",
      "\tEpoch 106: \tAverage Loss:  3.7749736328125\t ACC train:  0.619\t ACC test:  0.6444444444444445\n",
      "\tEpoch 107: \tAverage Loss:  3.7562767333984377\t ACC train:  0.631\t ACC test:  0.6088888888888889\n",
      "\tEpoch 108: \tAverage Loss:  3.7453541259765624\t ACC train:  0.606\t ACC test:  0.6133333333333333\n",
      "\tEpoch 109: \tAverage Loss:  3.7307117919921877\t ACC train:  0.604\t ACC test:  0.6311111111111111\n",
      "\tEpoch 110: \tAverage Loss:  3.7152528076171873\t ACC train:  0.621\t ACC test:  0.6111111111111112\n",
      "\tEpoch 111: \tAverage Loss:  3.6995477294921875\t ACC train:  0.624\t ACC test:  0.6111111111111112\n",
      "\tEpoch 112: \tAverage Loss:  3.6565908203125\t ACC train:  0.606\t ACC test:  0.6155555555555555\n",
      "\tEpoch 113: \tAverage Loss:  3.65357177734375\t ACC train:  0.612\t ACC test:  0.6066666666666667\n",
      "\tEpoch 114: \tAverage Loss:  3.601831298828125\t ACC train:  0.608\t ACC test:  0.6044444444444445\n",
      "\tEpoch 115: \tAverage Loss:  3.5495216064453126\t ACC train:  0.612\t ACC test:  0.6177777777777778\n",
      "\tEpoch 116: \tAverage Loss:  3.526583740234375\t ACC train:  0.597\t ACC test:  0.6044444444444445\n",
      "\tEpoch 117: \tAverage Loss:  3.480204345703125\t ACC train:  0.6\t ACC test:  0.5955555555555555\n",
      "\tEpoch 118: \tAverage Loss:  3.4621334228515623\t ACC train:  0.598\t ACC test:  0.6\n",
      "\tEpoch 119: \tAverage Loss:  3.396191650390625\t ACC train:  0.583\t ACC test:  0.5911111111111111\n",
      "\tEpoch 120: \tAverage Loss:  3.3405848388671875\t ACC train:  0.592\t ACC test:  0.6022222222222222\n",
      "\tEpoch 121: \tAverage Loss:  3.3182568359375\t ACC train:  0.591\t ACC test:  0.5844444444444444\n",
      "\tEpoch 122: \tAverage Loss:  3.279159912109375\t ACC train:  0.592\t ACC test:  0.6177777777777778\n",
      "\tEpoch 123: \tAverage Loss:  3.24881591796875\t ACC train:  0.597\t ACC test:  0.6133333333333333\n",
      "\tEpoch 124: \tAverage Loss:  3.2121571044921877\t ACC train:  0.605\t ACC test:  0.6022222222222222\n",
      "\tEpoch 125: \tAverage Loss:  3.165124755859375\t ACC train:  0.624\t ACC test:  0.6377777777777778\n",
      "\tEpoch 126: \tAverage Loss:  3.137114013671875\t ACC train:  0.626\t ACC test:  0.6222222222222222\n",
      "\tEpoch 127: \tAverage Loss:  3.107822998046875\t ACC train:  0.645\t ACC test:  0.6444444444444445\n",
      "\tEpoch 128: \tAverage Loss:  3.071709716796875\t ACC train:  0.645\t ACC test:  0.6533333333333333\n",
      "\tEpoch 129: \tAverage Loss:  3.039406005859375\t ACC train:  0.654\t ACC test:  0.6622222222222223\n",
      "\tEpoch 130: \tAverage Loss:  3.0157462158203123\t ACC train:  0.668\t ACC test:  0.6755555555555556\n",
      "\tEpoch 131: \tAverage Loss:  2.9942161865234374\t ACC train:  0.681\t ACC test:  0.6866666666666666\n",
      "\tEpoch 132: \tAverage Loss:  2.968070556640625\t ACC train:  0.694\t ACC test:  0.7111111111111111\n",
      "\tEpoch 133: \tAverage Loss:  2.9413126220703125\t ACC train:  0.694\t ACC test:  0.7244444444444444\n",
      "\tEpoch 134: \tAverage Loss:  2.9153670654296877\t ACC train:  0.695\t ACC test:  0.7222222222222222\n",
      "\tEpoch 135: \tAverage Loss:  2.8905987548828125\t ACC train:  0.713\t ACC test:  0.7355555555555555\n",
      "\tEpoch 136: \tAverage Loss:  2.8811611328125\t ACC train:  0.724\t ACC test:  0.7377777777777778\n",
      "\tEpoch 137: \tAverage Loss:  2.851781494140625\t ACC train:  0.736\t ACC test:  0.7666666666666667\n",
      "\tEpoch 138: \tAverage Loss:  2.828166015625\t ACC train:  0.741\t ACC test:  0.7511111111111111\n",
      "\tEpoch 139: \tAverage Loss:  2.8193992919921875\t ACC train:  0.747\t ACC test:  0.7577777777777778\n",
      "\tEpoch 140: \tAverage Loss:  2.78914013671875\t ACC train:  0.767\t ACC test:  0.7488888888888889\n",
      "\tEpoch 141: \tAverage Loss:  2.7870650634765624\t ACC train:  0.774\t ACC test:  0.7577777777777778\n",
      "\tEpoch 142: \tAverage Loss:  2.7653153076171875\t ACC train:  0.782\t ACC test:  0.7844444444444445\n",
      "\tEpoch 143: \tAverage Loss:  2.7562774658203124\t ACC train:  0.782\t ACC test:  0.7977777777777778\n",
      "\tEpoch 144: \tAverage Loss:  2.732495849609375\t ACC train:  0.81\t ACC test:  0.84\n",
      "\tEpoch 145: \tAverage Loss:  2.7247525634765624\t ACC train:  0.811\t ACC test:  0.8155555555555556\n",
      "\tEpoch 146: \tAverage Loss:  2.70288134765625\t ACC train:  0.813\t ACC test:  0.8266666666666667\n",
      "\tEpoch 147: \tAverage Loss:  2.7005452880859373\t ACC train:  0.81\t ACC test:  0.8155555555555556\n",
      "\tEpoch 148: \tAverage Loss:  2.6760400390625\t ACC train:  0.817\t ACC test:  0.8377777777777777\n",
      "\tEpoch 149: \tAverage Loss:  2.6744864501953125\t ACC train:  0.823\t ACC test:  0.8466666666666667\n",
      "\tEpoch 150: \tAverage Loss:  2.65916650390625\t ACC train:  0.838\t ACC test:  0.8622222222222222\n",
      "\tEpoch 151: \tAverage Loss:  2.640868408203125\t ACC train:  0.858\t ACC test:  0.8444444444444444\n",
      "\tEpoch 152: \tAverage Loss:  2.637449462890625\t ACC train:  0.852\t ACC test:  0.8488888888888889\n",
      "\tEpoch 153: \tAverage Loss:  2.62056103515625\t ACC train:  0.848\t ACC test:  0.8533333333333334\n",
      "\tEpoch 154: \tAverage Loss:  2.607578369140625\t ACC train:  0.839\t ACC test:  0.8511111111111112\n",
      "\tEpoch 155: \tAverage Loss:  2.5980731201171876\t ACC train:  0.84\t ACC test:  0.84\n",
      "\tEpoch 156: \tAverage Loss:  2.5905565185546875\t ACC train:  0.84\t ACC test:  0.8422222222222222\n",
      "\tEpoch 157: \tAverage Loss:  2.573267822265625\t ACC train:  0.865\t ACC test:  0.8688888888888889\n",
      "\tEpoch 158: \tAverage Loss:  2.5796666259765626\t ACC train:  0.85\t ACC test:  0.8822222222222222\n",
      "\tEpoch 159: \tAverage Loss:  2.558628173828125\t ACC train:  0.869\t ACC test:  0.8577777777777778\n",
      "\tEpoch 160: \tAverage Loss:  2.5451962890625\t ACC train:  0.875\t ACC test:  0.8777777777777778\n",
      "\tEpoch 161: \tAverage Loss:  2.53517724609375\t ACC train:  0.883\t ACC test:  0.8488888888888889\n",
      "\tEpoch 162: \tAverage Loss:  2.5352449951171874\t ACC train:  0.878\t ACC test:  0.8888888888888888\n",
      "\tEpoch 163: \tAverage Loss:  2.5311356201171873\t ACC train:  0.861\t ACC test:  0.8777777777777778\n",
      "\tEpoch 164: \tAverage Loss:  2.5174217529296876\t ACC train:  0.872\t ACC test:  0.88\n",
      "\tEpoch 165: \tAverage Loss:  2.50170849609375\t ACC train:  0.871\t ACC test:  0.8844444444444445\n",
      "\tEpoch 166: \tAverage Loss:  2.504342041015625\t ACC train:  0.877\t ACC test:  0.8755555555555555\n",
      "\tEpoch 167: \tAverage Loss:  2.48511181640625\t ACC train:  0.884\t ACC test:  0.8822222222222222\n",
      "\tEpoch 168: \tAverage Loss:  2.477866455078125\t ACC train:  0.882\t ACC test:  0.8911111111111111\n",
      "\tEpoch 169: \tAverage Loss:  2.46850048828125\t ACC train:  0.886\t ACC test:  0.9044444444444445\n",
      "\tEpoch 170: \tAverage Loss:  2.475603271484375\t ACC train:  0.884\t ACC test:  0.8933333333333333\n",
      "\tEpoch 171: \tAverage Loss:  2.4736646728515623\t ACC train:  0.888\t ACC test:  0.8755555555555555\n",
      "\tEpoch 172: \tAverage Loss:  2.459123046875\t ACC train:  0.887\t ACC test:  0.8955555555555555\n",
      "\tEpoch 173: \tAverage Loss:  2.45591162109375\t ACC train:  0.893\t ACC test:  0.9\n",
      "\tEpoch 174: \tAverage Loss:  2.452039794921875\t ACC train:  0.889\t ACC test:  0.9111111111111111\n",
      "\tEpoch 175: \tAverage Loss:  2.4347659912109374\t ACC train:  0.887\t ACC test:  0.9111111111111111\n",
      "\tEpoch 176: \tAverage Loss:  2.4353858642578126\t ACC train:  0.901\t ACC test:  0.9177777777777778\n",
      "\tEpoch 177: \tAverage Loss:  2.4312530517578126\t ACC train:  0.902\t ACC test:  0.9222222222222223\n",
      "\tEpoch 178: \tAverage Loss:  2.4286383056640624\t ACC train:  0.903\t ACC test:  0.9022222222222223\n",
      "\tEpoch 179: \tAverage Loss:  2.4103155517578125\t ACC train:  0.897\t ACC test:  0.9088888888888889\n",
      "\tEpoch 180: \tAverage Loss:  2.40687744140625\t ACC train:  0.901\t ACC test:  0.9222222222222223\n",
      "\tEpoch 181: \tAverage Loss:  2.4032216796875\t ACC train:  0.913\t ACC test:  0.9222222222222223\n",
      "\tEpoch 182: \tAverage Loss:  2.40252294921875\t ACC train:  0.914\t ACC test:  0.9244444444444444\n",
      "\tEpoch 183: \tAverage Loss:  2.395552490234375\t ACC train:  0.915\t ACC test:  0.9244444444444444\n",
      "\tEpoch 184: \tAverage Loss:  2.387760498046875\t ACC train:  0.915\t ACC test:  0.9288888888888889\n",
      "\tEpoch 185: \tAverage Loss:  2.38084033203125\t ACC train:  0.914\t ACC test:  0.9244444444444444\n",
      "\tEpoch 186: \tAverage Loss:  2.378282958984375\t ACC train:  0.915\t ACC test:  0.92\n",
      "\tEpoch 187: \tAverage Loss:  2.36951220703125\t ACC train:  0.923\t ACC test:  0.9311111111111111\n",
      "\tEpoch 188: \tAverage Loss:  2.379042724609375\t ACC train:  0.922\t ACC test:  0.9244444444444444\n",
      "\tEpoch 189: \tAverage Loss:  2.36202197265625\t ACC train:  0.923\t ACC test:  0.9288888888888889\n",
      "\tEpoch 190: \tAverage Loss:  2.35721435546875\t ACC train:  0.931\t ACC test:  0.94\n",
      "\tEpoch 191: \tAverage Loss:  2.3617706298828125\t ACC train:  0.928\t ACC test:  0.94\n",
      "\tEpoch 192: \tAverage Loss:  2.35362109375\t ACC train:  0.936\t ACC test:  0.9333333333333333\n",
      "\tEpoch 193: \tAverage Loss:  2.3465125732421876\t ACC train:  0.934\t ACC test:  0.9444444444444444\n",
      "\tEpoch 194: \tAverage Loss:  2.34342724609375\t ACC train:  0.932\t ACC test:  0.9333333333333333\n",
      "\tEpoch 195: \tAverage Loss:  2.3391591796875\t ACC train:  0.93\t ACC test:  0.9377777777777778\n",
      "\tEpoch 196: \tAverage Loss:  2.336903076171875\t ACC train:  0.93\t ACC test:  0.9377777777777778\n",
      "\tEpoch 197: \tAverage Loss:  2.3293895263671875\t ACC train:  0.938\t ACC test:  0.9266666666666666\n",
      "\tEpoch 198: \tAverage Loss:  2.3383834228515625\t ACC train:  0.934\t ACC test:  0.9311111111111111\n",
      "\tEpoch 199: \tAverage Loss:  2.3217413330078127\t ACC train:  0.945\t ACC test:  0.9488888888888889\n",
      "\tEpoch 200: \tAverage Loss:  2.319085205078125\t ACC train:  0.939\t ACC test:  0.9511111111111111\n",
      "\tEpoch 201: \tAverage Loss:  2.3170145263671875\t ACC train:  0.939\t ACC test:  0.9488888888888889\n",
      "\tEpoch 202: \tAverage Loss:  2.3091575927734374\t ACC train:  0.941\t ACC test:  0.96\n",
      "\tEpoch 203: \tAverage Loss:  2.311223388671875\t ACC train:  0.948\t ACC test:  0.9377777777777778\n",
      "\tEpoch 204: \tAverage Loss:  2.3034918212890627\t ACC train:  0.95\t ACC test:  0.9577777777777777\n",
      "\tEpoch 205: \tAverage Loss:  2.3029342041015624\t ACC train:  0.949\t ACC test:  0.9488888888888889\n",
      "\tEpoch 206: \tAverage Loss:  2.2939820556640624\t ACC train:  0.946\t ACC test:  0.9533333333333334\n",
      "\tEpoch 207: \tAverage Loss:  2.29292431640625\t ACC train:  0.949\t ACC test:  0.9533333333333334\n",
      "\tEpoch 208: \tAverage Loss:  2.2931029052734373\t ACC train:  0.953\t ACC test:  0.96\n",
      "\tEpoch 209: \tAverage Loss:  2.289560546875\t ACC train:  0.951\t ACC test:  0.9688888888888889\n",
      "\tEpoch 210: \tAverage Loss:  2.284947021484375\t ACC train:  0.958\t ACC test:  0.9555555555555556\n",
      "\tEpoch 211: \tAverage Loss:  2.2861099853515623\t ACC train:  0.958\t ACC test:  0.96\n",
      "\tEpoch 212: \tAverage Loss:  2.27831103515625\t ACC train:  0.964\t ACC test:  0.96\n",
      "\tEpoch 213: \tAverage Loss:  2.2779117431640623\t ACC train:  0.958\t ACC test:  0.9666666666666667\n",
      "\tEpoch 214: \tAverage Loss:  2.2707049560546877\t ACC train:  0.961\t ACC test:  0.9577777777777777\n",
      "\tEpoch 215: \tAverage Loss:  2.2702454833984373\t ACC train:  0.96\t ACC test:  0.9688888888888889\n",
      "\tEpoch 216: \tAverage Loss:  2.2697857666015624\t ACC train:  0.962\t ACC test:  0.9666666666666667\n",
      "\tEpoch 217: \tAverage Loss:  2.270533203125\t ACC train:  0.963\t ACC test:  0.9533333333333334\n",
      "\tEpoch 218: \tAverage Loss:  2.26386572265625\t ACC train:  0.963\t ACC test:  0.9711111111111111\n",
      "\tEpoch 219: \tAverage Loss:  2.2589420166015626\t ACC train:  0.962\t ACC test:  0.9711111111111111\n",
      "\tEpoch 220: \tAverage Loss:  2.2579561767578125\t ACC train:  0.969\t ACC test:  0.9577777777777777\n",
      "\tEpoch 221: \tAverage Loss:  2.2523604736328124\t ACC train:  0.965\t ACC test:  0.96\n",
      "\tEpoch 222: \tAverage Loss:  2.254448486328125\t ACC train:  0.965\t ACC test:  0.9644444444444444\n",
      "\tEpoch 223: \tAverage Loss:  2.253615478515625\t ACC train:  0.969\t ACC test:  0.9644444444444444\n",
      "\tEpoch 224: \tAverage Loss:  2.24004345703125\t ACC train:  0.967\t ACC test:  0.9711111111111111\n",
      "\tEpoch 225: \tAverage Loss:  2.247751220703125\t ACC train:  0.967\t ACC test:  0.9577777777777777\n",
      "\tEpoch 226: \tAverage Loss:  2.2481522216796876\t ACC train:  0.969\t ACC test:  0.9711111111111111\n",
      "\tEpoch 227: \tAverage Loss:  2.235858154296875\t ACC train:  0.97\t ACC test:  0.9666666666666667\n",
      "\tEpoch 228: \tAverage Loss:  2.2431614990234374\t ACC train:  0.968\t ACC test:  0.9644444444444444\n",
      "\tEpoch 229: \tAverage Loss:  2.2367960205078123\t ACC train:  0.968\t ACC test:  0.9711111111111111\n",
      "\tEpoch 230: \tAverage Loss:  2.233293701171875\t ACC train:  0.968\t ACC test:  0.9733333333333334\n",
      "\tEpoch 231: \tAverage Loss:  2.2343594970703125\t ACC train:  0.974\t ACC test:  0.9733333333333334\n",
      "\tEpoch 232: \tAverage Loss:  2.23009423828125\t ACC train:  0.97\t ACC test:  0.9711111111111111\n",
      "\tEpoch 233: \tAverage Loss:  2.2307877197265626\t ACC train:  0.975\t ACC test:  0.9711111111111111\n",
      "\tEpoch 234: \tAverage Loss:  2.224680908203125\t ACC train:  0.968\t ACC test:  0.9755555555555555\n",
      "\tEpoch 235: \tAverage Loss:  2.2246524658203124\t ACC train:  0.972\t ACC test:  0.9711111111111111\n",
      "\tEpoch 236: \tAverage Loss:  2.2240552978515624\t ACC train:  0.972\t ACC test:  0.9755555555555555\n",
      "\tEpoch 237: \tAverage Loss:  2.22230859375\t ACC train:  0.971\t ACC test:  0.9711111111111111\n",
      "\tEpoch 238: \tAverage Loss:  2.2162591552734376\t ACC train:  0.969\t ACC test:  0.9822222222222222\n",
      "\tEpoch 239: \tAverage Loss:  2.217697998046875\t ACC train:  0.975\t ACC test:  0.9711111111111111\n",
      "\tEpoch 240: \tAverage Loss:  2.21504345703125\t ACC train:  0.977\t ACC test:  0.9755555555555555\n",
      "\tEpoch 241: \tAverage Loss:  2.2092166748046873\t ACC train:  0.975\t ACC test:  0.9777777777777777\n",
      "\tEpoch 242: \tAverage Loss:  2.2124605712890624\t ACC train:  0.972\t ACC test:  0.9777777777777777\n",
      "\tEpoch 243: \tAverage Loss:  2.2065313720703124\t ACC train:  0.974\t ACC test:  0.98\n",
      "\tEpoch 244: \tAverage Loss:  2.2030380859375\t ACC train:  0.978\t ACC test:  0.98\n",
      "\tEpoch 245: \tAverage Loss:  2.200218017578125\t ACC train:  0.973\t ACC test:  0.9733333333333334\n",
      "\tEpoch 246: \tAverage Loss:  2.19948291015625\t ACC train:  0.978\t ACC test:  0.9733333333333334\n",
      "\tEpoch 247: \tAverage Loss:  2.19755712890625\t ACC train:  0.972\t ACC test:  0.9777777777777777\n",
      "\tEpoch 248: \tAverage Loss:  2.1977381591796874\t ACC train:  0.977\t ACC test:  0.9822222222222222\n",
      "\tEpoch 249: \tAverage Loss:  2.1950504150390624\t ACC train:  0.978\t ACC test:  0.98\n",
      "\tEpoch 250: \tAverage Loss:  2.1963428955078124\t ACC train:  0.972\t ACC test:  0.98\n",
      "\tEpoch 251: \tAverage Loss:  2.191112548828125\t ACC train:  0.977\t ACC test:  0.9755555555555555\n",
      "\tEpoch 252: \tAverage Loss:  2.1903438720703123\t ACC train:  0.982\t ACC test:  0.9844444444444445\n",
      "\tEpoch 253: \tAverage Loss:  2.19393408203125\t ACC train:  0.978\t ACC test:  0.98\n",
      "\tEpoch 254: \tAverage Loss:  2.1865203857421873\t ACC train:  0.979\t ACC test:  0.9822222222222222\n",
      "\tEpoch 255: \tAverage Loss:  2.1847022705078123\t ACC train:  0.979\t ACC test:  0.9777777777777777\n",
      "\tEpoch 256: \tAverage Loss:  2.1824310302734373\t ACC train:  0.979\t ACC test:  0.9844444444444445\n",
      "\tEpoch 257: \tAverage Loss:  2.1858677978515626\t ACC train:  0.976\t ACC test:  0.9822222222222222\n",
      "\tEpoch 258: \tAverage Loss:  2.1804195556640624\t ACC train:  0.977\t ACC test:  0.9888888888888889\n",
      "\tEpoch 259: \tAverage Loss:  2.1786702880859377\t ACC train:  0.979\t ACC test:  0.98\n",
      "\tEpoch 260: \tAverage Loss:  2.1789580078125\t ACC train:  0.983\t ACC test:  0.9777777777777777\n",
      "\tEpoch 261: \tAverage Loss:  2.1781390380859373\t ACC train:  0.979\t ACC test:  0.98\n",
      "\tEpoch 262: \tAverage Loss:  2.1745228271484374\t ACC train:  0.982\t ACC test:  0.9822222222222222\n",
      "\tEpoch 263: \tAverage Loss:  2.1718349609375\t ACC train:  0.979\t ACC test:  0.9866666666666667\n",
      "\tEpoch 264: \tAverage Loss:  2.1768226318359374\t ACC train:  0.981\t ACC test:  0.9888888888888889\n",
      "\tEpoch 265: \tAverage Loss:  2.172986572265625\t ACC train:  0.981\t ACC test:  0.9866666666666667\n",
      "\tEpoch 266: \tAverage Loss:  2.171230224609375\t ACC train:  0.98\t ACC test:  0.9844444444444445\n",
      "\tEpoch 267: \tAverage Loss:  2.1684342041015623\t ACC train:  0.983\t ACC test:  0.9844444444444445\n",
      "\tEpoch 268: \tAverage Loss:  2.167158935546875\t ACC train:  0.981\t ACC test:  0.9822222222222222\n",
      "\tEpoch 269: \tAverage Loss:  2.161572509765625\t ACC train:  0.984\t ACC test:  0.9866666666666667\n",
      "\tEpoch 270: \tAverage Loss:  2.1640572509765623\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 271: \tAverage Loss:  2.1641522216796876\t ACC train:  0.981\t ACC test:  0.9888888888888889\n",
      "\tEpoch 272: \tAverage Loss:  2.16250634765625\t ACC train:  0.982\t ACC test:  0.9888888888888889\n",
      "\tEpoch 273: \tAverage Loss:  2.1573603515625\t ACC train:  0.986\t ACC test:  0.9866666666666667\n",
      "\tEpoch 274: \tAverage Loss:  2.152934814453125\t ACC train:  0.984\t ACC test:  0.9866666666666667\n",
      "\tEpoch 275: \tAverage Loss:  2.1560128173828126\t ACC train:  0.98\t ACC test:  0.9866666666666667\n",
      "\tEpoch 276: \tAverage Loss:  2.1552230224609374\t ACC train:  0.981\t ACC test:  0.9866666666666667\n",
      "\tEpoch 277: \tAverage Loss:  2.15591943359375\t ACC train:  0.987\t ACC test:  0.9844444444444445\n",
      "\tEpoch 278: \tAverage Loss:  2.1531697998046875\t ACC train:  0.987\t ACC test:  0.9844444444444445\n",
      "\tEpoch 279: \tAverage Loss:  2.1536668701171875\t ACC train:  0.983\t ACC test:  0.9866666666666667\n",
      "\tEpoch 280: \tAverage Loss:  2.15351171875\t ACC train:  0.985\t ACC test:  0.9822222222222222\n",
      "\tEpoch 281: \tAverage Loss:  2.14693310546875\t ACC train:  0.985\t ACC test:  0.9866666666666667\n",
      "\tEpoch 282: \tAverage Loss:  2.15028759765625\t ACC train:  0.986\t ACC test:  0.9844444444444445\n",
      "\tEpoch 283: \tAverage Loss:  2.1445618896484375\t ACC train:  0.987\t ACC test:  0.9888888888888889\n",
      "\tEpoch 284: \tAverage Loss:  2.1456885986328125\t ACC train:  0.983\t ACC test:  0.9866666666666667\n",
      "\tEpoch 285: \tAverage Loss:  2.1430068359375\t ACC train:  0.986\t ACC test:  0.9888888888888889\n",
      "\tEpoch 286: \tAverage Loss:  2.1450255126953124\t ACC train:  0.989\t ACC test:  0.9888888888888889\n",
      "\tEpoch 287: \tAverage Loss:  2.1435267333984376\t ACC train:  0.993\t ACC test:  0.9866666666666667\n",
      "\tEpoch 288: \tAverage Loss:  2.139890625\t ACC train:  0.987\t ACC test:  0.9888888888888889\n",
      "\tEpoch 289: \tAverage Loss:  2.1376861572265624\t ACC train:  0.986\t ACC test:  0.9888888888888889\n",
      "\tEpoch 290: \tAverage Loss:  2.1421524658203124\t ACC train:  0.987\t ACC test:  0.9844444444444445\n",
      "\tEpoch 291: \tAverage Loss:  2.13519873046875\t ACC train:  0.987\t ACC test:  0.9888888888888889\n",
      "\tEpoch 292: \tAverage Loss:  2.1349132080078124\t ACC train:  0.985\t ACC test:  0.9866666666666667\n",
      "\tEpoch 293: \tAverage Loss:  2.1335313720703124\t ACC train:  0.984\t ACC test:  0.9888888888888889\n",
      "\tEpoch 294: \tAverage Loss:  2.1352039794921875\t ACC train:  0.989\t ACC test:  0.9888888888888889\n",
      "\tEpoch 295: \tAverage Loss:  2.130952392578125\t ACC train:  0.993\t ACC test:  0.9844444444444445\n",
      "\tEpoch 296: \tAverage Loss:  2.13261328125\t ACC train:  0.99\t ACC test:  0.9888888888888889\n",
      "\tEpoch 297: \tAverage Loss:  2.1308363037109377\t ACC train:  0.989\t ACC test:  0.9866666666666667\n",
      "\tEpoch 298: \tAverage Loss:  2.126154541015625\t ACC train:  0.988\t ACC test:  0.9866666666666667\n",
      "\tEpoch 299: \tAverage Loss:  2.1265897216796876\t ACC train:  0.993\t ACC test:  0.9888888888888889\n",
      "\tEpoch 300: \tAverage Loss:  2.1246824951171877\t ACC train:  0.993\t ACC test:  0.9866666666666667\n",
      "\tEpoch 301: \tAverage Loss:  2.124263916015625\t ACC train:  0.994\t ACC test:  0.9866666666666667\n",
      "\tEpoch 302: \tAverage Loss:  2.12310986328125\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 303: \tAverage Loss:  2.121920166015625\t ACC train:  0.995\t ACC test:  0.9888888888888889\n",
      "\tEpoch 304: \tAverage Loss:  2.1207276611328125\t ACC train:  0.99\t ACC test:  0.9866666666666667\n",
      "\tEpoch 305: \tAverage Loss:  2.119820068359375\t ACC train:  0.988\t ACC test:  0.9888888888888889\n",
      "\tEpoch 306: \tAverage Loss:  2.116560791015625\t ACC train:  0.992\t ACC test:  0.9888888888888889\n",
      "\tEpoch 307: \tAverage Loss:  2.1172440185546875\t ACC train:  0.993\t ACC test:  0.9888888888888889\n",
      "\tEpoch 308: \tAverage Loss:  2.1169041748046875\t ACC train:  0.995\t ACC test:  0.9888888888888889\n",
      "\tEpoch 309: \tAverage Loss:  2.1150811767578124\t ACC train:  0.992\t ACC test:  0.9888888888888889\n",
      "\tEpoch 310: \tAverage Loss:  2.11412060546875\t ACC train:  0.993\t ACC test:  0.9888888888888889\n",
      "\tEpoch 311: \tAverage Loss:  2.11414892578125\t ACC train:  0.995\t ACC test:  0.9888888888888889\n",
      "\tEpoch 312: \tAverage Loss:  2.1121729736328123\t ACC train:  0.995\t ACC test:  0.9866666666666667\n",
      "\tEpoch 313: \tAverage Loss:  2.11231787109375\t ACC train:  0.994\t ACC test:  0.9888888888888889\n",
      "\tEpoch 314: \tAverage Loss:  2.1108170166015623\t ACC train:  0.993\t ACC test:  0.9888888888888889\n",
      "\tEpoch 315: \tAverage Loss:  2.11311083984375\t ACC train:  0.994\t ACC test:  0.9888888888888889\n",
      "\tEpoch 316: \tAverage Loss:  2.1088953857421875\t ACC train:  0.996\t ACC test:  0.9888888888888889\n",
      "\tEpoch 317: \tAverage Loss:  2.109158935546875\t ACC train:  0.996\t ACC test:  0.9888888888888889\n",
      "\tEpoch 318: \tAverage Loss:  2.107673095703125\t ACC train:  0.996\t ACC test:  0.9888888888888889\n",
      "\tEpoch 319: \tAverage Loss:  2.106810791015625\t ACC train:  0.996\t ACC test:  0.9888888888888889\n",
      "\tEpoch 320: \tAverage Loss:  2.1054638671875\t ACC train:  0.995\t ACC test:  0.9888888888888889\n",
      "\tEpoch 321: \tAverage Loss:  2.1048458251953126\t ACC train:  0.994\t ACC test:  0.9866666666666667\n",
      "\tEpoch 322: \tAverage Loss:  2.1028231201171876\t ACC train:  0.997\t ACC test:  0.9911111111111112\n",
      "\tEpoch 323: \tAverage Loss:  2.1052347412109373\t ACC train:  0.997\t ACC test:  0.9911111111111112\n",
      "\tEpoch 324: \tAverage Loss:  2.104353759765625\t ACC train:  0.996\t ACC test:  0.9888888888888889\n",
      "\tEpoch 325: \tAverage Loss:  2.101268798828125\t ACC train:  0.994\t ACC test:  0.9888888888888889\n",
      "\tEpoch 326: \tAverage Loss:  2.1000400390625\t ACC train:  0.997\t ACC test:  0.9888888888888889\n",
      "\tEpoch 327: \tAverage Loss:  2.09862646484375\t ACC train:  0.997\t ACC test:  0.9911111111111112\n",
      "\tEpoch 328: \tAverage Loss:  2.0989129638671873\t ACC train:  0.996\t ACC test:  0.9888888888888889\n",
      "\tEpoch 329: \tAverage Loss:  2.0973267822265624\t ACC train:  0.996\t ACC test:  0.9888888888888889\n",
      "\tEpoch 330: \tAverage Loss:  2.0976917724609376\t ACC train:  0.996\t ACC test:  0.9888888888888889\n",
      "\tEpoch 331: \tAverage Loss:  2.0982322998046876\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 332: \tAverage Loss:  2.0963541259765623\t ACC train:  0.997\t ACC test:  0.9888888888888889\n",
      "\tEpoch 333: \tAverage Loss:  2.0958623046875\t ACC train:  0.997\t ACC test:  0.9888888888888889\n",
      "\tEpoch 334: \tAverage Loss:  2.0934764404296873\t ACC train:  0.997\t ACC test:  0.9888888888888889\n",
      "\tEpoch 335: \tAverage Loss:  2.0942513427734375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 336: \tAverage Loss:  2.0923341064453127\t ACC train:  0.997\t ACC test:  0.9888888888888889\n",
      "\tEpoch 337: \tAverage Loss:  2.092131103515625\t ACC train:  0.997\t ACC test:  0.9888888888888889\n",
      "\tEpoch 338: \tAverage Loss:  2.091740173339844\t ACC train:  0.997\t ACC test:  0.9888888888888889\n",
      "\tEpoch 339: \tAverage Loss:  2.0911373291015627\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 340: \tAverage Loss:  2.091133544921875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 341: \tAverage Loss:  2.0892843017578127\t ACC train:  0.997\t ACC test:  0.9911111111111112\n",
      "\tEpoch 342: \tAverage Loss:  2.089931640625\t ACC train:  0.997\t ACC test:  0.9888888888888889\n",
      "\tEpoch 343: \tAverage Loss:  2.0891453857421873\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 344: \tAverage Loss:  2.0878902587890624\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 345: \tAverage Loss:  2.0874637451171876\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 346: \tAverage Loss:  2.0855577392578124\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 347: \tAverage Loss:  2.0866173095703124\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 348: \tAverage Loss:  2.08576513671875\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 349: \tAverage Loss:  2.084841552734375\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 350: \tAverage Loss:  2.0830478515625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 351: \tAverage Loss:  2.08401953125\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 352: \tAverage Loss:  2.0839404296875\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 353: \tAverage Loss:  2.0826304931640625\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 354: \tAverage Loss:  2.0835828857421874\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 355: \tAverage Loss:  2.081499755859375\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 356: \tAverage Loss:  2.07966064453125\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 357: \tAverage Loss:  2.0800653076171876\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 358: \tAverage Loss:  2.079007080078125\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 359: \tAverage Loss:  2.0787696533203124\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 360: \tAverage Loss:  2.0781063232421877\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 361: \tAverage Loss:  2.0784749755859373\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 362: \tAverage Loss:  2.0771290283203125\t ACC train:  0.999\t ACC test:  0.9933333333333333\n",
      "\tEpoch 363: \tAverage Loss:  2.07780419921875\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 364: \tAverage Loss:  2.0757987060546874\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 365: \tAverage Loss:  2.0748333740234375\t ACC train:  0.998\t ACC test:  0.9933333333333333\n",
      "\tEpoch 366: \tAverage Loss:  2.0747421875\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 367: \tAverage Loss:  2.0745692138671874\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 368: \tAverage Loss:  2.0742451171875\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 369: \tAverage Loss:  2.0734487915039064\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 370: \tAverage Loss:  2.0723485107421875\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 371: \tAverage Loss:  2.0725947265625\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 372: \tAverage Loss:  2.0718851318359377\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 373: \tAverage Loss:  2.070399658203125\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 374: \tAverage Loss:  2.0724635009765624\t ACC train:  0.998\t ACC test:  0.9933333333333333\n",
      "\tEpoch 375: \tAverage Loss:  2.0706964111328126\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 376: \tAverage Loss:  2.0708131103515623\t ACC train:  0.998\t ACC test:  0.9933333333333333\n",
      "\tEpoch 377: \tAverage Loss:  2.070590759277344\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 378: \tAverage Loss:  2.068843200683594\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 379: \tAverage Loss:  2.0676563720703127\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 380: \tAverage Loss:  2.0681339111328123\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 381: \tAverage Loss:  2.0683812866210936\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 382: \tAverage Loss:  2.067257080078125\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 383: \tAverage Loss:  2.0672403564453123\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 384: \tAverage Loss:  2.0660152587890623\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 385: \tAverage Loss:  2.066253173828125\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 386: \tAverage Loss:  2.066822204589844\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 387: \tAverage Loss:  2.0655933837890625\t ACC train:  0.999\t ACC test:  0.9933333333333333\n",
      "\tEpoch 388: \tAverage Loss:  2.0651217041015624\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 389: \tAverage Loss:  2.0660250244140625\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 390: \tAverage Loss:  2.0639468383789064\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 391: \tAverage Loss:  2.063085693359375\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 392: \tAverage Loss:  2.062852783203125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 393: \tAverage Loss:  2.0631044921875\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 394: \tAverage Loss:  2.0634443359375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 395: \tAverage Loss:  2.0627071533203125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 396: \tAverage Loss:  2.0619346923828124\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 397: \tAverage Loss:  2.0621871337890627\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 398: \tAverage Loss:  2.0608342895507814\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 399: \tAverage Loss:  2.0607293701171874\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 400: \tAverage Loss:  2.0599306640625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 401: \tAverage Loss:  2.059401123046875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 402: \tAverage Loss:  2.059703918457031\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 403: \tAverage Loss:  2.059150634765625\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 404: \tAverage Loss:  2.0589901123046874\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 405: \tAverage Loss:  2.058159851074219\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 406: \tAverage Loss:  2.0585335693359377\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 407: \tAverage Loss:  2.0579248046875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 408: \tAverage Loss:  2.056786682128906\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 409: \tAverage Loss:  2.0569361572265623\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 410: \tAverage Loss:  2.057118713378906\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 411: \tAverage Loss:  2.056195007324219\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 412: \tAverage Loss:  2.0560234375\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 413: \tAverage Loss:  2.0555327758789064\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 414: \tAverage Loss:  2.055456726074219\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 415: \tAverage Loss:  2.0551234741210935\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 416: \tAverage Loss:  2.0544671630859375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 417: \tAverage Loss:  2.05469140625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 418: \tAverage Loss:  2.054402587890625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 419: \tAverage Loss:  2.0535234375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 420: \tAverage Loss:  2.054054016113281\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 421: \tAverage Loss:  2.0538496704101563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 422: \tAverage Loss:  2.0526066284179687\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 423: \tAverage Loss:  2.0528206787109373\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 424: \tAverage Loss:  2.0518865966796875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 425: \tAverage Loss:  2.0528571166992187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 426: \tAverage Loss:  2.051301025390625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 427: \tAverage Loss:  2.0511278076171875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 428: \tAverage Loss:  2.0512138671875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 429: \tAverage Loss:  2.0511525268554687\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 430: \tAverage Loss:  2.05101953125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 431: \tAverage Loss:  2.0500751953125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 432: \tAverage Loss:  2.049911315917969\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 433: \tAverage Loss:  2.0500150146484377\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 434: \tAverage Loss:  2.049710205078125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 435: \tAverage Loss:  2.048938720703125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 436: \tAverage Loss:  2.0483487548828125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 437: \tAverage Loss:  2.047900390625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 438: \tAverage Loss:  2.048353759765625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 439: \tAverage Loss:  2.047584899902344\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 440: \tAverage Loss:  2.04746875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 441: \tAverage Loss:  2.047494384765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 442: \tAverage Loss:  2.046971252441406\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 443: \tAverage Loss:  2.047060546875\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 444: \tAverage Loss:  2.0468017578125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 445: \tAverage Loss:  2.0463917846679687\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 446: \tAverage Loss:  2.0456371459960936\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 447: \tAverage Loss:  2.0449237060546874\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 448: \tAverage Loss:  2.044918029785156\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 449: \tAverage Loss:  2.04572216796875\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 450: \tAverage Loss:  2.0453875732421873\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 451: \tAverage Loss:  2.045092834472656\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 452: \tAverage Loss:  2.044533447265625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 453: \tAverage Loss:  2.0443045654296874\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 454: \tAverage Loss:  2.044161376953125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 455: \tAverage Loss:  2.044077880859375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 456: \tAverage Loss:  2.042964416503906\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 457: \tAverage Loss:  2.043352783203125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 458: \tAverage Loss:  2.0427763671875\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 459: \tAverage Loss:  2.042896484375\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 460: \tAverage Loss:  2.0425250854492187\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 461: \tAverage Loss:  2.0422850952148437\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 462: \tAverage Loss:  2.041649841308594\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 463: \tAverage Loss:  2.042223693847656\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 464: \tAverage Loss:  2.0413121337890625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 465: \tAverage Loss:  2.0418223876953125\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 466: \tAverage Loss:  2.0408585205078125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 467: \tAverage Loss:  2.041222106933594\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 468: \tAverage Loss:  2.040794921875\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 469: \tAverage Loss:  2.039820983886719\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 470: \tAverage Loss:  2.039675048828125\t ACC train:  1.0\t ACC test:  0.9977777777777778\n",
      "\tEpoch 471: \tAverage Loss:  2.039977783203125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 472: \tAverage Loss:  2.040128173828125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 473: \tAverage Loss:  2.0392767333984376\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 474: \tAverage Loss:  2.03914697265625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 475: \tAverage Loss:  2.0391160278320313\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 476: \tAverage Loss:  2.0385983276367186\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 477: \tAverage Loss:  2.0383780517578125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 478: \tAverage Loss:  2.0387396240234374\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 479: \tAverage Loss:  2.0380681762695314\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 480: \tAverage Loss:  2.0379298706054687\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 481: \tAverage Loss:  2.037664489746094\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 482: \tAverage Loss:  2.0373377685546874\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 483: \tAverage Loss:  2.037648681640625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 484: \tAverage Loss:  2.0369981079101565\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 485: \tAverage Loss:  2.036703796386719\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 486: \tAverage Loss:  2.036573974609375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 487: \tAverage Loss:  2.0362379760742186\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 488: \tAverage Loss:  2.0354786376953125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 489: \tAverage Loss:  2.0359573364257812\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 490: \tAverage Loss:  2.0356405639648436\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 491: \tAverage Loss:  2.0348690795898436\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 492: \tAverage Loss:  2.035152587890625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 493: \tAverage Loss:  2.035574462890625\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 494: \tAverage Loss:  2.0354444580078126\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 495: \tAverage Loss:  2.0341287841796873\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 496: \tAverage Loss:  2.0345400390625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 497: \tAverage Loss:  2.034028564453125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 498: \tAverage Loss:  2.0341451416015626\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 499: \tAverage Loss:  2.0335062255859375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 500: \tAverage Loss:  2.0336142578125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 501: \tAverage Loss:  2.0333875122070313\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 502: \tAverage Loss:  2.0334505615234373\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 503: \tAverage Loss:  2.0330286865234375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 504: \tAverage Loss:  2.0328690185546874\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 505: \tAverage Loss:  2.032523742675781\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 506: \tAverage Loss:  2.0319957885742186\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 507: \tAverage Loss:  2.032069641113281\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 508: \tAverage Loss:  2.0315933837890623\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 509: \tAverage Loss:  2.031714416503906\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 510: \tAverage Loss:  2.03103857421875\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 511: \tAverage Loss:  2.031030578613281\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 512: \tAverage Loss:  2.0309988403320314\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 513: \tAverage Loss:  2.030469970703125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 514: \tAverage Loss:  2.030346618652344\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 515: \tAverage Loss:  2.030723205566406\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 516: \tAverage Loss:  2.0298338623046877\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 517: \tAverage Loss:  2.029765625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 518: \tAverage Loss:  2.029577880859375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 519: \tAverage Loss:  2.0288276977539064\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 520: \tAverage Loss:  2.029125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 521: \tAverage Loss:  2.0291165771484376\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 522: \tAverage Loss:  2.028414794921875\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 523: \tAverage Loss:  2.0280215454101564\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 524: \tAverage Loss:  2.028109436035156\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 525: \tAverage Loss:  2.0281019287109374\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 526: \tAverage Loss:  2.0274742431640624\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 527: \tAverage Loss:  2.027191955566406\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 528: \tAverage Loss:  2.0273411254882814\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 529: \tAverage Loss:  2.0269505615234373\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 530: \tAverage Loss:  2.026528564453125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 531: \tAverage Loss:  2.026447692871094\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 532: \tAverage Loss:  2.0262218627929687\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 533: \tAverage Loss:  2.02586572265625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 534: \tAverage Loss:  2.02534423828125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 535: \tAverage Loss:  2.0254486083984373\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 536: \tAverage Loss:  2.0249544677734375\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 537: \tAverage Loss:  2.0244821166992186\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 538: \tAverage Loss:  2.024649108886719\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 539: \tAverage Loss:  2.0240685424804687\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 540: \tAverage Loss:  2.023550048828125\t ACC train:  1.0\t ACC test:  0.9955555555555555\n",
      "\tEpoch 541: \tAverage Loss:  2.02325537109375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 542: \tAverage Loss:  2.0228197021484373\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 543: \tAverage Loss:  2.0221790771484374\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 544: \tAverage Loss:  2.022052062988281\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 545: \tAverage Loss:  2.02190185546875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 546: \tAverage Loss:  2.021477233886719\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 547: \tAverage Loss:  2.021036804199219\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 548: \tAverage Loss:  2.020416259765625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 549: \tAverage Loss:  2.020196594238281\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 550: \tAverage Loss:  2.019378356933594\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 551: \tAverage Loss:  2.0192721557617186\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 552: \tAverage Loss:  2.0179560546875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 553: \tAverage Loss:  2.017812072753906\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 554: \tAverage Loss:  2.017339599609375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 555: \tAverage Loss:  2.0157364501953126\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 556: \tAverage Loss:  2.0144737548828124\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 557: \tAverage Loss:  2.0135765380859376\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 558: \tAverage Loss:  2.012436340332031\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 559: \tAverage Loss:  2.011157287597656\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 560: \tAverage Loss:  2.0101759643554686\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 561: \tAverage Loss:  2.0080118408203127\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 562: \tAverage Loss:  2.0056145629882813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 563: \tAverage Loss:  2.00363427734375\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 564: \tAverage Loss:  2.001467102050781\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 565: \tAverage Loss:  1.998432861328125\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 566: \tAverage Loss:  1.9948790893554686\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 567: \tAverage Loss:  1.9913026123046875\t ACC train:  0.999\t ACC test:  0.9888888888888889\n",
      "\tEpoch 568: \tAverage Loss:  1.9881712036132813\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 569: \tAverage Loss:  1.9842074584960938\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 570: \tAverage Loss:  1.9797759399414063\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 571: \tAverage Loss:  1.9769772338867186\t ACC train:  0.996\t ACC test:  0.9888888888888889\n",
      "\tEpoch 572: \tAverage Loss:  1.9713592529296875\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 573: \tAverage Loss:  1.9657215576171876\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 574: \tAverage Loss:  1.9603667602539063\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 575: \tAverage Loss:  1.9535460205078126\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 576: \tAverage Loss:  1.946925048828125\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 577: \tAverage Loss:  1.9393470458984374\t ACC train:  0.991\t ACC test:  0.9822222222222222\n",
      "\tEpoch 578: \tAverage Loss:  1.9332479248046874\t ACC train:  0.991\t ACC test:  0.9822222222222222\n",
      "\tEpoch 579: \tAverage Loss:  1.9251197509765625\t ACC train:  0.99\t ACC test:  0.9822222222222222\n",
      "\tEpoch 580: \tAverage Loss:  1.9166860961914063\t ACC train:  0.989\t ACC test:  0.9822222222222222\n",
      "\tEpoch 581: \tAverage Loss:  1.9085015869140625\t ACC train:  0.987\t ACC test:  0.9822222222222222\n",
      "\tEpoch 582: \tAverage Loss:  1.9002401123046875\t ACC train:  0.987\t ACC test:  0.9822222222222222\n",
      "\tEpoch 583: \tAverage Loss:  1.8910596923828125\t ACC train:  0.987\t ACC test:  0.98\n",
      "\tEpoch 584: \tAverage Loss:  1.8828923950195313\t ACC train:  0.986\t ACC test:  0.98\n",
      "\tEpoch 585: \tAverage Loss:  1.8738786010742188\t ACC train:  0.985\t ACC test:  0.9822222222222222\n",
      "\tEpoch 586: \tAverage Loss:  1.8660403442382814\t ACC train:  0.984\t ACC test:  0.9822222222222222\n",
      "\tEpoch 587: \tAverage Loss:  1.8579908447265625\t ACC train:  0.985\t ACC test:  0.98\n",
      "\tEpoch 588: \tAverage Loss:  1.8505816650390625\t ACC train:  0.982\t ACC test:  0.98\n",
      "\tEpoch 589: \tAverage Loss:  1.841609375\t ACC train:  0.982\t ACC test:  0.98\n",
      "\tEpoch 590: \tAverage Loss:  1.8349268188476562\t ACC train:  0.983\t ACC test:  0.98\n",
      "\tEpoch 591: \tAverage Loss:  1.8288447875976563\t ACC train:  0.984\t ACC test:  0.98\n",
      "\tEpoch 592: \tAverage Loss:  1.8213762817382813\t ACC train:  0.984\t ACC test:  0.98\n",
      "\tEpoch 593: \tAverage Loss:  1.816196044921875\t ACC train:  0.982\t ACC test:  0.98\n",
      "\tEpoch 594: \tAverage Loss:  1.8102523803710937\t ACC train:  0.985\t ACC test:  0.98\n",
      "\tEpoch 595: \tAverage Loss:  1.80614892578125\t ACC train:  0.985\t ACC test:  0.98\n",
      "\tEpoch 596: \tAverage Loss:  1.7998099365234375\t ACC train:  0.985\t ACC test:  0.98\n",
      "\tEpoch 597: \tAverage Loss:  1.7960615844726562\t ACC train:  0.984\t ACC test:  0.98\n",
      "\tEpoch 598: \tAverage Loss:  1.7903140258789063\t ACC train:  0.984\t ACC test:  0.98\n",
      "\tEpoch 599: \tAverage Loss:  1.7869503173828125\t ACC train:  0.988\t ACC test:  0.98\n",
      "\tEpoch 600: \tAverage Loss:  1.7831868286132813\t ACC train:  0.986\t ACC test:  0.98\n",
      "\tEpoch 601: \tAverage Loss:  1.7790029296875\t ACC train:  0.988\t ACC test:  0.98\n",
      "\tEpoch 602: \tAverage Loss:  1.776064697265625\t ACC train:  0.987\t ACC test:  0.98\n",
      "\tEpoch 603: \tAverage Loss:  1.7726472778320312\t ACC train:  0.988\t ACC test:  0.98\n",
      "\tEpoch 604: \tAverage Loss:  1.769614501953125\t ACC train:  0.987\t ACC test:  0.98\n",
      "\tEpoch 605: \tAverage Loss:  1.766844482421875\t ACC train:  0.987\t ACC test:  0.98\n",
      "\tEpoch 606: \tAverage Loss:  1.7640673828125\t ACC train:  0.989\t ACC test:  0.98\n",
      "\tEpoch 607: \tAverage Loss:  1.7622227172851563\t ACC train:  0.989\t ACC test:  0.98\n",
      "\tEpoch 608: \tAverage Loss:  1.7595226440429688\t ACC train:  0.991\t ACC test:  0.98\n",
      "\tEpoch 609: \tAverage Loss:  1.7571217651367188\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 610: \tAverage Loss:  1.7550203857421875\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 611: \tAverage Loss:  1.7533125\t ACC train:  0.99\t ACC test:  0.98\n",
      "\tEpoch 612: \tAverage Loss:  1.7509301147460938\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 613: \tAverage Loss:  1.7491946411132813\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 614: \tAverage Loss:  1.7483839111328126\t ACC train:  0.991\t ACC test:  0.98\n",
      "\tEpoch 615: \tAverage Loss:  1.7472023315429688\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 616: \tAverage Loss:  1.745136474609375\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 617: \tAverage Loss:  1.7432210083007813\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 618: \tAverage Loss:  1.741843017578125\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 619: \tAverage Loss:  1.7411757202148437\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 620: \tAverage Loss:  1.739200927734375\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 621: \tAverage Loss:  1.7381611938476562\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 622: \tAverage Loss:  1.7369338989257812\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 623: \tAverage Loss:  1.7352175903320313\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 624: \tAverage Loss:  1.7342008056640625\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 625: \tAverage Loss:  1.7333406982421875\t ACC train:  0.993\t ACC test:  0.98\n",
      "\tEpoch 626: \tAverage Loss:  1.7325771484375\t ACC train:  0.992\t ACC test:  0.98\n",
      "\tEpoch 627: \tAverage Loss:  1.7314627075195312\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 628: \tAverage Loss:  1.7302314453125\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 629: \tAverage Loss:  1.7294003295898437\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 630: \tAverage Loss:  1.7290988159179688\t ACC train:  0.993\t ACC test:  0.98\n",
      "\tEpoch 631: \tAverage Loss:  1.7278201904296875\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 632: \tAverage Loss:  1.7269421997070313\t ACC train:  0.993\t ACC test:  0.9844444444444445\n",
      "\tEpoch 633: \tAverage Loss:  1.7265159301757813\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 634: \tAverage Loss:  1.725406982421875\t ACC train:  0.993\t ACC test:  0.98\n",
      "\tEpoch 635: \tAverage Loss:  1.724602783203125\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 636: \tAverage Loss:  1.724282958984375\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 637: \tAverage Loss:  1.7227991333007813\t ACC train:  0.993\t ACC test:  0.98\n",
      "\tEpoch 638: \tAverage Loss:  1.7223405151367188\t ACC train:  0.992\t ACC test:  0.9822222222222222\n",
      "\tEpoch 639: \tAverage Loss:  1.721486083984375\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 640: \tAverage Loss:  1.7210609130859376\t ACC train:  0.995\t ACC test:  0.9844444444444445\n",
      "\tEpoch 641: \tAverage Loss:  1.7206248779296875\t ACC train:  0.993\t ACC test:  0.9822222222222222\n",
      "\tEpoch 642: \tAverage Loss:  1.7196609497070312\t ACC train:  0.993\t ACC test:  0.98\n",
      "\tEpoch 643: \tAverage Loss:  1.719173828125\t ACC train:  0.994\t ACC test:  0.98\n",
      "\tEpoch 644: \tAverage Loss:  1.7186666870117187\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 645: \tAverage Loss:  1.7180809936523438\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 646: \tAverage Loss:  1.7175216064453125\t ACC train:  0.994\t ACC test:  0.98\n",
      "\tEpoch 647: \tAverage Loss:  1.7172219848632813\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 648: \tAverage Loss:  1.7169552001953126\t ACC train:  0.994\t ACC test:  0.98\n",
      "\tEpoch 649: \tAverage Loss:  1.7161354370117188\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 650: \tAverage Loss:  1.715594970703125\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 651: \tAverage Loss:  1.7150415649414064\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 652: \tAverage Loss:  1.714468505859375\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 653: \tAverage Loss:  1.7141769409179688\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 654: \tAverage Loss:  1.7138013305664062\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 655: \tAverage Loss:  1.7132875366210938\t ACC train:  0.995\t ACC test:  0.9844444444444445\n",
      "\tEpoch 656: \tAverage Loss:  1.7126112670898437\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 657: \tAverage Loss:  1.7124030151367187\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 658: \tAverage Loss:  1.7119131469726563\t ACC train:  0.995\t ACC test:  0.9866666666666667\n",
      "\tEpoch 659: \tAverage Loss:  1.7116702880859376\t ACC train:  0.995\t ACC test:  0.9866666666666667\n",
      "\tEpoch 660: \tAverage Loss:  1.7111068725585938\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 661: \tAverage Loss:  1.7106121826171874\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 662: \tAverage Loss:  1.710363037109375\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 663: \tAverage Loss:  1.7099694213867187\t ACC train:  0.995\t ACC test:  0.9866666666666667\n",
      "\tEpoch 664: \tAverage Loss:  1.7095819091796876\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 665: \tAverage Loss:  1.7090380859375\t ACC train:  0.993\t ACC test:  0.9844444444444445\n",
      "\tEpoch 666: \tAverage Loss:  1.7090905151367188\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 667: \tAverage Loss:  1.7086091918945312\t ACC train:  0.995\t ACC test:  0.9866666666666667\n",
      "\tEpoch 668: \tAverage Loss:  1.7085379638671876\t ACC train:  0.995\t ACC test:  0.9844444444444445\n",
      "\tEpoch 669: \tAverage Loss:  1.7078565063476563\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 670: \tAverage Loss:  1.7078636474609374\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 671: \tAverage Loss:  1.7073571166992187\t ACC train:  0.995\t ACC test:  0.9866666666666667\n",
      "\tEpoch 672: \tAverage Loss:  1.7070042724609376\t ACC train:  0.995\t ACC test:  0.9866666666666667\n",
      "\tEpoch 673: \tAverage Loss:  1.7068405151367188\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 674: \tAverage Loss:  1.70656298828125\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 675: \tAverage Loss:  1.7065545043945312\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 676: \tAverage Loss:  1.705706787109375\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 677: \tAverage Loss:  1.7054794311523438\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 678: \tAverage Loss:  1.70533837890625\t ACC train:  0.994\t ACC test:  0.9844444444444445\n",
      "\tEpoch 679: \tAverage Loss:  1.70519189453125\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 680: \tAverage Loss:  1.7047655029296875\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 681: \tAverage Loss:  1.704447509765625\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 682: \tAverage Loss:  1.7041700439453125\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 683: \tAverage Loss:  1.70415087890625\t ACC train:  0.995\t ACC test:  0.9866666666666667\n",
      "\tEpoch 684: \tAverage Loss:  1.7037893676757812\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 685: \tAverage Loss:  1.7034158325195312\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 686: \tAverage Loss:  1.7031314086914062\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 687: \tAverage Loss:  1.7028501586914062\t ACC train:  0.995\t ACC test:  0.9866666666666667\n",
      "\tEpoch 688: \tAverage Loss:  1.7029187622070312\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 689: \tAverage Loss:  1.7023524169921875\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 690: \tAverage Loss:  1.7020524291992187\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 691: \tAverage Loss:  1.7020194091796874\t ACC train:  0.994\t ACC test:  0.9822222222222222\n",
      "\tEpoch 692: \tAverage Loss:  1.7018856811523437\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 693: \tAverage Loss:  1.701460693359375\t ACC train:  0.995\t ACC test:  0.9844444444444445\n",
      "\tEpoch 694: \tAverage Loss:  1.7011741943359375\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 695: \tAverage Loss:  1.700930419921875\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 696: \tAverage Loss:  1.7006768798828125\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 697: \tAverage Loss:  1.7005160522460938\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 698: \tAverage Loss:  1.7003252563476563\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 699: \tAverage Loss:  1.7001124877929688\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 700: \tAverage Loss:  1.69986279296875\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 701: \tAverage Loss:  1.6996806640625\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 702: \tAverage Loss:  1.6994127197265625\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 703: \tAverage Loss:  1.6993419799804688\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 704: \tAverage Loss:  1.6991207275390625\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 705: \tAverage Loss:  1.6987854614257814\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 706: \tAverage Loss:  1.6987062377929687\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 707: \tAverage Loss:  1.6984602661132813\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 708: \tAverage Loss:  1.6982860717773438\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 709: \tAverage Loss:  1.6980166015625\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 710: \tAverage Loss:  1.697786376953125\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 711: \tAverage Loss:  1.6977776489257812\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 712: \tAverage Loss:  1.6976445922851562\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 713: \tAverage Loss:  1.6975532836914062\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 714: \tAverage Loss:  1.6972144165039063\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 715: \tAverage Loss:  1.6970225830078125\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 716: \tAverage Loss:  1.6968161010742187\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 717: \tAverage Loss:  1.6966761474609375\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 718: \tAverage Loss:  1.6964331665039063\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 719: \tAverage Loss:  1.6964998168945313\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 720: \tAverage Loss:  1.6964319458007813\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 721: \tAverage Loss:  1.6959554443359375\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 722: \tAverage Loss:  1.6958359985351563\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 723: \tAverage Loss:  1.6959896240234376\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 724: \tAverage Loss:  1.6957606201171875\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 725: \tAverage Loss:  1.6955004272460938\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 726: \tAverage Loss:  1.6954088745117188\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 727: \tAverage Loss:  1.695193359375\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 728: \tAverage Loss:  1.6954673461914063\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 729: \tAverage Loss:  1.6951693725585937\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 730: \tAverage Loss:  1.695416748046875\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 731: \tAverage Loss:  1.69514306640625\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 732: \tAverage Loss:  1.6949216918945313\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 733: \tAverage Loss:  1.6944930419921875\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 734: \tAverage Loss:  1.6947362670898438\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 735: \tAverage Loss:  1.6945105590820313\t ACC train:  0.995\t ACC test:  0.9822222222222222\n",
      "\tEpoch 736: \tAverage Loss:  1.6945492553710937\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 737: \tAverage Loss:  1.694013671875\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 738: \tAverage Loss:  1.6937308349609375\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 739: \tAverage Loss:  1.693625732421875\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 740: \tAverage Loss:  1.6937411499023438\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 741: \tAverage Loss:  1.6934149780273438\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 742: \tAverage Loss:  1.6931720581054688\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 743: \tAverage Loss:  1.6932161865234374\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 744: \tAverage Loss:  1.6927454223632812\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 745: \tAverage Loss:  1.6927666015625\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 746: \tAverage Loss:  1.6928037719726563\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 747: \tAverage Loss:  1.692675048828125\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 748: \tAverage Loss:  1.6926527709960937\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 749: \tAverage Loss:  1.6923492431640625\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 750: \tAverage Loss:  1.6921624755859375\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 751: \tAverage Loss:  1.6920376586914063\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 752: \tAverage Loss:  1.6916673583984374\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 753: \tAverage Loss:  1.6915885009765625\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 754: \tAverage Loss:  1.6916048583984375\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 755: \tAverage Loss:  1.6915833129882814\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 756: \tAverage Loss:  1.691393310546875\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 757: \tAverage Loss:  1.6911004638671876\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 758: \tAverage Loss:  1.6912138061523438\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 759: \tAverage Loss:  1.6909866333007812\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 760: \tAverage Loss:  1.6908233642578125\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 761: \tAverage Loss:  1.6906111450195314\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 762: \tAverage Loss:  1.6906890258789062\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 763: \tAverage Loss:  1.6905542602539063\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 764: \tAverage Loss:  1.6904343872070313\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 765: \tAverage Loss:  1.6902750854492188\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 766: \tAverage Loss:  1.6901788330078125\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 767: \tAverage Loss:  1.6900467529296874\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 768: \tAverage Loss:  1.6901644287109374\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 769: \tAverage Loss:  1.6898958740234375\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 770: \tAverage Loss:  1.689736572265625\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 771: \tAverage Loss:  1.6895973510742188\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 772: \tAverage Loss:  1.689473388671875\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 773: \tAverage Loss:  1.6894517822265624\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 774: \tAverage Loss:  1.6894395751953124\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 775: \tAverage Loss:  1.6893174438476561\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 776: \tAverage Loss:  1.6892392578125\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 777: \tAverage Loss:  1.6889888916015625\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 778: \tAverage Loss:  1.6891298217773438\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 779: \tAverage Loss:  1.688777099609375\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 780: \tAverage Loss:  1.6887527465820313\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 781: \tAverage Loss:  1.688874267578125\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 782: \tAverage Loss:  1.688434326171875\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 783: \tAverage Loss:  1.688322998046875\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 784: \tAverage Loss:  1.6887205200195312\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 785: \tAverage Loss:  1.6883084106445312\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 786: \tAverage Loss:  1.68835595703125\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 787: \tAverage Loss:  1.6883303833007812\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 788: \tAverage Loss:  1.6881056518554687\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 789: \tAverage Loss:  1.68788232421875\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 790: \tAverage Loss:  1.687766845703125\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 791: \tAverage Loss:  1.687674560546875\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 792: \tAverage Loss:  1.6873233642578125\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 793: \tAverage Loss:  1.6875277709960939\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 794: \tAverage Loss:  1.687303955078125\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 795: \tAverage Loss:  1.687505859375\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 796: \tAverage Loss:  1.6871978149414062\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 797: \tAverage Loss:  1.6872435302734374\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 798: \tAverage Loss:  1.686943603515625\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 799: \tAverage Loss:  1.6868484497070313\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 800: \tAverage Loss:  1.68706396484375\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 801: \tAverage Loss:  1.6867205200195312\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 802: \tAverage Loss:  1.6866732788085939\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 803: \tAverage Loss:  1.6865903930664063\t ACC train:  0.996\t ACC test:  0.9866666666666667\n",
      "\tEpoch 804: \tAverage Loss:  1.686365234375\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 805: \tAverage Loss:  1.68623779296875\t ACC train:  0.996\t ACC test:  0.9822222222222222\n",
      "\tEpoch 806: \tAverage Loss:  1.686344970703125\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 807: \tAverage Loss:  1.6862430419921874\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 808: \tAverage Loss:  1.6859954223632811\t ACC train:  0.996\t ACC test:  0.9844444444444445\n",
      "\tEpoch 809: \tAverage Loss:  1.6863616943359374\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 810: \tAverage Loss:  1.6857796020507811\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 811: \tAverage Loss:  1.686125244140625\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 812: \tAverage Loss:  1.6855870971679687\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 813: \tAverage Loss:  1.685903564453125\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 814: \tAverage Loss:  1.685614013671875\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 815: \tAverage Loss:  1.6856345825195314\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 816: \tAverage Loss:  1.6855438232421875\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 817: \tAverage Loss:  1.68513525390625\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 818: \tAverage Loss:  1.6851773071289062\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 819: \tAverage Loss:  1.6852162475585937\t ACC train:  0.997\t ACC test:  0.9822222222222222\n",
      "\tEpoch 820: \tAverage Loss:  1.6849918212890624\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 821: \tAverage Loss:  1.6850675048828125\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 822: \tAverage Loss:  1.6847771606445312\t ACC train:  0.998\t ACC test:  0.9822222222222222\n",
      "\tEpoch 823: \tAverage Loss:  1.6845863037109374\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 824: \tAverage Loss:  1.6846678466796876\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 825: \tAverage Loss:  1.6847228393554687\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 826: \tAverage Loss:  1.6845484619140625\t ACC train:  0.998\t ACC test:  0.9844444444444445\n",
      "\tEpoch 827: \tAverage Loss:  1.6844607543945314\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 828: \tAverage Loss:  1.6842886962890624\t ACC train:  0.998\t ACC test:  0.9844444444444445\n",
      "\tEpoch 829: \tAverage Loss:  1.6843502807617188\t ACC train:  0.998\t ACC test:  0.9844444444444445\n",
      "\tEpoch 830: \tAverage Loss:  1.684205078125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 831: \tAverage Loss:  1.6840467529296874\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 832: \tAverage Loss:  1.6842507934570312\t ACC train:  0.998\t ACC test:  0.9844444444444445\n",
      "\tEpoch 833: \tAverage Loss:  1.6840301513671876\t ACC train:  0.997\t ACC test:  0.9844444444444445\n",
      "\tEpoch 834: \tAverage Loss:  1.68385595703125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 835: \tAverage Loss:  1.683847412109375\t ACC train:  0.998\t ACC test:  0.9844444444444445\n",
      "\tEpoch 836: \tAverage Loss:  1.6836453857421876\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 837: \tAverage Loss:  1.683512451171875\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 838: \tAverage Loss:  1.6835201416015626\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 839: \tAverage Loss:  1.6836985473632813\t ACC train:  0.997\t ACC test:  0.9866666666666667\n",
      "\tEpoch 840: \tAverage Loss:  1.6835084838867187\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 841: \tAverage Loss:  1.683169189453125\t ACC train:  0.998\t ACC test:  0.9844444444444445\n",
      "\tEpoch 842: \tAverage Loss:  1.6833591918945312\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 843: \tAverage Loss:  1.6831793212890624\t ACC train:  0.998\t ACC test:  0.9844444444444445\n",
      "\tEpoch 844: \tAverage Loss:  1.6831531372070312\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 845: \tAverage Loss:  1.6829839477539061\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 846: \tAverage Loss:  1.6828843994140625\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 847: \tAverage Loss:  1.6827611083984375\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 848: \tAverage Loss:  1.68284130859375\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 849: \tAverage Loss:  1.68258544921875\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 850: \tAverage Loss:  1.6825774536132811\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 851: \tAverage Loss:  1.6824762573242187\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 852: \tAverage Loss:  1.6825263671875\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 853: \tAverage Loss:  1.6825142822265624\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 854: \tAverage Loss:  1.6822667846679686\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 855: \tAverage Loss:  1.6825242309570312\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 856: \tAverage Loss:  1.6821415405273437\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 857: \tAverage Loss:  1.682076416015625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 858: \tAverage Loss:  1.6819701538085938\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 859: \tAverage Loss:  1.6821895141601562\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 860: \tAverage Loss:  1.6819661865234374\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 861: \tAverage Loss:  1.6818161010742188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 862: \tAverage Loss:  1.6819728393554687\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 863: \tAverage Loss:  1.6816757202148438\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 864: \tAverage Loss:  1.6820244140625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 865: \tAverage Loss:  1.6820999755859376\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 866: \tAverage Loss:  1.6817894897460937\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 867: \tAverage Loss:  1.6815538330078126\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 868: \tAverage Loss:  1.6815828857421875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 869: \tAverage Loss:  1.6814901733398437\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 870: \tAverage Loss:  1.6813147583007813\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 871: \tAverage Loss:  1.6812666625976562\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 872: \tAverage Loss:  1.6811030883789062\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 873: \tAverage Loss:  1.68115185546875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 874: \tAverage Loss:  1.6809857177734375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 875: \tAverage Loss:  1.6809732666015624\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 876: \tAverage Loss:  1.6811513061523438\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 877: \tAverage Loss:  1.6811585083007812\t ACC train:  0.998\t ACC test:  0.9844444444444445\n",
      "\tEpoch 878: \tAverage Loss:  1.6808723754882813\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 879: \tAverage Loss:  1.6806634521484376\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 880: \tAverage Loss:  1.680896728515625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 881: \tAverage Loss:  1.6805077514648437\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 882: \tAverage Loss:  1.680697265625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 883: \tAverage Loss:  1.68038623046875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 884: \tAverage Loss:  1.6804801635742188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 885: \tAverage Loss:  1.6802244262695312\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 886: \tAverage Loss:  1.6802377319335937\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 887: \tAverage Loss:  1.6801541137695313\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 888: \tAverage Loss:  1.6801354370117187\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 889: \tAverage Loss:  1.6800856323242188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 890: \tAverage Loss:  1.6801258544921875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 891: \tAverage Loss:  1.679973876953125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 892: \tAverage Loss:  1.6797960815429687\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 893: \tAverage Loss:  1.6798424682617188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 894: \tAverage Loss:  1.6798736572265625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 895: \tAverage Loss:  1.6796290893554688\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 896: \tAverage Loss:  1.6797908935546875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 897: \tAverage Loss:  1.67980322265625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 898: \tAverage Loss:  1.6795695190429687\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 899: \tAverage Loss:  1.6799141845703125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 900: \tAverage Loss:  1.6793864135742187\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 901: \tAverage Loss:  1.6795641479492187\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 902: \tAverage Loss:  1.6793184204101563\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 903: \tAverage Loss:  1.6794489135742188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 904: \tAverage Loss:  1.6793436889648437\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 905: \tAverage Loss:  1.6790564575195313\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 906: \tAverage Loss:  1.6791861572265625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 907: \tAverage Loss:  1.6790870361328125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 908: \tAverage Loss:  1.6790478515625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 909: \tAverage Loss:  1.6789608154296876\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 910: \tAverage Loss:  1.6789721069335937\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 911: \tAverage Loss:  1.6789573364257813\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 912: \tAverage Loss:  1.6789305419921876\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 913: \tAverage Loss:  1.6788929443359375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 914: \tAverage Loss:  1.6789805297851563\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 915: \tAverage Loss:  1.67885693359375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 916: \tAverage Loss:  1.6788821411132813\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 917: \tAverage Loss:  1.6789728393554688\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 918: \tAverage Loss:  1.6785587158203126\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 919: \tAverage Loss:  1.6786849975585938\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 920: \tAverage Loss:  1.6785872192382814\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 921: \tAverage Loss:  1.6791508178710937\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 922: \tAverage Loss:  1.6787857055664062\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 923: \tAverage Loss:  1.6790725708007812\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 924: \tAverage Loss:  1.6791982421875\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 925: \tAverage Loss:  1.6783883666992188\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 926: \tAverage Loss:  1.6786841430664063\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 927: \tAverage Loss:  1.6782806396484375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 928: \tAverage Loss:  1.6785145263671875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 929: \tAverage Loss:  1.678188232421875\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 930: \tAverage Loss:  1.6781460571289062\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 931: \tAverage Loss:  1.6779154663085938\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 932: \tAverage Loss:  1.6778527221679687\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 933: \tAverage Loss:  1.6777969360351563\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 934: \tAverage Loss:  1.6778189697265624\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 935: \tAverage Loss:  1.6777564086914063\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 936: \tAverage Loss:  1.6777664184570313\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 937: \tAverage Loss:  1.6777380981445313\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 938: \tAverage Loss:  1.6775140380859375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 939: \tAverage Loss:  1.677320068359375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 940: \tAverage Loss:  1.677470458984375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 941: \tAverage Loss:  1.6773629150390625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 942: \tAverage Loss:  1.6776783447265624\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 943: \tAverage Loss:  1.6771768188476563\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 944: \tAverage Loss:  1.6775531005859374\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 945: \tAverage Loss:  1.6773289794921875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 946: \tAverage Loss:  1.677284912109375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 947: \tAverage Loss:  1.6775328369140625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 948: \tAverage Loss:  1.6770923461914062\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 949: \tAverage Loss:  1.6771984252929688\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 950: \tAverage Loss:  1.67682568359375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 951: \tAverage Loss:  1.6767726440429687\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 952: \tAverage Loss:  1.676820556640625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 953: \tAverage Loss:  1.676874267578125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 954: \tAverage Loss:  1.6768193359375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 955: \tAverage Loss:  1.6767925415039062\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 956: \tAverage Loss:  1.6766509399414062\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 957: \tAverage Loss:  1.6765755615234375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 958: \tAverage Loss:  1.6766569213867188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 959: \tAverage Loss:  1.6764251708984375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 960: \tAverage Loss:  1.6763665161132812\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 961: \tAverage Loss:  1.6763902587890624\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 962: \tAverage Loss:  1.6765533447265626\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 963: \tAverage Loss:  1.6762395629882811\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 964: \tAverage Loss:  1.676226318359375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 965: \tAverage Loss:  1.6764551391601563\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 966: \tAverage Loss:  1.6763677978515625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 967: \tAverage Loss:  1.676026123046875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 968: \tAverage Loss:  1.6764791259765626\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 969: \tAverage Loss:  1.6762007446289062\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 970: \tAverage Loss:  1.6760347900390624\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 971: \tAverage Loss:  1.6761435546875\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 972: \tAverage Loss:  1.6761646728515625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 973: \tAverage Loss:  1.6760179443359375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 974: \tAverage Loss:  1.6758735961914062\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 975: \tAverage Loss:  1.675770263671875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 976: \tAverage Loss:  1.6758497314453125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 977: \tAverage Loss:  1.675750244140625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 978: \tAverage Loss:  1.675566650390625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 979: \tAverage Loss:  1.6756510620117187\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 980: \tAverage Loss:  1.6756678466796875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 981: \tAverage Loss:  1.67556396484375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 982: \tAverage Loss:  1.6753964233398437\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 983: \tAverage Loss:  1.6753155517578124\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 984: \tAverage Loss:  1.6752070922851563\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 985: \tAverage Loss:  1.6751836547851562\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 986: \tAverage Loss:  1.675279541015625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 987: \tAverage Loss:  1.675237060546875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 988: \tAverage Loss:  1.6752220458984375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 989: \tAverage Loss:  1.6751788330078126\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 990: \tAverage Loss:  1.6751362915039063\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 991: \tAverage Loss:  1.6751000366210937\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 992: \tAverage Loss:  1.6751570434570313\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 993: \tAverage Loss:  1.6749736328125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 994: \tAverage Loss:  1.6747953491210938\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 995: \tAverage Loss:  1.6749229736328124\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 996: \tAverage Loss:  1.6748262939453125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 997: \tAverage Loss:  1.6747145385742188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 998: \tAverage Loss:  1.6748397216796875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 999: \tAverage Loss:  1.6745487060546875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1000: \tAverage Loss:  1.674650634765625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1001: \tAverage Loss:  1.6745004272460937\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1002: \tAverage Loss:  1.6747320556640626\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1003: \tAverage Loss:  1.6746846923828125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1004: \tAverage Loss:  1.6743851318359375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1005: \tAverage Loss:  1.674322998046875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1006: \tAverage Loss:  1.674263427734375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1007: \tAverage Loss:  1.6742984008789064\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1008: \tAverage Loss:  1.6741407470703125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1009: \tAverage Loss:  1.674291259765625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1010: \tAverage Loss:  1.6741312255859375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1011: \tAverage Loss:  1.6742693481445312\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1012: \tAverage Loss:  1.6740563354492188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1013: \tAverage Loss:  1.6740750122070311\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1014: \tAverage Loss:  1.6741312866210938\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1015: \tAverage Loss:  1.673916748046875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1016: \tAverage Loss:  1.673862548828125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1017: \tAverage Loss:  1.6741310424804687\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1018: \tAverage Loss:  1.673920654296875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1019: \tAverage Loss:  1.6737706909179688\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1020: \tAverage Loss:  1.6738096923828125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1021: \tAverage Loss:  1.6737208251953124\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1022: \tAverage Loss:  1.6738309326171874\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1023: \tAverage Loss:  1.67374267578125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1024: \tAverage Loss:  1.6738323974609375\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1025: \tAverage Loss:  1.6736514282226562\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1026: \tAverage Loss:  1.6735169067382814\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1027: \tAverage Loss:  1.67332666015625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1028: \tAverage Loss:  1.673470947265625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1029: \tAverage Loss:  1.6733552856445313\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1030: \tAverage Loss:  1.6733899536132812\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1031: \tAverage Loss:  1.673239990234375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1032: \tAverage Loss:  1.6733690185546874\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1033: \tAverage Loss:  1.6732791748046876\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1034: \tAverage Loss:  1.6731979370117187\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1035: \tAverage Loss:  1.6732755737304688\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1036: \tAverage Loss:  1.6731295776367188\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1037: \tAverage Loss:  1.6731719970703125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1038: \tAverage Loss:  1.6730653076171875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1039: \tAverage Loss:  1.6730230102539063\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1040: \tAverage Loss:  1.673087646484375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1041: \tAverage Loss:  1.6729853515625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1042: \tAverage Loss:  1.6729330444335937\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1043: \tAverage Loss:  1.6732054443359374\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1044: \tAverage Loss:  1.672889404296875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1045: \tAverage Loss:  1.6730350952148438\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1046: \tAverage Loss:  1.6729409790039063\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1047: \tAverage Loss:  1.6726408081054687\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1048: \tAverage Loss:  1.6725694580078125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1049: \tAverage Loss:  1.6724243774414063\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1050: \tAverage Loss:  1.672955322265625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1051: \tAverage Loss:  1.6726860961914063\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1052: \tAverage Loss:  1.6726806030273438\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1053: \tAverage Loss:  1.67254833984375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1054: \tAverage Loss:  1.67274365234375\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1055: \tAverage Loss:  1.6726227416992188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1056: \tAverage Loss:  1.6728732299804687\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1057: \tAverage Loss:  1.6724657592773438\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1058: \tAverage Loss:  1.6725491943359374\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1059: \tAverage Loss:  1.6721085815429688\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1060: \tAverage Loss:  1.6725003051757812\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1061: \tAverage Loss:  1.67244580078125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1062: \tAverage Loss:  1.6721729125976563\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1063: \tAverage Loss:  1.6722797241210938\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1064: \tAverage Loss:  1.6727717895507812\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1065: \tAverage Loss:  1.6723745727539063\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1066: \tAverage Loss:  1.67210546875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1067: \tAverage Loss:  1.6720648193359375\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1068: \tAverage Loss:  1.6719808959960938\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1069: \tAverage Loss:  1.6723165283203125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1070: \tAverage Loss:  1.6720828857421874\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1071: \tAverage Loss:  1.6719644775390625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1072: \tAverage Loss:  1.671823486328125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1073: \tAverage Loss:  1.671744140625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1074: \tAverage Loss:  1.671798583984375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1075: \tAverage Loss:  1.6716746826171875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1076: \tAverage Loss:  1.67152685546875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1077: \tAverage Loss:  1.671529052734375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1078: \tAverage Loss:  1.67155224609375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1079: \tAverage Loss:  1.671586669921875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1080: \tAverage Loss:  1.6718594360351562\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1081: \tAverage Loss:  1.6711986083984376\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1082: \tAverage Loss:  1.6714491577148438\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1083: \tAverage Loss:  1.6712041625976561\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1084: \tAverage Loss:  1.6713050537109375\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1085: \tAverage Loss:  1.6712567749023437\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1086: \tAverage Loss:  1.6715681762695314\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1087: \tAverage Loss:  1.6712425537109374\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1088: \tAverage Loss:  1.6713826293945313\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1089: \tAverage Loss:  1.67128564453125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1090: \tAverage Loss:  1.671544677734375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1091: \tAverage Loss:  1.6720610961914062\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1092: \tAverage Loss:  1.6711929931640626\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1093: \tAverage Loss:  1.6716368408203126\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1094: \tAverage Loss:  1.6711560668945313\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1095: \tAverage Loss:  1.67112744140625\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1096: \tAverage Loss:  1.67098583984375\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1097: \tAverage Loss:  1.671194091796875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1098: \tAverage Loss:  1.6712838134765624\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1099: \tAverage Loss:  1.6709151611328126\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1100: \tAverage Loss:  1.6708162841796874\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1101: \tAverage Loss:  1.6707960205078125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1102: \tAverage Loss:  1.6705563354492188\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1103: \tAverage Loss:  1.67054248046875\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1104: \tAverage Loss:  1.6707860107421875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1105: \tAverage Loss:  1.6705762939453126\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1106: \tAverage Loss:  1.6706926879882813\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1107: \tAverage Loss:  1.6707037353515626\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1108: \tAverage Loss:  1.6704442138671876\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1109: \tAverage Loss:  1.6703094482421874\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1110: \tAverage Loss:  1.6700606079101563\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1111: \tAverage Loss:  1.6701985473632812\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1112: \tAverage Loss:  1.6701522827148438\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1113: \tAverage Loss:  1.6700367431640626\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1114: \tAverage Loss:  1.669954833984375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1115: \tAverage Loss:  1.6700311889648438\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1116: \tAverage Loss:  1.6697530517578125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1117: \tAverage Loss:  1.6698909301757812\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1118: \tAverage Loss:  1.66994140625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1119: \tAverage Loss:  1.66965185546875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1120: \tAverage Loss:  1.6696830444335937\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1121: \tAverage Loss:  1.6698970336914063\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1122: \tAverage Loss:  1.669538330078125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1123: \tAverage Loss:  1.6699616088867189\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1124: \tAverage Loss:  1.6698270263671875\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1125: \tAverage Loss:  1.66979931640625\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1126: \tAverage Loss:  1.6696077270507812\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1127: \tAverage Loss:  1.6696053466796874\t ACC train:  0.999\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1128: \tAverage Loss:  1.6695951538085938\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1129: \tAverage Loss:  1.6693560180664062\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1130: \tAverage Loss:  1.6693822021484375\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1131: \tAverage Loss:  1.669169189453125\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1132: \tAverage Loss:  1.6695925903320312\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1133: \tAverage Loss:  1.669020751953125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1134: \tAverage Loss:  1.669013427734375\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1135: \tAverage Loss:  1.6692514038085937\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1136: \tAverage Loss:  1.669289306640625\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1137: \tAverage Loss:  1.6691515502929688\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1138: \tAverage Loss:  1.6691807861328125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1139: \tAverage Loss:  1.6692012329101562\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1140: \tAverage Loss:  1.6689354858398437\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1141: \tAverage Loss:  1.66906201171875\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1142: \tAverage Loss:  1.6690126953125\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1143: \tAverage Loss:  1.6688885498046875\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1144: \tAverage Loss:  1.6688027954101563\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1145: \tAverage Loss:  1.668644287109375\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1146: \tAverage Loss:  1.6683934326171874\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1147: \tAverage Loss:  1.6685501708984376\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1148: \tAverage Loss:  1.668677490234375\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1149: \tAverage Loss:  1.6687105102539062\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1150: \tAverage Loss:  1.6687162475585937\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1151: \tAverage Loss:  1.6687206420898437\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1152: \tAverage Loss:  1.668903564453125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1153: \tAverage Loss:  1.6681350708007812\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1154: \tAverage Loss:  1.6681412963867188\t ACC train:  0.999\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1155: \tAverage Loss:  1.6680039672851563\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1156: \tAverage Loss:  1.6679972534179688\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1157: \tAverage Loss:  1.6681343994140625\t ACC train:  0.999\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1158: \tAverage Loss:  1.66788818359375\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1159: \tAverage Loss:  1.667814453125\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1160: \tAverage Loss:  1.6678809814453126\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1161: \tAverage Loss:  1.6677529296875\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1162: \tAverage Loss:  1.667755859375\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1163: \tAverage Loss:  1.6677938842773437\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1164: \tAverage Loss:  1.6674945678710937\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1165: \tAverage Loss:  1.667527099609375\t ACC train:  0.999\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1166: \tAverage Loss:  1.6677640991210938\t ACC train:  0.999\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1167: \tAverage Loss:  1.6676310424804688\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1168: \tAverage Loss:  1.6677224731445313\t ACC train:  0.998\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1169: \tAverage Loss:  1.66775244140625\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1170: \tAverage Loss:  1.6674706420898437\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1171: \tAverage Loss:  1.6671483154296876\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1172: \tAverage Loss:  1.66711279296875\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1173: \tAverage Loss:  1.66698095703125\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1174: \tAverage Loss:  1.6670469970703126\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1175: \tAverage Loss:  1.6672774047851562\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1176: \tAverage Loss:  1.66724462890625\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1177: \tAverage Loss:  1.667260009765625\t ACC train:  0.999\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1178: \tAverage Loss:  1.6673358764648438\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1179: \tAverage Loss:  1.6669351806640624\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1180: \tAverage Loss:  1.6672667236328125\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1181: \tAverage Loss:  1.6668555908203124\t ACC train:  0.998\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1182: \tAverage Loss:  1.6668628540039063\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1183: \tAverage Loss:  1.666809326171875\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1184: \tAverage Loss:  1.6667122802734375\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1185: \tAverage Loss:  1.667163330078125\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1186: \tAverage Loss:  1.6670900268554687\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1187: \tAverage Loss:  1.6665582275390625\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1188: \tAverage Loss:  1.6664950561523437\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1189: \tAverage Loss:  1.6664798583984375\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1190: \tAverage Loss:  1.6664072875976563\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1191: \tAverage Loss:  1.6662277221679687\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1192: \tAverage Loss:  1.6662998657226562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1193: \tAverage Loss:  1.6666416015625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1194: \tAverage Loss:  1.6665830688476562\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1195: \tAverage Loss:  1.66660009765625\t ACC train:  0.999\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1196: \tAverage Loss:  1.6666995849609374\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1197: \tAverage Loss:  1.6664488525390626\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1198: \tAverage Loss:  1.6665050048828125\t ACC train:  0.998\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1199: \tAverage Loss:  1.666231689453125\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1200: \tAverage Loss:  1.6657872924804686\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1201: \tAverage Loss:  1.6658001098632813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1202: \tAverage Loss:  1.6656881103515624\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1203: \tAverage Loss:  1.6655892944335937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1204: \tAverage Loss:  1.66556982421875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1205: \tAverage Loss:  1.665605712890625\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1206: \tAverage Loss:  1.6657418823242187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1207: \tAverage Loss:  1.6656723022460938\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1208: \tAverage Loss:  1.6657154541015624\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1209: \tAverage Loss:  1.6655199584960938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1210: \tAverage Loss:  1.6652871704101562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1211: \tAverage Loss:  1.665252685546875\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1212: \tAverage Loss:  1.6653621215820313\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1213: \tAverage Loss:  1.6653965454101562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1214: \tAverage Loss:  1.6652077026367187\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1215: \tAverage Loss:  1.665500244140625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1216: \tAverage Loss:  1.6652150268554688\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1217: \tAverage Loss:  1.6650453491210937\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1218: \tAverage Loss:  1.665153076171875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1219: \tAverage Loss:  1.6650045776367188\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1220: \tAverage Loss:  1.6648710327148437\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1221: \tAverage Loss:  1.6648381958007812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1222: \tAverage Loss:  1.664939208984375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1223: \tAverage Loss:  1.6648906860351562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1224: \tAverage Loss:  1.6650669555664062\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1225: \tAverage Loss:  1.6647866821289063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1226: \tAverage Loss:  1.6648441162109375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1227: \tAverage Loss:  1.6648497314453126\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1228: \tAverage Loss:  1.6647747802734374\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1229: \tAverage Loss:  1.6649600830078124\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1230: \tAverage Loss:  1.6646860961914063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1231: \tAverage Loss:  1.66492529296875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1232: \tAverage Loss:  1.6651400146484374\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1233: \tAverage Loss:  1.6644189453125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1234: \tAverage Loss:  1.664548828125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1235: \tAverage Loss:  1.6647282104492187\t ACC train:  0.999\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1236: \tAverage Loss:  1.6644508666992188\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1237: \tAverage Loss:  1.6644161376953126\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1238: \tAverage Loss:  1.6644305419921874\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1239: \tAverage Loss:  1.6641639404296875\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1240: \tAverage Loss:  1.6641048583984375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1241: \tAverage Loss:  1.6641768798828125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1242: \tAverage Loss:  1.6641557006835936\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1243: \tAverage Loss:  1.6639783935546875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1244: \tAverage Loss:  1.6639143676757813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1245: \tAverage Loss:  1.663892578125\t ACC train:  0.999\t ACC test:  0.9866666666666667\n",
      "\tEpoch 1246: \tAverage Loss:  1.66416552734375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1247: \tAverage Loss:  1.663914794921875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1248: \tAverage Loss:  1.6637978515625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1249: \tAverage Loss:  1.6638715209960937\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1250: \tAverage Loss:  1.6639707641601562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1251: \tAverage Loss:  1.6637522583007813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1252: \tAverage Loss:  1.6636939086914062\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1253: \tAverage Loss:  1.663833984375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1254: \tAverage Loss:  1.66357421875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1255: \tAverage Loss:  1.6635349731445312\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1256: \tAverage Loss:  1.6635060424804688\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1257: \tAverage Loss:  1.6634592895507812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1258: \tAverage Loss:  1.6634059448242187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1259: \tAverage Loss:  1.66340380859375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1260: \tAverage Loss:  1.663338134765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1261: \tAverage Loss:  1.663351318359375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1262: \tAverage Loss:  1.66339404296875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1263: \tAverage Loss:  1.6632839965820312\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1264: \tAverage Loss:  1.6632965087890625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1265: \tAverage Loss:  1.663213134765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1266: \tAverage Loss:  1.6632015380859375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1267: \tAverage Loss:  1.6631021728515625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1268: \tAverage Loss:  1.663271728515625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1269: \tAverage Loss:  1.6632266235351563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1270: \tAverage Loss:  1.6633455200195313\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1271: \tAverage Loss:  1.6630603637695311\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1272: \tAverage Loss:  1.6632598876953124\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1273: \tAverage Loss:  1.6631556396484375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1274: \tAverage Loss:  1.662895263671875\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1275: \tAverage Loss:  1.6630311889648437\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1276: \tAverage Loss:  1.6632378540039063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1277: \tAverage Loss:  1.6631876220703126\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1278: \tAverage Loss:  1.6628121948242187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1279: \tAverage Loss:  1.6631890869140624\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1280: \tAverage Loss:  1.6628827514648437\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1281: \tAverage Loss:  1.662900146484375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1282: \tAverage Loss:  1.6630465698242187\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1283: \tAverage Loss:  1.6627689208984375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1284: \tAverage Loss:  1.6624844970703125\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1285: \tAverage Loss:  1.6628450317382812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1286: \tAverage Loss:  1.6626185913085938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1287: \tAverage Loss:  1.6625930786132812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1288: \tAverage Loss:  1.6626443481445312\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1289: \tAverage Loss:  1.6625519409179688\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1290: \tAverage Loss:  1.6626823120117187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1291: \tAverage Loss:  1.662494384765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1292: \tAverage Loss:  1.662452392578125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1293: \tAverage Loss:  1.6624351806640625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1294: \tAverage Loss:  1.6626480102539063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1295: \tAverage Loss:  1.6624071044921875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1296: \tAverage Loss:  1.662321533203125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1297: \tAverage Loss:  1.662302978515625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1298: \tAverage Loss:  1.6623295288085937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1299: \tAverage Loss:  1.6620838623046874\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1300: \tAverage Loss:  1.662135986328125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1301: \tAverage Loss:  1.662047119140625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1302: \tAverage Loss:  1.6619781494140624\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1303: \tAverage Loss:  1.6620701904296875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1304: \tAverage Loss:  1.662028564453125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1305: \tAverage Loss:  1.6619924926757812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1306: \tAverage Loss:  1.6624122314453125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1307: \tAverage Loss:  1.6621831665039062\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1308: \tAverage Loss:  1.6620905151367187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1309: \tAverage Loss:  1.6620775146484374\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1310: \tAverage Loss:  1.6622769775390625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1311: \tAverage Loss:  1.6618980102539063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1312: \tAverage Loss:  1.6617648315429687\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1313: \tAverage Loss:  1.661851806640625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1314: \tAverage Loss:  1.661802001953125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1315: \tAverage Loss:  1.6616192626953126\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1316: \tAverage Loss:  1.6617792358398438\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1317: \tAverage Loss:  1.6616635131835937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1318: \tAverage Loss:  1.6617280883789063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1319: \tAverage Loss:  1.6616016235351563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1320: \tAverage Loss:  1.661841796875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1321: \tAverage Loss:  1.66183349609375\t ACC train:  0.999\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1322: \tAverage Loss:  1.6615806884765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1323: \tAverage Loss:  1.6615442504882814\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1324: \tAverage Loss:  1.6613236083984375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1325: \tAverage Loss:  1.6611922607421874\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1326: \tAverage Loss:  1.6617319946289062\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1327: \tAverage Loss:  1.6613428955078124\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1328: \tAverage Loss:  1.6613336791992188\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1329: \tAverage Loss:  1.6616427001953125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1330: \tAverage Loss:  1.6613136596679687\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1331: \tAverage Loss:  1.6611642456054687\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1332: \tAverage Loss:  1.66108544921875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1333: \tAverage Loss:  1.661349365234375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1334: \tAverage Loss:  1.6611878051757814\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1335: \tAverage Loss:  1.6611056518554688\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1336: \tAverage Loss:  1.6609845581054687\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1337: \tAverage Loss:  1.6613119506835938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1338: \tAverage Loss:  1.6611412963867187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1339: \tAverage Loss:  1.6610328369140626\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1340: \tAverage Loss:  1.6610436401367188\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1341: \tAverage Loss:  1.6608289184570313\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1342: \tAverage Loss:  1.660785888671875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1343: \tAverage Loss:  1.6608756713867188\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1344: \tAverage Loss:  1.6609220581054687\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1345: \tAverage Loss:  1.660635009765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1346: \tAverage Loss:  1.6607584228515626\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1347: \tAverage Loss:  1.6608187866210937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1348: \tAverage Loss:  1.6606322021484374\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1349: \tAverage Loss:  1.660634765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1350: \tAverage Loss:  1.6606659545898437\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1351: \tAverage Loss:  1.6606009521484375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1352: \tAverage Loss:  1.6604915771484374\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1353: \tAverage Loss:  1.6604739990234374\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1354: \tAverage Loss:  1.6603978881835937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1355: \tAverage Loss:  1.6603528442382813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1356: \tAverage Loss:  1.6604437866210937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1357: \tAverage Loss:  1.6603283081054687\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1358: \tAverage Loss:  1.6602393798828126\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1359: \tAverage Loss:  1.6602338256835938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1360: \tAverage Loss:  1.660416259765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1361: \tAverage Loss:  1.6602515258789063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1362: \tAverage Loss:  1.6602301025390624\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1363: \tAverage Loss:  1.66014404296875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1364: \tAverage Loss:  1.66013671875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1365: \tAverage Loss:  1.66016162109375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1366: \tAverage Loss:  1.660176025390625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1367: \tAverage Loss:  1.6601768188476562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1368: \tAverage Loss:  1.66031884765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1369: \tAverage Loss:  1.6601423950195313\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1370: \tAverage Loss:  1.6602079467773438\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1371: \tAverage Loss:  1.660051025390625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1372: \tAverage Loss:  1.6599354858398438\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1373: \tAverage Loss:  1.660023193359375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1374: \tAverage Loss:  1.659957763671875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1375: \tAverage Loss:  1.6599423217773437\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1376: \tAverage Loss:  1.6598519287109375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1377: \tAverage Loss:  1.6597399291992188\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1378: \tAverage Loss:  1.6598992919921876\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1379: \tAverage Loss:  1.6599447021484375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1380: \tAverage Loss:  1.6600796508789062\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1381: \tAverage Loss:  1.659810302734375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1382: \tAverage Loss:  1.6597877807617187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1383: \tAverage Loss:  1.65981201171875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1384: \tAverage Loss:  1.6597501220703126\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1385: \tAverage Loss:  1.6594511108398438\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1386: \tAverage Loss:  1.6597650146484375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1387: \tAverage Loss:  1.65952001953125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1388: \tAverage Loss:  1.6594041748046875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1389: \tAverage Loss:  1.6594418334960936\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1390: \tAverage Loss:  1.65944384765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1391: \tAverage Loss:  1.659357666015625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1392: \tAverage Loss:  1.6593020629882813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1393: \tAverage Loss:  1.659288330078125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1394: \tAverage Loss:  1.6594290161132812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1395: \tAverage Loss:  1.6592731323242187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1396: \tAverage Loss:  1.6593208618164061\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1397: \tAverage Loss:  1.6593323974609375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1398: \tAverage Loss:  1.6595601806640625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1399: \tAverage Loss:  1.6594347534179688\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1400: \tAverage Loss:  1.6594051513671875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1401: \tAverage Loss:  1.6595878295898439\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1402: \tAverage Loss:  1.6590448608398438\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1403: \tAverage Loss:  1.65923828125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1404: \tAverage Loss:  1.6592327270507812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1405: \tAverage Loss:  1.6591041259765624\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1406: \tAverage Loss:  1.6591681518554688\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1407: \tAverage Loss:  1.6592520751953126\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1408: \tAverage Loss:  1.659201171875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1409: \tAverage Loss:  1.6594869384765625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1410: \tAverage Loss:  1.6591817016601562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1411: \tAverage Loss:  1.6591858520507812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1412: \tAverage Loss:  1.6589707641601563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1413: \tAverage Loss:  1.6589139404296875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1414: \tAverage Loss:  1.658850341796875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1415: \tAverage Loss:  1.6586766357421876\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1416: \tAverage Loss:  1.6586765747070313\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1417: \tAverage Loss:  1.6586143188476563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1418: \tAverage Loss:  1.6586275634765626\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1419: \tAverage Loss:  1.6587183837890624\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1420: \tAverage Loss:  1.65864306640625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1421: \tAverage Loss:  1.65862744140625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1422: \tAverage Loss:  1.6585821533203124\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1423: \tAverage Loss:  1.6586508178710937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1424: \tAverage Loss:  1.6585703125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1425: \tAverage Loss:  1.6585216064453125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1426: \tAverage Loss:  1.6585259399414063\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1427: \tAverage Loss:  1.65847119140625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1428: \tAverage Loss:  1.65864892578125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1429: \tAverage Loss:  1.6583701782226563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1430: \tAverage Loss:  1.6583325805664062\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1431: \tAverage Loss:  1.6583532104492187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1432: \tAverage Loss:  1.6583719482421875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1433: \tAverage Loss:  1.6583602905273438\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1434: \tAverage Loss:  1.6581983032226562\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1435: \tAverage Loss:  1.6581434936523438\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1436: \tAverage Loss:  1.65829931640625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1437: \tAverage Loss:  1.6582859497070312\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1438: \tAverage Loss:  1.6585292358398438\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1439: \tAverage Loss:  1.6584146118164063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1440: \tAverage Loss:  1.6586489868164063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1441: \tAverage Loss:  1.6584016723632813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1442: \tAverage Loss:  1.6584181518554688\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1443: \tAverage Loss:  1.6582570190429688\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1444: \tAverage Loss:  1.658156005859375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1445: \tAverage Loss:  1.6581748657226563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1446: \tAverage Loss:  1.658316162109375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1447: \tAverage Loss:  1.6579202880859376\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1448: \tAverage Loss:  1.6578733520507813\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1449: \tAverage Loss:  1.6579114379882813\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1450: \tAverage Loss:  1.6578182983398437\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1451: \tAverage Loss:  1.6578209228515626\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1452: \tAverage Loss:  1.6576952514648438\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1453: \tAverage Loss:  1.65772314453125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1454: \tAverage Loss:  1.6576678466796875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1455: \tAverage Loss:  1.6577074584960938\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1456: \tAverage Loss:  1.6577416381835937\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1457: \tAverage Loss:  1.6576298217773437\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1458: \tAverage Loss:  1.6577715454101563\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1459: \tAverage Loss:  1.6577540283203125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1460: \tAverage Loss:  1.6577965698242187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1461: \tAverage Loss:  1.657878173828125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1462: \tAverage Loss:  1.6576140747070311\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1463: \tAverage Loss:  1.6575841674804688\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1464: \tAverage Loss:  1.6576963500976563\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1465: \tAverage Loss:  1.6574426879882813\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1466: \tAverage Loss:  1.6575553588867187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1467: \tAverage Loss:  1.6573817138671876\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1468: \tAverage Loss:  1.6575810546875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1469: \tAverage Loss:  1.6572438354492187\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1470: \tAverage Loss:  1.6574606323242187\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1471: \tAverage Loss:  1.6572478637695311\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1472: \tAverage Loss:  1.6572926635742187\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1473: \tAverage Loss:  1.65728955078125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1474: \tAverage Loss:  1.6572932739257813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1475: \tAverage Loss:  1.6571670532226563\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1476: \tAverage Loss:  1.6572489013671876\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1477: \tAverage Loss:  1.657227783203125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1478: \tAverage Loss:  1.6571788330078125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1479: \tAverage Loss:  1.6572473754882813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1480: \tAverage Loss:  1.6572109985351562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1481: \tAverage Loss:  1.6574404907226563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1482: \tAverage Loss:  1.6572640991210938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1483: \tAverage Loss:  1.6569779663085937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1484: \tAverage Loss:  1.6570023803710938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1485: \tAverage Loss:  1.6570070190429687\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1486: \tAverage Loss:  1.6571288452148438\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1487: \tAverage Loss:  1.6570657958984376\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1488: \tAverage Loss:  1.657154541015625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1489: \tAverage Loss:  1.657114013671875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1490: \tAverage Loss:  1.6568272094726562\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1491: \tAverage Loss:  1.6567410278320311\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1492: \tAverage Loss:  1.6566895751953126\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1493: \tAverage Loss:  1.6567600708007812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1494: \tAverage Loss:  1.6568015747070313\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1495: \tAverage Loss:  1.656670654296875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1496: \tAverage Loss:  1.656845947265625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1497: \tAverage Loss:  1.6565774536132813\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1498: \tAverage Loss:  1.6565932006835937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1499: \tAverage Loss:  1.6566166381835938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1500: \tAverage Loss:  1.6566148681640624\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1501: \tAverage Loss:  1.6566346435546875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1502: \tAverage Loss:  1.6567222290039063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1503: \tAverage Loss:  1.6566477661132812\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1504: \tAverage Loss:  1.6563701782226563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1505: \tAverage Loss:  1.6565530395507813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1506: \tAverage Loss:  1.6564411010742188\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1507: \tAverage Loss:  1.6563630981445312\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1508: \tAverage Loss:  1.6565345458984375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1509: \tAverage Loss:  1.6563765258789063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1510: \tAverage Loss:  1.6563543090820312\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1511: \tAverage Loss:  1.6563242797851563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1512: \tAverage Loss:  1.656629150390625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1513: \tAverage Loss:  1.65623046875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1514: \tAverage Loss:  1.6562420654296874\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1515: \tAverage Loss:  1.6561998291015625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1516: \tAverage Loss:  1.656180419921875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1517: \tAverage Loss:  1.6562735595703124\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1518: \tAverage Loss:  1.6562387084960937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1519: \tAverage Loss:  1.6560139770507813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1520: \tAverage Loss:  1.6560286254882812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1521: \tAverage Loss:  1.6560355834960938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1522: \tAverage Loss:  1.6559390869140624\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1523: \tAverage Loss:  1.6560040893554688\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1524: \tAverage Loss:  1.6561936645507813\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1525: \tAverage Loss:  1.6559419555664063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1526: \tAverage Loss:  1.65594677734375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1527: \tAverage Loss:  1.6559042358398437\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1528: \tAverage Loss:  1.6557855834960937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1529: \tAverage Loss:  1.6558757934570312\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1530: \tAverage Loss:  1.6557858276367188\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1531: \tAverage Loss:  1.6557099609375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1532: \tAverage Loss:  1.655837646484375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1533: \tAverage Loss:  1.6559044189453125\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1534: \tAverage Loss:  1.6557496337890625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1535: \tAverage Loss:  1.655887451171875\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1536: \tAverage Loss:  1.6557293701171876\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1537: \tAverage Loss:  1.6556430053710938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1538: \tAverage Loss:  1.6556261596679687\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1539: \tAverage Loss:  1.6556236572265626\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1540: \tAverage Loss:  1.6555635375976563\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1541: \tAverage Loss:  1.6557218017578126\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1542: \tAverage Loss:  1.6555167846679688\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1543: \tAverage Loss:  1.655545654296875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1544: \tAverage Loss:  1.6554915161132813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1545: \tAverage Loss:  1.6553915405273438\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1546: \tAverage Loss:  1.6555200805664063\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1547: \tAverage Loss:  1.6554797973632813\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1548: \tAverage Loss:  1.6554088134765625\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1549: \tAverage Loss:  1.6554476928710937\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1550: \tAverage Loss:  1.655330810546875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1551: \tAverage Loss:  1.6553375244140625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1552: \tAverage Loss:  1.6553851318359376\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1553: \tAverage Loss:  1.65534130859375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1554: \tAverage Loss:  1.6553118286132813\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1555: \tAverage Loss:  1.6552503051757812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1556: \tAverage Loss:  1.6554779663085937\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1557: \tAverage Loss:  1.6552018432617188\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1558: \tAverage Loss:  1.6551775512695313\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1559: \tAverage Loss:  1.655159423828125\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1560: \tAverage Loss:  1.6551361694335938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1561: \tAverage Loss:  1.6551978759765624\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1562: \tAverage Loss:  1.655119873046875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1563: \tAverage Loss:  1.6551742553710938\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1564: \tAverage Loss:  1.6550847778320312\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1565: \tAverage Loss:  1.6552718505859374\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1566: \tAverage Loss:  1.6549697265625\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1567: \tAverage Loss:  1.6549966430664063\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1568: \tAverage Loss:  1.6549067993164062\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1569: \tAverage Loss:  1.654833740234375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1570: \tAverage Loss:  1.65523583984375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1571: \tAverage Loss:  1.655513916015625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1572: \tAverage Loss:  1.655140869140625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1573: \tAverage Loss:  1.6549485473632812\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1574: \tAverage Loss:  1.655180419921875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1575: \tAverage Loss:  1.6553059692382812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1576: \tAverage Loss:  1.6549723510742187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1577: \tAverage Loss:  1.65481640625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 1578: \tAverage Loss:  1.6549490356445313\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1579: \tAverage Loss:  1.6546285400390626\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1580: \tAverage Loss:  1.655015380859375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1581: \tAverage Loss:  1.654769287109375\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1582: \tAverage Loss:  1.6546983642578126\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1583: \tAverage Loss:  1.6546157836914062\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1584: \tAverage Loss:  1.6546799926757811\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1585: \tAverage Loss:  1.65448046875\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1586: \tAverage Loss:  1.6545127563476563\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1587: \tAverage Loss:  1.6547097778320312\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1588: \tAverage Loss:  1.6546159057617187\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1589: \tAverage Loss:  1.654456787109375\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1590: \tAverage Loss:  1.6545765380859374\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1591: \tAverage Loss:  1.6547349853515625\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1592: \tAverage Loss:  1.6542844848632812\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1593: \tAverage Loss:  1.6543189697265626\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1594: \tAverage Loss:  1.6542750244140625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1595: \tAverage Loss:  1.6543131103515625\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1596: \tAverage Loss:  1.654228515625\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "\tEpoch 1597: \tAverage Loss:  1.6541687622070314\t ACC train:  1.0\t ACC test:  0.9911111111111112\n",
      "\tEpoch 1598: \tAverage Loss:  1.6541990966796876\t ACC train:  1.0\t ACC test:  0.9888888888888889\n",
      "Stopping early at epoch 1598. No improvement in validation loss for 20 epochs.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('metric_vae_dict0.json', 'r') as file:\n",
    "        metric_vae_dict = json.load(file)\n",
    "except:\n",
    "    batch_shape = torch.Size([yn_train.shape[-1]])\n",
    "    metric_vae_list = []\n",
    "    for train_size in list_size:\n",
    "        print(f\"Training for sample size: {train_size}\")\n",
    "        yn_train_limited, ys_train_limited, labels_train_limited = yn_train[:train_size], ys_train[:train_size], labels_train[:train_size]\n",
    "\n",
    "        # Train VAE Model\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = VAE(input_dim=yn_train_limited.shape[-1],\n",
    "                    hidden_dim=30,\n",
    "                    latent_dim=10,\n",
    "                    num_classes=len(np.unique(labels_train))).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        model.fit(x=yn_train_limited, y=labels_train_limited, x_test=yn_test, y_test=labels_test, optimizer=optimizer, epochs=2000, batch_size=500, patience=20)\n",
    "        x_hat, y_hat, mean, log_var, metrics = model.evaluate(yn_test, labels_test)\n",
    "\n",
    "        metric_vae_list.append(metrics)\n",
    "    winsound.Beep(freq, duration*3)\n",
    "    metric_vae_dict = dicts_to_dict_of_lists(metric_vae_list)\n",
    "    with open('metric_vae_dict.json', 'w') as file:\n",
    "        json.dump(metric_vae_dict, file, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T01:48:21.523647900Z",
     "start_time": "2024-02-21T01:40:08.977931900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('./saved_results/metric_ldgd_dict.json', 'r') as file:\n",
    "        metric_ldgd_dict = json.load(file)\n",
    "except:\n",
    "    batch_shape = torch.Size([yn_train.shape[-1]])\n",
    "    metric_ldgd_list = []\n",
    "    for train_size in list_size:\n",
    "        model_settings['num_inducing_points_reg']= np.max([int(train_size/10) + 5, 25])\n",
    "        model_settings['num_inducing_points_cls']= np.max([int(train_size/10) + 5, 25])\n",
    "        yn_train_limited, ys_train_limited, labels_train_limited = yn_train[:train_size], ys_train[:train_size], labels_train[:train_size]\n",
    "        # Train LDGD Model\n",
    "        model = create_LDGD_model(yn_train_limited, ys_train_limited, model_settings)\n",
    "        if load_saved_result is False:\n",
    "            losses, history_train = model.train_model(yn=yn_train_limited, ys=ys_train_limited,\n",
    "                                                      epochs=model_settings['num_epochs_train'],\n",
    "                                                      batch_size=model_settings['batch_size'],\n",
    "                                                      early_stop=1e-6)\n",
    "            model.save_wights(path_save='', file_name=f\"model_ldgd_task3_{train_size}\")\n",
    "        else:\n",
    "            model.load_weights(path_save='', file_name=f\"model_ldgd_task3_{train_size}\")\n",
    "\n",
    "        predictions, metrics, history_test = model.evaluate(yn_test=yn_test, ys_test=labels_test,\n",
    "                                                        epochs=model_settings['num_epochs_test'])\n",
    "\n",
    "        metric_ldgd_list.append(metrics)\n",
    "    winsound.Beep(freq, duration*3)\n",
    "    metric_ldgd_dict = dicts_to_dict_of_lists(metric_ldgd_list)\n",
    "    with open('metric_ldgd_dict.json', 'w') as file:\n",
    "        json.dump(metric_ldgd_dict, file, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T01:39:04.997138300Z",
     "start_time": "2024-02-21T01:39:04.849265Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('./saved_results/metric_fastldgd_dict.json', 'r') as file:\n",
    "        metric_fastldgd_dict = json.load(file)\n",
    "except:\n",
    "    batch_shape = torch.Size([yn_train.shape[-1]])\n",
    "    metric_fastldgd_list = []\n",
    "    for train_size in list_size:\n",
    "        print(f\"\\n ===== train size - {train_size} ======\")\n",
    "        model_settings['num_inducing_points_reg']= np.max([int(train_size/10) + 5, 25])\n",
    "        model_settings['num_inducing_points_cls']= np.max([int(train_size/10) + 5, 25])\n",
    "        yn_train_limited, ys_train_limited, labels_train_limited = yn_train[:train_size], ys_train[:train_size], labels_train[:train_size]\n",
    "        # Train LDGD Model\n",
    "        model = create_FastLDGD_model(yn_train_limited, ys_train_limited, model_settings)\n",
    "        if load_saved_result is False:\n",
    "            losses, history_train = model.train_model(yn=yn_train_limited, ys=ys_train_limited,\n",
    "                                                      epochs=model_settings['num_epochs_train'],\n",
    "                                                      batch_size=model_settings['batch_size'])\n",
    "            model.save_wights(path_save='', file_name=f\"model_fldgd_task3_{train_size}\")\n",
    "        else:\n",
    "            try:\n",
    "                model.load_weights(path_save='', file_name=f\"model_fldgd_task3_{train_size}\")\n",
    "            except:\n",
    "                losses, history_train = model.train_model(yn=yn_train_limited, ys=ys_train_limited,\n",
    "                                                      epochs=model_settings['num_epochs_train'],\n",
    "                                                      batch_size=model_settings['batch_size'])\n",
    "                model.save_wights(path_save='', file_name=f\"model_fldgd_task3_{train_size}\")\n",
    "\n",
    "\n",
    "        predictions, metrics, history_test = model.evaluate(yn_test=yn_test, ys_test=labels_test,\n",
    "                                                        epochs=model_settings['num_epochs_test'])\n",
    "\n",
    "        metric_fastldgd_list.append(metrics)\n",
    "    winsound.Beep(freq, duration*3)\n",
    "    metric_fastldgd_dict = dicts_to_dict_of_lists(metric_fastldgd_list)\n",
    "    with open('metric_fastldgd_dict.json', 'w') as file:\n",
    "        json.dump(metric_fastldgd_dict, file, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T01:39:07.980339400Z",
     "start_time": "2024-02-21T01:39:07.819806200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1400x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "AXIS_LABEL_FONTSIZE = 32\n",
    "TICKS_LABEL_FONTSIZE = 28\n",
    "LEGEND_FONTSIZE = 24\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(14, 5))\n",
    "# ax1.set_title('2D Latent Subspace Corresponding to 3 Phase Oilflow', fontsize=32)\n",
    "\n",
    "axes[0].plot(list_size, metric_vae_dict['accuracy'], label='VAE', marker='s')\n",
    "axes[0].plot(list_size, metric_ldgd_dict['accuracy'], label='LDGD', marker='d')\n",
    "axes[0].plot(list_size, metric_fastldgd_dict['accuracy'], label='FastLDGD', marker='o')\n",
    "\n",
    "axes[0].set_xlabel(f'Number of data points', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[0].set_ylabel(f'Accuracy', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[0].tick_params(axis='both', labelsize=TICKS_LABEL_FONTSIZE)\n",
    "# Applying consistent spines format\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].spines['left'].set_linewidth(1)\n",
    "axes[0].spines['bottom'].set_linewidth(1)\n",
    "#axes[0].legend(fontsize=LEGEND_FONTSIZE)\n",
    "axes[0].set_xscale('log')  # Making x-axis logarithmic for the accuracy plot\n",
    "\n",
    "\n",
    "axes[1].plot(list_size, metric_vae_dict['f1_score'], label='VAE', marker='s')\n",
    "axes[1].plot(list_size, metric_ldgd_dict['f1_score'], label='LDGD', marker='d')\n",
    "axes[1].plot(list_size, metric_fastldgd_dict['f1_score'], label='Fast LDGD', marker='o')\n",
    "\n",
    "axes[1].set_xlabel(f'Number of data points', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1].set_ylabel(f'F-measure', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "axes[1].tick_params(axis='both', labelsize=TICKS_LABEL_FONTSIZE)\n",
    "# Applying consistent spines format\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].spines['left'].set_linewidth(1)\n",
    "axes[1].spines['bottom'].set_linewidth(1)\n",
    "#axes[1].legend(fontsize=LEGEND_FONTSIZE)\n",
    "axes[1].set_xscale('log')  # Making x-axis logarithmic for the accuracy plot\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"task3.png\")\n",
    "fig.savefig(\"task3.svg\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T06:27:53.428885200Z",
     "start_time": "2024-02-21T06:27:52.269962700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 350\n",
      "test size = 150\n"
     ]
    }
   ],
   "source": [
    "yn_train, yn_test, ys_train, ys_test, labels_train, labels_test, orig_dataset = create_dataset(num_dimension=10,\n",
    "                                                                                               random_state= model_settings['random_state'],\n",
    "                                                                                               test_size=model_settings['test_size'],\n",
    "                                                                                               n_samples=500)\n",
    "\n",
    "print(f\"train size = {yn_train.shape[0]}\")\n",
    "print(f\"test size = {ys_test.shape[0]}\")\n",
    "\n",
    "load_saved_result = False\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T10:14:21.304578600Z",
     "start_time": "2024-02-21T10:14:20.993163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for sample size: 1000\n",
      "\tEpoch 1: \tAverage Loss:  3.15735009765625\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 2: \tAverage Loss:  3.15185888671875\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 3: \tAverage Loss:  3.14801513671875\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 4: \tAverage Loss:  3.14185107421875\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 5: \tAverage Loss:  3.13718212890625\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 6: \tAverage Loss:  3.132735595703125\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 7: \tAverage Loss:  3.127435791015625\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 8: \tAverage Loss:  3.123341064453125\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 9: \tAverage Loss:  3.118725341796875\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 10: \tAverage Loss:  3.113962890625\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 11: \tAverage Loss:  3.10968115234375\t ACC train:  0.5114285714285715\t ACC test:  0.48\n",
      "\tEpoch 12: \tAverage Loss:  3.103752197265625\t ACC train:  0.5085714285714286\t ACC test:  0.47333333333333333\n",
      "\tEpoch 13: \tAverage Loss:  3.10006640625\t ACC train:  0.5114285714285715\t ACC test:  0.46\n",
      "\tEpoch 14: \tAverage Loss:  3.094574951171875\t ACC train:  0.5171428571428571\t ACC test:  0.47333333333333333\n",
      "\tEpoch 15: \tAverage Loss:  3.0919501953125\t ACC train:  0.5114285714285715\t ACC test:  0.4666666666666667\n",
      "\tEpoch 16: \tAverage Loss:  3.086220947265625\t ACC train:  0.5085714285714286\t ACC test:  0.47333333333333333\n",
      "\tEpoch 17: \tAverage Loss:  3.08256982421875\t ACC train:  0.5085714285714286\t ACC test:  0.48\n",
      "\tEpoch 18: \tAverage Loss:  3.07764111328125\t ACC train:  0.5085714285714286\t ACC test:  0.4866666666666667\n",
      "\tEpoch 19: \tAverage Loss:  3.0732587890625\t ACC train:  0.5142857142857142\t ACC test:  0.4666666666666667\n",
      "\tEpoch 20: \tAverage Loss:  3.06719091796875\t ACC train:  0.5114285714285715\t ACC test:  0.47333333333333333\n",
      "\tEpoch 21: \tAverage Loss:  3.062712158203125\t ACC train:  0.5142857142857142\t ACC test:  0.4666666666666667\n",
      "\tEpoch 22: \tAverage Loss:  3.058111083984375\t ACC train:  0.5171428571428571\t ACC test:  0.46\n",
      "\tEpoch 23: \tAverage Loss:  3.05335009765625\t ACC train:  0.5085714285714286\t ACC test:  0.48\n",
      "\tEpoch 24: \tAverage Loss:  3.049161865234375\t ACC train:  0.5114285714285715\t ACC test:  0.4666666666666667\n",
      "\tEpoch 25: \tAverage Loss:  3.044498291015625\t ACC train:  0.5114285714285715\t ACC test:  0.4666666666666667\n",
      "\tEpoch 26: \tAverage Loss:  3.038478515625\t ACC train:  0.5114285714285715\t ACC test:  0.48\n",
      "\tEpoch 27: \tAverage Loss:  3.033014892578125\t ACC train:  0.5142857142857142\t ACC test:  0.48\n",
      "\tEpoch 28: \tAverage Loss:  3.030224609375\t ACC train:  0.5114285714285715\t ACC test:  0.48\n",
      "\tEpoch 29: \tAverage Loss:  3.024382080078125\t ACC train:  0.5114285714285715\t ACC test:  0.48\n",
      "\tEpoch 30: \tAverage Loss:  3.018970703125\t ACC train:  0.5171428571428571\t ACC test:  0.47333333333333333\n",
      "\tEpoch 31: \tAverage Loss:  3.01556689453125\t ACC train:  0.5142857142857142\t ACC test:  0.49333333333333335\n",
      "\tEpoch 32: \tAverage Loss:  3.01080126953125\t ACC train:  0.52\t ACC test:  0.48\n",
      "\tEpoch 33: \tAverage Loss:  3.0042041015625\t ACC train:  0.5228571428571429\t ACC test:  0.47333333333333333\n",
      "\tEpoch 34: \tAverage Loss:  3.000455322265625\t ACC train:  0.5285714285714286\t ACC test:  0.47333333333333333\n",
      "\tEpoch 35: \tAverage Loss:  2.99544091796875\t ACC train:  0.5314285714285715\t ACC test:  0.4866666666666667\n",
      "\tEpoch 36: \tAverage Loss:  2.990621337890625\t ACC train:  0.5314285714285715\t ACC test:  0.49333333333333335\n",
      "\tEpoch 37: \tAverage Loss:  2.985149169921875\t ACC train:  0.54\t ACC test:  0.5066666666666667\n",
      "\tEpoch 38: \tAverage Loss:  2.980378173828125\t ACC train:  0.5485714285714286\t ACC test:  0.5133333333333333\n",
      "\tEpoch 39: \tAverage Loss:  2.97648876953125\t ACC train:  0.5628571428571428\t ACC test:  0.5\n",
      "\tEpoch 40: \tAverage Loss:  2.969648193359375\t ACC train:  0.5685714285714286\t ACC test:  0.5266666666666666\n",
      "\tEpoch 41: \tAverage Loss:  2.964334716796875\t ACC train:  0.6\t ACC test:  0.54\n",
      "\tEpoch 42: \tAverage Loss:  2.962613037109375\t ACC train:  0.58\t ACC test:  0.5733333333333334\n",
      "\tEpoch 43: \tAverage Loss:  2.955649169921875\t ACC train:  0.6257142857142857\t ACC test:  0.5733333333333334\n",
      "\tEpoch 44: \tAverage Loss:  2.95079541015625\t ACC train:  0.6314285714285715\t ACC test:  0.6066666666666667\n",
      "\tEpoch 45: \tAverage Loss:  2.945535400390625\t ACC train:  0.66\t ACC test:  0.6066666666666667\n",
      "\tEpoch 46: \tAverage Loss:  2.93999755859375\t ACC train:  0.6428571428571429\t ACC test:  0.6066666666666667\n",
      "\tEpoch 47: \tAverage Loss:  2.93672705078125\t ACC train:  0.66\t ACC test:  0.62\n",
      "\tEpoch 48: \tAverage Loss:  2.929507080078125\t ACC train:  0.6371428571428571\t ACC test:  0.62\n",
      "\tEpoch 49: \tAverage Loss:  2.925359375\t ACC train:  0.6714285714285714\t ACC test:  0.5866666666666667\n",
      "\tEpoch 50: \tAverage Loss:  2.916856689453125\t ACC train:  0.66\t ACC test:  0.6133333333333333\n",
      "\tEpoch 51: \tAverage Loss:  2.91409228515625\t ACC train:  0.6457142857142857\t ACC test:  0.5866666666666667\n",
      "\tEpoch 52: \tAverage Loss:  2.908292724609375\t ACC train:  0.6542857142857142\t ACC test:  0.58\n",
      "\tEpoch 53: \tAverage Loss:  2.903457275390625\t ACC train:  0.6342857142857142\t ACC test:  0.54\n",
      "\tEpoch 54: \tAverage Loss:  2.89560205078125\t ACC train:  0.6285714285714286\t ACC test:  0.5666666666666667\n",
      "\tEpoch 55: \tAverage Loss:  2.890298095703125\t ACC train:  0.6314285714285715\t ACC test:  0.5666666666666667\n",
      "\tEpoch 56: \tAverage Loss:  2.882250732421875\t ACC train:  0.6314285714285715\t ACC test:  0.5666666666666667\n",
      "\tEpoch 57: \tAverage Loss:  2.87694970703125\t ACC train:  0.6057142857142858\t ACC test:  0.5666666666666667\n",
      "\tEpoch 58: \tAverage Loss:  2.86761962890625\t ACC train:  0.5914285714285714\t ACC test:  0.5333333333333333\n",
      "\tEpoch 59: \tAverage Loss:  2.860987060546875\t ACC train:  0.6085714285714285\t ACC test:  0.52\n",
      "\tEpoch 60: \tAverage Loss:  2.8534287109375\t ACC train:  0.5914285714285714\t ACC test:  0.5\n",
      "\tEpoch 61: \tAverage Loss:  2.8459619140625\t ACC train:  0.5857142857142857\t ACC test:  0.5333333333333333\n",
      "\tEpoch 62: \tAverage Loss:  2.836741455078125\t ACC train:  0.5857142857142857\t ACC test:  0.5266666666666666\n",
      "\tEpoch 63: \tAverage Loss:  2.83225390625\t ACC train:  0.6142857142857143\t ACC test:  0.49333333333333335\n",
      "\tEpoch 64: \tAverage Loss:  2.82107568359375\t ACC train:  0.6\t ACC test:  0.48\n",
      "\tEpoch 65: \tAverage Loss:  2.815025146484375\t ACC train:  0.5828571428571429\t ACC test:  0.49333333333333335\n",
      "\tEpoch 66: \tAverage Loss:  2.808165771484375\t ACC train:  0.6028571428571429\t ACC test:  0.52\n",
      "\tEpoch 67: \tAverage Loss:  2.796171142578125\t ACC train:  0.6\t ACC test:  0.49333333333333335\n",
      "\tEpoch 68: \tAverage Loss:  2.78966357421875\t ACC train:  0.6228571428571429\t ACC test:  0.4866666666666667\n",
      "\tEpoch 69: \tAverage Loss:  2.775979736328125\t ACC train:  0.6028571428571429\t ACC test:  0.5266666666666666\n",
      "\tEpoch 70: \tAverage Loss:  2.7716357421875\t ACC train:  0.5914285714285714\t ACC test:  0.5133333333333333\n",
      "\tEpoch 71: \tAverage Loss:  2.757171875\t ACC train:  0.6085714285714285\t ACC test:  0.4866666666666667\n",
      "\tEpoch 72: \tAverage Loss:  2.749667236328125\t ACC train:  0.6028571428571429\t ACC test:  0.48\n",
      "\tEpoch 73: \tAverage Loss:  2.739007080078125\t ACC train:  0.6057142857142858\t ACC test:  0.5\n",
      "\tEpoch 74: \tAverage Loss:  2.731452880859375\t ACC train:  0.6114285714285714\t ACC test:  0.4666666666666667\n",
      "\tEpoch 75: \tAverage Loss:  2.71726318359375\t ACC train:  0.6142857142857143\t ACC test:  0.5\n",
      "\tEpoch 76: \tAverage Loss:  2.70643310546875\t ACC train:  0.6142857142857143\t ACC test:  0.5133333333333333\n",
      "\tEpoch 77: \tAverage Loss:  2.696226806640625\t ACC train:  0.6142857142857143\t ACC test:  0.5066666666666667\n",
      "\tEpoch 78: \tAverage Loss:  2.68738818359375\t ACC train:  0.6285714285714286\t ACC test:  0.5\n",
      "\tEpoch 79: \tAverage Loss:  2.675888427734375\t ACC train:  0.6342857142857142\t ACC test:  0.5\n",
      "\tEpoch 80: \tAverage Loss:  2.6626904296875\t ACC train:  0.6257142857142857\t ACC test:  0.5266666666666666\n",
      "\tEpoch 81: \tAverage Loss:  2.65502783203125\t ACC train:  0.64\t ACC test:  0.5466666666666666\n",
      "\tEpoch 82: \tAverage Loss:  2.64149951171875\t ACC train:  0.6371428571428571\t ACC test:  0.54\n",
      "\tEpoch 83: \tAverage Loss:  2.625505126953125\t ACC train:  0.6428571428571429\t ACC test:  0.5333333333333333\n",
      "\tEpoch 84: \tAverage Loss:  2.61654541015625\t ACC train:  0.6457142857142857\t ACC test:  0.54\n",
      "\tEpoch 85: \tAverage Loss:  2.60348046875\t ACC train:  0.6485714285714286\t ACC test:  0.5266666666666666\n",
      "\tEpoch 86: \tAverage Loss:  2.590078125\t ACC train:  0.64\t ACC test:  0.56\n",
      "\tEpoch 87: \tAverage Loss:  2.57651806640625\t ACC train:  0.6571428571428571\t ACC test:  0.5533333333333333\n",
      "\tEpoch 88: \tAverage Loss:  2.56161474609375\t ACC train:  0.66\t ACC test:  0.5466666666666666\n",
      "\tEpoch 89: \tAverage Loss:  2.550444091796875\t ACC train:  0.6657142857142857\t ACC test:  0.5866666666666667\n",
      "\tEpoch 90: \tAverage Loss:  2.537531005859375\t ACC train:  0.68\t ACC test:  0.5666666666666667\n",
      "\tEpoch 91: \tAverage Loss:  2.527370849609375\t ACC train:  0.6742857142857143\t ACC test:  0.58\n",
      "\tEpoch 92: \tAverage Loss:  2.511206787109375\t ACC train:  0.6885714285714286\t ACC test:  0.5666666666666667\n",
      "\tEpoch 93: \tAverage Loss:  2.499124755859375\t ACC train:  0.6828571428571428\t ACC test:  0.6\n",
      "\tEpoch 94: \tAverage Loss:  2.48696484375\t ACC train:  0.68\t ACC test:  0.5666666666666667\n",
      "\tEpoch 95: \tAverage Loss:  2.47086279296875\t ACC train:  0.6914285714285714\t ACC test:  0.5933333333333334\n",
      "\tEpoch 96: \tAverage Loss:  2.460066162109375\t ACC train:  0.6885714285714286\t ACC test:  0.5866666666666667\n",
      "\tEpoch 97: \tAverage Loss:  2.4485380859375\t ACC train:  0.6942857142857143\t ACC test:  0.5933333333333334\n",
      "\tEpoch 98: \tAverage Loss:  2.435094970703125\t ACC train:  0.6971428571428572\t ACC test:  0.6066666666666667\n",
      "\tEpoch 99: \tAverage Loss:  2.422917236328125\t ACC train:  0.6971428571428572\t ACC test:  0.6266666666666667\n",
      "\tEpoch 100: \tAverage Loss:  2.409196533203125\t ACC train:  0.7085714285714285\t ACC test:  0.6133333333333333\n",
      "\tEpoch 101: \tAverage Loss:  2.39636083984375\t ACC train:  0.7028571428571428\t ACC test:  0.62\n",
      "\tEpoch 102: \tAverage Loss:  2.3837490234375\t ACC train:  0.7\t ACC test:  0.6\n",
      "\tEpoch 103: \tAverage Loss:  2.368920166015625\t ACC train:  0.7171428571428572\t ACC test:  0.6133333333333333\n",
      "\tEpoch 104: \tAverage Loss:  2.358646484375\t ACC train:  0.7085714285714285\t ACC test:  0.6133333333333333\n",
      "\tEpoch 105: \tAverage Loss:  2.345236572265625\t ACC train:  0.7171428571428572\t ACC test:  0.6066666666666667\n",
      "\tEpoch 106: \tAverage Loss:  2.332022216796875\t ACC train:  0.7171428571428572\t ACC test:  0.6266666666666667\n",
      "\tEpoch 107: \tAverage Loss:  2.319299072265625\t ACC train:  0.7057142857142857\t ACC test:  0.6466666666666666\n",
      "\tEpoch 108: \tAverage Loss:  2.3077919921875\t ACC train:  0.7342857142857143\t ACC test:  0.6333333333333333\n",
      "\tEpoch 109: \tAverage Loss:  2.2927724609375\t ACC train:  0.72\t ACC test:  0.62\n",
      "\tEpoch 110: \tAverage Loss:  2.279927978515625\t ACC train:  0.7257142857142858\t ACC test:  0.64\n",
      "\tEpoch 111: \tAverage Loss:  2.265962158203125\t ACC train:  0.7342857142857143\t ACC test:  0.6333333333333333\n",
      "\tEpoch 112: \tAverage Loss:  2.2562822265625\t ACC train:  0.7371428571428571\t ACC test:  0.6266666666666667\n",
      "\tEpoch 113: \tAverage Loss:  2.24402197265625\t ACC train:  0.7571428571428571\t ACC test:  0.6533333333333333\n",
      "\tEpoch 114: \tAverage Loss:  2.23321484375\t ACC train:  0.7485714285714286\t ACC test:  0.64\n",
      "\tEpoch 115: \tAverage Loss:  2.2202841796875\t ACC train:  0.7514285714285714\t ACC test:  0.6533333333333333\n",
      "\tEpoch 116: \tAverage Loss:  2.20896728515625\t ACC train:  0.74\t ACC test:  0.68\n",
      "\tEpoch 117: \tAverage Loss:  2.193986572265625\t ACC train:  0.7542857142857143\t ACC test:  0.68\n",
      "\tEpoch 118: \tAverage Loss:  2.184725341796875\t ACC train:  0.7571428571428571\t ACC test:  0.66\n",
      "\tEpoch 119: \tAverage Loss:  2.17060107421875\t ACC train:  0.7485714285714286\t ACC test:  0.66\n",
      "\tEpoch 120: \tAverage Loss:  2.15723046875\t ACC train:  0.7628571428571429\t ACC test:  0.68\n",
      "\tEpoch 121: \tAverage Loss:  2.148117431640625\t ACC train:  0.7628571428571429\t ACC test:  0.66\n",
      "\tEpoch 122: \tAverage Loss:  2.1344853515625\t ACC train:  0.7771428571428571\t ACC test:  0.68\n",
      "\tEpoch 123: \tAverage Loss:  2.127404541015625\t ACC train:  0.7742857142857142\t ACC test:  0.6866666666666666\n",
      "\tEpoch 124: \tAverage Loss:  2.111333251953125\t ACC train:  0.7771428571428571\t ACC test:  0.7\n",
      "\tEpoch 125: \tAverage Loss:  2.1008193359375\t ACC train:  0.78\t ACC test:  0.68\n",
      "\tEpoch 126: \tAverage Loss:  2.0896982421875\t ACC train:  0.7942857142857143\t ACC test:  0.7133333333333334\n",
      "\tEpoch 127: \tAverage Loss:  2.081447021484375\t ACC train:  0.7971428571428572\t ACC test:  0.7066666666666667\n",
      "\tEpoch 128: \tAverage Loss:  2.06977490234375\t ACC train:  0.7971428571428572\t ACC test:  0.7\n",
      "\tEpoch 129: \tAverage Loss:  2.057648681640625\t ACC train:  0.8057142857142857\t ACC test:  0.7066666666666667\n",
      "\tEpoch 130: \tAverage Loss:  2.045456298828125\t ACC train:  0.82\t ACC test:  0.7133333333333334\n",
      "\tEpoch 131: \tAverage Loss:  2.0361212158203124\t ACC train:  0.8257142857142857\t ACC test:  0.7466666666666667\n",
      "\tEpoch 132: \tAverage Loss:  2.0269608154296876\t ACC train:  0.8257142857142857\t ACC test:  0.7533333333333333\n",
      "\tEpoch 133: \tAverage Loss:  2.017412353515625\t ACC train:  0.8371428571428572\t ACC test:  0.7533333333333333\n",
      "\tEpoch 134: \tAverage Loss:  2.006574462890625\t ACC train:  0.8514285714285714\t ACC test:  0.7733333333333333\n",
      "\tEpoch 135: \tAverage Loss:  1.99710888671875\t ACC train:  0.8628571428571429\t ACC test:  0.78\n",
      "\tEpoch 136: \tAverage Loss:  1.9875498046875\t ACC train:  0.86\t ACC test:  0.7866666666666666\n",
      "\tEpoch 137: \tAverage Loss:  1.9802379150390625\t ACC train:  0.8628571428571429\t ACC test:  0.7933333333333333\n",
      "\tEpoch 138: \tAverage Loss:  1.969257568359375\t ACC train:  0.8742857142857143\t ACC test:  0.82\n",
      "\tEpoch 139: \tAverage Loss:  1.95981884765625\t ACC train:  0.8771428571428571\t ACC test:  0.8066666666666666\n",
      "\tEpoch 140: \tAverage Loss:  1.9515084228515625\t ACC train:  0.8742857142857143\t ACC test:  0.82\n",
      "\tEpoch 141: \tAverage Loss:  1.944343505859375\t ACC train:  0.88\t ACC test:  0.84\n",
      "\tEpoch 142: \tAverage Loss:  1.9337259521484376\t ACC train:  0.8742857142857143\t ACC test:  0.8466666666666667\n",
      "\tEpoch 143: \tAverage Loss:  1.927697265625\t ACC train:  0.88\t ACC test:  0.82\n",
      "\tEpoch 144: \tAverage Loss:  1.9163956298828124\t ACC train:  0.8857142857142857\t ACC test:  0.86\n",
      "\tEpoch 145: \tAverage Loss:  1.9108515625\t ACC train:  0.9028571428571428\t ACC test:  0.8666666666666667\n",
      "\tEpoch 146: \tAverage Loss:  1.9014697265625\t ACC train:  0.8914285714285715\t ACC test:  0.8466666666666667\n",
      "\tEpoch 147: \tAverage Loss:  1.89533251953125\t ACC train:  0.9028571428571428\t ACC test:  0.8733333333333333\n",
      "\tEpoch 148: \tAverage Loss:  1.884384033203125\t ACC train:  0.9057142857142857\t ACC test:  0.8733333333333333\n",
      "\tEpoch 149: \tAverage Loss:  1.88062158203125\t ACC train:  0.9171428571428571\t ACC test:  0.8866666666666667\n",
      "\tEpoch 150: \tAverage Loss:  1.8712208251953124\t ACC train:  0.9285714285714286\t ACC test:  0.88\n",
      "\tEpoch 151: \tAverage Loss:  1.865102783203125\t ACC train:  0.9171428571428571\t ACC test:  0.8933333333333333\n",
      "\tEpoch 152: \tAverage Loss:  1.85896484375\t ACC train:  0.9257142857142857\t ACC test:  0.8933333333333333\n",
      "\tEpoch 153: \tAverage Loss:  1.852602294921875\t ACC train:  0.9285714285714286\t ACC test:  0.8933333333333333\n",
      "\tEpoch 154: \tAverage Loss:  1.8428140869140626\t ACC train:  0.9342857142857143\t ACC test:  0.8933333333333333\n",
      "\tEpoch 155: \tAverage Loss:  1.8369884033203125\t ACC train:  0.9257142857142857\t ACC test:  0.9066666666666666\n",
      "\tEpoch 156: \tAverage Loss:  1.835799560546875\t ACC train:  0.9342857142857143\t ACC test:  0.8866666666666667\n",
      "\tEpoch 157: \tAverage Loss:  1.824337890625\t ACC train:  0.9371428571428572\t ACC test:  0.9\n",
      "\tEpoch 158: \tAverage Loss:  1.8206025390625\t ACC train:  0.9371428571428572\t ACC test:  0.9066666666666666\n",
      "\tEpoch 159: \tAverage Loss:  1.8156697998046876\t ACC train:  0.9457142857142857\t ACC test:  0.9066666666666666\n",
      "\tEpoch 160: \tAverage Loss:  1.808248779296875\t ACC train:  0.9314285714285714\t ACC test:  0.9\n",
      "\tEpoch 161: \tAverage Loss:  1.80149560546875\t ACC train:  0.9542857142857143\t ACC test:  0.9133333333333333\n",
      "\tEpoch 162: \tAverage Loss:  1.79950048828125\t ACC train:  0.94\t ACC test:  0.9133333333333333\n",
      "\tEpoch 163: \tAverage Loss:  1.790283203125\t ACC train:  0.9428571428571428\t ACC test:  0.9133333333333333\n",
      "\tEpoch 164: \tAverage Loss:  1.7849542236328124\t ACC train:  0.9371428571428572\t ACC test:  0.9266666666666666\n",
      "\tEpoch 165: \tAverage Loss:  1.7818341064453125\t ACC train:  0.9457142857142857\t ACC test:  0.9333333333333333\n",
      "\tEpoch 166: \tAverage Loss:  1.7762952880859375\t ACC train:  0.94\t ACC test:  0.92\n",
      "\tEpoch 167: \tAverage Loss:  1.7709957275390624\t ACC train:  0.9485714285714286\t ACC test:  0.9266666666666666\n",
      "\tEpoch 168: \tAverage Loss:  1.7673468017578124\t ACC train:  0.9542857142857143\t ACC test:  0.92\n",
      "\tEpoch 169: \tAverage Loss:  1.7609825439453124\t ACC train:  0.9514285714285714\t ACC test:  0.9133333333333333\n",
      "\tEpoch 170: \tAverage Loss:  1.7571563720703125\t ACC train:  0.9457142857142857\t ACC test:  0.9266666666666666\n",
      "\tEpoch 171: \tAverage Loss:  1.752171630859375\t ACC train:  0.9542857142857143\t ACC test:  0.9266666666666666\n",
      "\tEpoch 172: \tAverage Loss:  1.7464803466796874\t ACC train:  0.9542857142857143\t ACC test:  0.9333333333333333\n",
      "\tEpoch 173: \tAverage Loss:  1.744234375\t ACC train:  0.9542857142857143\t ACC test:  0.9266666666666666\n",
      "\tEpoch 174: \tAverage Loss:  1.740210693359375\t ACC train:  0.9542857142857143\t ACC test:  0.92\n",
      "\tEpoch 175: \tAverage Loss:  1.7328870849609375\t ACC train:  0.9542857142857143\t ACC test:  0.9333333333333333\n",
      "\tEpoch 176: \tAverage Loss:  1.7295081787109374\t ACC train:  0.9571428571428572\t ACC test:  0.92\n",
      "\tEpoch 177: \tAverage Loss:  1.7266337890625\t ACC train:  0.9514285714285714\t ACC test:  0.9333333333333333\n",
      "\tEpoch 178: \tAverage Loss:  1.72398974609375\t ACC train:  0.9571428571428572\t ACC test:  0.9333333333333333\n",
      "\tEpoch 179: \tAverage Loss:  1.7217646484375\t ACC train:  0.9542857142857143\t ACC test:  0.9333333333333333\n",
      "\tEpoch 180: \tAverage Loss:  1.71571142578125\t ACC train:  0.9542857142857143\t ACC test:  0.94\n",
      "\tEpoch 181: \tAverage Loss:  1.712675048828125\t ACC train:  0.96\t ACC test:  0.94\n",
      "\tEpoch 182: \tAverage Loss:  1.70769580078125\t ACC train:  0.96\t ACC test:  0.94\n",
      "\tEpoch 183: \tAverage Loss:  1.705241943359375\t ACC train:  0.9542857142857143\t ACC test:  0.9333333333333333\n",
      "\tEpoch 184: \tAverage Loss:  1.7015106201171875\t ACC train:  0.9657142857142857\t ACC test:  0.9466666666666667\n",
      "\tEpoch 185: \tAverage Loss:  1.698714599609375\t ACC train:  0.9571428571428572\t ACC test:  0.9466666666666667\n",
      "\tEpoch 186: \tAverage Loss:  1.6949510498046876\t ACC train:  0.9571428571428572\t ACC test:  0.9333333333333333\n",
      "\tEpoch 187: \tAverage Loss:  1.6900833740234376\t ACC train:  0.9628571428571429\t ACC test:  0.9333333333333333\n",
      "\tEpoch 188: \tAverage Loss:  1.6887896728515626\t ACC train:  0.9685714285714285\t ACC test:  0.9533333333333334\n",
      "\tEpoch 189: \tAverage Loss:  1.686316162109375\t ACC train:  0.9657142857142857\t ACC test:  0.96\n",
      "\tEpoch 190: \tAverage Loss:  1.6814195556640625\t ACC train:  0.9628571428571429\t ACC test:  0.94\n",
      "\tEpoch 191: \tAverage Loss:  1.6828052978515624\t ACC train:  0.9714285714285714\t ACC test:  0.9466666666666667\n",
      "\tEpoch 192: \tAverage Loss:  1.6786649169921875\t ACC train:  0.9628571428571429\t ACC test:  0.9466666666666667\n",
      "\tEpoch 193: \tAverage Loss:  1.6753873291015624\t ACC train:  0.9628571428571429\t ACC test:  0.9466666666666667\n",
      "\tEpoch 194: \tAverage Loss:  1.6716754150390625\t ACC train:  0.9657142857142857\t ACC test:  0.9533333333333334\n",
      "\tEpoch 195: \tAverage Loss:  1.66884033203125\t ACC train:  0.9657142857142857\t ACC test:  0.9466666666666667\n",
      "\tEpoch 196: \tAverage Loss:  1.66600146484375\t ACC train:  0.9628571428571429\t ACC test:  0.9533333333333334\n",
      "\tEpoch 197: \tAverage Loss:  1.6642103271484374\t ACC train:  0.96\t ACC test:  0.9533333333333334\n",
      "\tEpoch 198: \tAverage Loss:  1.661601318359375\t ACC train:  0.9628571428571429\t ACC test:  0.96\n",
      "\tEpoch 199: \tAverage Loss:  1.65809814453125\t ACC train:  0.9657142857142857\t ACC test:  0.9533333333333334\n",
      "\tEpoch 200: \tAverage Loss:  1.6575413818359375\t ACC train:  0.9742857142857143\t ACC test:  0.9533333333333334\n",
      "\tEpoch 201: \tAverage Loss:  1.6536016845703125\t ACC train:  0.9657142857142857\t ACC test:  0.96\n",
      "\tEpoch 202: \tAverage Loss:  1.6521590576171874\t ACC train:  0.9714285714285714\t ACC test:  0.9533333333333334\n",
      "\tEpoch 203: \tAverage Loss:  1.65061572265625\t ACC train:  0.9571428571428572\t ACC test:  0.9666666666666667\n",
      "\tEpoch 204: \tAverage Loss:  1.647940673828125\t ACC train:  0.9714285714285714\t ACC test:  0.96\n",
      "\tEpoch 205: \tAverage Loss:  1.6432491455078124\t ACC train:  0.9685714285714285\t ACC test:  0.9533333333333334\n",
      "\tEpoch 206: \tAverage Loss:  1.64122998046875\t ACC train:  0.98\t ACC test:  0.96\n",
      "\tEpoch 207: \tAverage Loss:  1.637732177734375\t ACC train:  0.9714285714285714\t ACC test:  0.9533333333333334\n",
      "\tEpoch 208: \tAverage Loss:  1.6371375732421876\t ACC train:  0.9714285714285714\t ACC test:  0.9666666666666667\n",
      "\tEpoch 209: \tAverage Loss:  1.63519580078125\t ACC train:  0.9685714285714285\t ACC test:  0.9733333333333334\n",
      "\tEpoch 210: \tAverage Loss:  1.63390185546875\t ACC train:  0.9628571428571429\t ACC test:  0.9666666666666667\n",
      "\tEpoch 211: \tAverage Loss:  1.631328125\t ACC train:  0.9742857142857143\t ACC test:  0.9733333333333334\n",
      "\tEpoch 212: \tAverage Loss:  1.629683349609375\t ACC train:  0.9771428571428571\t ACC test:  0.9733333333333334\n",
      "\tEpoch 213: \tAverage Loss:  1.627897216796875\t ACC train:  0.9857142857142858\t ACC test:  0.9666666666666667\n",
      "\tEpoch 214: \tAverage Loss:  1.62514208984375\t ACC train:  0.98\t ACC test:  0.9666666666666667\n",
      "\tEpoch 215: \tAverage Loss:  1.6239593505859375\t ACC train:  0.9771428571428571\t ACC test:  0.9666666666666667\n",
      "\tEpoch 216: \tAverage Loss:  1.6207200927734375\t ACC train:  0.9742857142857143\t ACC test:  0.96\n",
      "\tEpoch 217: \tAverage Loss:  1.62\t ACC train:  0.9714285714285714\t ACC test:  0.9466666666666667\n",
      "\tEpoch 218: \tAverage Loss:  1.618884033203125\t ACC train:  0.98\t ACC test:  0.9733333333333334\n",
      "\tEpoch 219: \tAverage Loss:  1.6159947509765624\t ACC train:  0.9771428571428571\t ACC test:  0.9733333333333334\n",
      "\tEpoch 220: \tAverage Loss:  1.6144404296875\t ACC train:  0.9828571428571429\t ACC test:  0.9733333333333334\n",
      "\tEpoch 221: \tAverage Loss:  1.614519287109375\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 222: \tAverage Loss:  1.6105185546875\t ACC train:  0.9828571428571429\t ACC test:  0.9733333333333334\n",
      "\tEpoch 223: \tAverage Loss:  1.608426025390625\t ACC train:  0.9857142857142858\t ACC test:  0.9666666666666667\n",
      "\tEpoch 224: \tAverage Loss:  1.609246826171875\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 225: \tAverage Loss:  1.606562255859375\t ACC train:  0.9857142857142858\t ACC test:  0.98\n",
      "\tEpoch 226: \tAverage Loss:  1.604811767578125\t ACC train:  0.9828571428571429\t ACC test:  0.9733333333333334\n",
      "\tEpoch 227: \tAverage Loss:  1.603111572265625\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 228: \tAverage Loss:  1.6021715087890624\t ACC train:  0.98\t ACC test:  0.9666666666666667\n",
      "\tEpoch 229: \tAverage Loss:  1.601715576171875\t ACC train:  0.9857142857142858\t ACC test:  0.9733333333333334\n",
      "\tEpoch 230: \tAverage Loss:  1.600092041015625\t ACC train:  0.9857142857142858\t ACC test:  0.9733333333333334\n",
      "\tEpoch 231: \tAverage Loss:  1.5965087890625\t ACC train:  0.9828571428571429\t ACC test:  0.9733333333333334\n",
      "\tEpoch 232: \tAverage Loss:  1.594716064453125\t ACC train:  0.98\t ACC test:  0.98\n",
      "\tEpoch 233: \tAverage Loss:  1.59231005859375\t ACC train:  0.9857142857142858\t ACC test:  0.9733333333333334\n",
      "\tEpoch 234: \tAverage Loss:  1.59407080078125\t ACC train:  0.9828571428571429\t ACC test:  0.98\n",
      "\tEpoch 235: \tAverage Loss:  1.590762939453125\t ACC train:  0.9857142857142858\t ACC test:  0.98\n",
      "\tEpoch 236: \tAverage Loss:  1.5883544921875\t ACC train:  0.9914285714285714\t ACC test:  0.98\n",
      "\tEpoch 237: \tAverage Loss:  1.5880916748046876\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 238: \tAverage Loss:  1.588212158203125\t ACC train:  0.9914285714285714\t ACC test:  0.9733333333333334\n",
      "\tEpoch 239: \tAverage Loss:  1.585953369140625\t ACC train:  0.9828571428571429\t ACC test:  0.9733333333333334\n",
      "\tEpoch 240: \tAverage Loss:  1.5843428955078125\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 241: \tAverage Loss:  1.5828056640625\t ACC train:  0.9857142857142858\t ACC test:  0.9666666666666667\n",
      "\tEpoch 242: \tAverage Loss:  1.582267333984375\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 243: \tAverage Loss:  1.5807261962890624\t ACC train:  0.9885714285714285\t ACC test:  0.9666666666666667\n",
      "\tEpoch 244: \tAverage Loss:  1.5799307861328125\t ACC train:  0.9914285714285714\t ACC test:  0.9733333333333334\n",
      "\tEpoch 245: \tAverage Loss:  1.578094970703125\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 246: \tAverage Loss:  1.5773201904296874\t ACC train:  0.9914285714285714\t ACC test:  0.98\n",
      "\tEpoch 247: \tAverage Loss:  1.5751689453125\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 248: \tAverage Loss:  1.5751158447265625\t ACC train:  0.9914285714285714\t ACC test:  0.98\n",
      "\tEpoch 249: \tAverage Loss:  1.5728795166015626\t ACC train:  0.9885714285714285\t ACC test:  0.9866666666666667\n",
      "\tEpoch 250: \tAverage Loss:  1.571891357421875\t ACC train:  0.9885714285714285\t ACC test:  0.9866666666666667\n",
      "\tEpoch 251: \tAverage Loss:  1.5702611083984375\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 252: \tAverage Loss:  1.5705511474609375\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 253: \tAverage Loss:  1.570709228515625\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 254: \tAverage Loss:  1.5681363525390626\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 255: \tAverage Loss:  1.567000732421875\t ACC train:  0.9885714285714285\t ACC test:  0.9866666666666667\n",
      "\tEpoch 256: \tAverage Loss:  1.5659312744140625\t ACC train:  0.9914285714285714\t ACC test:  0.98\n",
      "\tEpoch 257: \tAverage Loss:  1.5642216796875\t ACC train:  0.9885714285714285\t ACC test:  0.9866666666666667\n",
      "\tEpoch 258: \tAverage Loss:  1.56287158203125\t ACC train:  0.9885714285714285\t ACC test:  0.9866666666666667\n",
      "\tEpoch 259: \tAverage Loss:  1.5618819580078125\t ACC train:  0.9914285714285714\t ACC test:  0.98\n",
      "\tEpoch 260: \tAverage Loss:  1.5618486328125\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 261: \tAverage Loss:  1.56034326171875\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 262: \tAverage Loss:  1.5593114013671876\t ACC train:  0.9885714285714285\t ACC test:  0.98\n",
      "\tEpoch 263: \tAverage Loss:  1.5588836669921875\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 264: \tAverage Loss:  1.5565677490234375\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 265: \tAverage Loss:  1.557068603515625\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 266: \tAverage Loss:  1.554218505859375\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 267: \tAverage Loss:  1.5538834228515626\t ACC train:  0.9914285714285714\t ACC test:  0.9733333333333334\n",
      "\tEpoch 268: \tAverage Loss:  1.5533316650390625\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 269: \tAverage Loss:  1.552396728515625\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 270: \tAverage Loss:  1.550716552734375\t ACC train:  0.9885714285714285\t ACC test:  0.9866666666666667\n",
      "\tEpoch 271: \tAverage Loss:  1.5498092041015625\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 272: \tAverage Loss:  1.5496044921875\t ACC train:  0.9914285714285714\t ACC test:  0.98\n",
      "\tEpoch 273: \tAverage Loss:  1.54950341796875\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 274: \tAverage Loss:  1.547700927734375\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 275: \tAverage Loss:  1.5471077880859374\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 276: \tAverage Loss:  1.5456085205078125\t ACC train:  0.9942857142857143\t ACC test:  0.98\n",
      "\tEpoch 277: \tAverage Loss:  1.54508935546875\t ACC train:  0.9885714285714285\t ACC test:  0.9866666666666667\n",
      "\tEpoch 278: \tAverage Loss:  1.5440452880859374\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 279: \tAverage Loss:  1.5444036865234374\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 280: \tAverage Loss:  1.543940673828125\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 281: \tAverage Loss:  1.5425775146484375\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 282: \tAverage Loss:  1.541653564453125\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 283: \tAverage Loss:  1.5399647216796875\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 284: \tAverage Loss:  1.5394931640625\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 285: \tAverage Loss:  1.537977783203125\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 286: \tAverage Loss:  1.53774169921875\t ACC train:  0.9914285714285714\t ACC test:  0.98\n",
      "\tEpoch 287: \tAverage Loss:  1.537732177734375\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 288: \tAverage Loss:  1.5366046142578125\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 289: \tAverage Loss:  1.536629638671875\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 290: \tAverage Loss:  1.535030517578125\t ACC train:  0.9942857142857143\t ACC test:  0.98\n",
      "\tEpoch 291: \tAverage Loss:  1.533749755859375\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 292: \tAverage Loss:  1.533621826171875\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 293: \tAverage Loss:  1.5334652099609376\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 294: \tAverage Loss:  1.5311781005859375\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 295: \tAverage Loss:  1.530864501953125\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 296: \tAverage Loss:  1.53021142578125\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 297: \tAverage Loss:  1.529235595703125\t ACC train:  0.9914285714285714\t ACC test:  0.9866666666666667\n",
      "\tEpoch 298: \tAverage Loss:  1.5283680419921875\t ACC train:  0.9914285714285714\t ACC test:  0.9933333333333333\n",
      "\tEpoch 299: \tAverage Loss:  1.528456298828125\t ACC train:  0.9914285714285714\t ACC test:  0.98\n",
      "\tEpoch 300: \tAverage Loss:  1.52727392578125\t ACC train:  0.9885714285714285\t ACC test:  0.9733333333333334\n",
      "\tEpoch 301: \tAverage Loss:  1.52616796875\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 302: \tAverage Loss:  1.5257664794921875\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 303: \tAverage Loss:  1.52528857421875\t ACC train:  0.9942857142857143\t ACC test:  0.98\n",
      "\tEpoch 304: \tAverage Loss:  1.5252386474609374\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 305: \tAverage Loss:  1.524423583984375\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 306: \tAverage Loss:  1.5227921142578125\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 307: \tAverage Loss:  1.52230078125\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 308: \tAverage Loss:  1.522174072265625\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 309: \tAverage Loss:  1.5207528076171875\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 310: \tAverage Loss:  1.51935595703125\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 311: \tAverage Loss:  1.51968994140625\t ACC train:  0.9914285714285714\t ACC test:  0.9933333333333333\n",
      "\tEpoch 312: \tAverage Loss:  1.519139404296875\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 313: \tAverage Loss:  1.5178895263671874\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 314: \tAverage Loss:  1.517521484375\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 315: \tAverage Loss:  1.516523681640625\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 316: \tAverage Loss:  1.5152686767578125\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 317: \tAverage Loss:  1.5146966552734376\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 318: \tAverage Loss:  1.5146268310546875\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 319: \tAverage Loss:  1.5139287109375\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 320: \tAverage Loss:  1.51298486328125\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 321: \tAverage Loss:  1.5116314697265625\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 322: \tAverage Loss:  1.5107877197265625\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 323: \tAverage Loss:  1.51103466796875\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 324: \tAverage Loss:  1.510232177734375\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 325: \tAverage Loss:  1.509375244140625\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 326: \tAverage Loss:  1.5082735595703125\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 327: \tAverage Loss:  1.5072335205078125\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 328: \tAverage Loss:  1.506653076171875\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 329: \tAverage Loss:  1.506308837890625\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 330: \tAverage Loss:  1.505852294921875\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 331: \tAverage Loss:  1.5043460693359374\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 332: \tAverage Loss:  1.50365869140625\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 333: \tAverage Loss:  1.5028548583984376\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 334: \tAverage Loss:  1.5023291015625\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 335: \tAverage Loss:  1.501366943359375\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 336: \tAverage Loss:  1.50039599609375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 337: \tAverage Loss:  1.4998294677734374\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 338: \tAverage Loss:  1.4993944091796876\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 339: \tAverage Loss:  1.4984986572265624\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 340: \tAverage Loss:  1.4977152099609374\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 341: \tAverage Loss:  1.496736572265625\t ACC train:  0.9942857142857143\t ACC test:  0.9933333333333333\n",
      "\tEpoch 342: \tAverage Loss:  1.495724609375\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 343: \tAverage Loss:  1.49508984375\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 344: \tAverage Loss:  1.4945750732421874\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 345: \tAverage Loss:  1.49334521484375\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 346: \tAverage Loss:  1.492655029296875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 347: \tAverage Loss:  1.4921151123046874\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 348: \tAverage Loss:  1.490856689453125\t ACC train:  0.9971428571428571\t ACC test:  0.9933333333333333\n",
      "\tEpoch 349: \tAverage Loss:  1.489912353515625\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 350: \tAverage Loss:  1.4891141357421875\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 351: \tAverage Loss:  1.4885458984375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 352: \tAverage Loss:  1.4882802734375\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 353: \tAverage Loss:  1.486837646484375\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 354: \tAverage Loss:  1.485446533203125\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 355: \tAverage Loss:  1.4842628173828125\t ACC train:  0.9971428571428571\t ACC test:  0.9733333333333334\n",
      "\tEpoch 356: \tAverage Loss:  1.4838544921875\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 357: \tAverage Loss:  1.4825606689453126\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 358: \tAverage Loss:  1.482438720703125\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 359: \tAverage Loss:  1.4807685546875\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 360: \tAverage Loss:  1.48000390625\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 361: \tAverage Loss:  1.4790198974609374\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 362: \tAverage Loss:  1.4775150146484375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 363: \tAverage Loss:  1.47748681640625\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 364: \tAverage Loss:  1.4761712646484375\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 365: \tAverage Loss:  1.47444189453125\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 366: \tAverage Loss:  1.4736812744140626\t ACC train:  0.9942857142857143\t ACC test:  0.9866666666666667\n",
      "\tEpoch 367: \tAverage Loss:  1.47295068359375\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 368: \tAverage Loss:  1.47117041015625\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 369: \tAverage Loss:  1.471025634765625\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 370: \tAverage Loss:  1.4699415283203126\t ACC train:  0.9971428571428571\t ACC test:  0.9733333333333334\n",
      "\tEpoch 371: \tAverage Loss:  1.468998291015625\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 372: \tAverage Loss:  1.46725341796875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 373: \tAverage Loss:  1.4657705078125\t ACC train:  0.9971428571428571\t ACC test:  0.9866666666666667\n",
      "\tEpoch 374: \tAverage Loss:  1.464934326171875\t ACC train:  1.0\t ACC test:  0.9933333333333333\n",
      "\tEpoch 375: \tAverage Loss:  1.463260498046875\t ACC train:  1.0\t ACC test:  0.9866666666666667\n",
      "\tEpoch 376: \tAverage Loss:  1.4622005615234375\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 377: \tAverage Loss:  1.46132666015625\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 378: \tAverage Loss:  1.4595482177734376\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 379: \tAverage Loss:  1.45946875\t ACC train:  0.9971428571428571\t ACC test:  0.9733333333333334\n",
      "\tEpoch 380: \tAverage Loss:  1.457849609375\t ACC train:  0.9971428571428571\t ACC test:  0.9666666666666667\n",
      "\tEpoch 381: \tAverage Loss:  1.4559161376953125\t ACC train:  0.9971428571428571\t ACC test:  0.98\n",
      "\tEpoch 382: \tAverage Loss:  1.454298583984375\t ACC train:  0.9971428571428571\t ACC test:  0.9733333333333334\n",
      "\tEpoch 383: \tAverage Loss:  1.4532979736328124\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 384: \tAverage Loss:  1.4519151611328125\t ACC train:  1.0\t ACC test:  0.98\n",
      "\tEpoch 385: \tAverage Loss:  1.450587646484375\t ACC train:  0.9971428571428571\t ACC test:  0.9733333333333334\n",
      "\tEpoch 386: \tAverage Loss:  1.4486923828125\t ACC train:  0.9971428571428571\t ACC test:  0.9733333333333334\n",
      "\tEpoch 387: \tAverage Loss:  1.448160400390625\t ACC train:  0.9971428571428571\t ACC test:  0.9733333333333334\n",
      "\tEpoch 388: \tAverage Loss:  1.4465054931640624\t ACC train:  0.9971428571428571\t ACC test:  0.9666666666666667\n",
      "\tEpoch 389: \tAverage Loss:  1.4450438232421876\t ACC train:  0.9971428571428571\t ACC test:  0.9666666666666667\n",
      "\tEpoch 390: \tAverage Loss:  1.443802734375\t ACC train:  1.0\t ACC test:  0.9733333333333334\n",
      "\tEpoch 391: \tAverage Loss:  1.4411334228515624\t ACC train:  0.9942857142857143\t ACC test:  0.98\n",
      "\tEpoch 392: \tAverage Loss:  1.4403624267578126\t ACC train:  0.9971428571428571\t ACC test:  0.96\n",
      "\tEpoch 393: \tAverage Loss:  1.43865966796875\t ACC train:  0.9971428571428571\t ACC test:  0.9666666666666667\n",
      "\tEpoch 394: \tAverage Loss:  1.4368052978515624\t ACC train:  0.9971428571428571\t ACC test:  0.98\n",
      "\tEpoch 395: \tAverage Loss:  1.4355052490234375\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 396: \tAverage Loss:  1.433732421875\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 397: \tAverage Loss:  1.4324593505859375\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 398: \tAverage Loss:  1.430434326171875\t ACC train:  0.9971428571428571\t ACC test:  0.96\n",
      "\tEpoch 399: \tAverage Loss:  1.42939453125\t ACC train:  0.9971428571428571\t ACC test:  0.9666666666666667\n",
      "\tEpoch 400: \tAverage Loss:  1.4272855224609375\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 401: \tAverage Loss:  1.425751953125\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 402: \tAverage Loss:  1.4244638671875\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 403: \tAverage Loss:  1.4219046630859375\t ACC train:  0.9971428571428571\t ACC test:  0.96\n",
      "\tEpoch 404: \tAverage Loss:  1.4205421142578125\t ACC train:  0.9971428571428571\t ACC test:  0.9666666666666667\n",
      "\tEpoch 405: \tAverage Loss:  1.418885498046875\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 406: \tAverage Loss:  1.41694970703125\t ACC train:  0.9971428571428571\t ACC test:  0.9666666666666667\n",
      "\tEpoch 407: \tAverage Loss:  1.4149854736328125\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 408: \tAverage Loss:  1.4136746826171875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 409: \tAverage Loss:  1.4118048095703124\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 410: \tAverage Loss:  1.4102677001953126\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 411: \tAverage Loss:  1.4082293701171875\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 412: \tAverage Loss:  1.4063685302734374\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 413: \tAverage Loss:  1.4043001708984375\t ACC train:  0.9971428571428571\t ACC test:  0.96\n",
      "\tEpoch 414: \tAverage Loss:  1.4028775634765625\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 415: \tAverage Loss:  1.4005960693359376\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 416: \tAverage Loss:  1.3993565673828126\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 417: \tAverage Loss:  1.3974891357421875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 418: \tAverage Loss:  1.3954769287109374\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 419: \tAverage Loss:  1.393393798828125\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 420: \tAverage Loss:  1.392984375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 421: \tAverage Loss:  1.3901114501953125\t ACC train:  0.9971428571428571\t ACC test:  0.9533333333333334\n",
      "\tEpoch 422: \tAverage Loss:  1.3889930419921874\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 423: \tAverage Loss:  1.3864820556640625\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 424: \tAverage Loss:  1.38563330078125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 425: \tAverage Loss:  1.384419921875\t ACC train:  0.9971428571428571\t ACC test:  0.96\n",
      "\tEpoch 426: \tAverage Loss:  1.382135498046875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 427: \tAverage Loss:  1.3802642822265625\t ACC train:  0.9971428571428571\t ACC test:  0.96\n",
      "\tEpoch 428: \tAverage Loss:  1.3786309814453126\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 429: \tAverage Loss:  1.3770482177734376\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 430: \tAverage Loss:  1.37550732421875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 431: \tAverage Loss:  1.3733382568359376\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 432: \tAverage Loss:  1.3722049560546874\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 433: \tAverage Loss:  1.370352294921875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 434: \tAverage Loss:  1.3688270263671876\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 435: \tAverage Loss:  1.367105224609375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 436: \tAverage Loss:  1.3657081298828124\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 437: \tAverage Loss:  1.3643585205078126\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 438: \tAverage Loss:  1.3623167724609375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 439: \tAverage Loss:  1.360953857421875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 440: \tAverage Loss:  1.3595318603515625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 441: \tAverage Loss:  1.358775634765625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 442: \tAverage Loss:  1.3566287841796876\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 443: \tAverage Loss:  1.355685791015625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 444: \tAverage Loss:  1.3542442626953124\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 445: \tAverage Loss:  1.3526865234375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 446: \tAverage Loss:  1.351333740234375\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 447: \tAverage Loss:  1.3504976806640625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 448: \tAverage Loss:  1.348756103515625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 449: \tAverage Loss:  1.3474791259765626\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 450: \tAverage Loss:  1.3460584716796875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 451: \tAverage Loss:  1.3451478271484374\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 452: \tAverage Loss:  1.343790283203125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 453: \tAverage Loss:  1.34252685546875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 454: \tAverage Loss:  1.3415159912109376\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 455: \tAverage Loss:  1.34024951171875\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 456: \tAverage Loss:  1.3386925048828124\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 457: \tAverage Loss:  1.3379468994140624\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 458: \tAverage Loss:  1.33629345703125\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 459: \tAverage Loss:  1.33530908203125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 460: \tAverage Loss:  1.33428271484375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 461: \tAverage Loss:  1.33304052734375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 462: \tAverage Loss:  1.3317161865234375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 463: \tAverage Loss:  1.3309853515625\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 464: \tAverage Loss:  1.3297015380859376\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 465: \tAverage Loss:  1.3290460205078125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 466: \tAverage Loss:  1.3274486083984376\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 467: \tAverage Loss:  1.3275322265625\t ACC train:  0.9971428571428571\t ACC test:  0.94\n",
      "\tEpoch 468: \tAverage Loss:  1.3256658935546874\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 469: \tAverage Loss:  1.324648681640625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 470: \tAverage Loss:  1.324071533203125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 471: \tAverage Loss:  1.3229129638671875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 472: \tAverage Loss:  1.32168505859375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 473: \tAverage Loss:  1.3217550048828124\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 474: \tAverage Loss:  1.3199559326171875\t ACC train:  0.9971428571428571\t ACC test:  0.9533333333333334\n",
      "\tEpoch 475: \tAverage Loss:  1.3192734375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 476: \tAverage Loss:  1.3186439208984375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 477: \tAverage Loss:  1.3168028564453125\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 478: \tAverage Loss:  1.31681298828125\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 479: \tAverage Loss:  1.3157987060546874\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 480: \tAverage Loss:  1.3152655029296876\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 481: \tAverage Loss:  1.314393310546875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 482: \tAverage Loss:  1.3131851806640624\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 483: \tAverage Loss:  1.3131226806640626\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 484: \tAverage Loss:  1.3118212890625\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 485: \tAverage Loss:  1.3104527587890624\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 486: \tAverage Loss:  1.309471923828125\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 487: \tAverage Loss:  1.30914208984375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 488: \tAverage Loss:  1.3084471435546876\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 489: \tAverage Loss:  1.307909423828125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 490: \tAverage Loss:  1.3072777099609374\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 491: \tAverage Loss:  1.3061629638671874\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 492: \tAverage Loss:  1.305921630859375\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 493: \tAverage Loss:  1.30527978515625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 494: \tAverage Loss:  1.3048011474609376\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 495: \tAverage Loss:  1.3035960693359374\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 496: \tAverage Loss:  1.3029964599609376\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 497: \tAverage Loss:  1.3027630615234376\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 498: \tAverage Loss:  1.301505859375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 499: \tAverage Loss:  1.3012822265625\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 500: \tAverage Loss:  1.3004727783203125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 501: \tAverage Loss:  1.2996461181640624\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 502: \tAverage Loss:  1.2988441162109374\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 503: \tAverage Loss:  1.2988714599609374\t ACC train:  1.0\t ACC test:  0.9333333333333333\n",
      "\tEpoch 504: \tAverage Loss:  1.297655517578125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 505: \tAverage Loss:  1.2969505615234376\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 506: \tAverage Loss:  1.296550537109375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 507: \tAverage Loss:  1.2960330810546874\t ACC train:  0.9971428571428571\t ACC test:  0.94\n",
      "\tEpoch 508: \tAverage Loss:  1.295870849609375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 509: \tAverage Loss:  1.2948203125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 510: \tAverage Loss:  1.29435693359375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 511: \tAverage Loss:  1.2938408203125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 512: \tAverage Loss:  1.2931839599609376\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 513: \tAverage Loss:  1.2922296142578125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 514: \tAverage Loss:  1.29185888671875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 515: \tAverage Loss:  1.291685791015625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 516: \tAverage Loss:  1.29132763671875\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 517: \tAverage Loss:  1.290208984375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 518: \tAverage Loss:  1.2895079345703124\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 519: \tAverage Loss:  1.289164306640625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 520: \tAverage Loss:  1.288468994140625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 521: \tAverage Loss:  1.28824462890625\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 522: \tAverage Loss:  1.2874854736328125\t ACC train:  0.9971428571428571\t ACC test:  0.9533333333333334\n",
      "\tEpoch 523: \tAverage Loss:  1.2878134765625\t ACC train:  0.9971428571428571\t ACC test:  0.9466666666666667\n",
      "\tEpoch 524: \tAverage Loss:  1.2872052001953125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 525: \tAverage Loss:  1.28669140625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 526: \tAverage Loss:  1.2864007568359375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 527: \tAverage Loss:  1.28569580078125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 528: \tAverage Loss:  1.284849365234375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 529: \tAverage Loss:  1.28416064453125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 530: \tAverage Loss:  1.2841934814453124\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 531: \tAverage Loss:  1.2840665283203125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 532: \tAverage Loss:  1.2835653076171876\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 533: \tAverage Loss:  1.2826412353515626\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 534: \tAverage Loss:  1.2826021728515624\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 535: \tAverage Loss:  1.282162109375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 536: \tAverage Loss:  1.28171875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 537: \tAverage Loss:  1.281404541015625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 538: \tAverage Loss:  1.2808128662109375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 539: \tAverage Loss:  1.2811102294921874\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 540: \tAverage Loss:  1.2801236572265624\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 541: \tAverage Loss:  1.279419189453125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 542: \tAverage Loss:  1.27970947265625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 543: \tAverage Loss:  1.2790506591796875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 544: \tAverage Loss:  1.2785941162109375\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 545: \tAverage Loss:  1.2781453857421874\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 546: \tAverage Loss:  1.2784676513671875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 547: \tAverage Loss:  1.277572509765625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 548: \tAverage Loss:  1.2772752685546875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 549: \tAverage Loss:  1.276916015625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 550: \tAverage Loss:  1.2763082275390625\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 551: \tAverage Loss:  1.2761783447265624\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 552: \tAverage Loss:  1.2755836181640625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 553: \tAverage Loss:  1.2756622314453125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 554: \tAverage Loss:  1.2750472412109375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 555: \tAverage Loss:  1.2747176513671874\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 556: \tAverage Loss:  1.2747197265625\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 557: \tAverage Loss:  1.274382080078125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 558: \tAverage Loss:  1.2735418701171874\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 559: \tAverage Loss:  1.2732845458984374\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 560: \tAverage Loss:  1.273300537109375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 561: \tAverage Loss:  1.2730118408203126\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 562: \tAverage Loss:  1.272384765625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 563: \tAverage Loss:  1.2726715087890625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 564: \tAverage Loss:  1.27278759765625\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 565: \tAverage Loss:  1.2715784912109376\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 566: \tAverage Loss:  1.2715543212890625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 567: \tAverage Loss:  1.271538818359375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 568: \tAverage Loss:  1.270981201171875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 569: \tAverage Loss:  1.2706578369140624\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 570: \tAverage Loss:  1.2703948974609376\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 571: \tAverage Loss:  1.27004296875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 572: \tAverage Loss:  1.2696981201171875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 573: \tAverage Loss:  1.26976806640625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 574: \tAverage Loss:  1.2695279541015625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 575: \tAverage Loss:  1.2685675048828124\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 576: \tAverage Loss:  1.2687314453125\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 577: \tAverage Loss:  1.2685560302734376\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 578: \tAverage Loss:  1.2677015380859376\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 579: \tAverage Loss:  1.26783056640625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 580: \tAverage Loss:  1.26736767578125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 581: \tAverage Loss:  1.267514404296875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 582: \tAverage Loss:  1.266971923828125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 583: \tAverage Loss:  1.2666121826171874\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 584: \tAverage Loss:  1.266734375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 585: \tAverage Loss:  1.265852783203125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 586: \tAverage Loss:  1.2661597900390624\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 587: \tAverage Loss:  1.26591162109375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 588: \tAverage Loss:  1.2650693359375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 589: \tAverage Loss:  1.265080078125\t ACC train:  1.0\t ACC test:  0.94\n",
      "\tEpoch 590: \tAverage Loss:  1.265058349609375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 591: \tAverage Loss:  1.2648702392578124\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 592: \tAverage Loss:  1.2643236083984375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 593: \tAverage Loss:  1.2641871337890624\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 594: \tAverage Loss:  1.2638358154296876\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 595: \tAverage Loss:  1.2638372802734374\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 596: \tAverage Loss:  1.2632027587890624\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 597: \tAverage Loss:  1.2631031494140625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 598: \tAverage Loss:  1.2631319580078124\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 599: \tAverage Loss:  1.262670654296875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 600: \tAverage Loss:  1.2628980712890625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 601: \tAverage Loss:  1.2622000732421874\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 602: \tAverage Loss:  1.2617532958984374\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 603: \tAverage Loss:  1.2619049072265625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 604: \tAverage Loss:  1.2617369384765624\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 605: \tAverage Loss:  1.26105908203125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 606: \tAverage Loss:  1.2609306640625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 607: \tAverage Loss:  1.260920654296875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 608: \tAverage Loss:  1.2607547607421874\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 609: \tAverage Loss:  1.2605892333984374\t ACC train:  0.9971428571428571\t ACC test:  0.9466666666666667\n",
      "\tEpoch 610: \tAverage Loss:  1.2603515625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 611: \tAverage Loss:  1.2601171875\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 612: \tAverage Loss:  1.2604091796875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 613: \tAverage Loss:  1.25959814453125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 614: \tAverage Loss:  1.2596375732421874\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 615: \tAverage Loss:  1.2589949951171875\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 616: \tAverage Loss:  1.2591121826171876\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 617: \tAverage Loss:  1.2587802734375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 618: \tAverage Loss:  1.258676513671875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 619: \tAverage Loss:  1.258064208984375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 620: \tAverage Loss:  1.2584677734375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 621: \tAverage Loss:  1.2581802978515626\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 622: \tAverage Loss:  1.2575823974609375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 623: \tAverage Loss:  1.25719482421875\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 624: \tAverage Loss:  1.2576549072265626\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 625: \tAverage Loss:  1.2568414306640625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 626: \tAverage Loss:  1.25682177734375\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 627: \tAverage Loss:  1.2566070556640625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 628: \tAverage Loss:  1.2569156494140625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 629: \tAverage Loss:  1.2562315673828126\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 630: \tAverage Loss:  1.25628662109375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 631: \tAverage Loss:  1.2559388427734375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 632: \tAverage Loss:  1.25564306640625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 633: \tAverage Loss:  1.2557501220703124\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 634: \tAverage Loss:  1.2555728759765625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 635: \tAverage Loss:  1.2555255126953124\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 636: \tAverage Loss:  1.2548450927734376\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 637: \tAverage Loss:  1.254802978515625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 638: \tAverage Loss:  1.254728515625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 639: \tAverage Loss:  1.254560546875\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 640: \tAverage Loss:  1.254236083984375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 641: \tAverage Loss:  1.2537318115234375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 642: \tAverage Loss:  1.254033447265625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 643: \tAverage Loss:  1.2534544677734376\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 644: \tAverage Loss:  1.2536129150390625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 645: \tAverage Loss:  1.2530770263671875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 646: \tAverage Loss:  1.2529925537109374\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 647: \tAverage Loss:  1.2531300048828125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 648: \tAverage Loss:  1.2527982177734376\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 649: \tAverage Loss:  1.252577392578125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 650: \tAverage Loss:  1.252525390625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 651: \tAverage Loss:  1.252326416015625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 652: \tAverage Loss:  1.2520758056640624\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 653: \tAverage Loss:  1.2518072509765625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 654: \tAverage Loss:  1.251502685546875\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 655: \tAverage Loss:  1.25141552734375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 656: \tAverage Loss:  1.2512886962890626\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 657: \tAverage Loss:  1.2512264404296876\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 658: \tAverage Loss:  1.250794921875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 659: \tAverage Loss:  1.25059033203125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 660: \tAverage Loss:  1.2504678955078126\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 661: \tAverage Loss:  1.250383056640625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 662: \tAverage Loss:  1.25032177734375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 663: \tAverage Loss:  1.250389892578125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 664: \tAverage Loss:  1.249836181640625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 665: \tAverage Loss:  1.249809326171875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 666: \tAverage Loss:  1.249631591796875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 667: \tAverage Loss:  1.24949072265625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 668: \tAverage Loss:  1.249502685546875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 669: \tAverage Loss:  1.248734375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 670: \tAverage Loss:  1.2484720458984375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 671: \tAverage Loss:  1.2488997802734374\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 672: \tAverage Loss:  1.248402099609375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 673: \tAverage Loss:  1.2482879638671875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 674: \tAverage Loss:  1.248016357421875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 675: \tAverage Loss:  1.24789453125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 676: \tAverage Loss:  1.2477607421875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 677: \tAverage Loss:  1.248037353515625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 678: \tAverage Loss:  1.2478988037109375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 679: \tAverage Loss:  1.247696044921875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 680: \tAverage Loss:  1.2475518798828125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 681: \tAverage Loss:  1.2473099365234375\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 682: \tAverage Loss:  1.24741259765625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 683: \tAverage Loss:  1.2467886962890624\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 684: \tAverage Loss:  1.2474603271484375\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 685: \tAverage Loss:  1.2466439208984375\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 686: \tAverage Loss:  1.2466531982421876\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 687: \tAverage Loss:  1.2466971435546874\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 688: \tAverage Loss:  1.2461026611328125\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 689: \tAverage Loss:  1.24651025390625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 690: \tAverage Loss:  1.2457235107421876\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 691: \tAverage Loss:  1.2456680908203126\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 692: \tAverage Loss:  1.2455555419921875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 693: \tAverage Loss:  1.245170654296875\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 694: \tAverage Loss:  1.2455987548828125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 695: \tAverage Loss:  1.245177490234375\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 696: \tAverage Loss:  1.244753662109375\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 697: \tAverage Loss:  1.2449444580078124\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 698: \tAverage Loss:  1.244517822265625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 699: \tAverage Loss:  1.24465234375\t ACC train:  1.0\t ACC test:  0.9666666666666667\n",
      "\tEpoch 700: \tAverage Loss:  1.2446177978515625\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 701: \tAverage Loss:  1.244094482421875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 702: \tAverage Loss:  1.2441014404296875\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 703: \tAverage Loss:  1.243912841796875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 704: \tAverage Loss:  1.2437552490234376\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 705: \tAverage Loss:  1.2438577880859376\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 706: \tAverage Loss:  1.2436787109375\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 707: \tAverage Loss:  1.2435933837890625\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 708: \tAverage Loss:  1.2430968017578126\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 709: \tAverage Loss:  1.24288232421875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 710: \tAverage Loss:  1.242899658203125\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 711: \tAverage Loss:  1.24273046875\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 712: \tAverage Loss:  1.242491455078125\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 713: \tAverage Loss:  1.2421654052734374\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 714: \tAverage Loss:  1.2427767333984374\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 715: \tAverage Loss:  1.242403564453125\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 716: \tAverage Loss:  1.242566650390625\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 717: \tAverage Loss:  1.2420662841796875\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "\tEpoch 718: \tAverage Loss:  1.2421085205078124\t ACC train:  1.0\t ACC test:  0.9533333333333334\n",
      "\tEpoch 719: \tAverage Loss:  1.2417947998046874\t ACC train:  1.0\t ACC test:  0.96\n",
      "\tEpoch 720: \tAverage Loss:  1.2416014404296876\t ACC train:  1.0\t ACC test:  0.9466666666666667\n",
      "Stopping early at epoch 720. No improvement in validation loss for 20 epochs.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training for sample size: {train_size}\")\n",
    "\n",
    "# Train VAE Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VAE(input_dim=yn_train.shape[-1],\n",
    "            hidden_dim=30,\n",
    "            latent_dim=10,\n",
    "            num_classes=len(np.unique(labels_train))).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model.fit(x=yn_train, y=labels_train, x_test=yn_test, y_test=labels_test, optimizer=optimizer, epochs=2000, batch_size=500, patience=20)\n",
    "x_hat, y_hat, mean, log_var, metrics = model.evaluate(yn_test, labels_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T10:15:09.225649300Z",
     "start_time": "2024-02-21T10:14:53.799330500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "x_train_hat, y_hat, mean_train, log_var_train, metrics = model.evaluate(yn_train, labels_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T10:20:41.217726700Z",
     "start_time": "2024-02-21T10:20:41.091879600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1600x800 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(16, 8))\n",
    "l1=0\n",
    "l2=1\n",
    "plot_scatter_gplvm(mean_train, labels_train, l1=l1, l2=l2, ax=axs[0], colors=['r', 'b', 'g'], show_errorbars=False, std=None)\n",
    "plot_scatter_gplvm(mean, labels_test, l1=l1, l2=l2, ax=axs[1], colors=['r', 'b', 'g'], show_errorbars=False, std=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T10:21:19.707535100Z",
     "start_time": "2024-02-21T10:21:19.270466200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
